id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/scverse/scanpy/issues/1259:319,testability,log,lognormalize,319,"HI everyone, . I have the excat same issue, which prevents me from performing further analysis. . What I did : . - dropna(), still boolean values, which poses the same error again (boolean values are NANs appearently). - fillna(0) : replaced all NAN values with 0, but this poses a problem later in the analysis when i lognormalize the data (log(0) = inf). How do you guys deal with these sorts of problems with your data ? . I don't think the mt colum should contain boolean values... (cf. screeshot). Please correct me if i am wrong, and thank you in advance for your help. ![Screenshot from 2021-12-13 17-17-56](https://user-images.githubusercontent.com/45742503/145848639-6d7c6ee6-a38f-4c48-b38a-c8339984e360.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:342,testability,log,log,342,"HI everyone, . I have the excat same issue, which prevents me from performing further analysis. . What I did : . - dropna(), still boolean values, which poses the same error again (boolean values are NANs appearently). - fillna(0) : replaced all NAN values with 0, but this poses a problem later in the analysis when i lognormalize the data (log(0) = inf). How do you guys deal with these sorts of problems with your data ? . I don't think the mt colum should contain boolean values... (cf. screeshot). Please correct me if i am wrong, and thank you in advance for your help. ![Screenshot from 2021-12-13 17-17-56](https://user-images.githubusercontent.com/45742503/145848639-6d7c6ee6-a38f-4c48-b38a-c8339984e360.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:67,usability,perform,performing,67,"HI everyone, . I have the excat same issue, which prevents me from performing further analysis. . What I did : . - dropna(), still boolean values, which poses the same error again (boolean values are NANs appearently). - fillna(0) : replaced all NAN values with 0, but this poses a problem later in the analysis when i lognormalize the data (log(0) = inf). How do you guys deal with these sorts of problems with your data ? . I don't think the mt colum should contain boolean values... (cf. screeshot). Please correct me if i am wrong, and thank you in advance for your help. ![Screenshot from 2021-12-13 17-17-56](https://user-images.githubusercontent.com/45742503/145848639-6d7c6ee6-a38f-4c48-b38a-c8339984e360.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:168,usability,error,error,168,"HI everyone, . I have the excat same issue, which prevents me from performing further analysis. . What I did : . - dropna(), still boolean values, which poses the same error again (boolean values are NANs appearently). - fillna(0) : replaced all NAN values with 0, but this poses a problem later in the analysis when i lognormalize the data (log(0) = inf). How do you guys deal with these sorts of problems with your data ? . I don't think the mt colum should contain boolean values... (cf. screeshot). Please correct me if i am wrong, and thank you in advance for your help. ![Screenshot from 2021-12-13 17-17-56](https://user-images.githubusercontent.com/45742503/145848639-6d7c6ee6-a38f-4c48-b38a-c8339984e360.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:570,usability,help,help,570,"HI everyone, . I have the excat same issue, which prevents me from performing further analysis. . What I did : . - dropna(), still boolean values, which poses the same error again (boolean values are NANs appearently). - fillna(0) : replaced all NAN values with 0, but this poses a problem later in the analysis when i lognormalize the data (log(0) = inf). How do you guys deal with these sorts of problems with your data ? . I don't think the mt colum should contain boolean values... (cf. screeshot). Please correct me if i am wrong, and thank you in advance for your help. ![Screenshot from 2021-12-13 17-17-56](https://user-images.githubusercontent.com/45742503/145848639-6d7c6ee6-a38f-4c48-b38a-c8339984e360.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:623,usability,user,user-images,623,"HI everyone, . I have the excat same issue, which prevents me from performing further analysis. . What I did : . - dropna(), still boolean values, which poses the same error again (boolean values are NANs appearently). - fillna(0) : replaced all NAN values with 0, but this poses a problem later in the analysis when i lognormalize the data (log(0) = inf). How do you guys deal with these sorts of problems with your data ? . I don't think the mt colum should contain boolean values... (cf. screeshot). Please correct me if i am wrong, and thank you in advance for your help. ![Screenshot from 2021-12-13 17-17-56](https://user-images.githubusercontent.com/45742503/145848639-6d7c6ee6-a38f-4c48-b38a-c8339984e360.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:391,usability,user,user-images,391,"The problem is Drosophila gtf has a gene with gene_name as 'nan'. ```. 3L FlyBase CDS 14187463 14187689 . - 2 gene_id ""FBgn0036414""; transcript_id ""FBtr0089524""; exon_number ""5""; gene_name ""nan""; gene_source ""FlyBase""; gene_biotype ""protein_coding""; transcript_name ""nan-RA""; transcript_source ""FlyBase""; transcript_biotype ""protein_coding""; protein_id ""FBpp0088509"";. ```. ![image](https://user-images.githubusercontent.com/30204951/213412902-70b1eedb-50ca-458d-b68d-c589a5252a11.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1260:104,deployability,Version,Versions,104,"Hello, I am running into exactly the same bug when using both **scanpy-1.5.1** or **scanpy-1.5.0**. . **Versions**: . scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.3.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 leidenalg==0.8.0. **Input**: . `import time. t0 = time.time(). sc.external.exporting.spring_project(adata, './SPRING',. 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],. custom_color_tracks=['total_counts']). print(time.time() - t0)`. **Output**: . `WARNING: root:Overwriting the files in SPRING. Writing subplot to SPRING\all. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). <ipython-input-59-9c683583ff59> in <module>. 1 import time. 2 t0 = time.time(). ----> 3 sc.external.exporting.spring_project(adata, './SPRING',. 4 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],. 5 custom_color_tracks=['total_counts']). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in spring_project(adata, project_dir, embedding_method, subplot_name, cell_groupings, custom_color_tracks, total_counts_key, neighbors_key, overwrite). 179 . 180 # Write graph in two formats for backwards compatibility. --> 181 edges = _get_edges(adata, neighbors_key). 182 _write_graph(subplot_dir / 'graph_data.json', E.shape[0], edges). 183 _write_edges(subplot_dir / 'edges.csv', edges). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in _get_edges(adata, neighbors_key). 217 . 218 def _get_edges(adata, neighbors_key=None):. --> 219 neighbors = NeighborsView(adata, neighbors_key). 220 if 'distances' in neighbors: # these are sparse matrices. 221 matrix = neighbors['distances']. NameError: name 'NeighborsView' is not defined`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1260
https://github.com/scverse/scanpy/issues/1260:770,deployability,modul,module,770,"Hello, I am running into exactly the same bug when using both **scanpy-1.5.1** or **scanpy-1.5.0**. . **Versions**: . scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.3.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 leidenalg==0.8.0. **Input**: . `import time. t0 = time.time(). sc.external.exporting.spring_project(adata, './SPRING',. 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],. custom_color_tracks=['total_counts']). print(time.time() - t0)`. **Output**: . `WARNING: root:Overwriting the files in SPRING. Writing subplot to SPRING\all. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). <ipython-input-59-9c683583ff59> in <module>. 1 import time. 2 t0 = time.time(). ----> 3 sc.external.exporting.spring_project(adata, './SPRING',. 4 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],. 5 custom_color_tracks=['total_counts']). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in spring_project(adata, project_dir, embedding_method, subplot_name, cell_groupings, custom_color_tracks, total_counts_key, neighbors_key, overwrite). 179 . 180 # Write graph in two formats for backwards compatibility. --> 181 edges = _get_edges(adata, neighbors_key). 182 _write_graph(subplot_dir / 'graph_data.json', E.shape[0], edges). 183 _write_edges(subplot_dir / 'edges.csv', edges). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in _get_edges(adata, neighbors_key). 217 . 218 def _get_edges(adata, neighbors_key=None):. --> 219 neighbors = NeighborsView(adata, neighbors_key). 220 if 'distances' in neighbors: # these are sparse matrices. 221 matrix = neighbors['distances']. NameError: name 'NeighborsView' is not defined`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1260
https://github.com/scverse/scanpy/issues/1260:104,integrability,Version,Versions,104,"Hello, I am running into exactly the same bug when using both **scanpy-1.5.1** or **scanpy-1.5.0**. . **Versions**: . scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.3.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 leidenalg==0.8.0. **Input**: . `import time. t0 = time.time(). sc.external.exporting.spring_project(adata, './SPRING',. 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],. custom_color_tracks=['total_counts']). print(time.time() - t0)`. **Output**: . `WARNING: root:Overwriting the files in SPRING. Writing subplot to SPRING\all. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). <ipython-input-59-9c683583ff59> in <module>. 1 import time. 2 t0 = time.time(). ----> 3 sc.external.exporting.spring_project(adata, './SPRING',. 4 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],. 5 custom_color_tracks=['total_counts']). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in spring_project(adata, project_dir, embedding_method, subplot_name, cell_groupings, custom_color_tracks, total_counts_key, neighbors_key, overwrite). 179 . 180 # Write graph in two formats for backwards compatibility. --> 181 edges = _get_edges(adata, neighbors_key). 182 _write_graph(subplot_dir / 'graph_data.json', E.shape[0], edges). 183 _write_edges(subplot_dir / 'edges.csv', edges). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in _get_edges(adata, neighbors_key). 217 . 218 def _get_edges(adata, neighbors_key=None):. --> 219 neighbors = NeighborsView(adata, neighbors_key). 220 if 'distances' in neighbors: # these are sparse matrices. 221 matrix = neighbors['distances']. NameError: name 'NeighborsView' is not defined`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1260
https://github.com/scverse/scanpy/issues/1260:589,integrability,sub,subplot,589,"Hello, I am running into exactly the same bug when using both **scanpy-1.5.1** or **scanpy-1.5.0**. . **Versions**: . scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.3.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 leidenalg==0.8.0. **Input**: . `import time. t0 = time.time(). sc.external.exporting.spring_project(adata, './SPRING',. 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],. custom_color_tracks=['total_counts']). print(time.time() - t0)`. **Output**: . `WARNING: root:Overwriting the files in SPRING. Writing subplot to SPRING\all. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). <ipython-input-59-9c683583ff59> in <module>. 1 import time. 2 t0 = time.time(). ----> 3 sc.external.exporting.spring_project(adata, './SPRING',. 4 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],. 5 custom_color_tracks=['total_counts']). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in spring_project(adata, project_dir, embedding_method, subplot_name, cell_groupings, custom_color_tracks, total_counts_key, neighbors_key, overwrite). 179 . 180 # Write graph in two formats for backwards compatibility. --> 181 edges = _get_edges(adata, neighbors_key). 182 _write_graph(subplot_dir / 'graph_data.json', E.shape[0], edges). 183 _write_edges(subplot_dir / 'edges.csv', edges). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in _get_edges(adata, neighbors_key). 217 . 218 def _get_edges(adata, neighbors_key=None):. --> 219 neighbors = NeighborsView(adata, neighbors_key). 220 if 'distances' in neighbors: # these are sparse matrices. 221 matrix = neighbors['distances']. NameError: name 'NeighborsView' is not defined`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1260
https://github.com/scverse/scanpy/issues/1260:1254,interoperability,format,formats,1254,"Hello, I am running into exactly the same bug when using both **scanpy-1.5.1** or **scanpy-1.5.0**. . **Versions**: . scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.3.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 leidenalg==0.8.0. **Input**: . `import time. t0 = time.time(). sc.external.exporting.spring_project(adata, './SPRING',. 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],. custom_color_tracks=['total_counts']). print(time.time() - t0)`. **Output**: . `WARNING: root:Overwriting the files in SPRING. Writing subplot to SPRING\all. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). <ipython-input-59-9c683583ff59> in <module>. 1 import time. 2 t0 = time.time(). ----> 3 sc.external.exporting.spring_project(adata, './SPRING',. 4 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],. 5 custom_color_tracks=['total_counts']). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in spring_project(adata, project_dir, embedding_method, subplot_name, cell_groupings, custom_color_tracks, total_counts_key, neighbors_key, overwrite). 179 . 180 # Write graph in two formats for backwards compatibility. --> 181 edges = _get_edges(adata, neighbors_key). 182 _write_graph(subplot_dir / 'graph_data.json', E.shape[0], edges). 183 _write_edges(subplot_dir / 'edges.csv', edges). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in _get_edges(adata, neighbors_key). 217 . 218 def _get_edges(adata, neighbors_key=None):. --> 219 neighbors = NeighborsView(adata, neighbors_key). 220 if 'distances' in neighbors: # these are sparse matrices. 221 matrix = neighbors['distances']. NameError: name 'NeighborsView' is not defined`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1260
https://github.com/scverse/scanpy/issues/1260:1276,interoperability,compatib,compatibility,1276,"Hello, I am running into exactly the same bug when using both **scanpy-1.5.1** or **scanpy-1.5.0**. . **Versions**: . scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.3.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 leidenalg==0.8.0. **Input**: . `import time. t0 = time.time(). sc.external.exporting.spring_project(adata, './SPRING',. 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],. custom_color_tracks=['total_counts']). print(time.time() - t0)`. **Output**: . `WARNING: root:Overwriting the files in SPRING. Writing subplot to SPRING\all. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). <ipython-input-59-9c683583ff59> in <module>. 1 import time. 2 t0 = time.time(). ----> 3 sc.external.exporting.spring_project(adata, './SPRING',. 4 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],. 5 custom_color_tracks=['total_counts']). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in spring_project(adata, project_dir, embedding_method, subplot_name, cell_groupings, custom_color_tracks, total_counts_key, neighbors_key, overwrite). 179 . 180 # Write graph in two formats for backwards compatibility. --> 181 edges = _get_edges(adata, neighbors_key). 182 _write_graph(subplot_dir / 'graph_data.json', E.shape[0], edges). 183 _write_edges(subplot_dir / 'edges.csv', edges). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in _get_edges(adata, neighbors_key). 217 . 218 def _get_edges(adata, neighbors_key=None):. --> 219 neighbors = NeighborsView(adata, neighbors_key). 220 if 'distances' in neighbors: # these are sparse matrices. 221 matrix = neighbors['distances']. NameError: name 'NeighborsView' is not defined`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1260
https://github.com/scverse/scanpy/issues/1260:104,modifiability,Version,Versions,104,"Hello, I am running into exactly the same bug when using both **scanpy-1.5.1** or **scanpy-1.5.0**. . **Versions**: . scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.3.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 leidenalg==0.8.0. **Input**: . `import time. t0 = time.time(). sc.external.exporting.spring_project(adata, './SPRING',. 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],. custom_color_tracks=['total_counts']). print(time.time() - t0)`. **Output**: . `WARNING: root:Overwriting the files in SPRING. Writing subplot to SPRING\all. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). <ipython-input-59-9c683583ff59> in <module>. 1 import time. 2 t0 = time.time(). ----> 3 sc.external.exporting.spring_project(adata, './SPRING',. 4 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],. 5 custom_color_tracks=['total_counts']). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in spring_project(adata, project_dir, embedding_method, subplot_name, cell_groupings, custom_color_tracks, total_counts_key, neighbors_key, overwrite). 179 . 180 # Write graph in two formats for backwards compatibility. --> 181 edges = _get_edges(adata, neighbors_key). 182 _write_graph(subplot_dir / 'graph_data.json', E.shape[0], edges). 183 _write_edges(subplot_dir / 'edges.csv', edges). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in _get_edges(adata, neighbors_key). 217 . 218 def _get_edges(adata, neighbors_key=None):. --> 219 neighbors = NeighborsView(adata, neighbors_key). 220 if 'distances' in neighbors: # these are sparse matrices. 221 matrix = neighbors['distances']. NameError: name 'NeighborsView' is not defined`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1260
https://github.com/scverse/scanpy/issues/1260:770,modifiability,modul,module,770,"Hello, I am running into exactly the same bug when using both **scanpy-1.5.1** or **scanpy-1.5.0**. . **Versions**: . scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.3.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 leidenalg==0.8.0. **Input**: . `import time. t0 = time.time(). sc.external.exporting.spring_project(adata, './SPRING',. 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],. custom_color_tracks=['total_counts']). print(time.time() - t0)`. **Output**: . `WARNING: root:Overwriting the files in SPRING. Writing subplot to SPRING\all. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). <ipython-input-59-9c683583ff59> in <module>. 1 import time. 2 t0 = time.time(). ----> 3 sc.external.exporting.spring_project(adata, './SPRING',. 4 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],. 5 custom_color_tracks=['total_counts']). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in spring_project(adata, project_dir, embedding_method, subplot_name, cell_groupings, custom_color_tracks, total_counts_key, neighbors_key, overwrite). 179 . 180 # Write graph in two formats for backwards compatibility. --> 181 edges = _get_edges(adata, neighbors_key). 182 _write_graph(subplot_dir / 'graph_data.json', E.shape[0], edges). 183 _write_edges(subplot_dir / 'edges.csv', edges). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in _get_edges(adata, neighbors_key). 217 . 218 def _get_edges(adata, neighbors_key=None):. --> 219 neighbors = NeighborsView(adata, neighbors_key). 220 if 'distances' in neighbors: # these are sparse matrices. 221 matrix = neighbors['distances']. NameError: name 'NeighborsView' is not defined`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1260
https://github.com/scverse/scanpy/issues/1260:1033,modifiability,pac,packages,1033,"Hello, I am running into exactly the same bug when using both **scanpy-1.5.1** or **scanpy-1.5.0**. . **Versions**: . scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.3.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 leidenalg==0.8.0. **Input**: . `import time. t0 = time.time(). sc.external.exporting.spring_project(adata, './SPRING',. 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],. custom_color_tracks=['total_counts']). print(time.time() - t0)`. **Output**: . `WARNING: root:Overwriting the files in SPRING. Writing subplot to SPRING\all. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). <ipython-input-59-9c683583ff59> in <module>. 1 import time. 2 t0 = time.time(). ----> 3 sc.external.exporting.spring_project(adata, './SPRING',. 4 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],. 5 custom_color_tracks=['total_counts']). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in spring_project(adata, project_dir, embedding_method, subplot_name, cell_groupings, custom_color_tracks, total_counts_key, neighbors_key, overwrite). 179 . 180 # Write graph in two formats for backwards compatibility. --> 181 edges = _get_edges(adata, neighbors_key). 182 _write_graph(subplot_dir / 'graph_data.json', E.shape[0], edges). 183 _write_edges(subplot_dir / 'edges.csv', edges). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in _get_edges(adata, neighbors_key). 217 . 218 def _get_edges(adata, neighbors_key=None):. --> 219 neighbors = NeighborsView(adata, neighbors_key). 220 if 'distances' in neighbors: # these are sparse matrices. 221 matrix = neighbors['distances']. NameError: name 'NeighborsView' is not defined`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1260
https://github.com/scverse/scanpy/issues/1260:1502,modifiability,pac,packages,1502,"Hello, I am running into exactly the same bug when using both **scanpy-1.5.1** or **scanpy-1.5.0**. . **Versions**: . scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.3.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 leidenalg==0.8.0. **Input**: . `import time. t0 = time.time(). sc.external.exporting.spring_project(adata, './SPRING',. 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],. custom_color_tracks=['total_counts']). print(time.time() - t0)`. **Output**: . `WARNING: root:Overwriting the files in SPRING. Writing subplot to SPRING\all. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). <ipython-input-59-9c683583ff59> in <module>. 1 import time. 2 t0 = time.time(). ----> 3 sc.external.exporting.spring_project(adata, './SPRING',. 4 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],. 5 custom_color_tracks=['total_counts']). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in spring_project(adata, project_dir, embedding_method, subplot_name, cell_groupings, custom_color_tracks, total_counts_key, neighbors_key, overwrite). 179 . 180 # Write graph in two formats for backwards compatibility. --> 181 edges = _get_edges(adata, neighbors_key). 182 _write_graph(subplot_dir / 'graph_data.json', E.shape[0], edges). 183 _write_edges(subplot_dir / 'edges.csv', edges). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in _get_edges(adata, neighbors_key). 217 . 218 def _get_edges(adata, neighbors_key=None):. --> 219 neighbors = NeighborsView(adata, neighbors_key). 220 if 'distances' in neighbors: # these are sparse matrices. 221 matrix = neighbors['distances']. NameError: name 'NeighborsView' is not defined`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1260
https://github.com/scverse/scanpy/issues/1260:301,performance,time,time,301,"Hello, I am running into exactly the same bug when using both **scanpy-1.5.1** or **scanpy-1.5.0**. . **Versions**: . scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.3.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 leidenalg==0.8.0. **Input**: . `import time. t0 = time.time(). sc.external.exporting.spring_project(adata, './SPRING',. 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],. custom_color_tracks=['total_counts']). print(time.time() - t0)`. **Output**: . `WARNING: root:Overwriting the files in SPRING. Writing subplot to SPRING\all. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). <ipython-input-59-9c683583ff59> in <module>. 1 import time. 2 t0 = time.time(). ----> 3 sc.external.exporting.spring_project(adata, './SPRING',. 4 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],. 5 custom_color_tracks=['total_counts']). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in spring_project(adata, project_dir, embedding_method, subplot_name, cell_groupings, custom_color_tracks, total_counts_key, neighbors_key, overwrite). 179 . 180 # Write graph in two formats for backwards compatibility. --> 181 edges = _get_edges(adata, neighbors_key). 182 _write_graph(subplot_dir / 'graph_data.json', E.shape[0], edges). 183 _write_edges(subplot_dir / 'edges.csv', edges). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in _get_edges(adata, neighbors_key). 217 . 218 def _get_edges(adata, neighbors_key=None):. --> 219 neighbors = NeighborsView(adata, neighbors_key). 220 if 'distances' in neighbors: # these are sparse matrices. 221 matrix = neighbors['distances']. NameError: name 'NeighborsView' is not defined`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1260
https://github.com/scverse/scanpy/issues/1260:312,performance,time,time,312,"Hello, I am running into exactly the same bug when using both **scanpy-1.5.1** or **scanpy-1.5.0**. . **Versions**: . scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.3.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 leidenalg==0.8.0. **Input**: . `import time. t0 = time.time(). sc.external.exporting.spring_project(adata, './SPRING',. 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],. custom_color_tracks=['total_counts']). print(time.time() - t0)`. **Output**: . `WARNING: root:Overwriting the files in SPRING. Writing subplot to SPRING\all. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). <ipython-input-59-9c683583ff59> in <module>. 1 import time. 2 t0 = time.time(). ----> 3 sc.external.exporting.spring_project(adata, './SPRING',. 4 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],. 5 custom_color_tracks=['total_counts']). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in spring_project(adata, project_dir, embedding_method, subplot_name, cell_groupings, custom_color_tracks, total_counts_key, neighbors_key, overwrite). 179 . 180 # Write graph in two formats for backwards compatibility. --> 181 edges = _get_edges(adata, neighbors_key). 182 _write_graph(subplot_dir / 'graph_data.json', E.shape[0], edges). 183 _write_edges(subplot_dir / 'edges.csv', edges). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in _get_edges(adata, neighbors_key). 217 . 218 def _get_edges(adata, neighbors_key=None):. --> 219 neighbors = NeighborsView(adata, neighbors_key). 220 if 'distances' in neighbors: # these are sparse matrices. 221 matrix = neighbors['distances']. NameError: name 'NeighborsView' is not defined`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1260
https://github.com/scverse/scanpy/issues/1260:317,performance,time,time,317,"Hello, I am running into exactly the same bug when using both **scanpy-1.5.1** or **scanpy-1.5.0**. . **Versions**: . scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.3.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 leidenalg==0.8.0. **Input**: . `import time. t0 = time.time(). sc.external.exporting.spring_project(adata, './SPRING',. 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],. custom_color_tracks=['total_counts']). print(time.time() - t0)`. **Output**: . `WARNING: root:Overwriting the files in SPRING. Writing subplot to SPRING\all. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). <ipython-input-59-9c683583ff59> in <module>. 1 import time. 2 t0 = time.time(). ----> 3 sc.external.exporting.spring_project(adata, './SPRING',. 4 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],. 5 custom_color_tracks=['total_counts']). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in spring_project(adata, project_dir, embedding_method, subplot_name, cell_groupings, custom_color_tracks, total_counts_key, neighbors_key, overwrite). 179 . 180 # Write graph in two formats for backwards compatibility. --> 181 edges = _get_edges(adata, neighbors_key). 182 _write_graph(subplot_dir / 'graph_data.json', E.shape[0], edges). 183 _write_edges(subplot_dir / 'edges.csv', edges). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in _get_edges(adata, neighbors_key). 217 . 218 def _get_edges(adata, neighbors_key=None):. --> 219 neighbors = NeighborsView(adata, neighbors_key). 220 if 'distances' in neighbors: # these are sparse matrices. 221 matrix = neighbors['distances']. NameError: name 'NeighborsView' is not defined`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1260
https://github.com/scverse/scanpy/issues/1260:499,performance,time,time,499,"Hello, I am running into exactly the same bug when using both **scanpy-1.5.1** or **scanpy-1.5.0**. . **Versions**: . scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.3.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 leidenalg==0.8.0. **Input**: . `import time. t0 = time.time(). sc.external.exporting.spring_project(adata, './SPRING',. 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],. custom_color_tracks=['total_counts']). print(time.time() - t0)`. **Output**: . `WARNING: root:Overwriting the files in SPRING. Writing subplot to SPRING\all. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). <ipython-input-59-9c683583ff59> in <module>. 1 import time. 2 t0 = time.time(). ----> 3 sc.external.exporting.spring_project(adata, './SPRING',. 4 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],. 5 custom_color_tracks=['total_counts']). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in spring_project(adata, project_dir, embedding_method, subplot_name, cell_groupings, custom_color_tracks, total_counts_key, neighbors_key, overwrite). 179 . 180 # Write graph in two formats for backwards compatibility. --> 181 edges = _get_edges(adata, neighbors_key). 182 _write_graph(subplot_dir / 'graph_data.json', E.shape[0], edges). 183 _write_edges(subplot_dir / 'edges.csv', edges). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in _get_edges(adata, neighbors_key). 217 . 218 def _get_edges(adata, neighbors_key=None):. --> 219 neighbors = NeighborsView(adata, neighbors_key). 220 if 'distances' in neighbors: # these are sparse matrices. 221 matrix = neighbors['distances']. NameError: name 'NeighborsView' is not defined`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1260
https://github.com/scverse/scanpy/issues/1260:504,performance,time,time,504,"Hello, I am running into exactly the same bug when using both **scanpy-1.5.1** or **scanpy-1.5.0**. . **Versions**: . scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.3.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 leidenalg==0.8.0. **Input**: . `import time. t0 = time.time(). sc.external.exporting.spring_project(adata, './SPRING',. 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],. custom_color_tracks=['total_counts']). print(time.time() - t0)`. **Output**: . `WARNING: root:Overwriting the files in SPRING. Writing subplot to SPRING\all. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). <ipython-input-59-9c683583ff59> in <module>. 1 import time. 2 t0 = time.time(). ----> 3 sc.external.exporting.spring_project(adata, './SPRING',. 4 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],. 5 custom_color_tracks=['total_counts']). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in spring_project(adata, project_dir, embedding_method, subplot_name, cell_groupings, custom_color_tracks, total_counts_key, neighbors_key, overwrite). 179 . 180 # Write graph in two formats for backwards compatibility. --> 181 edges = _get_edges(adata, neighbors_key). 182 _write_graph(subplot_dir / 'graph_data.json', E.shape[0], edges). 183 _write_edges(subplot_dir / 'edges.csv', edges). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in _get_edges(adata, neighbors_key). 217 . 218 def _get_edges(adata, neighbors_key=None):. --> 219 neighbors = NeighborsView(adata, neighbors_key). 220 if 'distances' in neighbors: # these are sparse matrices. 221 matrix = neighbors['distances']. NameError: name 'NeighborsView' is not defined`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1260
https://github.com/scverse/scanpy/issues/1260:788,performance,time,time,788,"Hello, I am running into exactly the same bug when using both **scanpy-1.5.1** or **scanpy-1.5.0**. . **Versions**: . scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.3.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 leidenalg==0.8.0. **Input**: . `import time. t0 = time.time(). sc.external.exporting.spring_project(adata, './SPRING',. 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],. custom_color_tracks=['total_counts']). print(time.time() - t0)`. **Output**: . `WARNING: root:Overwriting the files in SPRING. Writing subplot to SPRING\all. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). <ipython-input-59-9c683583ff59> in <module>. 1 import time. 2 t0 = time.time(). ----> 3 sc.external.exporting.spring_project(adata, './SPRING',. 4 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],. 5 custom_color_tracks=['total_counts']). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in spring_project(adata, project_dir, embedding_method, subplot_name, cell_groupings, custom_color_tracks, total_counts_key, neighbors_key, overwrite). 179 . 180 # Write graph in two formats for backwards compatibility. --> 181 edges = _get_edges(adata, neighbors_key). 182 _write_graph(subplot_dir / 'graph_data.json', E.shape[0], edges). 183 _write_edges(subplot_dir / 'edges.csv', edges). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in _get_edges(adata, neighbors_key). 217 . 218 def _get_edges(adata, neighbors_key=None):. --> 219 neighbors = NeighborsView(adata, neighbors_key). 220 if 'distances' in neighbors: # these are sparse matrices. 221 matrix = neighbors['distances']. NameError: name 'NeighborsView' is not defined`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1260
https://github.com/scverse/scanpy/issues/1260:801,performance,time,time,801,"Hello, I am running into exactly the same bug when using both **scanpy-1.5.1** or **scanpy-1.5.0**. . **Versions**: . scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.3.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 leidenalg==0.8.0. **Input**: . `import time. t0 = time.time(). sc.external.exporting.spring_project(adata, './SPRING',. 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],. custom_color_tracks=['total_counts']). print(time.time() - t0)`. **Output**: . `WARNING: root:Overwriting the files in SPRING. Writing subplot to SPRING\all. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). <ipython-input-59-9c683583ff59> in <module>. 1 import time. 2 t0 = time.time(). ----> 3 sc.external.exporting.spring_project(adata, './SPRING',. 4 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],. 5 custom_color_tracks=['total_counts']). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in spring_project(adata, project_dir, embedding_method, subplot_name, cell_groupings, custom_color_tracks, total_counts_key, neighbors_key, overwrite). 179 . 180 # Write graph in two formats for backwards compatibility. --> 181 edges = _get_edges(adata, neighbors_key). 182 _write_graph(subplot_dir / 'graph_data.json', E.shape[0], edges). 183 _write_edges(subplot_dir / 'edges.csv', edges). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in _get_edges(adata, neighbors_key). 217 . 218 def _get_edges(adata, neighbors_key=None):. --> 219 neighbors = NeighborsView(adata, neighbors_key). 220 if 'distances' in neighbors: # these are sparse matrices. 221 matrix = neighbors['distances']. NameError: name 'NeighborsView' is not defined`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1260
https://github.com/scverse/scanpy/issues/1260:806,performance,time,time,806,"Hello, I am running into exactly the same bug when using both **scanpy-1.5.1** or **scanpy-1.5.0**. . **Versions**: . scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.3.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 leidenalg==0.8.0. **Input**: . `import time. t0 = time.time(). sc.external.exporting.spring_project(adata, './SPRING',. 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],. custom_color_tracks=['total_counts']). print(time.time() - t0)`. **Output**: . `WARNING: root:Overwriting the files in SPRING. Writing subplot to SPRING\all. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). <ipython-input-59-9c683583ff59> in <module>. 1 import time. 2 t0 = time.time(). ----> 3 sc.external.exporting.spring_project(adata, './SPRING',. 4 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],. 5 custom_color_tracks=['total_counts']). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in spring_project(adata, project_dir, embedding_method, subplot_name, cell_groupings, custom_color_tracks, total_counts_key, neighbors_key, overwrite). 179 . 180 # Write graph in two formats for backwards compatibility. --> 181 edges = _get_edges(adata, neighbors_key). 182 _write_graph(subplot_dir / 'graph_data.json', E.shape[0], edges). 183 _write_edges(subplot_dir / 'edges.csv', edges). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in _get_edges(adata, neighbors_key). 217 . 218 def _get_edges(adata, neighbors_key=None):. --> 219 neighbors = NeighborsView(adata, neighbors_key). 220 if 'distances' in neighbors: # these are sparse matrices. 221 matrix = neighbors['distances']. NameError: name 'NeighborsView' is not defined`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1260
https://github.com/scverse/scanpy/issues/1260:282,safety,Input,Input,282,"Hello, I am running into exactly the same bug when using both **scanpy-1.5.1** or **scanpy-1.5.0**. . **Versions**: . scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.3.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 leidenalg==0.8.0. **Input**: . `import time. t0 = time.time(). sc.external.exporting.spring_project(adata, './SPRING',. 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],. custom_color_tracks=['total_counts']). print(time.time() - t0)`. **Output**: . `WARNING: root:Overwriting the files in SPRING. Writing subplot to SPRING\all. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). <ipython-input-59-9c683583ff59> in <module>. 1 import time. 2 t0 = time.time(). ----> 3 sc.external.exporting.spring_project(adata, './SPRING',. 4 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],. 5 custom_color_tracks=['total_counts']). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in spring_project(adata, project_dir, embedding_method, subplot_name, cell_groupings, custom_color_tracks, total_counts_key, neighbors_key, overwrite). 179 . 180 # Write graph in two formats for backwards compatibility. --> 181 edges = _get_edges(adata, neighbors_key). 182 _write_graph(subplot_dir / 'graph_data.json', E.shape[0], edges). 183 _write_edges(subplot_dir / 'edges.csv', edges). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in _get_edges(adata, neighbors_key). 217 . 218 def _get_edges(adata, neighbors_key=None):. --> 219 neighbors = NeighborsView(adata, neighbors_key). 220 if 'distances' in neighbors: # these are sparse matrices. 221 matrix = neighbors['distances']. NameError: name 'NeighborsView' is not defined`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1260
https://github.com/scverse/scanpy/issues/1260:743,safety,input,input-,743,"Hello, I am running into exactly the same bug when using both **scanpy-1.5.1** or **scanpy-1.5.0**. . **Versions**: . scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.3.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 leidenalg==0.8.0. **Input**: . `import time. t0 = time.time(). sc.external.exporting.spring_project(adata, './SPRING',. 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],. custom_color_tracks=['total_counts']). print(time.time() - t0)`. **Output**: . `WARNING: root:Overwriting the files in SPRING. Writing subplot to SPRING\all. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). <ipython-input-59-9c683583ff59> in <module>. 1 import time. 2 t0 = time.time(). ----> 3 sc.external.exporting.spring_project(adata, './SPRING',. 4 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],. 5 custom_color_tracks=['total_counts']). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in spring_project(adata, project_dir, embedding_method, subplot_name, cell_groupings, custom_color_tracks, total_counts_key, neighbors_key, overwrite). 179 . 180 # Write graph in two formats for backwards compatibility. --> 181 edges = _get_edges(adata, neighbors_key). 182 _write_graph(subplot_dir / 'graph_data.json', E.shape[0], edges). 183 _write_edges(subplot_dir / 'edges.csv', edges). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in _get_edges(adata, neighbors_key). 217 . 218 def _get_edges(adata, neighbors_key=None):. --> 219 neighbors = NeighborsView(adata, neighbors_key). 220 if 'distances' in neighbors: # these are sparse matrices. 221 matrix = neighbors['distances']. NameError: name 'NeighborsView' is not defined`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1260
https://github.com/scverse/scanpy/issues/1260:770,safety,modul,module,770,"Hello, I am running into exactly the same bug when using both **scanpy-1.5.1** or **scanpy-1.5.0**. . **Versions**: . scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.3.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 leidenalg==0.8.0. **Input**: . `import time. t0 = time.time(). sc.external.exporting.spring_project(adata, './SPRING',. 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],. custom_color_tracks=['total_counts']). print(time.time() - t0)`. **Output**: . `WARNING: root:Overwriting the files in SPRING. Writing subplot to SPRING\all. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). <ipython-input-59-9c683583ff59> in <module>. 1 import time. 2 t0 = time.time(). ----> 3 sc.external.exporting.spring_project(adata, './SPRING',. 4 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],. 5 custom_color_tracks=['total_counts']). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in spring_project(adata, project_dir, embedding_method, subplot_name, cell_groupings, custom_color_tracks, total_counts_key, neighbors_key, overwrite). 179 . 180 # Write graph in two formats for backwards compatibility. --> 181 edges = _get_edges(adata, neighbors_key). 182 _write_graph(subplot_dir / 'graph_data.json', E.shape[0], edges). 183 _write_edges(subplot_dir / 'edges.csv', edges). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in _get_edges(adata, neighbors_key). 217 . 218 def _get_edges(adata, neighbors_key=None):. --> 219 neighbors = NeighborsView(adata, neighbors_key). 220 if 'distances' in neighbors: # these are sparse matrices. 221 matrix = neighbors['distances']. NameError: name 'NeighborsView' is not defined`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1260
https://github.com/scverse/scanpy/issues/1260:699,testability,Trace,Traceback,699,"Hello, I am running into exactly the same bug when using both **scanpy-1.5.1** or **scanpy-1.5.0**. . **Versions**: . scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.3.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 leidenalg==0.8.0. **Input**: . `import time. t0 = time.time(). sc.external.exporting.spring_project(adata, './SPRING',. 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],. custom_color_tracks=['total_counts']). print(time.time() - t0)`. **Output**: . `WARNING: root:Overwriting the files in SPRING. Writing subplot to SPRING\all. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). <ipython-input-59-9c683583ff59> in <module>. 1 import time. 2 t0 = time.time(). ----> 3 sc.external.exporting.spring_project(adata, './SPRING',. 4 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],. 5 custom_color_tracks=['total_counts']). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in spring_project(adata, project_dir, embedding_method, subplot_name, cell_groupings, custom_color_tracks, total_counts_key, neighbors_key, overwrite). 179 . 180 # Write graph in two formats for backwards compatibility. --> 181 edges = _get_edges(adata, neighbors_key). 182 _write_graph(subplot_dir / 'graph_data.json', E.shape[0], edges). 183 _write_edges(subplot_dir / 'edges.csv', edges). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in _get_edges(adata, neighbors_key). 217 . 218 def _get_edges(adata, neighbors_key=None):. --> 219 neighbors = NeighborsView(adata, neighbors_key). 220 if 'distances' in neighbors: # these are sparse matrices. 221 matrix = neighbors['distances']. NameError: name 'NeighborsView' is not defined`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1260
https://github.com/scverse/scanpy/issues/1260:207,usability,learn,learn,207,"Hello, I am running into exactly the same bug when using both **scanpy-1.5.1** or **scanpy-1.5.0**. . **Versions**: . scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.3.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 leidenalg==0.8.0. **Input**: . `import time. t0 = time.time(). sc.external.exporting.spring_project(adata, './SPRING',. 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],. custom_color_tracks=['total_counts']). print(time.time() - t0)`. **Output**: . `WARNING: root:Overwriting the files in SPRING. Writing subplot to SPRING\all. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). <ipython-input-59-9c683583ff59> in <module>. 1 import time. 2 t0 = time.time(). ----> 3 sc.external.exporting.spring_project(adata, './SPRING',. 4 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],. 5 custom_color_tracks=['total_counts']). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in spring_project(adata, project_dir, embedding_method, subplot_name, cell_groupings, custom_color_tracks, total_counts_key, neighbors_key, overwrite). 179 . 180 # Write graph in two formats for backwards compatibility. --> 181 edges = _get_edges(adata, neighbors_key). 182 _write_graph(subplot_dir / 'graph_data.json', E.shape[0], edges). 183 _write_edges(subplot_dir / 'edges.csv', edges). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in _get_edges(adata, neighbors_key). 217 . 218 def _get_edges(adata, neighbors_key=None):. --> 219 neighbors = NeighborsView(adata, neighbors_key). 220 if 'distances' in neighbors: # these are sparse matrices. 221 matrix = neighbors['distances']. NameError: name 'NeighborsView' is not defined`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1260
https://github.com/scverse/scanpy/issues/1260:282,usability,Input,Input,282,"Hello, I am running into exactly the same bug when using both **scanpy-1.5.1** or **scanpy-1.5.0**. . **Versions**: . scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.3.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 leidenalg==0.8.0. **Input**: . `import time. t0 = time.time(). sc.external.exporting.spring_project(adata, './SPRING',. 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],. custom_color_tracks=['total_counts']). print(time.time() - t0)`. **Output**: . `WARNING: root:Overwriting the files in SPRING. Writing subplot to SPRING\all. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). <ipython-input-59-9c683583ff59> in <module>. 1 import time. 2 t0 = time.time(). ----> 3 sc.external.exporting.spring_project(adata, './SPRING',. 4 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],. 5 custom_color_tracks=['total_counts']). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in spring_project(adata, project_dir, embedding_method, subplot_name, cell_groupings, custom_color_tracks, total_counts_key, neighbors_key, overwrite). 179 . 180 # Write graph in two formats for backwards compatibility. --> 181 edges = _get_edges(adata, neighbors_key). 182 _write_graph(subplot_dir / 'graph_data.json', E.shape[0], edges). 183 _write_edges(subplot_dir / 'edges.csv', edges). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in _get_edges(adata, neighbors_key). 217 . 218 def _get_edges(adata, neighbors_key=None):. --> 219 neighbors = NeighborsView(adata, neighbors_key). 220 if 'distances' in neighbors: # these are sparse matrices. 221 matrix = neighbors['distances']. NameError: name 'NeighborsView' is not defined`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1260
https://github.com/scverse/scanpy/issues/1260:743,usability,input,input-,743,"Hello, I am running into exactly the same bug when using both **scanpy-1.5.1** or **scanpy-1.5.0**. . **Versions**: . scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.3.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 leidenalg==0.8.0. **Input**: . `import time. t0 = time.time(). sc.external.exporting.spring_project(adata, './SPRING',. 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],. custom_color_tracks=['total_counts']). print(time.time() - t0)`. **Output**: . `WARNING: root:Overwriting the files in SPRING. Writing subplot to SPRING\all. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). <ipython-input-59-9c683583ff59> in <module>. 1 import time. 2 t0 = time.time(). ----> 3 sc.external.exporting.spring_project(adata, './SPRING',. 4 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],. 5 custom_color_tracks=['total_counts']). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in spring_project(adata, project_dir, embedding_method, subplot_name, cell_groupings, custom_color_tracks, total_counts_key, neighbors_key, overwrite). 179 . 180 # Write graph in two formats for backwards compatibility. --> 181 edges = _get_edges(adata, neighbors_key). 182 _write_graph(subplot_dir / 'graph_data.json', E.shape[0], edges). 183 _write_edges(subplot_dir / 'edges.csv', edges). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in _get_edges(adata, neighbors_key). 217 . 218 def _get_edges(adata, neighbors_key=None):. --> 219 neighbors = NeighborsView(adata, neighbors_key). 220 if 'distances' in neighbors: # these are sparse matrices. 221 matrix = neighbors['distances']. NameError: name 'NeighborsView' is not defined`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1260
https://github.com/scverse/scanpy/issues/1263:55,modifiability,paramet,parameter,55,"This is the categorical equivalent of the `sort_order` parameter basically, right? I like the idea.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:149,safety,test,tests,149,"Yes, exactly :). I would have a default that turns it to random. I don't think it should be too hard either. However, this will probably break a few tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:149,testability,test,tests,149,"Yes, exactly :). I would have a default that turns it to random. I don't think it should be too hard either. However, this will probably break a few tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:946,energy efficiency,load,load,946,"Sounds good to me. How are you thinking of handling reproducibility w.r.t. random seeds? To me, the best solution here is to make it easy to do small multiples for categorical plots like this, but that's a big change in the kind of plot being made. . As an aside, I've also tried coloring the pixel by which group showed up the most under it, but this can look weird (less so, if density is used to calculate the alpha level). ![image](https://user-images.githubusercontent.com/8238804/83601513-16985600-a5b4-11ea-8f0d-68a15a3fbf96.png). <details>. <summary> Example without accounting for density </summary>. ![image](https://user-images.githubusercontent.com/8238804/83601587-362f7e80-a5b4-11ea-8e1a-b1bc20948504.png). </details>. <details>. <summary> Snippet to reproduce </summary>. ```python. import datashader as ds. from datashader import transfer_functions as tf. import scanpy as sc. import numpy as np. import xarray as xr. # Where you load your AnnData, I was using a preprocessed set of 1.3 million mouse braincells. df = sc.get.obs_df(. adata,. [""Sox17"", ""louvain""],. obsm_keys=[(""X_umap"", 0), (""X_umap"", 1)]. ). louvain_colors = dict(. zip(. adata.obs[""louvain""].cat.categories, . adata.uns[""louvain_colors""]. ). ). pts = (. ds.Canvas(500, 500). .points(df, ""X_umap-0"", ""X_umap-1"", agg=ds.count_cat(""louvain"")). ). newpts = xr.zeros_like(pts). newpts[:, :, pts.argmax(dim=""louvain"")] = pts.sum(dim=""louvain""). tf.shade(newpts, color_key=louvain_colors). ```. </details>. What datashader does by default is takes the average of the RGB values for the categories under a pixel, weighted by number of samples, and calculates an alpha level based on the number of samples present. This looks like:. ![image](https://user-images.githubusercontent.com/8238804/83599943-c9ff4b80-a5b0-11ea-8acf-3cfc640a9abb.png). <details>. <summary> Addendum to previous snippet for plotting this </summary>. ```python. tf.shade(pts, color_key=louvain_colors). ```. </details>. </details>. I've also been wond",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:2189,energy efficiency,sensor,sensor,2189,"ot being made. . As an aside, I've also tried coloring the pixel by which group showed up the most under it, but this can look weird (less so, if density is used to calculate the alpha level). ![image](https://user-images.githubusercontent.com/8238804/83601513-16985600-a5b4-11ea-8f0d-68a15a3fbf96.png). <details>. <summary> Example without accounting for density </summary>. ![image](https://user-images.githubusercontent.com/8238804/83601587-362f7e80-a5b4-11ea-8e1a-b1bc20948504.png). </details>. <details>. <summary> Snippet to reproduce </summary>. ```python. import datashader as ds. from datashader import transfer_functions as tf. import scanpy as sc. import numpy as np. import xarray as xr. # Where you load your AnnData, I was using a preprocessed set of 1.3 million mouse braincells. df = sc.get.obs_df(. adata,. [""Sox17"", ""louvain""],. obsm_keys=[(""X_umap"", 0), (""X_umap"", 1)]. ). louvain_colors = dict(. zip(. adata.obs[""louvain""].cat.categories, . adata.uns[""louvain_colors""]. ). ). pts = (. ds.Canvas(500, 500). .points(df, ""X_umap-0"", ""X_umap-1"", agg=ds.count_cat(""louvain"")). ). newpts = xr.zeros_like(pts). newpts[:, :, pts.argmax(dim=""louvain"")] = pts.sum(dim=""louvain""). tf.shade(newpts, color_key=louvain_colors). ```. </details>. What datashader does by default is takes the average of the RGB values for the categories under a pixel, weighted by number of samples, and calculates an alpha level based on the number of samples present. This looks like:. ![image](https://user-images.githubusercontent.com/8238804/83599943-c9ff4b80-a5b0-11ea-8acf-3cfc640a9abb.png). <details>. <summary> Addendum to previous snippet for plotting this </summary>. ```python. tf.shade(pts, color_key=louvain_colors). ```. </details>. </details>. I've also been wondering if there's a good way to show ""colors cannot be trusted in this region"". This could be done like how camera's do zebra stripes  where a texture is overlaid on the viewfinder for the sensor pixels which are saturated with light.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:946,performance,load,load,946,"Sounds good to me. How are you thinking of handling reproducibility w.r.t. random seeds? To me, the best solution here is to make it easy to do small multiples for categorical plots like this, but that's a big change in the kind of plot being made. . As an aside, I've also tried coloring the pixel by which group showed up the most under it, but this can look weird (less so, if density is used to calculate the alpha level). ![image](https://user-images.githubusercontent.com/8238804/83601513-16985600-a5b4-11ea-8f0d-68a15a3fbf96.png). <details>. <summary> Example without accounting for density </summary>. ![image](https://user-images.githubusercontent.com/8238804/83601587-362f7e80-a5b4-11ea-8e1a-b1bc20948504.png). </details>. <details>. <summary> Snippet to reproduce </summary>. ```python. import datashader as ds. from datashader import transfer_functions as tf. import scanpy as sc. import numpy as np. import xarray as xr. # Where you load your AnnData, I was using a preprocessed set of 1.3 million mouse braincells. df = sc.get.obs_df(. adata,. [""Sox17"", ""louvain""],. obsm_keys=[(""X_umap"", 0), (""X_umap"", 1)]. ). louvain_colors = dict(. zip(. adata.obs[""louvain""].cat.categories, . adata.uns[""louvain_colors""]. ). ). pts = (. ds.Canvas(500, 500). .points(df, ""X_umap-0"", ""X_umap-1"", agg=ds.count_cat(""louvain"")). ). newpts = xr.zeros_like(pts). newpts[:, :, pts.argmax(dim=""louvain"")] = pts.sum(dim=""louvain""). tf.shade(newpts, color_key=louvain_colors). ```. </details>. What datashader does by default is takes the average of the RGB values for the categories under a pixel, weighted by number of samples, and calculates an alpha level based on the number of samples present. This looks like:. ![image](https://user-images.githubusercontent.com/8238804/83599943-c9ff4b80-a5b0-11ea-8acf-3cfc640a9abb.png). <details>. <summary> Addendum to previous snippet for plotting this </summary>. ```python. tf.shade(pts, color_key=louvain_colors). ```. </details>. </details>. I've also been wond",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:1501,reliability,doe,does,1501,"ot being made. . As an aside, I've also tried coloring the pixel by which group showed up the most under it, but this can look weird (less so, if density is used to calculate the alpha level). ![image](https://user-images.githubusercontent.com/8238804/83601513-16985600-a5b4-11ea-8f0d-68a15a3fbf96.png). <details>. <summary> Example without accounting for density </summary>. ![image](https://user-images.githubusercontent.com/8238804/83601587-362f7e80-a5b4-11ea-8e1a-b1bc20948504.png). </details>. <details>. <summary> Snippet to reproduce </summary>. ```python. import datashader as ds. from datashader import transfer_functions as tf. import scanpy as sc. import numpy as np. import xarray as xr. # Where you load your AnnData, I was using a preprocessed set of 1.3 million mouse braincells. df = sc.get.obs_df(. adata,. [""Sox17"", ""louvain""],. obsm_keys=[(""X_umap"", 0), (""X_umap"", 1)]. ). louvain_colors = dict(. zip(. adata.obs[""louvain""].cat.categories, . adata.uns[""louvain_colors""]. ). ). pts = (. ds.Canvas(500, 500). .points(df, ""X_umap-0"", ""X_umap-1"", agg=ds.count_cat(""louvain"")). ). newpts = xr.zeros_like(pts). newpts[:, :, pts.argmax(dim=""louvain"")] = pts.sum(dim=""louvain""). tf.shade(newpts, color_key=louvain_colors). ```. </details>. What datashader does by default is takes the average of the RGB values for the categories under a pixel, weighted by number of samples, and calculates an alpha level based on the number of samples present. This looks like:. ![image](https://user-images.githubusercontent.com/8238804/83599943-c9ff4b80-a5b0-11ea-8acf-3cfc640a9abb.png). <details>. <summary> Addendum to previous snippet for plotting this </summary>. ```python. tf.shade(pts, color_key=louvain_colors). ```. </details>. </details>. I've also been wondering if there's a good way to show ""colors cannot be trusted in this region"". This could be done like how camera's do zebra stripes  where a texture is overlaid on the viewfinder for the sensor pixels which are saturated with light.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:2054,security,trust,trusted,2054,"ot being made. . As an aside, I've also tried coloring the pixel by which group showed up the most under it, but this can look weird (less so, if density is used to calculate the alpha level). ![image](https://user-images.githubusercontent.com/8238804/83601513-16985600-a5b4-11ea-8f0d-68a15a3fbf96.png). <details>. <summary> Example without accounting for density </summary>. ![image](https://user-images.githubusercontent.com/8238804/83601587-362f7e80-a5b4-11ea-8e1a-b1bc20948504.png). </details>. <details>. <summary> Snippet to reproduce </summary>. ```python. import datashader as ds. from datashader import transfer_functions as tf. import scanpy as sc. import numpy as np. import xarray as xr. # Where you load your AnnData, I was using a preprocessed set of 1.3 million mouse braincells. df = sc.get.obs_df(. adata,. [""Sox17"", ""louvain""],. obsm_keys=[(""X_umap"", 0), (""X_umap"", 1)]. ). louvain_colors = dict(. zip(. adata.obs[""louvain""].cat.categories, . adata.uns[""louvain_colors""]. ). ). pts = (. ds.Canvas(500, 500). .points(df, ""X_umap-0"", ""X_umap-1"", agg=ds.count_cat(""louvain"")). ). newpts = xr.zeros_like(pts). newpts[:, :, pts.argmax(dim=""louvain"")] = pts.sum(dim=""louvain""). tf.shade(newpts, color_key=louvain_colors). ```. </details>. What datashader does by default is takes the average of the RGB values for the categories under a pixel, weighted by number of samples, and calculates an alpha level based on the number of samples present. This looks like:. ![image](https://user-images.githubusercontent.com/8238804/83599943-c9ff4b80-a5b0-11ea-8acf-3cfc640a9abb.png). <details>. <summary> Addendum to previous snippet for plotting this </summary>. ```python. tf.shade(pts, color_key=louvain_colors). ```. </details>. </details>. I've also been wondering if there's a good way to show ""colors cannot be trusted in this region"". This could be done like how camera's do zebra stripes  where a texture is overlaid on the viewfinder for the sensor pixels which are saturated with light.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:444,usability,user,user-images,444,"Sounds good to me. How are you thinking of handling reproducibility w.r.t. random seeds? To me, the best solution here is to make it easy to do small multiples for categorical plots like this, but that's a big change in the kind of plot being made. . As an aside, I've also tried coloring the pixel by which group showed up the most under it, but this can look weird (less so, if density is used to calculate the alpha level). ![image](https://user-images.githubusercontent.com/8238804/83601513-16985600-a5b4-11ea-8f0d-68a15a3fbf96.png). <details>. <summary> Example without accounting for density </summary>. ![image](https://user-images.githubusercontent.com/8238804/83601587-362f7e80-a5b4-11ea-8e1a-b1bc20948504.png). </details>. <details>. <summary> Snippet to reproduce </summary>. ```python. import datashader as ds. from datashader import transfer_functions as tf. import scanpy as sc. import numpy as np. import xarray as xr. # Where you load your AnnData, I was using a preprocessed set of 1.3 million mouse braincells. df = sc.get.obs_df(. adata,. [""Sox17"", ""louvain""],. obsm_keys=[(""X_umap"", 0), (""X_umap"", 1)]. ). louvain_colors = dict(. zip(. adata.obs[""louvain""].cat.categories, . adata.uns[""louvain_colors""]. ). ). pts = (. ds.Canvas(500, 500). .points(df, ""X_umap-0"", ""X_umap-1"", agg=ds.count_cat(""louvain"")). ). newpts = xr.zeros_like(pts). newpts[:, :, pts.argmax(dim=""louvain"")] = pts.sum(dim=""louvain""). tf.shade(newpts, color_key=louvain_colors). ```. </details>. What datashader does by default is takes the average of the RGB values for the categories under a pixel, weighted by number of samples, and calculates an alpha level based on the number of samples present. This looks like:. ![image](https://user-images.githubusercontent.com/8238804/83599943-c9ff4b80-a5b0-11ea-8acf-3cfc640a9abb.png). <details>. <summary> Addendum to previous snippet for plotting this </summary>. ```python. tf.shade(pts, color_key=louvain_colors). ```. </details>. </details>. I've also been wond",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:627,usability,user,user-images,627,"Sounds good to me. How are you thinking of handling reproducibility w.r.t. random seeds? To me, the best solution here is to make it easy to do small multiples for categorical plots like this, but that's a big change in the kind of plot being made. . As an aside, I've also tried coloring the pixel by which group showed up the most under it, but this can look weird (less so, if density is used to calculate the alpha level). ![image](https://user-images.githubusercontent.com/8238804/83601513-16985600-a5b4-11ea-8f0d-68a15a3fbf96.png). <details>. <summary> Example without accounting for density </summary>. ![image](https://user-images.githubusercontent.com/8238804/83601587-362f7e80-a5b4-11ea-8e1a-b1bc20948504.png). </details>. <details>. <summary> Snippet to reproduce </summary>. ```python. import datashader as ds. from datashader import transfer_functions as tf. import scanpy as sc. import numpy as np. import xarray as xr. # Where you load your AnnData, I was using a preprocessed set of 1.3 million mouse braincells. df = sc.get.obs_df(. adata,. [""Sox17"", ""louvain""],. obsm_keys=[(""X_umap"", 0), (""X_umap"", 1)]. ). louvain_colors = dict(. zip(. adata.obs[""louvain""].cat.categories, . adata.uns[""louvain_colors""]. ). ). pts = (. ds.Canvas(500, 500). .points(df, ""X_umap-0"", ""X_umap-1"", agg=ds.count_cat(""louvain"")). ). newpts = xr.zeros_like(pts). newpts[:, :, pts.argmax(dim=""louvain"")] = pts.sum(dim=""louvain""). tf.shade(newpts, color_key=louvain_colors). ```. </details>. What datashader does by default is takes the average of the RGB values for the categories under a pixel, weighted by number of samples, and calculates an alpha level based on the number of samples present. This looks like:. ![image](https://user-images.githubusercontent.com/8238804/83599943-c9ff4b80-a5b0-11ea-8acf-3cfc640a9abb.png). <details>. <summary> Addendum to previous snippet for plotting this </summary>. ```python. tf.shade(pts, color_key=louvain_colors). ```. </details>. </details>. I've also been wond",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:1011,usability,mous,mouse,1011," me. How are you thinking of handling reproducibility w.r.t. random seeds? To me, the best solution here is to make it easy to do small multiples for categorical plots like this, but that's a big change in the kind of plot being made. . As an aside, I've also tried coloring the pixel by which group showed up the most under it, but this can look weird (less so, if density is used to calculate the alpha level). ![image](https://user-images.githubusercontent.com/8238804/83601513-16985600-a5b4-11ea-8f0d-68a15a3fbf96.png). <details>. <summary> Example without accounting for density </summary>. ![image](https://user-images.githubusercontent.com/8238804/83601587-362f7e80-a5b4-11ea-8e1a-b1bc20948504.png). </details>. <details>. <summary> Snippet to reproduce </summary>. ```python. import datashader as ds. from datashader import transfer_functions as tf. import scanpy as sc. import numpy as np. import xarray as xr. # Where you load your AnnData, I was using a preprocessed set of 1.3 million mouse braincells. df = sc.get.obs_df(. adata,. [""Sox17"", ""louvain""],. obsm_keys=[(""X_umap"", 0), (""X_umap"", 1)]. ). louvain_colors = dict(. zip(. adata.obs[""louvain""].cat.categories, . adata.uns[""louvain_colors""]. ). ). pts = (. ds.Canvas(500, 500). .points(df, ""X_umap-0"", ""X_umap-1"", agg=ds.count_cat(""louvain"")). ). newpts = xr.zeros_like(pts). newpts[:, :, pts.argmax(dim=""louvain"")] = pts.sum(dim=""louvain""). tf.shade(newpts, color_key=louvain_colors). ```. </details>. What datashader does by default is takes the average of the RGB values for the categories under a pixel, weighted by number of samples, and calculates an alpha level based on the number of samples present. This looks like:. ![image](https://user-images.githubusercontent.com/8238804/83599943-c9ff4b80-a5b0-11ea-8acf-3cfc640a9abb.png). <details>. <summary> Addendum to previous snippet for plotting this </summary>. ```python. tf.shade(pts, color_key=louvain_colors). ```. </details>. </details>. I've also been wondering if there",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:1726,usability,user,user-images,1726,"ot being made. . As an aside, I've also tried coloring the pixel by which group showed up the most under it, but this can look weird (less so, if density is used to calculate the alpha level). ![image](https://user-images.githubusercontent.com/8238804/83601513-16985600-a5b4-11ea-8f0d-68a15a3fbf96.png). <details>. <summary> Example without accounting for density </summary>. ![image](https://user-images.githubusercontent.com/8238804/83601587-362f7e80-a5b4-11ea-8e1a-b1bc20948504.png). </details>. <details>. <summary> Snippet to reproduce </summary>. ```python. import datashader as ds. from datashader import transfer_functions as tf. import scanpy as sc. import numpy as np. import xarray as xr. # Where you load your AnnData, I was using a preprocessed set of 1.3 million mouse braincells. df = sc.get.obs_df(. adata,. [""Sox17"", ""louvain""],. obsm_keys=[(""X_umap"", 0), (""X_umap"", 1)]. ). louvain_colors = dict(. zip(. adata.obs[""louvain""].cat.categories, . adata.uns[""louvain_colors""]. ). ). pts = (. ds.Canvas(500, 500). .points(df, ""X_umap-0"", ""X_umap-1"", agg=ds.count_cat(""louvain"")). ). newpts = xr.zeros_like(pts). newpts[:, :, pts.argmax(dim=""louvain"")] = pts.sum(dim=""louvain""). tf.shade(newpts, color_key=louvain_colors). ```. </details>. What datashader does by default is takes the average of the RGB values for the categories under a pixel, weighted by number of samples, and calculates an alpha level based on the number of samples present. This looks like:. ![image](https://user-images.githubusercontent.com/8238804/83599943-c9ff4b80-a5b0-11ea-8acf-3cfc640a9abb.png). <details>. <summary> Addendum to previous snippet for plotting this </summary>. ```python. tf.shade(pts, color_key=louvain_colors). ```. </details>. </details>. I've also been wondering if there's a good way to show ""colors cannot be trusted in this region"". This could be done like how camera's do zebra stripes  where a texture is overlaid on the viewfinder for the sensor pixels which are saturated with light.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:163,availability,consist,consistent,163,"> Sounds good to me. How are you thinking of handling reproducibility w.r.t. random seeds? I was thinking of just setting the seed to 0 by default, which would be consistent with other Scanpy code. I don't actually mind the version of the plot without accounting for sample density. I do think that randomization would result in sth similar to the `datashader` example you show though, except that it wouldn't change alphas by density. I'm not sure if doing that is so helpful as it can lead to hardly being able to see small clusters in less dense regions of the plot. These clusters (potentially rare cell types) are often the interesting features in such a plot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:526,availability,cluster,clusters,526,"> Sounds good to me. How are you thinking of handling reproducibility w.r.t. random seeds? I was thinking of just setting the seed to 0 by default, which would be consistent with other Scanpy code. I don't actually mind the version of the plot without accounting for sample density. I do think that randomization would result in sth similar to the `datashader` example you show though, except that it wouldn't change alphas by density. I'm not sure if doing that is so helpful as it can lead to hardly being able to see small clusters in less dense regions of the plot. These clusters (potentially rare cell types) are often the interesting features in such a plot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:576,availability,cluster,clusters,576,"> Sounds good to me. How are you thinking of handling reproducibility w.r.t. random seeds? I was thinking of just setting the seed to 0 by default, which would be consistent with other Scanpy code. I don't actually mind the version of the plot without accounting for sample density. I do think that randomization would result in sth similar to the `datashader` example you show though, except that it wouldn't change alphas by density. I'm not sure if doing that is so helpful as it can lead to hardly being able to see small clusters in less dense regions of the plot. These clusters (potentially rare cell types) are often the interesting features in such a plot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:224,deployability,version,version,224,"> Sounds good to me. How are you thinking of handling reproducibility w.r.t. random seeds? I was thinking of just setting the seed to 0 by default, which would be consistent with other Scanpy code. I don't actually mind the version of the plot without accounting for sample density. I do think that randomization would result in sth similar to the `datashader` example you show though, except that it wouldn't change alphas by density. I'm not sure if doing that is so helpful as it can lead to hardly being able to see small clusters in less dense regions of the plot. These clusters (potentially rare cell types) are often the interesting features in such a plot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:526,deployability,cluster,clusters,526,"> Sounds good to me. How are you thinking of handling reproducibility w.r.t. random seeds? I was thinking of just setting the seed to 0 by default, which would be consistent with other Scanpy code. I don't actually mind the version of the plot without accounting for sample density. I do think that randomization would result in sth similar to the `datashader` example you show though, except that it wouldn't change alphas by density. I'm not sure if doing that is so helpful as it can lead to hardly being able to see small clusters in less dense regions of the plot. These clusters (potentially rare cell types) are often the interesting features in such a plot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:576,deployability,cluster,clusters,576,"> Sounds good to me. How are you thinking of handling reproducibility w.r.t. random seeds? I was thinking of just setting the seed to 0 by default, which would be consistent with other Scanpy code. I don't actually mind the version of the plot without accounting for sample density. I do think that randomization would result in sth similar to the `datashader` example you show though, except that it wouldn't change alphas by density. I'm not sure if doing that is so helpful as it can lead to hardly being able to see small clusters in less dense regions of the plot. These clusters (potentially rare cell types) are often the interesting features in such a plot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:224,integrability,version,version,224,"> Sounds good to me. How are you thinking of handling reproducibility w.r.t. random seeds? I was thinking of just setting the seed to 0 by default, which would be consistent with other Scanpy code. I don't actually mind the version of the plot without accounting for sample density. I do think that randomization would result in sth similar to the `datashader` example you show though, except that it wouldn't change alphas by density. I'm not sure if doing that is so helpful as it can lead to hardly being able to see small clusters in less dense regions of the plot. These clusters (potentially rare cell types) are often the interesting features in such a plot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:224,modifiability,version,version,224,"> Sounds good to me. How are you thinking of handling reproducibility w.r.t. random seeds? I was thinking of just setting the seed to 0 by default, which would be consistent with other Scanpy code. I don't actually mind the version of the plot without accounting for sample density. I do think that randomization would result in sth similar to the `datashader` example you show though, except that it wouldn't change alphas by density. I'm not sure if doing that is so helpful as it can lead to hardly being able to see small clusters in less dense regions of the plot. These clusters (potentially rare cell types) are often the interesting features in such a plot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:386,safety,except,except,386,"> Sounds good to me. How are you thinking of handling reproducibility w.r.t. random seeds? I was thinking of just setting the seed to 0 by default, which would be consistent with other Scanpy code. I don't actually mind the version of the plot without accounting for sample density. I do think that randomization would result in sth similar to the `datashader` example you show though, except that it wouldn't change alphas by density. I'm not sure if doing that is so helpful as it can lead to hardly being able to see small clusters in less dense regions of the plot. These clusters (potentially rare cell types) are often the interesting features in such a plot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:163,usability,consist,consistent,163,"> Sounds good to me. How are you thinking of handling reproducibility w.r.t. random seeds? I was thinking of just setting the seed to 0 by default, which would be consistent with other Scanpy code. I don't actually mind the version of the plot without accounting for sample density. I do think that randomization would result in sth similar to the `datashader` example you show though, except that it wouldn't change alphas by density. I'm not sure if doing that is so helpful as it can lead to hardly being able to see small clusters in less dense regions of the plot. These clusters (potentially rare cell types) are often the interesting features in such a plot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:469,usability,help,helpful,469,"> Sounds good to me. How are you thinking of handling reproducibility w.r.t. random seeds? I was thinking of just setting the seed to 0 by default, which would be consistent with other Scanpy code. I don't actually mind the version of the plot without accounting for sample density. I do think that randomization would result in sth similar to the `datashader` example you show though, except that it wouldn't change alphas by density. I'm not sure if doing that is so helpful as it can lead to hardly being able to see small clusters in less dense regions of the plot. These clusters (potentially rare cell types) are often the interesting features in such a plot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:2505,availability,cluster,clusters,2505,""", ""louvain""],. obsm_keys=[(""X_umap"", 0), (""X_umap"", 1)]. ). louvain_colors = dict(. zip(. adata.obs[""louvain""].cat.categories, . adata.uns[""louvain_colors""]. ). ). pts = (. ds.Canvas(1000, 1000). .points(df, ""X_umap-0"", ""X_umap-1"", agg=ds.count_cat(""louvain"")). ). # Make images. pts_ncats = (pts != 0).sum(axis=2). overlap_idx = pts_ncats == 1. zebra_source = xr.DataArray(. diagonal_bands_like(overlap_idx, 13),. coords=overlap_idx.coords. ). color_by_cluster = tf.shade(pts, color_key=louvain_colors). tf.Images(. color_by_cluster,. tf.stack(. tf.Image(xr.where(pts_ncats == 1, color_by_cluster, 0)),. tf.Image(tf.shade(xr.where(pts_ncats > 1, zebra_source, False), cmap=""black"")). ),. tf.stack(. color_by_cluster,. tf.Image(tf.shade(xr.where(pts_ncats > 1, zebra_source, False), cmap=""black"")). ),. ). ```. </details>. > I do think that randomization would result in sth similar to the datashader example you show though, except that it wouldn't change alphas by density. I wonder how either of these are effected by number of points. Say you have two cell types (A and B) in an overlapping region. . A has 10x the representation of B in this region, but it's only 10% of the A in this dataset, while this region has all of B. What the fair way to color this? If it were random, or purely by count this would look mostly like A. > I'm not sure if doing that is so helpful as it can lead to hardly being able to see small clusters in less dense regions of the plot. I think bin size would be helpful here. Additionally [datashader has methods](https://pyviz-dev.github.io/datashader/api.html#datashader.transfer_functions.dynspread) for exaggerating points in less dense regions so they are visible. This could be worth looking into. Update: Turns out `dynspread` uses global density, not local. The spread operators could still be of help here. Also, minimum alpha values can be set. Overall, I do like that there is a sense of density with the alpha levels, and wouldn't want to miss out on it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:2890,availability,operat,operators,2890,""", ""louvain""],. obsm_keys=[(""X_umap"", 0), (""X_umap"", 1)]. ). louvain_colors = dict(. zip(. adata.obs[""louvain""].cat.categories, . adata.uns[""louvain_colors""]. ). ). pts = (. ds.Canvas(1000, 1000). .points(df, ""X_umap-0"", ""X_umap-1"", agg=ds.count_cat(""louvain"")). ). # Make images. pts_ncats = (pts != 0).sum(axis=2). overlap_idx = pts_ncats == 1. zebra_source = xr.DataArray(. diagonal_bands_like(overlap_idx, 13),. coords=overlap_idx.coords. ). color_by_cluster = tf.shade(pts, color_key=louvain_colors). tf.Images(. color_by_cluster,. tf.stack(. tf.Image(xr.where(pts_ncats == 1, color_by_cluster, 0)),. tf.Image(tf.shade(xr.where(pts_ncats > 1, zebra_source, False), cmap=""black"")). ),. tf.stack(. color_by_cluster,. tf.Image(tf.shade(xr.where(pts_ncats > 1, zebra_source, False), cmap=""black"")). ),. ). ```. </details>. > I do think that randomization would result in sth similar to the datashader example you show though, except that it wouldn't change alphas by density. I wonder how either of these are effected by number of points. Say you have two cell types (A and B) in an overlapping region. . A has 10x the representation of B in this region, but it's only 10% of the A in this dataset, while this region has all of B. What the fair way to color this? If it were random, or purely by count this would look mostly like A. > I'm not sure if doing that is so helpful as it can lead to hardly being able to see small clusters in less dense regions of the plot. I think bin size would be helpful here. Additionally [datashader has methods](https://pyviz-dev.github.io/datashader/api.html#datashader.transfer_functions.dynspread) for exaggerating points in less dense regions so they are visible. This could be worth looking into. Update: Turns out `dynspread` uses global density, not local. The spread operators could still be of help here. Also, minimum alpha values can be set. Overall, I do like that there is a sense of density with the alpha levels, and wouldn't want to miss out on it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:1619,deployability,stack,stack,1619,"(arr, width=3):. assert arr.ndim == 2. a = np.zeros_like(arr, dtype=bool). step = a.shape[1] + 1. # Not sure why end isn't making a difference. end = None. # end = a.shape[1] * a.shape[1]. fill = True. for i in range(arr.shape[0]):. if (i + width // 2) % width == 0:. fill = not fill. if fill:. a.flat[i:end:step] = True. return a. # Setup. adata = sc.read(""/Users/isaac/data/10x_mouse_13MM_processed.h5ad"", backed=""r""). df = sc.get.obs_df(. adata,. [""Sox17"", ""louvain""],. obsm_keys=[(""X_umap"", 0), (""X_umap"", 1)]. ). louvain_colors = dict(. zip(. adata.obs[""louvain""].cat.categories, . adata.uns[""louvain_colors""]. ). ). pts = (. ds.Canvas(1000, 1000). .points(df, ""X_umap-0"", ""X_umap-1"", agg=ds.count_cat(""louvain"")). ). # Make images. pts_ncats = (pts != 0).sum(axis=2). overlap_idx = pts_ncats == 1. zebra_source = xr.DataArray(. diagonal_bands_like(overlap_idx, 13),. coords=overlap_idx.coords. ). color_by_cluster = tf.shade(pts, color_key=louvain_colors). tf.Images(. color_by_cluster,. tf.stack(. tf.Image(xr.where(pts_ncats == 1, color_by_cluster, 0)),. tf.Image(tf.shade(xr.where(pts_ncats > 1, zebra_source, False), cmap=""black"")). ),. tf.stack(. color_by_cluster,. tf.Image(tf.shade(xr.where(pts_ncats > 1, zebra_source, False), cmap=""black"")). ),. ). ```. </details>. > I do think that randomization would result in sth similar to the datashader example you show though, except that it wouldn't change alphas by density. I wonder how either of these are effected by number of points. Say you have two cell types (A and B) in an overlapping region. . A has 10x the representation of B in this region, but it's only 10% of the A in this dataset, while this region has all of B. What the fair way to color this? If it were random, or purely by count this would look mostly like A. > I'm not sure if doing that is so helpful as it can lead to hardly being able to see small clusters in less dense regions of the plot. I think bin size would be helpful here. Additionally [datashader has meth",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:1772,deployability,stack,stack,1772,"e. # end = a.shape[1] * a.shape[1]. fill = True. for i in range(arr.shape[0]):. if (i + width // 2) % width == 0:. fill = not fill. if fill:. a.flat[i:end:step] = True. return a. # Setup. adata = sc.read(""/Users/isaac/data/10x_mouse_13MM_processed.h5ad"", backed=""r""). df = sc.get.obs_df(. adata,. [""Sox17"", ""louvain""],. obsm_keys=[(""X_umap"", 0), (""X_umap"", 1)]. ). louvain_colors = dict(. zip(. adata.obs[""louvain""].cat.categories, . adata.uns[""louvain_colors""]. ). ). pts = (. ds.Canvas(1000, 1000). .points(df, ""X_umap-0"", ""X_umap-1"", agg=ds.count_cat(""louvain"")). ). # Make images. pts_ncats = (pts != 0).sum(axis=2). overlap_idx = pts_ncats == 1. zebra_source = xr.DataArray(. diagonal_bands_like(overlap_idx, 13),. coords=overlap_idx.coords. ). color_by_cluster = tf.shade(pts, color_key=louvain_colors). tf.Images(. color_by_cluster,. tf.stack(. tf.Image(xr.where(pts_ncats == 1, color_by_cluster, 0)),. tf.Image(tf.shade(xr.where(pts_ncats > 1, zebra_source, False), cmap=""black"")). ),. tf.stack(. color_by_cluster,. tf.Image(tf.shade(xr.where(pts_ncats > 1, zebra_source, False), cmap=""black"")). ),. ). ```. </details>. > I do think that randomization would result in sth similar to the datashader example you show though, except that it wouldn't change alphas by density. I wonder how either of these are effected by number of points. Say you have two cell types (A and B) in an overlapping region. . A has 10x the representation of B in this region, but it's only 10% of the A in this dataset, while this region has all of B. What the fair way to color this? If it were random, or purely by count this would look mostly like A. > I'm not sure if doing that is so helpful as it can lead to hardly being able to see small clusters in less dense regions of the plot. I think bin size would be helpful here. Additionally [datashader has methods](https://pyviz-dev.github.io/datashader/api.html#datashader.transfer_functions.dynspread) for exaggerating points in less dense regions so they are v",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:2505,deployability,cluster,clusters,2505,""", ""louvain""],. obsm_keys=[(""X_umap"", 0), (""X_umap"", 1)]. ). louvain_colors = dict(. zip(. adata.obs[""louvain""].cat.categories, . adata.uns[""louvain_colors""]. ). ). pts = (. ds.Canvas(1000, 1000). .points(df, ""X_umap-0"", ""X_umap-1"", agg=ds.count_cat(""louvain"")). ). # Make images. pts_ncats = (pts != 0).sum(axis=2). overlap_idx = pts_ncats == 1. zebra_source = xr.DataArray(. diagonal_bands_like(overlap_idx, 13),. coords=overlap_idx.coords. ). color_by_cluster = tf.shade(pts, color_key=louvain_colors). tf.Images(. color_by_cluster,. tf.stack(. tf.Image(xr.where(pts_ncats == 1, color_by_cluster, 0)),. tf.Image(tf.shade(xr.where(pts_ncats > 1, zebra_source, False), cmap=""black"")). ),. tf.stack(. color_by_cluster,. tf.Image(tf.shade(xr.where(pts_ncats > 1, zebra_source, False), cmap=""black"")). ),. ). ```. </details>. > I do think that randomization would result in sth similar to the datashader example you show though, except that it wouldn't change alphas by density. I wonder how either of these are effected by number of points. Say you have two cell types (A and B) in an overlapping region. . A has 10x the representation of B in this region, but it's only 10% of the A in this dataset, while this region has all of B. What the fair way to color this? If it were random, or purely by count this would look mostly like A. > I'm not sure if doing that is so helpful as it can lead to hardly being able to see small clusters in less dense regions of the plot. I think bin size would be helpful here. Additionally [datashader has methods](https://pyviz-dev.github.io/datashader/api.html#datashader.transfer_functions.dynspread) for exaggerating points in less dense regions so they are visible. This could be worth looking into. Update: Turns out `dynspread` uses global density, not local. The spread operators could still be of help here. Also, minimum alpha values can be set. Overall, I do like that there is a sense of density with the alpha levels, and wouldn't want to miss out on it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:2666,deployability,api,api,2666,""", ""louvain""],. obsm_keys=[(""X_umap"", 0), (""X_umap"", 1)]. ). louvain_colors = dict(. zip(. adata.obs[""louvain""].cat.categories, . adata.uns[""louvain_colors""]. ). ). pts = (. ds.Canvas(1000, 1000). .points(df, ""X_umap-0"", ""X_umap-1"", agg=ds.count_cat(""louvain"")). ). # Make images. pts_ncats = (pts != 0).sum(axis=2). overlap_idx = pts_ncats == 1. zebra_source = xr.DataArray(. diagonal_bands_like(overlap_idx, 13),. coords=overlap_idx.coords. ). color_by_cluster = tf.shade(pts, color_key=louvain_colors). tf.Images(. color_by_cluster,. tf.stack(. tf.Image(xr.where(pts_ncats == 1, color_by_cluster, 0)),. tf.Image(tf.shade(xr.where(pts_ncats > 1, zebra_source, False), cmap=""black"")). ),. tf.stack(. color_by_cluster,. tf.Image(tf.shade(xr.where(pts_ncats > 1, zebra_source, False), cmap=""black"")). ),. ). ```. </details>. > I do think that randomization would result in sth similar to the datashader example you show though, except that it wouldn't change alphas by density. I wonder how either of these are effected by number of points. Say you have two cell types (A and B) in an overlapping region. . A has 10x the representation of B in this region, but it's only 10% of the A in this dataset, while this region has all of B. What the fair way to color this? If it were random, or purely by count this would look mostly like A. > I'm not sure if doing that is so helpful as it can lead to hardly being able to see small clusters in less dense regions of the plot. I think bin size would be helpful here. Additionally [datashader has methods](https://pyviz-dev.github.io/datashader/api.html#datashader.transfer_functions.dynspread) for exaggerating points in less dense regions so they are visible. This could be worth looking into. Update: Turns out `dynspread` uses global density, not local. The spread operators could still be of help here. Also, minimum alpha values can be set. Overall, I do like that there is a sense of density with the alpha levels, and wouldn't want to miss out on it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:2817,deployability,Updat,Update,2817,""", ""louvain""],. obsm_keys=[(""X_umap"", 0), (""X_umap"", 1)]. ). louvain_colors = dict(. zip(. adata.obs[""louvain""].cat.categories, . adata.uns[""louvain_colors""]. ). ). pts = (. ds.Canvas(1000, 1000). .points(df, ""X_umap-0"", ""X_umap-1"", agg=ds.count_cat(""louvain"")). ). # Make images. pts_ncats = (pts != 0).sum(axis=2). overlap_idx = pts_ncats == 1. zebra_source = xr.DataArray(. diagonal_bands_like(overlap_idx, 13),. coords=overlap_idx.coords. ). color_by_cluster = tf.shade(pts, color_key=louvain_colors). tf.Images(. color_by_cluster,. tf.stack(. tf.Image(xr.where(pts_ncats == 1, color_by_cluster, 0)),. tf.Image(tf.shade(xr.where(pts_ncats > 1, zebra_source, False), cmap=""black"")). ),. tf.stack(. color_by_cluster,. tf.Image(tf.shade(xr.where(pts_ncats > 1, zebra_source, False), cmap=""black"")). ),. ). ```. </details>. > I do think that randomization would result in sth similar to the datashader example you show though, except that it wouldn't change alphas by density. I wonder how either of these are effected by number of points. Say you have two cell types (A and B) in an overlapping region. . A has 10x the representation of B in this region, but it's only 10% of the A in this dataset, while this region has all of B. What the fair way to color this? If it were random, or purely by count this would look mostly like A. > I'm not sure if doing that is so helpful as it can lead to hardly being able to see small clusters in less dense regions of the plot. I think bin size would be helpful here. Additionally [datashader has methods](https://pyviz-dev.github.io/datashader/api.html#datashader.transfer_functions.dynspread) for exaggerating points in less dense regions so they are visible. This could be worth looking into. Update: Turns out `dynspread` uses global density, not local. The spread operators could still be of help here. Also, minimum alpha values can be set. Overall, I do like that there is a sense of density with the alpha levels, and wouldn't want to miss out on it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:2666,integrability,api,api,2666,""", ""louvain""],. obsm_keys=[(""X_umap"", 0), (""X_umap"", 1)]. ). louvain_colors = dict(. zip(. adata.obs[""louvain""].cat.categories, . adata.uns[""louvain_colors""]. ). ). pts = (. ds.Canvas(1000, 1000). .points(df, ""X_umap-0"", ""X_umap-1"", agg=ds.count_cat(""louvain"")). ). # Make images. pts_ncats = (pts != 0).sum(axis=2). overlap_idx = pts_ncats == 1. zebra_source = xr.DataArray(. diagonal_bands_like(overlap_idx, 13),. coords=overlap_idx.coords. ). color_by_cluster = tf.shade(pts, color_key=louvain_colors). tf.Images(. color_by_cluster,. tf.stack(. tf.Image(xr.where(pts_ncats == 1, color_by_cluster, 0)),. tf.Image(tf.shade(xr.where(pts_ncats > 1, zebra_source, False), cmap=""black"")). ),. tf.stack(. color_by_cluster,. tf.Image(tf.shade(xr.where(pts_ncats > 1, zebra_source, False), cmap=""black"")). ),. ). ```. </details>. > I do think that randomization would result in sth similar to the datashader example you show though, except that it wouldn't change alphas by density. I wonder how either of these are effected by number of points. Say you have two cell types (A and B) in an overlapping region. . A has 10x the representation of B in this region, but it's only 10% of the A in this dataset, while this region has all of B. What the fair way to color this? If it were random, or purely by count this would look mostly like A. > I'm not sure if doing that is so helpful as it can lead to hardly being able to see small clusters in less dense regions of the plot. I think bin size would be helpful here. Additionally [datashader has methods](https://pyviz-dev.github.io/datashader/api.html#datashader.transfer_functions.dynspread) for exaggerating points in less dense regions so they are visible. This could be worth looking into. Update: Turns out `dynspread` uses global density, not local. The spread operators could still be of help here. Also, minimum alpha values can be set. Overall, I do like that there is a sense of density with the alpha levels, and wouldn't want to miss out on it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:2666,interoperability,api,api,2666,""", ""louvain""],. obsm_keys=[(""X_umap"", 0), (""X_umap"", 1)]. ). louvain_colors = dict(. zip(. adata.obs[""louvain""].cat.categories, . adata.uns[""louvain_colors""]. ). ). pts = (. ds.Canvas(1000, 1000). .points(df, ""X_umap-0"", ""X_umap-1"", agg=ds.count_cat(""louvain"")). ). # Make images. pts_ncats = (pts != 0).sum(axis=2). overlap_idx = pts_ncats == 1. zebra_source = xr.DataArray(. diagonal_bands_like(overlap_idx, 13),. coords=overlap_idx.coords. ). color_by_cluster = tf.shade(pts, color_key=louvain_colors). tf.Images(. color_by_cluster,. tf.stack(. tf.Image(xr.where(pts_ncats == 1, color_by_cluster, 0)),. tf.Image(tf.shade(xr.where(pts_ncats > 1, zebra_source, False), cmap=""black"")). ),. tf.stack(. color_by_cluster,. tf.Image(tf.shade(xr.where(pts_ncats > 1, zebra_source, False), cmap=""black"")). ),. ). ```. </details>. > I do think that randomization would result in sth similar to the datashader example you show though, except that it wouldn't change alphas by density. I wonder how either of these are effected by number of points. Say you have two cell types (A and B) in an overlapping region. . A has 10x the representation of B in this region, but it's only 10% of the A in this dataset, while this region has all of B. What the fair way to color this? If it were random, or purely by count this would look mostly like A. > I'm not sure if doing that is so helpful as it can lead to hardly being able to see small clusters in less dense regions of the plot. I think bin size would be helpful here. Additionally [datashader has methods](https://pyviz-dev.github.io/datashader/api.html#datashader.transfer_functions.dynspread) for exaggerating points in less dense regions so they are visible. This could be worth looking into. Update: Turns out `dynspread` uses global density, not local. The spread operators could still be of help here. Also, minimum alpha values can be set. Overall, I do like that there is a sense of density with the alpha levels, and wouldn't want to miss out on it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:2006,safety,except,except,2006,"3MM_processed.h5ad"", backed=""r""). df = sc.get.obs_df(. adata,. [""Sox17"", ""louvain""],. obsm_keys=[(""X_umap"", 0), (""X_umap"", 1)]. ). louvain_colors = dict(. zip(. adata.obs[""louvain""].cat.categories, . adata.uns[""louvain_colors""]. ). ). pts = (. ds.Canvas(1000, 1000). .points(df, ""X_umap-0"", ""X_umap-1"", agg=ds.count_cat(""louvain"")). ). # Make images. pts_ncats = (pts != 0).sum(axis=2). overlap_idx = pts_ncats == 1. zebra_source = xr.DataArray(. diagonal_bands_like(overlap_idx, 13),. coords=overlap_idx.coords. ). color_by_cluster = tf.shade(pts, color_key=louvain_colors). tf.Images(. color_by_cluster,. tf.stack(. tf.Image(xr.where(pts_ncats == 1, color_by_cluster, 0)),. tf.Image(tf.shade(xr.where(pts_ncats > 1, zebra_source, False), cmap=""black"")). ),. tf.stack(. color_by_cluster,. tf.Image(tf.shade(xr.where(pts_ncats > 1, zebra_source, False), cmap=""black"")). ),. ). ```. </details>. > I do think that randomization would result in sth similar to the datashader example you show though, except that it wouldn't change alphas by density. I wonder how either of these are effected by number of points. Say you have two cell types (A and B) in an overlapping region. . A has 10x the representation of B in this region, but it's only 10% of the A in this dataset, while this region has all of B. What the fair way to color this? If it were random, or purely by count this would look mostly like A. > I'm not sure if doing that is so helpful as it can lead to hardly being able to see small clusters in less dense regions of the plot. I think bin size would be helpful here. Additionally [datashader has methods](https://pyviz-dev.github.io/datashader/api.html#datashader.transfer_functions.dynspread) for exaggerating points in less dense regions so they are visible. This could be worth looking into. Update: Turns out `dynspread` uses global density, not local. The spread operators could still be of help here. Also, minimum alpha values can be set. Overall, I do like that there is a sense ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:2817,safety,Updat,Update,2817,""", ""louvain""],. obsm_keys=[(""X_umap"", 0), (""X_umap"", 1)]. ). louvain_colors = dict(. zip(. adata.obs[""louvain""].cat.categories, . adata.uns[""louvain_colors""]. ). ). pts = (. ds.Canvas(1000, 1000). .points(df, ""X_umap-0"", ""X_umap-1"", agg=ds.count_cat(""louvain"")). ). # Make images. pts_ncats = (pts != 0).sum(axis=2). overlap_idx = pts_ncats == 1. zebra_source = xr.DataArray(. diagonal_bands_like(overlap_idx, 13),. coords=overlap_idx.coords. ). color_by_cluster = tf.shade(pts, color_key=louvain_colors). tf.Images(. color_by_cluster,. tf.stack(. tf.Image(xr.where(pts_ncats == 1, color_by_cluster, 0)),. tf.Image(tf.shade(xr.where(pts_ncats > 1, zebra_source, False), cmap=""black"")). ),. tf.stack(. color_by_cluster,. tf.Image(tf.shade(xr.where(pts_ncats > 1, zebra_source, False), cmap=""black"")). ),. ). ```. </details>. > I do think that randomization would result in sth similar to the datashader example you show though, except that it wouldn't change alphas by density. I wonder how either of these are effected by number of points. Say you have two cell types (A and B) in an overlapping region. . A has 10x the representation of B in this region, but it's only 10% of the A in this dataset, while this region has all of B. What the fair way to color this? If it were random, or purely by count this would look mostly like A. > I'm not sure if doing that is so helpful as it can lead to hardly being able to see small clusters in less dense regions of the plot. I think bin size would be helpful here. Additionally [datashader has methods](https://pyviz-dev.github.io/datashader/api.html#datashader.transfer_functions.dynspread) for exaggerating points in less dense regions so they are visible. This could be worth looking into. Update: Turns out `dynspread` uses global density, not local. The spread operators could still be of help here. Also, minimum alpha values can be set. Overall, I do like that there is a sense of density with the alpha levels, and wouldn't want to miss out on it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:2817,security,Updat,Update,2817,""", ""louvain""],. obsm_keys=[(""X_umap"", 0), (""X_umap"", 1)]. ). louvain_colors = dict(. zip(. adata.obs[""louvain""].cat.categories, . adata.uns[""louvain_colors""]. ). ). pts = (. ds.Canvas(1000, 1000). .points(df, ""X_umap-0"", ""X_umap-1"", agg=ds.count_cat(""louvain"")). ). # Make images. pts_ncats = (pts != 0).sum(axis=2). overlap_idx = pts_ncats == 1. zebra_source = xr.DataArray(. diagonal_bands_like(overlap_idx, 13),. coords=overlap_idx.coords. ). color_by_cluster = tf.shade(pts, color_key=louvain_colors). tf.Images(. color_by_cluster,. tf.stack(. tf.Image(xr.where(pts_ncats == 1, color_by_cluster, 0)),. tf.Image(tf.shade(xr.where(pts_ncats > 1, zebra_source, False), cmap=""black"")). ),. tf.stack(. color_by_cluster,. tf.Image(tf.shade(xr.where(pts_ncats > 1, zebra_source, False), cmap=""black"")). ),. ). ```. </details>. > I do think that randomization would result in sth similar to the datashader example you show though, except that it wouldn't change alphas by density. I wonder how either of these are effected by number of points. Say you have two cell types (A and B) in an overlapping region. . A has 10x the representation of B in this region, but it's only 10% of the A in this dataset, while this region has all of B. What the fair way to color this? If it were random, or purely by count this would look mostly like A. > I'm not sure if doing that is so helpful as it can lead to hardly being able to see small clusters in less dense regions of the plot. I think bin size would be helpful here. Additionally [datashader has methods](https://pyviz-dev.github.io/datashader/api.html#datashader.transfer_functions.dynspread) for exaggerating points in less dense regions so they are visible. This could be worth looking into. Update: Turns out `dynspread` uses global density, not local. The spread operators could still be of help here. Also, minimum alpha values can be set. Overall, I do like that there is a sense of density with the alpha levels, and wouldn't want to miss out on it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:639,testability,assert,assert,639,"As an additional example, I was thinking about using [zebra-stripes (like a camera)](https://en.wikipedia.org/wiki/Zebra_patterning) for showing when information was hidden. Not sure if it's quite there yet, but its something:. <img width=""1318"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/104683802-c2f60980-574b-11eb-9a96-8d65e853739d.png"">. <details>. <summary> Code </summary>. ```python. import datashader as ds. from datashader import transfer_functions as tf. import numpy as np. import pandas as pd. from scipy import sparse. import xarray as xr. import scanpy as sc. def diagonal_bands_like(arr, width=3):. assert arr.ndim == 2. a = np.zeros_like(arr, dtype=bool). step = a.shape[1] + 1. # Not sure why end isn't making a difference. end = None. # end = a.shape[1] * a.shape[1]. fill = True. for i in range(arr.shape[0]):. if (i + width // 2) % width == 0:. fill = not fill. if fill:. a.flat[i:end:step] = True. return a. # Setup. adata = sc.read(""/Users/isaac/data/10x_mouse_13MM_processed.h5ad"", backed=""r""). df = sc.get.obs_df(. adata,. [""Sox17"", ""louvain""],. obsm_keys=[(""X_umap"", 0), (""X_umap"", 1)]. ). louvain_colors = dict(. zip(. adata.obs[""louvain""].cat.categories, . adata.uns[""louvain_colors""]. ). ). pts = (. ds.Canvas(1000, 1000). .points(df, ""X_umap-0"", ""X_umap-1"", agg=ds.count_cat(""louvain"")). ). # Make images. pts_ncats = (pts != 0).sum(axis=2). overlap_idx = pts_ncats == 1. zebra_source = xr.DataArray(. diagonal_bands_like(overlap_idx, 13),. coords=overlap_idx.coords. ). color_by_cluster = tf.shade(pts, color_key=louvain_colors). tf.Images(. color_by_cluster,. tf.stack(. tf.Image(xr.where(pts_ncats == 1, color_by_cluster, 0)),. tf.Image(tf.shade(xr.where(pts_ncats > 1, zebra_source, False), cmap=""black"")). ),. tf.stack(. color_by_cluster,. tf.Image(tf.shade(xr.where(pts_ncats > 1, zebra_source, False), cmap=""black"")). ),. ). ```. </details>. > I do think that randomization would result in sth similar to the datashader example you show th",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:271,usability,user,user-images,271,"As an additional example, I was thinking about using [zebra-stripes (like a camera)](https://en.wikipedia.org/wiki/Zebra_patterning) for showing when information was hidden. Not sure if it's quite there yet, but its something:. <img width=""1318"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/104683802-c2f60980-574b-11eb-9a96-8d65e853739d.png"">. <details>. <summary> Code </summary>. ```python. import datashader as ds. from datashader import transfer_functions as tf. import numpy as np. import pandas as pd. from scipy import sparse. import xarray as xr. import scanpy as sc. def diagonal_bands_like(arr, width=3):. assert arr.ndim == 2. a = np.zeros_like(arr, dtype=bool). step = a.shape[1] + 1. # Not sure why end isn't making a difference. end = None. # end = a.shape[1] * a.shape[1]. fill = True. for i in range(arr.shape[0]):. if (i + width // 2) % width == 0:. fill = not fill. if fill:. a.flat[i:end:step] = True. return a. # Setup. adata = sc.read(""/Users/isaac/data/10x_mouse_13MM_processed.h5ad"", backed=""r""). df = sc.get.obs_df(. adata,. [""Sox17"", ""louvain""],. obsm_keys=[(""X_umap"", 0), (""X_umap"", 1)]. ). louvain_colors = dict(. zip(. adata.obs[""louvain""].cat.categories, . adata.uns[""louvain_colors""]. ). ). pts = (. ds.Canvas(1000, 1000). .points(df, ""X_umap-0"", ""X_umap-1"", agg=ds.count_cat(""louvain"")). ). # Make images. pts_ncats = (pts != 0).sum(axis=2). overlap_idx = pts_ncats == 1. zebra_source = xr.DataArray(. diagonal_bands_like(overlap_idx, 13),. coords=overlap_idx.coords. ). color_by_cluster = tf.shade(pts, color_key=louvain_colors). tf.Images(. color_by_cluster,. tf.stack(. tf.Image(xr.where(pts_ncats == 1, color_by_cluster, 0)),. tf.Image(tf.shade(xr.where(pts_ncats > 1, zebra_source, False), cmap=""black"")). ),. tf.stack(. color_by_cluster,. tf.Image(tf.shade(xr.where(pts_ncats > 1, zebra_source, False), cmap=""black"")). ),. ). ```. </details>. > I do think that randomization would result in sth similar to the datashader example you show th",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:981,usability,User,Users,981,"As an additional example, I was thinking about using [zebra-stripes (like a camera)](https://en.wikipedia.org/wiki/Zebra_patterning) for showing when information was hidden. Not sure if it's quite there yet, but its something:. <img width=""1318"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/104683802-c2f60980-574b-11eb-9a96-8d65e853739d.png"">. <details>. <summary> Code </summary>. ```python. import datashader as ds. from datashader import transfer_functions as tf. import numpy as np. import pandas as pd. from scipy import sparse. import xarray as xr. import scanpy as sc. def diagonal_bands_like(arr, width=3):. assert arr.ndim == 2. a = np.zeros_like(arr, dtype=bool). step = a.shape[1] + 1. # Not sure why end isn't making a difference. end = None. # end = a.shape[1] * a.shape[1]. fill = True. for i in range(arr.shape[0]):. if (i + width // 2) % width == 0:. fill = not fill. if fill:. a.flat[i:end:step] = True. return a. # Setup. adata = sc.read(""/Users/isaac/data/10x_mouse_13MM_processed.h5ad"", backed=""r""). df = sc.get.obs_df(. adata,. [""Sox17"", ""louvain""],. obsm_keys=[(""X_umap"", 0), (""X_umap"", 1)]. ). louvain_colors = dict(. zip(. adata.obs[""louvain""].cat.categories, . adata.uns[""louvain_colors""]. ). ). pts = (. ds.Canvas(1000, 1000). .points(df, ""X_umap-0"", ""X_umap-1"", agg=ds.count_cat(""louvain"")). ). # Make images. pts_ncats = (pts != 0).sum(axis=2). overlap_idx = pts_ncats == 1. zebra_source = xr.DataArray(. diagonal_bands_like(overlap_idx, 13),. coords=overlap_idx.coords. ). color_by_cluster = tf.shade(pts, color_key=louvain_colors). tf.Images(. color_by_cluster,. tf.stack(. tf.Image(xr.where(pts_ncats == 1, color_by_cluster, 0)),. tf.Image(tf.shade(xr.where(pts_ncats > 1, zebra_source, False), cmap=""black"")). ),. tf.stack(. color_by_cluster,. tf.Image(tf.shade(xr.where(pts_ncats > 1, zebra_source, False), cmap=""black"")). ),. ). ```. </details>. > I do think that randomization would result in sth similar to the datashader example you show th",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:2448,usability,help,helpful,2448,""", ""louvain""],. obsm_keys=[(""X_umap"", 0), (""X_umap"", 1)]. ). louvain_colors = dict(. zip(. adata.obs[""louvain""].cat.categories, . adata.uns[""louvain_colors""]. ). ). pts = (. ds.Canvas(1000, 1000). .points(df, ""X_umap-0"", ""X_umap-1"", agg=ds.count_cat(""louvain"")). ). # Make images. pts_ncats = (pts != 0).sum(axis=2). overlap_idx = pts_ncats == 1. zebra_source = xr.DataArray(. diagonal_bands_like(overlap_idx, 13),. coords=overlap_idx.coords. ). color_by_cluster = tf.shade(pts, color_key=louvain_colors). tf.Images(. color_by_cluster,. tf.stack(. tf.Image(xr.where(pts_ncats == 1, color_by_cluster, 0)),. tf.Image(tf.shade(xr.where(pts_ncats > 1, zebra_source, False), cmap=""black"")). ),. tf.stack(. color_by_cluster,. tf.Image(tf.shade(xr.where(pts_ncats > 1, zebra_source, False), cmap=""black"")). ),. ). ```. </details>. > I do think that randomization would result in sth similar to the datashader example you show though, except that it wouldn't change alphas by density. I wonder how either of these are effected by number of points. Say you have two cell types (A and B) in an overlapping region. . A has 10x the representation of B in this region, but it's only 10% of the A in this dataset, while this region has all of B. What the fair way to color this? If it were random, or purely by count this would look mostly like A. > I'm not sure if doing that is so helpful as it can lead to hardly being able to see small clusters in less dense regions of the plot. I think bin size would be helpful here. Additionally [datashader has methods](https://pyviz-dev.github.io/datashader/api.html#datashader.transfer_functions.dynspread) for exaggerating points in less dense regions so they are visible. This could be worth looking into. Update: Turns out `dynspread` uses global density, not local. The spread operators could still be of help here. Also, minimum alpha values can be set. Overall, I do like that there is a sense of density with the alpha levels, and wouldn't want to miss out on it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:2575,usability,help,helpful,2575,""", ""louvain""],. obsm_keys=[(""X_umap"", 0), (""X_umap"", 1)]. ). louvain_colors = dict(. zip(. adata.obs[""louvain""].cat.categories, . adata.uns[""louvain_colors""]. ). ). pts = (. ds.Canvas(1000, 1000). .points(df, ""X_umap-0"", ""X_umap-1"", agg=ds.count_cat(""louvain"")). ). # Make images. pts_ncats = (pts != 0).sum(axis=2). overlap_idx = pts_ncats == 1. zebra_source = xr.DataArray(. diagonal_bands_like(overlap_idx, 13),. coords=overlap_idx.coords. ). color_by_cluster = tf.shade(pts, color_key=louvain_colors). tf.Images(. color_by_cluster,. tf.stack(. tf.Image(xr.where(pts_ncats == 1, color_by_cluster, 0)),. tf.Image(tf.shade(xr.where(pts_ncats > 1, zebra_source, False), cmap=""black"")). ),. tf.stack(. color_by_cluster,. tf.Image(tf.shade(xr.where(pts_ncats > 1, zebra_source, False), cmap=""black"")). ),. ). ```. </details>. > I do think that randomization would result in sth similar to the datashader example you show though, except that it wouldn't change alphas by density. I wonder how either of these are effected by number of points. Say you have two cell types (A and B) in an overlapping region. . A has 10x the representation of B in this region, but it's only 10% of the A in this dataset, while this region has all of B. What the fair way to color this? If it were random, or purely by count this would look mostly like A. > I'm not sure if doing that is so helpful as it can lead to hardly being able to see small clusters in less dense regions of the plot. I think bin size would be helpful here. Additionally [datashader has methods](https://pyviz-dev.github.io/datashader/api.html#datashader.transfer_functions.dynspread) for exaggerating points in less dense regions so they are visible. This could be worth looking into. Update: Turns out `dynspread` uses global density, not local. The spread operators could still be of help here. Also, minimum alpha values can be set. Overall, I do like that there is a sense of density with the alpha levels, and wouldn't want to miss out on it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:2918,usability,help,help,2918,""", ""louvain""],. obsm_keys=[(""X_umap"", 0), (""X_umap"", 1)]. ). louvain_colors = dict(. zip(. adata.obs[""louvain""].cat.categories, . adata.uns[""louvain_colors""]. ). ). pts = (. ds.Canvas(1000, 1000). .points(df, ""X_umap-0"", ""X_umap-1"", agg=ds.count_cat(""louvain"")). ). # Make images. pts_ncats = (pts != 0).sum(axis=2). overlap_idx = pts_ncats == 1. zebra_source = xr.DataArray(. diagonal_bands_like(overlap_idx, 13),. coords=overlap_idx.coords. ). color_by_cluster = tf.shade(pts, color_key=louvain_colors). tf.Images(. color_by_cluster,. tf.stack(. tf.Image(xr.where(pts_ncats == 1, color_by_cluster, 0)),. tf.Image(tf.shade(xr.where(pts_ncats > 1, zebra_source, False), cmap=""black"")). ),. tf.stack(. color_by_cluster,. tf.Image(tf.shade(xr.where(pts_ncats > 1, zebra_source, False), cmap=""black"")). ),. ). ```. </details>. > I do think that randomization would result in sth similar to the datashader example you show though, except that it wouldn't change alphas by density. I wonder how either of these are effected by number of points. Say you have two cell types (A and B) in an overlapping region. . A has 10x the representation of B in this region, but it's only 10% of the A in this dataset, while this region has all of B. What the fair way to color this? If it were random, or purely by count this would look mostly like A. > I'm not sure if doing that is so helpful as it can lead to hardly being able to see small clusters in less dense regions of the plot. I think bin size would be helpful here. Additionally [datashader has methods](https://pyviz-dev.github.io/datashader/api.html#datashader.transfer_functions.dynspread) for exaggerating points in less dense regions so they are visible. This could be worth looking into. Update: Turns out `dynspread` uses global density, not local. The spread operators could still be of help here. Also, minimum alpha values can be set. Overall, I do like that there is a sense of density with the alpha levels, and wouldn't want to miss out on it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:2935,usability,minim,minimum,2935,""", ""louvain""],. obsm_keys=[(""X_umap"", 0), (""X_umap"", 1)]. ). louvain_colors = dict(. zip(. adata.obs[""louvain""].cat.categories, . adata.uns[""louvain_colors""]. ). ). pts = (. ds.Canvas(1000, 1000). .points(df, ""X_umap-0"", ""X_umap-1"", agg=ds.count_cat(""louvain"")). ). # Make images. pts_ncats = (pts != 0).sum(axis=2). overlap_idx = pts_ncats == 1. zebra_source = xr.DataArray(. diagonal_bands_like(overlap_idx, 13),. coords=overlap_idx.coords. ). color_by_cluster = tf.shade(pts, color_key=louvain_colors). tf.Images(. color_by_cluster,. tf.stack(. tf.Image(xr.where(pts_ncats == 1, color_by_cluster, 0)),. tf.Image(tf.shade(xr.where(pts_ncats > 1, zebra_source, False), cmap=""black"")). ),. tf.stack(. color_by_cluster,. tf.Image(tf.shade(xr.where(pts_ncats > 1, zebra_source, False), cmap=""black"")). ),. ). ```. </details>. > I do think that randomization would result in sth similar to the datashader example you show though, except that it wouldn't change alphas by density. I wonder how either of these are effected by number of points. Say you have two cell types (A and B) in an overlapping region. . A has 10x the representation of B in this region, but it's only 10% of the A in this dataset, while this region has all of B. What the fair way to color this? If it were random, or purely by count this would look mostly like A. > I'm not sure if doing that is so helpful as it can lead to hardly being able to see small clusters in less dense regions of the plot. I think bin size would be helpful here. Additionally [datashader has methods](https://pyviz-dev.github.io/datashader/api.html#datashader.transfer_functions.dynspread) for exaggerating points in less dense regions so they are visible. This could be worth looking into. Update: Turns out `dynspread` uses global density, not local. The spread operators could still be of help here. Also, minimum alpha values can be set. Overall, I do like that there is a sense of density with the alpha levels, and wouldn't want to miss out on it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:410,modifiability,paramet,parameters,410,"We should make dynamic 3D plots ;-) . If I remember correctly, in the past we have the issue that the categorical colors were given by the adata.obs order and we change them such that they follow the order of the categories. Yet, I agree that a good mix of categorical colors is good sometimes. To address this issue I think that we can simply randomize the order if `sort_order=False` to avoid adding any new parameters. . Isaac's solution looks great for dealing with of lots of cells, something that I imagine will become more frequent. I think we should have a 'cookbook' where we can keep this and other information. I find this better than adding more and more functionality to the scatter plots.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:43,safety,reme,remember,43,"We should make dynamic 3D plots ;-) . If I remember correctly, in the past we have the issue that the categorical colors were given by the adata.obs order and we change them such that they follow the order of the categories. Yet, I agree that a good mix of categorical colors is good sometimes. To address this issue I think that we can simply randomize the order if `sort_order=False` to avoid adding any new parameters. . Isaac's solution looks great for dealing with of lots of cells, something that I imagine will become more frequent. I think we should have a 'cookbook' where we can keep this and other information. I find this better than adding more and more functionality to the scatter plots.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:389,safety,avoid,avoid,389,"We should make dynamic 3D plots ;-) . If I remember correctly, in the past we have the issue that the categorical colors were given by the adata.obs order and we change them such that they follow the order of the categories. Yet, I agree that a good mix of categorical colors is good sometimes. To address this issue I think that we can simply randomize the order if `sort_order=False` to avoid adding any new parameters. . Isaac's solution looks great for dealing with of lots of cells, something that I imagine will become more frequent. I think we should have a 'cookbook' where we can keep this and other information. I find this better than adding more and more functionality to the scatter plots.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:337,testability,simpl,simply,337,"We should make dynamic 3D plots ;-) . If I remember correctly, in the past we have the issue that the categorical colors were given by the adata.obs order and we change them such that they follow the order of the categories. Yet, I agree that a good mix of categorical colors is good sometimes. To address this issue I think that we can simply randomize the order if `sort_order=False` to avoid adding any new parameters. . Isaac's solution looks great for dealing with of lots of cells, something that I imagine will become more frequent. I think we should have a 'cookbook' where we can keep this and other information. I find this better than adding more and more functionality to the scatter plots.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:337,usability,simpl,simply,337,"We should make dynamic 3D plots ;-) . If I remember correctly, in the past we have the issue that the categorical colors were given by the adata.obs order and we change them such that they follow the order of the categories. Yet, I agree that a good mix of categorical colors is good sometimes. To address this issue I think that we can simply randomize the order if `sort_order=False` to avoid adding any new parameters. . Isaac's solution looks great for dealing with of lots of cells, something that I imagine will become more frequent. I think we should have a 'cookbook' where we can keep this and other information. I find this better than adding more and more functionality to the scatter plots.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:518,deployability,updat,update,518,"> What the fair way to color this? If it were random, or purely by count this would look mostly like A. I would argue that this would be fair. In the end it's about showing which cells are represented per pixel/pixel bin. And rare cell types shouldn't be up-weighted in that in an unbiased representation (if there is such a thing). In general I do like the idea of density being linked to transparency though. We could do a quick fix based on random order for now though, and then look into transparency for a larger update that would have to do with updating scanpy plotting to larger cell numbers?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:552,deployability,updat,updating,552,"> What the fair way to color this? If it were random, or purely by count this would look mostly like A. I would argue that this would be fair. In the end it's about showing which cells are represented per pixel/pixel bin. And rare cell types shouldn't be up-weighted in that in an unbiased representation (if there is such a thing). In general I do like the idea of density being linked to transparency though. We could do a quick fix based on random order for now though, and then look into transparency for a larger update that would have to do with updating scanpy plotting to larger cell numbers?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:518,safety,updat,update,518,"> What the fair way to color this? If it were random, or purely by count this would look mostly like A. I would argue that this would be fair. In the end it's about showing which cells are represented per pixel/pixel bin. And rare cell types shouldn't be up-weighted in that in an unbiased representation (if there is such a thing). In general I do like the idea of density being linked to transparency though. We could do a quick fix based on random order for now though, and then look into transparency for a larger update that would have to do with updating scanpy plotting to larger cell numbers?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:552,safety,updat,updating,552,"> What the fair way to color this? If it were random, or purely by count this would look mostly like A. I would argue that this would be fair. In the end it's about showing which cells are represented per pixel/pixel bin. And rare cell types shouldn't be up-weighted in that in an unbiased representation (if there is such a thing). In general I do like the idea of density being linked to transparency though. We could do a quick fix based on random order for now though, and then look into transparency for a larger update that would have to do with updating scanpy plotting to larger cell numbers?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:518,security,updat,update,518,"> What the fair way to color this? If it were random, or purely by count this would look mostly like A. I would argue that this would be fair. In the end it's about showing which cells are represented per pixel/pixel bin. And rare cell types shouldn't be up-weighted in that in an unbiased representation (if there is such a thing). In general I do like the idea of density being linked to transparency though. We could do a quick fix based on random order for now though, and then look into transparency for a larger update that would have to do with updating scanpy plotting to larger cell numbers?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:552,security,updat,updating,552,"> What the fair way to color this? If it were random, or purely by count this would look mostly like A. I would argue that this would be fair. In the end it's about showing which cells are represented per pixel/pixel bin. And rare cell types shouldn't be up-weighted in that in an unbiased representation (if there is such a thing). In general I do like the idea of density being linked to transparency though. We could do a quick fix based on random order for now though, and then look into transparency for a larger update that would have to do with updating scanpy plotting to larger cell numbers?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:1463,deployability,updat,update,1463,"> I think we should have a 'cookbook' where we can keep this and other information. I've been trying to be organized about keeping notebooks around for this ([here](https://github.com/ivirshup/notebooks/tree/master/plotting)). Of course, I rarely get the notebooks clean enough to push . > > In the end it's about showing which cells are represented per pixel/pixel bin. >. > I would argue that this would be fair. In the end it's about showing which cells are represented per pixel/pixel bin. Is it fair if coloring by batch and one dataset had fewer samples? Wouldn't you want to know that multiple batches were showing up in this region? I'm fairly convinced there is no good way to show this in one plot, other than telling users some information is hidden. > We could do a quick fix based on random order for now. I'm trying to think of the simplest way to implement this. I would like to keep the behaviour of `sort_order=False` just using the order from the anndata object. Some options:. * `sort_order=""random""`, this would make the order random, but we might need to add a seed argument. Also, do we still plot over null values? * `sort_order=order_array` where `order_array: np.ndarray[1, int]`. Basically, the user can pass whatever order they like. For random order it would be `np.random.choice(adata.n_obs, adata.n_obs, repeat=False)`. This is pretty flexible since it allows whatever order you want to be used without sorting the object. > larger update that would have to do with updating scanpy plotting to larger cell numbers? I think this might be worth a separate package, at least to start out. At least with how I'm handling it now, there would be a large number of dependencies. Plus, I think overplottting like this is an unsolved problem, so freedom to experiment in important.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:1497,deployability,updat,updating,1497,"> I think we should have a 'cookbook' where we can keep this and other information. I've been trying to be organized about keeping notebooks around for this ([here](https://github.com/ivirshup/notebooks/tree/master/plotting)). Of course, I rarely get the notebooks clean enough to push . > > In the end it's about showing which cells are represented per pixel/pixel bin. >. > I would argue that this would be fair. In the end it's about showing which cells are represented per pixel/pixel bin. Is it fair if coloring by batch and one dataset had fewer samples? Wouldn't you want to know that multiple batches were showing up in this region? I'm fairly convinced there is no good way to show this in one plot, other than telling users some information is hidden. > We could do a quick fix based on random order for now. I'm trying to think of the simplest way to implement this. I would like to keep the behaviour of `sort_order=False` just using the order from the anndata object. Some options:. * `sort_order=""random""`, this would make the order random, but we might need to add a seed argument. Also, do we still plot over null values? * `sort_order=order_array` where `order_array: np.ndarray[1, int]`. Basically, the user can pass whatever order they like. For random order it would be `np.random.choice(adata.n_obs, adata.n_obs, repeat=False)`. This is pretty flexible since it allows whatever order you want to be used without sorting the object. > larger update that would have to do with updating scanpy plotting to larger cell numbers? I think this might be worth a separate package, at least to start out. At least with how I'm handling it now, there would be a large number of dependencies. Plus, I think overplottting like this is an unsolved problem, so freedom to experiment in important.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:1689,deployability,depend,dependencies,1689,"> I think we should have a 'cookbook' where we can keep this and other information. I've been trying to be organized about keeping notebooks around for this ([here](https://github.com/ivirshup/notebooks/tree/master/plotting)). Of course, I rarely get the notebooks clean enough to push . > > In the end it's about showing which cells are represented per pixel/pixel bin. >. > I would argue that this would be fair. In the end it's about showing which cells are represented per pixel/pixel bin. Is it fair if coloring by batch and one dataset had fewer samples? Wouldn't you want to know that multiple batches were showing up in this region? I'm fairly convinced there is no good way to show this in one plot, other than telling users some information is hidden. > We could do a quick fix based on random order for now. I'm trying to think of the simplest way to implement this. I would like to keep the behaviour of `sort_order=False` just using the order from the anndata object. Some options:. * `sort_order=""random""`, this would make the order random, but we might need to add a seed argument. Also, do we still plot over null values? * `sort_order=order_array` where `order_array: np.ndarray[1, int]`. Basically, the user can pass whatever order they like. For random order it would be `np.random.choice(adata.n_obs, adata.n_obs, repeat=False)`. This is pretty flexible since it allows whatever order you want to be used without sorting the object. > larger update that would have to do with updating scanpy plotting to larger cell numbers? I think this might be worth a separate package, at least to start out. At least with how I'm handling it now, there would be a large number of dependencies. Plus, I think overplottting like this is an unsolved problem, so freedom to experiment in important.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:521,integrability,batch,batch,521,"> I think we should have a 'cookbook' where we can keep this and other information. I've been trying to be organized about keeping notebooks around for this ([here](https://github.com/ivirshup/notebooks/tree/master/plotting)). Of course, I rarely get the notebooks clean enough to push . > > In the end it's about showing which cells are represented per pixel/pixel bin. >. > I would argue that this would be fair. In the end it's about showing which cells are represented per pixel/pixel bin. Is it fair if coloring by batch and one dataset had fewer samples? Wouldn't you want to know that multiple batches were showing up in this region? I'm fairly convinced there is no good way to show this in one plot, other than telling users some information is hidden. > We could do a quick fix based on random order for now. I'm trying to think of the simplest way to implement this. I would like to keep the behaviour of `sort_order=False` just using the order from the anndata object. Some options:. * `sort_order=""random""`, this would make the order random, but we might need to add a seed argument. Also, do we still plot over null values? * `sort_order=order_array` where `order_array: np.ndarray[1, int]`. Basically, the user can pass whatever order they like. For random order it would be `np.random.choice(adata.n_obs, adata.n_obs, repeat=False)`. This is pretty flexible since it allows whatever order you want to be used without sorting the object. > larger update that would have to do with updating scanpy plotting to larger cell numbers? I think this might be worth a separate package, at least to start out. At least with how I'm handling it now, there would be a large number of dependencies. Plus, I think overplottting like this is an unsolved problem, so freedom to experiment in important.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:602,integrability,batch,batches,602,"> I think we should have a 'cookbook' where we can keep this and other information. I've been trying to be organized about keeping notebooks around for this ([here](https://github.com/ivirshup/notebooks/tree/master/plotting)). Of course, I rarely get the notebooks clean enough to push . > > In the end it's about showing which cells are represented per pixel/pixel bin. >. > I would argue that this would be fair. In the end it's about showing which cells are represented per pixel/pixel bin. Is it fair if coloring by batch and one dataset had fewer samples? Wouldn't you want to know that multiple batches were showing up in this region? I'm fairly convinced there is no good way to show this in one plot, other than telling users some information is hidden. > We could do a quick fix based on random order for now. I'm trying to think of the simplest way to implement this. I would like to keep the behaviour of `sort_order=False` just using the order from the anndata object. Some options:. * `sort_order=""random""`, this would make the order random, but we might need to add a seed argument. Also, do we still plot over null values? * `sort_order=order_array` where `order_array: np.ndarray[1, int]`. Basically, the user can pass whatever order they like. For random order it would be `np.random.choice(adata.n_obs, adata.n_obs, repeat=False)`. This is pretty flexible since it allows whatever order you want to be used without sorting the object. > larger update that would have to do with updating scanpy plotting to larger cell numbers? I think this might be worth a separate package, at least to start out. At least with how I'm handling it now, there would be a large number of dependencies. Plus, I think overplottting like this is an unsolved problem, so freedom to experiment in important.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:1689,integrability,depend,dependencies,1689,"> I think we should have a 'cookbook' where we can keep this and other information. I've been trying to be organized about keeping notebooks around for this ([here](https://github.com/ivirshup/notebooks/tree/master/plotting)). Of course, I rarely get the notebooks clean enough to push . > > In the end it's about showing which cells are represented per pixel/pixel bin. >. > I would argue that this would be fair. In the end it's about showing which cells are represented per pixel/pixel bin. Is it fair if coloring by batch and one dataset had fewer samples? Wouldn't you want to know that multiple batches were showing up in this region? I'm fairly convinced there is no good way to show this in one plot, other than telling users some information is hidden. > We could do a quick fix based on random order for now. I'm trying to think of the simplest way to implement this. I would like to keep the behaviour of `sort_order=False` just using the order from the anndata object. Some options:. * `sort_order=""random""`, this would make the order random, but we might need to add a seed argument. Also, do we still plot over null values? * `sort_order=order_array` where `order_array: np.ndarray[1, int]`. Basically, the user can pass whatever order they like. For random order it would be `np.random.choice(adata.n_obs, adata.n_obs, repeat=False)`. This is pretty flexible since it allows whatever order you want to be used without sorting the object. > larger update that would have to do with updating scanpy plotting to larger cell numbers? I think this might be worth a separate package, at least to start out. At least with how I'm handling it now, there would be a large number of dependencies. Plus, I think overplottting like this is an unsolved problem, so freedom to experiment in important.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:1585,modifiability,pac,package,1585,"> I think we should have a 'cookbook' where we can keep this and other information. I've been trying to be organized about keeping notebooks around for this ([here](https://github.com/ivirshup/notebooks/tree/master/plotting)). Of course, I rarely get the notebooks clean enough to push . > > In the end it's about showing which cells are represented per pixel/pixel bin. >. > I would argue that this would be fair. In the end it's about showing which cells are represented per pixel/pixel bin. Is it fair if coloring by batch and one dataset had fewer samples? Wouldn't you want to know that multiple batches were showing up in this region? I'm fairly convinced there is no good way to show this in one plot, other than telling users some information is hidden. > We could do a quick fix based on random order for now. I'm trying to think of the simplest way to implement this. I would like to keep the behaviour of `sort_order=False` just using the order from the anndata object. Some options:. * `sort_order=""random""`, this would make the order random, but we might need to add a seed argument. Also, do we still plot over null values? * `sort_order=order_array` where `order_array: np.ndarray[1, int]`. Basically, the user can pass whatever order they like. For random order it would be `np.random.choice(adata.n_obs, adata.n_obs, repeat=False)`. This is pretty flexible since it allows whatever order you want to be used without sorting the object. > larger update that would have to do with updating scanpy plotting to larger cell numbers? I think this might be worth a separate package, at least to start out. At least with how I'm handling it now, there would be a large number of dependencies. Plus, I think overplottting like this is an unsolved problem, so freedom to experiment in important.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:1689,modifiability,depend,dependencies,1689,"> I think we should have a 'cookbook' where we can keep this and other information. I've been trying to be organized about keeping notebooks around for this ([here](https://github.com/ivirshup/notebooks/tree/master/plotting)). Of course, I rarely get the notebooks clean enough to push . > > In the end it's about showing which cells are represented per pixel/pixel bin. >. > I would argue that this would be fair. In the end it's about showing which cells are represented per pixel/pixel bin. Is it fair if coloring by batch and one dataset had fewer samples? Wouldn't you want to know that multiple batches were showing up in this region? I'm fairly convinced there is no good way to show this in one plot, other than telling users some information is hidden. > We could do a quick fix based on random order for now. I'm trying to think of the simplest way to implement this. I would like to keep the behaviour of `sort_order=False` just using the order from the anndata object. Some options:. * `sort_order=""random""`, this would make the order random, but we might need to add a seed argument. Also, do we still plot over null values? * `sort_order=order_array` where `order_array: np.ndarray[1, int]`. Basically, the user can pass whatever order they like. For random order it would be `np.random.choice(adata.n_obs, adata.n_obs, repeat=False)`. This is pretty flexible since it allows whatever order you want to be used without sorting the object. > larger update that would have to do with updating scanpy plotting to larger cell numbers? I think this might be worth a separate package, at least to start out. At least with how I'm handling it now, there would be a large number of dependencies. Plus, I think overplottting like this is an unsolved problem, so freedom to experiment in important.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:521,performance,batch,batch,521,"> I think we should have a 'cookbook' where we can keep this and other information. I've been trying to be organized about keeping notebooks around for this ([here](https://github.com/ivirshup/notebooks/tree/master/plotting)). Of course, I rarely get the notebooks clean enough to push . > > In the end it's about showing which cells are represented per pixel/pixel bin. >. > I would argue that this would be fair. In the end it's about showing which cells are represented per pixel/pixel bin. Is it fair if coloring by batch and one dataset had fewer samples? Wouldn't you want to know that multiple batches were showing up in this region? I'm fairly convinced there is no good way to show this in one plot, other than telling users some information is hidden. > We could do a quick fix based on random order for now. I'm trying to think of the simplest way to implement this. I would like to keep the behaviour of `sort_order=False` just using the order from the anndata object. Some options:. * `sort_order=""random""`, this would make the order random, but we might need to add a seed argument. Also, do we still plot over null values? * `sort_order=order_array` where `order_array: np.ndarray[1, int]`. Basically, the user can pass whatever order they like. For random order it would be `np.random.choice(adata.n_obs, adata.n_obs, repeat=False)`. This is pretty flexible since it allows whatever order you want to be used without sorting the object. > larger update that would have to do with updating scanpy plotting to larger cell numbers? I think this might be worth a separate package, at least to start out. At least with how I'm handling it now, there would be a large number of dependencies. Plus, I think overplottting like this is an unsolved problem, so freedom to experiment in important.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:602,performance,batch,batches,602,"> I think we should have a 'cookbook' where we can keep this and other information. I've been trying to be organized about keeping notebooks around for this ([here](https://github.com/ivirshup/notebooks/tree/master/plotting)). Of course, I rarely get the notebooks clean enough to push . > > In the end it's about showing which cells are represented per pixel/pixel bin. >. > I would argue that this would be fair. In the end it's about showing which cells are represented per pixel/pixel bin. Is it fair if coloring by batch and one dataset had fewer samples? Wouldn't you want to know that multiple batches were showing up in this region? I'm fairly convinced there is no good way to show this in one plot, other than telling users some information is hidden. > We could do a quick fix based on random order for now. I'm trying to think of the simplest way to implement this. I would like to keep the behaviour of `sort_order=False` just using the order from the anndata object. Some options:. * `sort_order=""random""`, this would make the order random, but we might need to add a seed argument. Also, do we still plot over null values? * `sort_order=order_array` where `order_array: np.ndarray[1, int]`. Basically, the user can pass whatever order they like. For random order it would be `np.random.choice(adata.n_obs, adata.n_obs, repeat=False)`. This is pretty flexible since it allows whatever order you want to be used without sorting the object. > larger update that would have to do with updating scanpy plotting to larger cell numbers? I think this might be worth a separate package, at least to start out. At least with how I'm handling it now, there would be a large number of dependencies. Plus, I think overplottting like this is an unsolved problem, so freedom to experiment in important.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:1463,safety,updat,update,1463,"> I think we should have a 'cookbook' where we can keep this and other information. I've been trying to be organized about keeping notebooks around for this ([here](https://github.com/ivirshup/notebooks/tree/master/plotting)). Of course, I rarely get the notebooks clean enough to push . > > In the end it's about showing which cells are represented per pixel/pixel bin. >. > I would argue that this would be fair. In the end it's about showing which cells are represented per pixel/pixel bin. Is it fair if coloring by batch and one dataset had fewer samples? Wouldn't you want to know that multiple batches were showing up in this region? I'm fairly convinced there is no good way to show this in one plot, other than telling users some information is hidden. > We could do a quick fix based on random order for now. I'm trying to think of the simplest way to implement this. I would like to keep the behaviour of `sort_order=False` just using the order from the anndata object. Some options:. * `sort_order=""random""`, this would make the order random, but we might need to add a seed argument. Also, do we still plot over null values? * `sort_order=order_array` where `order_array: np.ndarray[1, int]`. Basically, the user can pass whatever order they like. For random order it would be `np.random.choice(adata.n_obs, adata.n_obs, repeat=False)`. This is pretty flexible since it allows whatever order you want to be used without sorting the object. > larger update that would have to do with updating scanpy plotting to larger cell numbers? I think this might be worth a separate package, at least to start out. At least with how I'm handling it now, there would be a large number of dependencies. Plus, I think overplottting like this is an unsolved problem, so freedom to experiment in important.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:1497,safety,updat,updating,1497,"> I think we should have a 'cookbook' where we can keep this and other information. I've been trying to be organized about keeping notebooks around for this ([here](https://github.com/ivirshup/notebooks/tree/master/plotting)). Of course, I rarely get the notebooks clean enough to push . > > In the end it's about showing which cells are represented per pixel/pixel bin. >. > I would argue that this would be fair. In the end it's about showing which cells are represented per pixel/pixel bin. Is it fair if coloring by batch and one dataset had fewer samples? Wouldn't you want to know that multiple batches were showing up in this region? I'm fairly convinced there is no good way to show this in one plot, other than telling users some information is hidden. > We could do a quick fix based on random order for now. I'm trying to think of the simplest way to implement this. I would like to keep the behaviour of `sort_order=False` just using the order from the anndata object. Some options:. * `sort_order=""random""`, this would make the order random, but we might need to add a seed argument. Also, do we still plot over null values? * `sort_order=order_array` where `order_array: np.ndarray[1, int]`. Basically, the user can pass whatever order they like. For random order it would be `np.random.choice(adata.n_obs, adata.n_obs, repeat=False)`. This is pretty flexible since it allows whatever order you want to be used without sorting the object. > larger update that would have to do with updating scanpy plotting to larger cell numbers? I think this might be worth a separate package, at least to start out. At least with how I'm handling it now, there would be a large number of dependencies. Plus, I think overplottting like this is an unsolved problem, so freedom to experiment in important.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:1689,safety,depend,dependencies,1689,"> I think we should have a 'cookbook' where we can keep this and other information. I've been trying to be organized about keeping notebooks around for this ([here](https://github.com/ivirshup/notebooks/tree/master/plotting)). Of course, I rarely get the notebooks clean enough to push . > > In the end it's about showing which cells are represented per pixel/pixel bin. >. > I would argue that this would be fair. In the end it's about showing which cells are represented per pixel/pixel bin. Is it fair if coloring by batch and one dataset had fewer samples? Wouldn't you want to know that multiple batches were showing up in this region? I'm fairly convinced there is no good way to show this in one plot, other than telling users some information is hidden. > We could do a quick fix based on random order for now. I'm trying to think of the simplest way to implement this. I would like to keep the behaviour of `sort_order=False` just using the order from the anndata object. Some options:. * `sort_order=""random""`, this would make the order random, but we might need to add a seed argument. Also, do we still plot over null values? * `sort_order=order_array` where `order_array: np.ndarray[1, int]`. Basically, the user can pass whatever order they like. For random order it would be `np.random.choice(adata.n_obs, adata.n_obs, repeat=False)`. This is pretty flexible since it allows whatever order you want to be used without sorting the object. > larger update that would have to do with updating scanpy plotting to larger cell numbers? I think this might be worth a separate package, at least to start out. At least with how I'm handling it now, there would be a large number of dependencies. Plus, I think overplottting like this is an unsolved problem, so freedom to experiment in important.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:1463,security,updat,update,1463,"> I think we should have a 'cookbook' where we can keep this and other information. I've been trying to be organized about keeping notebooks around for this ([here](https://github.com/ivirshup/notebooks/tree/master/plotting)). Of course, I rarely get the notebooks clean enough to push . > > In the end it's about showing which cells are represented per pixel/pixel bin. >. > I would argue that this would be fair. In the end it's about showing which cells are represented per pixel/pixel bin. Is it fair if coloring by batch and one dataset had fewer samples? Wouldn't you want to know that multiple batches were showing up in this region? I'm fairly convinced there is no good way to show this in one plot, other than telling users some information is hidden. > We could do a quick fix based on random order for now. I'm trying to think of the simplest way to implement this. I would like to keep the behaviour of `sort_order=False` just using the order from the anndata object. Some options:. * `sort_order=""random""`, this would make the order random, but we might need to add a seed argument. Also, do we still plot over null values? * `sort_order=order_array` where `order_array: np.ndarray[1, int]`. Basically, the user can pass whatever order they like. For random order it would be `np.random.choice(adata.n_obs, adata.n_obs, repeat=False)`. This is pretty flexible since it allows whatever order you want to be used without sorting the object. > larger update that would have to do with updating scanpy plotting to larger cell numbers? I think this might be worth a separate package, at least to start out. At least with how I'm handling it now, there would be a large number of dependencies. Plus, I think overplottting like this is an unsolved problem, so freedom to experiment in important.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:1497,security,updat,updating,1497,"> I think we should have a 'cookbook' where we can keep this and other information. I've been trying to be organized about keeping notebooks around for this ([here](https://github.com/ivirshup/notebooks/tree/master/plotting)). Of course, I rarely get the notebooks clean enough to push . > > In the end it's about showing which cells are represented per pixel/pixel bin. >. > I would argue that this would be fair. In the end it's about showing which cells are represented per pixel/pixel bin. Is it fair if coloring by batch and one dataset had fewer samples? Wouldn't you want to know that multiple batches were showing up in this region? I'm fairly convinced there is no good way to show this in one plot, other than telling users some information is hidden. > We could do a quick fix based on random order for now. I'm trying to think of the simplest way to implement this. I would like to keep the behaviour of `sort_order=False` just using the order from the anndata object. Some options:. * `sort_order=""random""`, this would make the order random, but we might need to add a seed argument. Also, do we still plot over null values? * `sort_order=order_array` where `order_array: np.ndarray[1, int]`. Basically, the user can pass whatever order they like. For random order it would be `np.random.choice(adata.n_obs, adata.n_obs, repeat=False)`. This is pretty flexible since it allows whatever order you want to be used without sorting the object. > larger update that would have to do with updating scanpy plotting to larger cell numbers? I think this might be worth a separate package, at least to start out. At least with how I'm handling it now, there would be a large number of dependencies. Plus, I think overplottting like this is an unsolved problem, so freedom to experiment in important.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:847,testability,simpl,simplest,847,"> I think we should have a 'cookbook' where we can keep this and other information. I've been trying to be organized about keeping notebooks around for this ([here](https://github.com/ivirshup/notebooks/tree/master/plotting)). Of course, I rarely get the notebooks clean enough to push . > > In the end it's about showing which cells are represented per pixel/pixel bin. >. > I would argue that this would be fair. In the end it's about showing which cells are represented per pixel/pixel bin. Is it fair if coloring by batch and one dataset had fewer samples? Wouldn't you want to know that multiple batches were showing up in this region? I'm fairly convinced there is no good way to show this in one plot, other than telling users some information is hidden. > We could do a quick fix based on random order for now. I'm trying to think of the simplest way to implement this. I would like to keep the behaviour of `sort_order=False` just using the order from the anndata object. Some options:. * `sort_order=""random""`, this would make the order random, but we might need to add a seed argument. Also, do we still plot over null values? * `sort_order=order_array` where `order_array: np.ndarray[1, int]`. Basically, the user can pass whatever order they like. For random order it would be `np.random.choice(adata.n_obs, adata.n_obs, repeat=False)`. This is pretty flexible since it allows whatever order you want to be used without sorting the object. > larger update that would have to do with updating scanpy plotting to larger cell numbers? I think this might be worth a separate package, at least to start out. At least with how I'm handling it now, there would be a large number of dependencies. Plus, I think overplottting like this is an unsolved problem, so freedom to experiment in important.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:1689,testability,depend,dependencies,1689,"> I think we should have a 'cookbook' where we can keep this and other information. I've been trying to be organized about keeping notebooks around for this ([here](https://github.com/ivirshup/notebooks/tree/master/plotting)). Of course, I rarely get the notebooks clean enough to push . > > In the end it's about showing which cells are represented per pixel/pixel bin. >. > I would argue that this would be fair. In the end it's about showing which cells are represented per pixel/pixel bin. Is it fair if coloring by batch and one dataset had fewer samples? Wouldn't you want to know that multiple batches were showing up in this region? I'm fairly convinced there is no good way to show this in one plot, other than telling users some information is hidden. > We could do a quick fix based on random order for now. I'm trying to think of the simplest way to implement this. I would like to keep the behaviour of `sort_order=False` just using the order from the anndata object. Some options:. * `sort_order=""random""`, this would make the order random, but we might need to add a seed argument. Also, do we still plot over null values? * `sort_order=order_array` where `order_array: np.ndarray[1, int]`. Basically, the user can pass whatever order they like. For random order it would be `np.random.choice(adata.n_obs, adata.n_obs, repeat=False)`. This is pretty flexible since it allows whatever order you want to be used without sorting the object. > larger update that would have to do with updating scanpy plotting to larger cell numbers? I think this might be worth a separate package, at least to start out. At least with how I'm handling it now, there would be a large number of dependencies. Plus, I think overplottting like this is an unsolved problem, so freedom to experiment in important.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:729,usability,user,users,729,"> I think we should have a 'cookbook' where we can keep this and other information. I've been trying to be organized about keeping notebooks around for this ([here](https://github.com/ivirshup/notebooks/tree/master/plotting)). Of course, I rarely get the notebooks clean enough to push . > > In the end it's about showing which cells are represented per pixel/pixel bin. >. > I would argue that this would be fair. In the end it's about showing which cells are represented per pixel/pixel bin. Is it fair if coloring by batch and one dataset had fewer samples? Wouldn't you want to know that multiple batches were showing up in this region? I'm fairly convinced there is no good way to show this in one plot, other than telling users some information is hidden. > We could do a quick fix based on random order for now. I'm trying to think of the simplest way to implement this. I would like to keep the behaviour of `sort_order=False` just using the order from the anndata object. Some options:. * `sort_order=""random""`, this would make the order random, but we might need to add a seed argument. Also, do we still plot over null values? * `sort_order=order_array` where `order_array: np.ndarray[1, int]`. Basically, the user can pass whatever order they like. For random order it would be `np.random.choice(adata.n_obs, adata.n_obs, repeat=False)`. This is pretty flexible since it allows whatever order you want to be used without sorting the object. > larger update that would have to do with updating scanpy plotting to larger cell numbers? I think this might be worth a separate package, at least to start out. At least with how I'm handling it now, there would be a large number of dependencies. Plus, I think overplottting like this is an unsolved problem, so freedom to experiment in important.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:847,usability,simpl,simplest,847,"> I think we should have a 'cookbook' where we can keep this and other information. I've been trying to be organized about keeping notebooks around for this ([here](https://github.com/ivirshup/notebooks/tree/master/plotting)). Of course, I rarely get the notebooks clean enough to push . > > In the end it's about showing which cells are represented per pixel/pixel bin. >. > I would argue that this would be fair. In the end it's about showing which cells are represented per pixel/pixel bin. Is it fair if coloring by batch and one dataset had fewer samples? Wouldn't you want to know that multiple batches were showing up in this region? I'm fairly convinced there is no good way to show this in one plot, other than telling users some information is hidden. > We could do a quick fix based on random order for now. I'm trying to think of the simplest way to implement this. I would like to keep the behaviour of `sort_order=False` just using the order from the anndata object. Some options:. * `sort_order=""random""`, this would make the order random, but we might need to add a seed argument. Also, do we still plot over null values? * `sort_order=order_array` where `order_array: np.ndarray[1, int]`. Basically, the user can pass whatever order they like. For random order it would be `np.random.choice(adata.n_obs, adata.n_obs, repeat=False)`. This is pretty flexible since it allows whatever order you want to be used without sorting the object. > larger update that would have to do with updating scanpy plotting to larger cell numbers? I think this might be worth a separate package, at least to start out. At least with how I'm handling it now, there would be a large number of dependencies. Plus, I think overplottting like this is an unsolved problem, so freedom to experiment in important.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:904,usability,behavi,behaviour,904,"> I think we should have a 'cookbook' where we can keep this and other information. I've been trying to be organized about keeping notebooks around for this ([here](https://github.com/ivirshup/notebooks/tree/master/plotting)). Of course, I rarely get the notebooks clean enough to push . > > In the end it's about showing which cells are represented per pixel/pixel bin. >. > I would argue that this would be fair. In the end it's about showing which cells are represented per pixel/pixel bin. Is it fair if coloring by batch and one dataset had fewer samples? Wouldn't you want to know that multiple batches were showing up in this region? I'm fairly convinced there is no good way to show this in one plot, other than telling users some information is hidden. > We could do a quick fix based on random order for now. I'm trying to think of the simplest way to implement this. I would like to keep the behaviour of `sort_order=False` just using the order from the anndata object. Some options:. * `sort_order=""random""`, this would make the order random, but we might need to add a seed argument. Also, do we still plot over null values? * `sort_order=order_array` where `order_array: np.ndarray[1, int]`. Basically, the user can pass whatever order they like. For random order it would be `np.random.choice(adata.n_obs, adata.n_obs, repeat=False)`. This is pretty flexible since it allows whatever order you want to be used without sorting the object. > larger update that would have to do with updating scanpy plotting to larger cell numbers? I think this might be worth a separate package, at least to start out. At least with how I'm handling it now, there would be a large number of dependencies. Plus, I think overplottting like this is an unsolved problem, so freedom to experiment in important.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:1222,usability,user,user,1222,"> I think we should have a 'cookbook' where we can keep this and other information. I've been trying to be organized about keeping notebooks around for this ([here](https://github.com/ivirshup/notebooks/tree/master/plotting)). Of course, I rarely get the notebooks clean enough to push . > > In the end it's about showing which cells are represented per pixel/pixel bin. >. > I would argue that this would be fair. In the end it's about showing which cells are represented per pixel/pixel bin. Is it fair if coloring by batch and one dataset had fewer samples? Wouldn't you want to know that multiple batches were showing up in this region? I'm fairly convinced there is no good way to show this in one plot, other than telling users some information is hidden. > We could do a quick fix based on random order for now. I'm trying to think of the simplest way to implement this. I would like to keep the behaviour of `sort_order=False` just using the order from the anndata object. Some options:. * `sort_order=""random""`, this would make the order random, but we might need to add a seed argument. Also, do we still plot over null values? * `sort_order=order_array` where `order_array: np.ndarray[1, int]`. Basically, the user can pass whatever order they like. For random order it would be `np.random.choice(adata.n_obs, adata.n_obs, repeat=False)`. This is pretty flexible since it allows whatever order you want to be used without sorting the object. > larger update that would have to do with updating scanpy plotting to larger cell numbers? I think this might be worth a separate package, at least to start out. At least with how I'm handling it now, there would be a large number of dependencies. Plus, I think overplottting like this is an unsolved problem, so freedom to experiment in important.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:48,reliability,Doe,Does,48,"@ivirshup I like your notebooks for a cookbook. Does it need to be super organized to add it to the readthedocs page? . Regarding the options, I like the `sort_order='random'`. . The `order_array` option would be equivalent to `sc.pl.embedding(adata[adata.obs.sample(frac=1).index], ...)` for `random` or any other sorting from of the adata object. The point is that user defined sorting is already covered. The only advantage of `sort_order=order_array` is that is explicit for the user.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:367,usability,user,user,367,"@ivirshup I like your notebooks for a cookbook. Does it need to be super organized to add it to the readthedocs page? . Regarding the options, I like the `sort_order='random'`. . The `order_array` option would be equivalent to `sc.pl.embedding(adata[adata.obs.sample(frac=1).index], ...)` for `random` or any other sorting from of the adata object. The point is that user defined sorting is already covered. The only advantage of `sort_order=order_array` is that is explicit for the user.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:483,usability,user,user,483,"@ivirshup I like your notebooks for a cookbook. Does it need to be super organized to add it to the readthedocs page? . Regarding the options, I like the `sort_order='random'`. . The `order_array` option would be equivalent to `sc.pl.embedding(adata[adata.obs.sample(frac=1).index], ...)` for `random` or any other sorting from of the adata object. The point is that user defined sorting is already covered. The only advantage of `sort_order=order_array` is that is explicit for the user.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:737,deployability,continu,continuous,737,"> The only advantage of sort_order=order_array is that is explicit for the user. Another advantage is that it could be user specified per plot when there are multiple plots. -------------------. I think there is another issue, which is that `sort_order` currently just applies to numeric values while here we are trying to deal with issues around categorical values. To me this suggests a need to have separate arguments for the two cases (`order_categorical`, `order_continuous`), though this raises issues with ""vectorizing"" the argument. Docstrings for these arguments would look something like:. ```rst. order_continuous: Literal[""current"", ""random"", ""ascending"", ""descending""] = ""ascending"". How to order points in plots colored by continuous values. Options include:. * ""current"": use current ordering of AnnData object. * ""random"": randomize the order. * ""ascending"": points with the highest value are plotted on top. * ""descending"": points with lowest value are plotted on top. order_categorical: Literal[""current"", ""random"", ""ascending"", ""descending""] = ""random"". How to order non-null categorical points in the plot. Uses same options as order_continuous. ```. In this case, `sort_order` would be deprecated, and tell the user to use `order_continuous` instead. ## Potential extensions. * We could also allow users to pass `Callable[Vector, Vector[int]]`s (e.g. function which takes color vector, returns vector of integers) as arguments. ## Possible issues. ### Vectorization could be complicated. Vectorization of argument unclear/ maybe not possible. That is, what if I want the same variable twice, but ordered differently? This would look like: . ```python. sc.pl.umap(adata, color=[""CD8"", ""CD8""], order_continuous=[""ascending"", ""descending""]). ```. Now what if I wanted to also plot a categorical value? Is this: . ```python. sc.pl.umap(adata, color=[""CD8"", ""CD8"", ""leiden""], order_continuous=[""ascending"", ""descending"", None]). ```. ### Null values. This solution assumes we still wa",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:254,energy efficiency,current,currently,254,"> The only advantage of sort_order=order_array is that is explicit for the user. Another advantage is that it could be user specified per plot when there are multiple plots. -------------------. I think there is another issue, which is that `sort_order` currently just applies to numeric values while here we are trying to deal with issues around categorical values. To me this suggests a need to have separate arguments for the two cases (`order_categorical`, `order_continuous`), though this raises issues with ""vectorizing"" the argument. Docstrings for these arguments would look something like:. ```rst. order_continuous: Literal[""current"", ""random"", ""ascending"", ""descending""] = ""ascending"". How to order points in plots colored by continuous values. Options include:. * ""current"": use current ordering of AnnData object. * ""random"": randomize the order. * ""ascending"": points with the highest value are plotted on top. * ""descending"": points with lowest value are plotted on top. order_categorical: Literal[""current"", ""random"", ""ascending"", ""descending""] = ""random"". How to order non-null categorical points in the plot. Uses same options as order_continuous. ```. In this case, `sort_order` would be deprecated, and tell the user to use `order_continuous` instead. ## Potential extensions. * We could also allow users to pass `Callable[Vector, Vector[int]]`s (e.g. function which takes color vector, returns vector of integers) as arguments. ## Possible issues. ### Vectorization could be complicated. Vectorization of argument unclear/ maybe not possible. That is, what if I want the same variable twice, but ordered differently? This would look like: . ```python. sc.pl.umap(adata, color=[""CD8"", ""CD8""], order_continuous=[""ascending"", ""descending""]). ```. Now what if I wanted to also plot a categorical value? Is this: . ```python. sc.pl.umap(adata, color=[""CD8"", ""CD8"", ""leiden""], order_continuous=[""ascending"", ""descending"", None]). ```. ### Null values. This solution assumes we still wa",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:635,energy efficiency,current,current,635,"> The only advantage of sort_order=order_array is that is explicit for the user. Another advantage is that it could be user specified per plot when there are multiple plots. -------------------. I think there is another issue, which is that `sort_order` currently just applies to numeric values while here we are trying to deal with issues around categorical values. To me this suggests a need to have separate arguments for the two cases (`order_categorical`, `order_continuous`), though this raises issues with ""vectorizing"" the argument. Docstrings for these arguments would look something like:. ```rst. order_continuous: Literal[""current"", ""random"", ""ascending"", ""descending""] = ""ascending"". How to order points in plots colored by continuous values. Options include:. * ""current"": use current ordering of AnnData object. * ""random"": randomize the order. * ""ascending"": points with the highest value are plotted on top. * ""descending"": points with lowest value are plotted on top. order_categorical: Literal[""current"", ""random"", ""ascending"", ""descending""] = ""random"". How to order non-null categorical points in the plot. Uses same options as order_continuous. ```. In this case, `sort_order` would be deprecated, and tell the user to use `order_continuous` instead. ## Potential extensions. * We could also allow users to pass `Callable[Vector, Vector[int]]`s (e.g. function which takes color vector, returns vector of integers) as arguments. ## Possible issues. ### Vectorization could be complicated. Vectorization of argument unclear/ maybe not possible. That is, what if I want the same variable twice, but ordered differently? This would look like: . ```python. sc.pl.umap(adata, color=[""CD8"", ""CD8""], order_continuous=[""ascending"", ""descending""]). ```. Now what if I wanted to also plot a categorical value? Is this: . ```python. sc.pl.umap(adata, color=[""CD8"", ""CD8"", ""leiden""], order_continuous=[""ascending"", ""descending"", None]). ```. ### Null values. This solution assumes we still wa",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:777,energy efficiency,current,current,777,"> The only advantage of sort_order=order_array is that is explicit for the user. Another advantage is that it could be user specified per plot when there are multiple plots. -------------------. I think there is another issue, which is that `sort_order` currently just applies to numeric values while here we are trying to deal with issues around categorical values. To me this suggests a need to have separate arguments for the two cases (`order_categorical`, `order_continuous`), though this raises issues with ""vectorizing"" the argument. Docstrings for these arguments would look something like:. ```rst. order_continuous: Literal[""current"", ""random"", ""ascending"", ""descending""] = ""ascending"". How to order points in plots colored by continuous values. Options include:. * ""current"": use current ordering of AnnData object. * ""random"": randomize the order. * ""ascending"": points with the highest value are plotted on top. * ""descending"": points with lowest value are plotted on top. order_categorical: Literal[""current"", ""random"", ""ascending"", ""descending""] = ""random"". How to order non-null categorical points in the plot. Uses same options as order_continuous. ```. In this case, `sort_order` would be deprecated, and tell the user to use `order_continuous` instead. ## Potential extensions. * We could also allow users to pass `Callable[Vector, Vector[int]]`s (e.g. function which takes color vector, returns vector of integers) as arguments. ## Possible issues. ### Vectorization could be complicated. Vectorization of argument unclear/ maybe not possible. That is, what if I want the same variable twice, but ordered differently? This would look like: . ```python. sc.pl.umap(adata, color=[""CD8"", ""CD8""], order_continuous=[""ascending"", ""descending""]). ```. Now what if I wanted to also plot a categorical value? Is this: . ```python. sc.pl.umap(adata, color=[""CD8"", ""CD8"", ""leiden""], order_continuous=[""ascending"", ""descending"", None]). ```. ### Null values. This solution assumes we still wa",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:791,energy efficiency,current,current,791,"> The only advantage of sort_order=order_array is that is explicit for the user. Another advantage is that it could be user specified per plot when there are multiple plots. -------------------. I think there is another issue, which is that `sort_order` currently just applies to numeric values while here we are trying to deal with issues around categorical values. To me this suggests a need to have separate arguments for the two cases (`order_categorical`, `order_continuous`), though this raises issues with ""vectorizing"" the argument. Docstrings for these arguments would look something like:. ```rst. order_continuous: Literal[""current"", ""random"", ""ascending"", ""descending""] = ""ascending"". How to order points in plots colored by continuous values. Options include:. * ""current"": use current ordering of AnnData object. * ""random"": randomize the order. * ""ascending"": points with the highest value are plotted on top. * ""descending"": points with lowest value are plotted on top. order_categorical: Literal[""current"", ""random"", ""ascending"", ""descending""] = ""random"". How to order non-null categorical points in the plot. Uses same options as order_continuous. ```. In this case, `sort_order` would be deprecated, and tell the user to use `order_continuous` instead. ## Potential extensions. * We could also allow users to pass `Callable[Vector, Vector[int]]`s (e.g. function which takes color vector, returns vector of integers) as arguments. ## Possible issues. ### Vectorization could be complicated. Vectorization of argument unclear/ maybe not possible. That is, what if I want the same variable twice, but ordered differently? This would look like: . ```python. sc.pl.umap(adata, color=[""CD8"", ""CD8""], order_continuous=[""ascending"", ""descending""]). ```. Now what if I wanted to also plot a categorical value? Is this: . ```python. sc.pl.umap(adata, color=[""CD8"", ""CD8"", ""leiden""], order_continuous=[""ascending"", ""descending"", None]). ```. ### Null values. This solution assumes we still wa",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:1014,energy efficiency,current,current,1014,"ge of sort_order=order_array is that is explicit for the user. Another advantage is that it could be user specified per plot when there are multiple plots. -------------------. I think there is another issue, which is that `sort_order` currently just applies to numeric values while here we are trying to deal with issues around categorical values. To me this suggests a need to have separate arguments for the two cases (`order_categorical`, `order_continuous`), though this raises issues with ""vectorizing"" the argument. Docstrings for these arguments would look something like:. ```rst. order_continuous: Literal[""current"", ""random"", ""ascending"", ""descending""] = ""ascending"". How to order points in plots colored by continuous values. Options include:. * ""current"": use current ordering of AnnData object. * ""random"": randomize the order. * ""ascending"": points with the highest value are plotted on top. * ""descending"": points with lowest value are plotted on top. order_categorical: Literal[""current"", ""random"", ""ascending"", ""descending""] = ""random"". How to order non-null categorical points in the plot. Uses same options as order_continuous. ```. In this case, `sort_order` would be deprecated, and tell the user to use `order_continuous` instead. ## Potential extensions. * We could also allow users to pass `Callable[Vector, Vector[int]]`s (e.g. function which takes color vector, returns vector of integers) as arguments. ## Possible issues. ### Vectorization could be complicated. Vectorization of argument unclear/ maybe not possible. That is, what if I want the same variable twice, but ordered differently? This would look like: . ```python. sc.pl.umap(adata, color=[""CD8"", ""CD8""], order_continuous=[""ascending"", ""descending""]). ```. Now what if I wanted to also plot a categorical value? Is this: . ```python. sc.pl.umap(adata, color=[""CD8"", ""CD8"", ""leiden""], order_continuous=[""ascending"", ""descending"", None]). ```. ### Null values. This solution assumes we still want null values plo",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:2178,energy efficiency,core,core,2178,"with issues around categorical values. To me this suggests a need to have separate arguments for the two cases (`order_categorical`, `order_continuous`), though this raises issues with ""vectorizing"" the argument. Docstrings for these arguments would look something like:. ```rst. order_continuous: Literal[""current"", ""random"", ""ascending"", ""descending""] = ""ascending"". How to order points in plots colored by continuous values. Options include:. * ""current"": use current ordering of AnnData object. * ""random"": randomize the order. * ""ascending"": points with the highest value are plotted on top. * ""descending"": points with lowest value are plotted on top. order_categorical: Literal[""current"", ""random"", ""ascending"", ""descending""] = ""random"". How to order non-null categorical points in the plot. Uses same options as order_continuous. ```. In this case, `sort_order` would be deprecated, and tell the user to use `order_continuous` instead. ## Potential extensions. * We could also allow users to pass `Callable[Vector, Vector[int]]`s (e.g. function which takes color vector, returns vector of integers) as arguments. ## Possible issues. ### Vectorization could be complicated. Vectorization of argument unclear/ maybe not possible. That is, what if I want the same variable twice, but ordered differently? This would look like: . ```python. sc.pl.umap(adata, color=[""CD8"", ""CD8""], order_continuous=[""ascending"", ""descending""]). ```. Now what if I wanted to also plot a categorical value? Is this: . ```python. sc.pl.umap(adata, color=[""CD8"", ""CD8"", ""leiden""], order_continuous=[""ascending"", ""descending"", None]). ```. ### Null values. This solution assumes we still want null values plotted on bottom. Should there be control over that? ## Some references for other libraries:. * [`altair.Sort`](https://altair-viz.github.io/user_guide/generated/core/altair.Sort.html#altair.Sort). * (I'm actually not sure if other libraries do this, datashader does `max`/ `min`/ `mean` which is sorta similar?)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:124,interoperability,specif,specified,124,"> The only advantage of sort_order=order_array is that is explicit for the user. Another advantage is that it could be user specified per plot when there are multiple plots. -------------------. I think there is another issue, which is that `sort_order` currently just applies to numeric values while here we are trying to deal with issues around categorical values. To me this suggests a need to have separate arguments for the two cases (`order_categorical`, `order_continuous`), though this raises issues with ""vectorizing"" the argument. Docstrings for these arguments would look something like:. ```rst. order_continuous: Literal[""current"", ""random"", ""ascending"", ""descending""] = ""ascending"". How to order points in plots colored by continuous values. Options include:. * ""current"": use current ordering of AnnData object. * ""random"": randomize the order. * ""ascending"": points with the highest value are plotted on top. * ""descending"": points with lowest value are plotted on top. order_categorical: Literal[""current"", ""random"", ""ascending"", ""descending""] = ""random"". How to order non-null categorical points in the plot. Uses same options as order_continuous. ```. In this case, `sort_order` would be deprecated, and tell the user to use `order_continuous` instead. ## Potential extensions. * We could also allow users to pass `Callable[Vector, Vector[int]]`s (e.g. function which takes color vector, returns vector of integers) as arguments. ## Possible issues. ### Vectorization could be complicated. Vectorization of argument unclear/ maybe not possible. That is, what if I want the same variable twice, but ordered differently? This would look like: . ```python. sc.pl.umap(adata, color=[""CD8"", ""CD8""], order_continuous=[""ascending"", ""descending""]). ```. Now what if I wanted to also plot a categorical value? Is this: . ```python. sc.pl.umap(adata, color=[""CD8"", ""CD8"", ""leiden""], order_continuous=[""ascending"", ""descending"", None]). ```. ### Null values. This solution assumes we still wa",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:1285,modifiability,extens,extensions,1285,"lues while here we are trying to deal with issues around categorical values. To me this suggests a need to have separate arguments for the two cases (`order_categorical`, `order_continuous`), though this raises issues with ""vectorizing"" the argument. Docstrings for these arguments would look something like:. ```rst. order_continuous: Literal[""current"", ""random"", ""ascending"", ""descending""] = ""ascending"". How to order points in plots colored by continuous values. Options include:. * ""current"": use current ordering of AnnData object. * ""random"": randomize the order. * ""ascending"": points with the highest value are plotted on top. * ""descending"": points with lowest value are plotted on top. order_categorical: Literal[""current"", ""random"", ""ascending"", ""descending""] = ""random"". How to order non-null categorical points in the plot. Uses same options as order_continuous. ```. In this case, `sort_order` would be deprecated, and tell the user to use `order_continuous` instead. ## Potential extensions. * We could also allow users to pass `Callable[Vector, Vector[int]]`s (e.g. function which takes color vector, returns vector of integers) as arguments. ## Possible issues. ### Vectorization could be complicated. Vectorization of argument unclear/ maybe not possible. That is, what if I want the same variable twice, but ordered differently? This would look like: . ```python. sc.pl.umap(adata, color=[""CD8"", ""CD8""], order_continuous=[""ascending"", ""descending""]). ```. Now what if I wanted to also plot a categorical value? Is this: . ```python. sc.pl.umap(adata, color=[""CD8"", ""CD8"", ""leiden""], order_continuous=[""ascending"", ""descending"", None]). ```. ### Null values. This solution assumes we still want null values plotted on bottom. Should there be control over that? ## Some references for other libraries:. * [`altair.Sort`](https://altair-viz.github.io/user_guide/generated/core/altair.Sort.html#altair.Sort). * (I'm actually not sure if other libraries do this, datashader does `max`/ ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:1597,modifiability,variab,variable,1597,"with issues around categorical values. To me this suggests a need to have separate arguments for the two cases (`order_categorical`, `order_continuous`), though this raises issues with ""vectorizing"" the argument. Docstrings for these arguments would look something like:. ```rst. order_continuous: Literal[""current"", ""random"", ""ascending"", ""descending""] = ""ascending"". How to order points in plots colored by continuous values. Options include:. * ""current"": use current ordering of AnnData object. * ""random"": randomize the order. * ""ascending"": points with the highest value are plotted on top. * ""descending"": points with lowest value are plotted on top. order_categorical: Literal[""current"", ""random"", ""ascending"", ""descending""] = ""random"". How to order non-null categorical points in the plot. Uses same options as order_continuous. ```. In this case, `sort_order` would be deprecated, and tell the user to use `order_continuous` instead. ## Potential extensions. * We could also allow users to pass `Callable[Vector, Vector[int]]`s (e.g. function which takes color vector, returns vector of integers) as arguments. ## Possible issues. ### Vectorization could be complicated. Vectorization of argument unclear/ maybe not possible. That is, what if I want the same variable twice, but ordered differently? This would look like: . ```python. sc.pl.umap(adata, color=[""CD8"", ""CD8""], order_continuous=[""ascending"", ""descending""]). ```. Now what if I wanted to also plot a categorical value? Is this: . ```python. sc.pl.umap(adata, color=[""CD8"", ""CD8"", ""leiden""], order_continuous=[""ascending"", ""descending"", None]). ```. ### Null values. This solution assumes we still want null values plotted on bottom. Should there be control over that? ## Some references for other libraries:. * [`altair.Sort`](https://altair-viz.github.io/user_guide/generated/core/altair.Sort.html#altair.Sort). * (I'm actually not sure if other libraries do this, datashader does `max`/ `min`/ `mean` which is sorta similar?)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:2278,reliability,doe,does,2278,"with issues around categorical values. To me this suggests a need to have separate arguments for the two cases (`order_categorical`, `order_continuous`), though this raises issues with ""vectorizing"" the argument. Docstrings for these arguments would look something like:. ```rst. order_continuous: Literal[""current"", ""random"", ""ascending"", ""descending""] = ""ascending"". How to order points in plots colored by continuous values. Options include:. * ""current"": use current ordering of AnnData object. * ""random"": randomize the order. * ""ascending"": points with the highest value are plotted on top. * ""descending"": points with lowest value are plotted on top. order_categorical: Literal[""current"", ""random"", ""ascending"", ""descending""] = ""random"". How to order non-null categorical points in the plot. Uses same options as order_continuous. ```. In this case, `sort_order` would be deprecated, and tell the user to use `order_continuous` instead. ## Potential extensions. * We could also allow users to pass `Callable[Vector, Vector[int]]`s (e.g. function which takes color vector, returns vector of integers) as arguments. ## Possible issues. ### Vectorization could be complicated. Vectorization of argument unclear/ maybe not possible. That is, what if I want the same variable twice, but ordered differently? This would look like: . ```python. sc.pl.umap(adata, color=[""CD8"", ""CD8""], order_continuous=[""ascending"", ""descending""]). ```. Now what if I wanted to also plot a categorical value? Is this: . ```python. sc.pl.umap(adata, color=[""CD8"", ""CD8"", ""leiden""], order_continuous=[""ascending"", ""descending"", None]). ```. ### Null values. This solution assumes we still want null values plotted on bottom. Should there be control over that? ## Some references for other libraries:. * [`altair.Sort`](https://altair-viz.github.io/user_guide/generated/core/altair.Sort.html#altair.Sort). * (I'm actually not sure if other libraries do this, datashader does `max`/ `min`/ `mean` which is sorta similar?)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:1496,safety,compl,complicated,1496,"with issues around categorical values. To me this suggests a need to have separate arguments for the two cases (`order_categorical`, `order_continuous`), though this raises issues with ""vectorizing"" the argument. Docstrings for these arguments would look something like:. ```rst. order_continuous: Literal[""current"", ""random"", ""ascending"", ""descending""] = ""ascending"". How to order points in plots colored by continuous values. Options include:. * ""current"": use current ordering of AnnData object. * ""random"": randomize the order. * ""ascending"": points with the highest value are plotted on top. * ""descending"": points with lowest value are plotted on top. order_categorical: Literal[""current"", ""random"", ""ascending"", ""descending""] = ""random"". How to order non-null categorical points in the plot. Uses same options as order_continuous. ```. In this case, `sort_order` would be deprecated, and tell the user to use `order_continuous` instead. ## Potential extensions. * We could also allow users to pass `Callable[Vector, Vector[int]]`s (e.g. function which takes color vector, returns vector of integers) as arguments. ## Possible issues. ### Vectorization could be complicated. Vectorization of argument unclear/ maybe not possible. That is, what if I want the same variable twice, but ordered differently? This would look like: . ```python. sc.pl.umap(adata, color=[""CD8"", ""CD8""], order_continuous=[""ascending"", ""descending""]). ```. Now what if I wanted to also plot a categorical value? Is this: . ```python. sc.pl.umap(adata, color=[""CD8"", ""CD8"", ""leiden""], order_continuous=[""ascending"", ""descending"", None]). ```. ### Null values. This solution assumes we still want null values plotted on bottom. Should there be control over that? ## Some references for other libraries:. * [`altair.Sort`](https://altair-viz.github.io/user_guide/generated/core/altair.Sort.html#altair.Sort). * (I'm actually not sure if other libraries do this, datashader does `max`/ `min`/ `mean` which is sorta similar?)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:1496,security,compl,complicated,1496,"with issues around categorical values. To me this suggests a need to have separate arguments for the two cases (`order_categorical`, `order_continuous`), though this raises issues with ""vectorizing"" the argument. Docstrings for these arguments would look something like:. ```rst. order_continuous: Literal[""current"", ""random"", ""ascending"", ""descending""] = ""ascending"". How to order points in plots colored by continuous values. Options include:. * ""current"": use current ordering of AnnData object. * ""random"": randomize the order. * ""ascending"": points with the highest value are plotted on top. * ""descending"": points with lowest value are plotted on top. order_categorical: Literal[""current"", ""random"", ""ascending"", ""descending""] = ""random"". How to order non-null categorical points in the plot. Uses same options as order_continuous. ```. In this case, `sort_order` would be deprecated, and tell the user to use `order_continuous` instead. ## Potential extensions. * We could also allow users to pass `Callable[Vector, Vector[int]]`s (e.g. function which takes color vector, returns vector of integers) as arguments. ## Possible issues. ### Vectorization could be complicated. Vectorization of argument unclear/ maybe not possible. That is, what if I want the same variable twice, but ordered differently? This would look like: . ```python. sc.pl.umap(adata, color=[""CD8"", ""CD8""], order_continuous=[""ascending"", ""descending""]). ```. Now what if I wanted to also plot a categorical value? Is this: . ```python. sc.pl.umap(adata, color=[""CD8"", ""CD8"", ""leiden""], order_continuous=[""ascending"", ""descending"", None]). ```. ### Null values. This solution assumes we still want null values plotted on bottom. Should there be control over that? ## Some references for other libraries:. * [`altair.Sort`](https://altair-viz.github.io/user_guide/generated/core/altair.Sort.html#altair.Sort). * (I'm actually not sure if other libraries do this, datashader does `max`/ `min`/ `mean` which is sorta similar?)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:2050,security,control,control,2050,"with issues around categorical values. To me this suggests a need to have separate arguments for the two cases (`order_categorical`, `order_continuous`), though this raises issues with ""vectorizing"" the argument. Docstrings for these arguments would look something like:. ```rst. order_continuous: Literal[""current"", ""random"", ""ascending"", ""descending""] = ""ascending"". How to order points in plots colored by continuous values. Options include:. * ""current"": use current ordering of AnnData object. * ""random"": randomize the order. * ""ascending"": points with the highest value are plotted on top. * ""descending"": points with lowest value are plotted on top. order_categorical: Literal[""current"", ""random"", ""ascending"", ""descending""] = ""random"". How to order non-null categorical points in the plot. Uses same options as order_continuous. ```. In this case, `sort_order` would be deprecated, and tell the user to use `order_continuous` instead. ## Potential extensions. * We could also allow users to pass `Callable[Vector, Vector[int]]`s (e.g. function which takes color vector, returns vector of integers) as arguments. ## Possible issues. ### Vectorization could be complicated. Vectorization of argument unclear/ maybe not possible. That is, what if I want the same variable twice, but ordered differently? This would look like: . ```python. sc.pl.umap(adata, color=[""CD8"", ""CD8""], order_continuous=[""ascending"", ""descending""]). ```. Now what if I wanted to also plot a categorical value? Is this: . ```python. sc.pl.umap(adata, color=[""CD8"", ""CD8"", ""leiden""], order_continuous=[""ascending"", ""descending"", None]). ```. ### Null values. This solution assumes we still want null values plotted on bottom. Should there be control over that? ## Some references for other libraries:. * [`altair.Sort`](https://altair-viz.github.io/user_guide/generated/core/altair.Sort.html#altair.Sort). * (I'm actually not sure if other libraries do this, datashader does `max`/ `min`/ `mean` which is sorta similar?)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:2050,testability,control,control,2050,"with issues around categorical values. To me this suggests a need to have separate arguments for the two cases (`order_categorical`, `order_continuous`), though this raises issues with ""vectorizing"" the argument. Docstrings for these arguments would look something like:. ```rst. order_continuous: Literal[""current"", ""random"", ""ascending"", ""descending""] = ""ascending"". How to order points in plots colored by continuous values. Options include:. * ""current"": use current ordering of AnnData object. * ""random"": randomize the order. * ""ascending"": points with the highest value are plotted on top. * ""descending"": points with lowest value are plotted on top. order_categorical: Literal[""current"", ""random"", ""ascending"", ""descending""] = ""random"". How to order non-null categorical points in the plot. Uses same options as order_continuous. ```. In this case, `sort_order` would be deprecated, and tell the user to use `order_continuous` instead. ## Potential extensions. * We could also allow users to pass `Callable[Vector, Vector[int]]`s (e.g. function which takes color vector, returns vector of integers) as arguments. ## Possible issues. ### Vectorization could be complicated. Vectorization of argument unclear/ maybe not possible. That is, what if I want the same variable twice, but ordered differently? This would look like: . ```python. sc.pl.umap(adata, color=[""CD8"", ""CD8""], order_continuous=[""ascending"", ""descending""]). ```. Now what if I wanted to also plot a categorical value? Is this: . ```python. sc.pl.umap(adata, color=[""CD8"", ""CD8"", ""leiden""], order_continuous=[""ascending"", ""descending"", None]). ```. ### Null values. This solution assumes we still want null values plotted on bottom. Should there be control over that? ## Some references for other libraries:. * [`altair.Sort`](https://altair-viz.github.io/user_guide/generated/core/altair.Sort.html#altair.Sort). * (I'm actually not sure if other libraries do this, datashader does `max`/ `min`/ `mean` which is sorta similar?)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:75,usability,user,user,75,"> The only advantage of sort_order=order_array is that is explicit for the user. Another advantage is that it could be user specified per plot when there are multiple plots. -------------------. I think there is another issue, which is that `sort_order` currently just applies to numeric values while here we are trying to deal with issues around categorical values. To me this suggests a need to have separate arguments for the two cases (`order_categorical`, `order_continuous`), though this raises issues with ""vectorizing"" the argument. Docstrings for these arguments would look something like:. ```rst. order_continuous: Literal[""current"", ""random"", ""ascending"", ""descending""] = ""ascending"". How to order points in plots colored by continuous values. Options include:. * ""current"": use current ordering of AnnData object. * ""random"": randomize the order. * ""ascending"": points with the highest value are plotted on top. * ""descending"": points with lowest value are plotted on top. order_categorical: Literal[""current"", ""random"", ""ascending"", ""descending""] = ""random"". How to order non-null categorical points in the plot. Uses same options as order_continuous. ```. In this case, `sort_order` would be deprecated, and tell the user to use `order_continuous` instead. ## Potential extensions. * We could also allow users to pass `Callable[Vector, Vector[int]]`s (e.g. function which takes color vector, returns vector of integers) as arguments. ## Possible issues. ### Vectorization could be complicated. Vectorization of argument unclear/ maybe not possible. That is, what if I want the same variable twice, but ordered differently? This would look like: . ```python. sc.pl.umap(adata, color=[""CD8"", ""CD8""], order_continuous=[""ascending"", ""descending""]). ```. Now what if I wanted to also plot a categorical value? Is this: . ```python. sc.pl.umap(adata, color=[""CD8"", ""CD8"", ""leiden""], order_continuous=[""ascending"", ""descending"", None]). ```. ### Null values. This solution assumes we still wa",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:119,usability,user,user,119,"> The only advantage of sort_order=order_array is that is explicit for the user. Another advantage is that it could be user specified per plot when there are multiple plots. -------------------. I think there is another issue, which is that `sort_order` currently just applies to numeric values while here we are trying to deal with issues around categorical values. To me this suggests a need to have separate arguments for the two cases (`order_categorical`, `order_continuous`), though this raises issues with ""vectorizing"" the argument. Docstrings for these arguments would look something like:. ```rst. order_continuous: Literal[""current"", ""random"", ""ascending"", ""descending""] = ""ascending"". How to order points in plots colored by continuous values. Options include:. * ""current"": use current ordering of AnnData object. * ""random"": randomize the order. * ""ascending"": points with the highest value are plotted on top. * ""descending"": points with lowest value are plotted on top. order_categorical: Literal[""current"", ""random"", ""ascending"", ""descending""] = ""random"". How to order non-null categorical points in the plot. Uses same options as order_continuous. ```. In this case, `sort_order` would be deprecated, and tell the user to use `order_continuous` instead. ## Potential extensions. * We could also allow users to pass `Callable[Vector, Vector[int]]`s (e.g. function which takes color vector, returns vector of integers) as arguments. ## Possible issues. ### Vectorization could be complicated. Vectorization of argument unclear/ maybe not possible. That is, what if I want the same variable twice, but ordered differently? This would look like: . ```python. sc.pl.umap(adata, color=[""CD8"", ""CD8""], order_continuous=[""ascending"", ""descending""]). ```. Now what if I wanted to also plot a categorical value? Is this: . ```python. sc.pl.umap(adata, color=[""CD8"", ""CD8"", ""leiden""], order_continuous=[""ascending"", ""descending"", None]). ```. ### Null values. This solution assumes we still wa",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:1232,usability,user,user,1232,"s that `sort_order` currently just applies to numeric values while here we are trying to deal with issues around categorical values. To me this suggests a need to have separate arguments for the two cases (`order_categorical`, `order_continuous`), though this raises issues with ""vectorizing"" the argument. Docstrings for these arguments would look something like:. ```rst. order_continuous: Literal[""current"", ""random"", ""ascending"", ""descending""] = ""ascending"". How to order points in plots colored by continuous values. Options include:. * ""current"": use current ordering of AnnData object. * ""random"": randomize the order. * ""ascending"": points with the highest value are plotted on top. * ""descending"": points with lowest value are plotted on top. order_categorical: Literal[""current"", ""random"", ""ascending"", ""descending""] = ""random"". How to order non-null categorical points in the plot. Uses same options as order_continuous. ```. In this case, `sort_order` would be deprecated, and tell the user to use `order_continuous` instead. ## Potential extensions. * We could also allow users to pass `Callable[Vector, Vector[int]]`s (e.g. function which takes color vector, returns vector of integers) as arguments. ## Possible issues. ### Vectorization could be complicated. Vectorization of argument unclear/ maybe not possible. That is, what if I want the same variable twice, but ordered differently? This would look like: . ```python. sc.pl.umap(adata, color=[""CD8"", ""CD8""], order_continuous=[""ascending"", ""descending""]). ```. Now what if I wanted to also plot a categorical value? Is this: . ```python. sc.pl.umap(adata, color=[""CD8"", ""CD8"", ""leiden""], order_continuous=[""ascending"", ""descending"", None]). ```. ### Null values. This solution assumes we still want null values plotted on bottom. Should there be control over that? ## Some references for other libraries:. * [`altair.Sort`](https://altair-viz.github.io/user_guide/generated/core/altair.Sort.html#altair.Sort). * (I'm actually not ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:1319,usability,user,users,1319," deal with issues around categorical values. To me this suggests a need to have separate arguments for the two cases (`order_categorical`, `order_continuous`), though this raises issues with ""vectorizing"" the argument. Docstrings for these arguments would look something like:. ```rst. order_continuous: Literal[""current"", ""random"", ""ascending"", ""descending""] = ""ascending"". How to order points in plots colored by continuous values. Options include:. * ""current"": use current ordering of AnnData object. * ""random"": randomize the order. * ""ascending"": points with the highest value are plotted on top. * ""descending"": points with lowest value are plotted on top. order_categorical: Literal[""current"", ""random"", ""ascending"", ""descending""] = ""random"". How to order non-null categorical points in the plot. Uses same options as order_continuous. ```. In this case, `sort_order` would be deprecated, and tell the user to use `order_continuous` instead. ## Potential extensions. * We could also allow users to pass `Callable[Vector, Vector[int]]`s (e.g. function which takes color vector, returns vector of integers) as arguments. ## Possible issues. ### Vectorization could be complicated. Vectorization of argument unclear/ maybe not possible. That is, what if I want the same variable twice, but ordered differently? This would look like: . ```python. sc.pl.umap(adata, color=[""CD8"", ""CD8""], order_continuous=[""ascending"", ""descending""]). ```. Now what if I wanted to also plot a categorical value? Is this: . ```python. sc.pl.umap(adata, color=[""CD8"", ""CD8"", ""leiden""], order_continuous=[""ascending"", ""descending"", None]). ```. ### Null values. This solution assumes we still want null values plotted on bottom. Should there be control over that? ## Some references for other libraries:. * [`altair.Sort`](https://altair-viz.github.io/user_guide/generated/core/altair.Sort.html#altair.Sort). * (I'm actually not sure if other libraries do this, datashader does `max`/ `min`/ `mean` which is sorta sim",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1266:486,deployability,log,log-normalized,486,"Hi @preetida,. I think this question is more directed towards the `single-cell-tutorial` github [here](github.com/theislab/single-cell-tutorial). I assume that's where you got the above sentence from. In case you haven't done so already, you can check out the accompanying paper with that tutorial [here](http://msb.embopress.org/lookup/doi/10.15252/msb.20188746). In general whatever you store in `adata.raw` is what is used when you set `use_raw=True`. In that tutorial I have stored log-normalized data in `adata.raw.X` and I store log-normalized and batch corrected data in `adata.X`. Thus, you are plotting two different versions of the data when you set `use_raw` differently. In general, if you set up your `adata.raw` as I did in the tutorial, it is advisable to plot with `use_raw=False`, but when you perform a DE test, you shouldn't use the corrected data stored in `adata.X`, so the default is `use_raw=True`. I hope that helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1266
https://github.com/scverse/scanpy/issues/1266:535,deployability,log,log-normalized,535,"Hi @preetida,. I think this question is more directed towards the `single-cell-tutorial` github [here](github.com/theislab/single-cell-tutorial). I assume that's where you got the above sentence from. In case you haven't done so already, you can check out the accompanying paper with that tutorial [here](http://msb.embopress.org/lookup/doi/10.15252/msb.20188746). In general whatever you store in `adata.raw` is what is used when you set `use_raw=True`. In that tutorial I have stored log-normalized data in `adata.raw.X` and I store log-normalized and batch corrected data in `adata.X`. Thus, you are plotting two different versions of the data when you set `use_raw` differently. In general, if you set up your `adata.raw` as I did in the tutorial, it is advisable to plot with `use_raw=False`, but when you perform a DE test, you shouldn't use the corrected data stored in `adata.X`, so the default is `use_raw=True`. I hope that helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1266
https://github.com/scverse/scanpy/issues/1266:626,deployability,version,versions,626,"Hi @preetida,. I think this question is more directed towards the `single-cell-tutorial` github [here](github.com/theislab/single-cell-tutorial). I assume that's where you got the above sentence from. In case you haven't done so already, you can check out the accompanying paper with that tutorial [here](http://msb.embopress.org/lookup/doi/10.15252/msb.20188746). In general whatever you store in `adata.raw` is what is used when you set `use_raw=True`. In that tutorial I have stored log-normalized data in `adata.raw.X` and I store log-normalized and batch corrected data in `adata.X`. Thus, you are plotting two different versions of the data when you set `use_raw` differently. In general, if you set up your `adata.raw` as I did in the tutorial, it is advisable to plot with `use_raw=False`, but when you perform a DE test, you shouldn't use the corrected data stored in `adata.X`, so the default is `use_raw=True`. I hope that helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1266
https://github.com/scverse/scanpy/issues/1266:554,integrability,batch,batch,554,"Hi @preetida,. I think this question is more directed towards the `single-cell-tutorial` github [here](github.com/theislab/single-cell-tutorial). I assume that's where you got the above sentence from. In case you haven't done so already, you can check out the accompanying paper with that tutorial [here](http://msb.embopress.org/lookup/doi/10.15252/msb.20188746). In general whatever you store in `adata.raw` is what is used when you set `use_raw=True`. In that tutorial I have stored log-normalized data in `adata.raw.X` and I store log-normalized and batch corrected data in `adata.X`. Thus, you are plotting two different versions of the data when you set `use_raw` differently. In general, if you set up your `adata.raw` as I did in the tutorial, it is advisable to plot with `use_raw=False`, but when you perform a DE test, you shouldn't use the corrected data stored in `adata.X`, so the default is `use_raw=True`. I hope that helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1266
https://github.com/scverse/scanpy/issues/1266:626,integrability,version,versions,626,"Hi @preetida,. I think this question is more directed towards the `single-cell-tutorial` github [here](github.com/theislab/single-cell-tutorial). I assume that's where you got the above sentence from. In case you haven't done so already, you can check out the accompanying paper with that tutorial [here](http://msb.embopress.org/lookup/doi/10.15252/msb.20188746). In general whatever you store in `adata.raw` is what is used when you set `use_raw=True`. In that tutorial I have stored log-normalized data in `adata.raw.X` and I store log-normalized and batch corrected data in `adata.X`. Thus, you are plotting two different versions of the data when you set `use_raw` differently. In general, if you set up your `adata.raw` as I did in the tutorial, it is advisable to plot with `use_raw=False`, but when you perform a DE test, you shouldn't use the corrected data stored in `adata.X`, so the default is `use_raw=True`. I hope that helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1266
https://github.com/scverse/scanpy/issues/1266:626,modifiability,version,versions,626,"Hi @preetida,. I think this question is more directed towards the `single-cell-tutorial` github [here](github.com/theislab/single-cell-tutorial). I assume that's where you got the above sentence from. In case you haven't done so already, you can check out the accompanying paper with that tutorial [here](http://msb.embopress.org/lookup/doi/10.15252/msb.20188746). In general whatever you store in `adata.raw` is what is used when you set `use_raw=True`. In that tutorial I have stored log-normalized data in `adata.raw.X` and I store log-normalized and batch corrected data in `adata.X`. Thus, you are plotting two different versions of the data when you set `use_raw` differently. In general, if you set up your `adata.raw` as I did in the tutorial, it is advisable to plot with `use_raw=False`, but when you perform a DE test, you shouldn't use the corrected data stored in `adata.X`, so the default is `use_raw=True`. I hope that helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1266
https://github.com/scverse/scanpy/issues/1266:554,performance,batch,batch,554,"Hi @preetida,. I think this question is more directed towards the `single-cell-tutorial` github [here](github.com/theislab/single-cell-tutorial). I assume that's where you got the above sentence from. In case you haven't done so already, you can check out the accompanying paper with that tutorial [here](http://msb.embopress.org/lookup/doi/10.15252/msb.20188746). In general whatever you store in `adata.raw` is what is used when you set `use_raw=True`. In that tutorial I have stored log-normalized data in `adata.raw.X` and I store log-normalized and batch corrected data in `adata.X`. Thus, you are plotting two different versions of the data when you set `use_raw` differently. In general, if you set up your `adata.raw` as I did in the tutorial, it is advisable to plot with `use_raw=False`, but when you perform a DE test, you shouldn't use the corrected data stored in `adata.X`, so the default is `use_raw=True`. I hope that helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1266
https://github.com/scverse/scanpy/issues/1266:811,performance,perform,perform,811,"Hi @preetida,. I think this question is more directed towards the `single-cell-tutorial` github [here](github.com/theislab/single-cell-tutorial). I assume that's where you got the above sentence from. In case you haven't done so already, you can check out the accompanying paper with that tutorial [here](http://msb.embopress.org/lookup/doi/10.15252/msb.20188746). In general whatever you store in `adata.raw` is what is used when you set `use_raw=True`. In that tutorial I have stored log-normalized data in `adata.raw.X` and I store log-normalized and batch corrected data in `adata.X`. Thus, you are plotting two different versions of the data when you set `use_raw` differently. In general, if you set up your `adata.raw` as I did in the tutorial, it is advisable to plot with `use_raw=False`, but when you perform a DE test, you shouldn't use the corrected data stored in `adata.X`, so the default is `use_raw=True`. I hope that helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1266
https://github.com/scverse/scanpy/issues/1266:486,safety,log,log-normalized,486,"Hi @preetida,. I think this question is more directed towards the `single-cell-tutorial` github [here](github.com/theislab/single-cell-tutorial). I assume that's where you got the above sentence from. In case you haven't done so already, you can check out the accompanying paper with that tutorial [here](http://msb.embopress.org/lookup/doi/10.15252/msb.20188746). In general whatever you store in `adata.raw` is what is used when you set `use_raw=True`. In that tutorial I have stored log-normalized data in `adata.raw.X` and I store log-normalized and batch corrected data in `adata.X`. Thus, you are plotting two different versions of the data when you set `use_raw` differently. In general, if you set up your `adata.raw` as I did in the tutorial, it is advisable to plot with `use_raw=False`, but when you perform a DE test, you shouldn't use the corrected data stored in `adata.X`, so the default is `use_raw=True`. I hope that helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1266
https://github.com/scverse/scanpy/issues/1266:535,safety,log,log-normalized,535,"Hi @preetida,. I think this question is more directed towards the `single-cell-tutorial` github [here](github.com/theislab/single-cell-tutorial). I assume that's where you got the above sentence from. In case you haven't done so already, you can check out the accompanying paper with that tutorial [here](http://msb.embopress.org/lookup/doi/10.15252/msb.20188746). In general whatever you store in `adata.raw` is what is used when you set `use_raw=True`. In that tutorial I have stored log-normalized data in `adata.raw.X` and I store log-normalized and batch corrected data in `adata.X`. Thus, you are plotting two different versions of the data when you set `use_raw` differently. In general, if you set up your `adata.raw` as I did in the tutorial, it is advisable to plot with `use_raw=False`, but when you perform a DE test, you shouldn't use the corrected data stored in `adata.X`, so the default is `use_raw=True`. I hope that helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1266
https://github.com/scverse/scanpy/issues/1266:824,safety,test,test,824,"Hi @preetida,. I think this question is more directed towards the `single-cell-tutorial` github [here](github.com/theislab/single-cell-tutorial). I assume that's where you got the above sentence from. In case you haven't done so already, you can check out the accompanying paper with that tutorial [here](http://msb.embopress.org/lookup/doi/10.15252/msb.20188746). In general whatever you store in `adata.raw` is what is used when you set `use_raw=True`. In that tutorial I have stored log-normalized data in `adata.raw.X` and I store log-normalized and batch corrected data in `adata.X`. Thus, you are plotting two different versions of the data when you set `use_raw` differently. In general, if you set up your `adata.raw` as I did in the tutorial, it is advisable to plot with `use_raw=False`, but when you perform a DE test, you shouldn't use the corrected data stored in `adata.X`, so the default is `use_raw=True`. I hope that helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1266
https://github.com/scverse/scanpy/issues/1266:486,security,log,log-normalized,486,"Hi @preetida,. I think this question is more directed towards the `single-cell-tutorial` github [here](github.com/theislab/single-cell-tutorial). I assume that's where you got the above sentence from. In case you haven't done so already, you can check out the accompanying paper with that tutorial [here](http://msb.embopress.org/lookup/doi/10.15252/msb.20188746). In general whatever you store in `adata.raw` is what is used when you set `use_raw=True`. In that tutorial I have stored log-normalized data in `adata.raw.X` and I store log-normalized and batch corrected data in `adata.X`. Thus, you are plotting two different versions of the data when you set `use_raw` differently. In general, if you set up your `adata.raw` as I did in the tutorial, it is advisable to plot with `use_raw=False`, but when you perform a DE test, you shouldn't use the corrected data stored in `adata.X`, so the default is `use_raw=True`. I hope that helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1266
https://github.com/scverse/scanpy/issues/1266:535,security,log,log-normalized,535,"Hi @preetida,. I think this question is more directed towards the `single-cell-tutorial` github [here](github.com/theislab/single-cell-tutorial). I assume that's where you got the above sentence from. In case you haven't done so already, you can check out the accompanying paper with that tutorial [here](http://msb.embopress.org/lookup/doi/10.15252/msb.20188746). In general whatever you store in `adata.raw` is what is used when you set `use_raw=True`. In that tutorial I have stored log-normalized data in `adata.raw.X` and I store log-normalized and batch corrected data in `adata.X`. Thus, you are plotting two different versions of the data when you set `use_raw` differently. In general, if you set up your `adata.raw` as I did in the tutorial, it is advisable to plot with `use_raw=False`, but when you perform a DE test, you shouldn't use the corrected data stored in `adata.X`, so the default is `use_raw=True`. I hope that helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1266
https://github.com/scverse/scanpy/issues/1266:486,testability,log,log-normalized,486,"Hi @preetida,. I think this question is more directed towards the `single-cell-tutorial` github [here](github.com/theislab/single-cell-tutorial). I assume that's where you got the above sentence from. In case you haven't done so already, you can check out the accompanying paper with that tutorial [here](http://msb.embopress.org/lookup/doi/10.15252/msb.20188746). In general whatever you store in `adata.raw` is what is used when you set `use_raw=True`. In that tutorial I have stored log-normalized data in `adata.raw.X` and I store log-normalized and batch corrected data in `adata.X`. Thus, you are plotting two different versions of the data when you set `use_raw` differently. In general, if you set up your `adata.raw` as I did in the tutorial, it is advisable to plot with `use_raw=False`, but when you perform a DE test, you shouldn't use the corrected data stored in `adata.X`, so the default is `use_raw=True`. I hope that helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1266
https://github.com/scverse/scanpy/issues/1266:535,testability,log,log-normalized,535,"Hi @preetida,. I think this question is more directed towards the `single-cell-tutorial` github [here](github.com/theislab/single-cell-tutorial). I assume that's where you got the above sentence from. In case you haven't done so already, you can check out the accompanying paper with that tutorial [here](http://msb.embopress.org/lookup/doi/10.15252/msb.20188746). In general whatever you store in `adata.raw` is what is used when you set `use_raw=True`. In that tutorial I have stored log-normalized data in `adata.raw.X` and I store log-normalized and batch corrected data in `adata.X`. Thus, you are plotting two different versions of the data when you set `use_raw` differently. In general, if you set up your `adata.raw` as I did in the tutorial, it is advisable to plot with `use_raw=False`, but when you perform a DE test, you shouldn't use the corrected data stored in `adata.X`, so the default is `use_raw=True`. I hope that helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1266
https://github.com/scverse/scanpy/issues/1266:824,testability,test,test,824,"Hi @preetida,. I think this question is more directed towards the `single-cell-tutorial` github [here](github.com/theislab/single-cell-tutorial). I assume that's where you got the above sentence from. In case you haven't done so already, you can check out the accompanying paper with that tutorial [here](http://msb.embopress.org/lookup/doi/10.15252/msb.20188746). In general whatever you store in `adata.raw` is what is used when you set `use_raw=True`. In that tutorial I have stored log-normalized data in `adata.raw.X` and I store log-normalized and batch corrected data in `adata.X`. Thus, you are plotting two different versions of the data when you set `use_raw` differently. In general, if you set up your `adata.raw` as I did in the tutorial, it is advisable to plot with `use_raw=False`, but when you perform a DE test, you shouldn't use the corrected data stored in `adata.X`, so the default is `use_raw=True`. I hope that helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1266
https://github.com/scverse/scanpy/issues/1266:811,usability,perform,perform,811,"Hi @preetida,. I think this question is more directed towards the `single-cell-tutorial` github [here](github.com/theislab/single-cell-tutorial). I assume that's where you got the above sentence from. In case you haven't done so already, you can check out the accompanying paper with that tutorial [here](http://msb.embopress.org/lookup/doi/10.15252/msb.20188746). In general whatever you store in `adata.raw` is what is used when you set `use_raw=True`. In that tutorial I have stored log-normalized data in `adata.raw.X` and I store log-normalized and batch corrected data in `adata.X`. Thus, you are plotting two different versions of the data when you set `use_raw` differently. In general, if you set up your `adata.raw` as I did in the tutorial, it is advisable to plot with `use_raw=False`, but when you perform a DE test, you shouldn't use the corrected data stored in `adata.X`, so the default is `use_raw=True`. I hope that helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1266
https://github.com/scverse/scanpy/issues/1266:934,usability,help,helps,934,"Hi @preetida,. I think this question is more directed towards the `single-cell-tutorial` github [here](github.com/theislab/single-cell-tutorial). I assume that's where you got the above sentence from. In case you haven't done so already, you can check out the accompanying paper with that tutorial [here](http://msb.embopress.org/lookup/doi/10.15252/msb.20188746). In general whatever you store in `adata.raw` is what is used when you set `use_raw=True`. In that tutorial I have stored log-normalized data in `adata.raw.X` and I store log-normalized and batch corrected data in `adata.X`. Thus, you are plotting two different versions of the data when you set `use_raw` differently. In general, if you set up your `adata.raw` as I did in the tutorial, it is advisable to plot with `use_raw=False`, but when you perform a DE test, you shouldn't use the corrected data stored in `adata.X`, so the default is `use_raw=True`. I hope that helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1266
https://github.com/scverse/scanpy/issues/1268:72,modifiability,refact,refactoring,72,"Sorry but the question is not clear. The plotting functions underwent a refactoring recently but that one should still work no? I'll close this for the moment, feel free to reopen it but please do so with a reproducible example, thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1268
https://github.com/scverse/scanpy/issues/1268:72,performance,refactor,refactoring,72,"Sorry but the question is not clear. The plotting functions underwent a refactoring recently but that one should still work no? I'll close this for the moment, feel free to reopen it but please do so with a reproducible example, thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1268
https://github.com/scverse/scanpy/issues/1268:30,usability,clear,clear,30,"Sorry but the question is not clear. The plotting functions underwent a refactoring recently but that one should still work no? I'll close this for the moment, feel free to reopen it but please do so with a reproducible example, thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1268
https://github.com/scverse/scanpy/issues/1268:133,usability,close,close,133,"Sorry but the question is not clear. The plotting functions underwent a refactoring recently but that one should still work no? I'll close this for the moment, feel free to reopen it but please do so with a reproducible example, thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1268
https://github.com/scverse/scanpy/pull/1270:267,integrability,sub,subplots,267,"@falexwolf I added a padding argument to dotplot (already merged into master):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,5), gridspec_kw={'width_ratios': [1.2, 1], 'wspace':0.6}, sharex=False, sharey=False). ax1 = sc.pl.dotplot(adata, markers, groupby='bulk_labels', ax=ax1, dendrogram=True, show=False). ax2 = sc.pl.dotplot(adata, markers, groupby='bulk_labels', ax=ax2, dendrogram=True, show=False, return_fig=True).\. style(x_padding=0.5, y_padding=0.5, cmap='Reds').show(). ```. ![image](https://user-images.githubusercontent.com/4964309/87307385-c9e05d00-c519-11ea-92b0-43cd23b81e6b.png). The units for the `x_padding` and `y_padding` are in ticks distance.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1270
https://github.com/scverse/scanpy/pull/1270:352,interoperability,share,sharex,352,"@falexwolf I added a padding argument to dotplot (already merged into master):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,5), gridspec_kw={'width_ratios': [1.2, 1], 'wspace':0.6}, sharex=False, sharey=False). ax1 = sc.pl.dotplot(adata, markers, groupby='bulk_labels', ax=ax1, dendrogram=True, show=False). ax2 = sc.pl.dotplot(adata, markers, groupby='bulk_labels', ax=ax2, dendrogram=True, show=False, return_fig=True).\. style(x_padding=0.5, y_padding=0.5, cmap='Reds').show(). ```. ![image](https://user-images.githubusercontent.com/4964309/87307385-c9e05d00-c519-11ea-92b0-43cd23b81e6b.png). The units for the `x_padding` and `y_padding` are in ticks distance.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1270
https://github.com/scverse/scanpy/pull/1270:366,interoperability,share,sharey,366,"@falexwolf I added a padding argument to dotplot (already merged into master):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,5), gridspec_kw={'width_ratios': [1.2, 1], 'wspace':0.6}, sharex=False, sharey=False). ax1 = sc.pl.dotplot(adata, markers, groupby='bulk_labels', ax=ax1, dendrogram=True, show=False). ax2 = sc.pl.dotplot(adata, markers, groupby='bulk_labels', ax=ax2, dendrogram=True, show=False, return_fig=True).\. style(x_padding=0.5, y_padding=0.5, cmap='Reds').show(). ```. ![image](https://user-images.githubusercontent.com/4964309/87307385-c9e05d00-c519-11ea-92b0-43cd23b81e6b.png). The units for the `x_padding` and `y_padding` are in ticks distance.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1270
https://github.com/scverse/scanpy/pull/1270:771,testability,unit,units,771,"@falexwolf I added a padding argument to dotplot (already merged into master):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,5), gridspec_kw={'width_ratios': [1.2, 1], 'wspace':0.6}, sharex=False, sharey=False). ax1 = sc.pl.dotplot(adata, markers, groupby='bulk_labels', ax=ax1, dendrogram=True, show=False). ax2 = sc.pl.dotplot(adata, markers, groupby='bulk_labels', ax=ax2, dendrogram=True, show=False, return_fig=True).\. style(x_padding=0.5, y_padding=0.5, cmap='Reds').show(). ```. ![image](https://user-images.githubusercontent.com/4964309/87307385-c9e05d00-c519-11ea-92b0-43cd23b81e6b.png). The units for the `x_padding` and `y_padding` are in ticks distance.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1270
https://github.com/scverse/scanpy/pull/1270:673,usability,user,user-images,673,"@falexwolf I added a padding argument to dotplot (already merged into master):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,5), gridspec_kw={'width_ratios': [1.2, 1], 'wspace':0.6}, sharex=False, sharey=False). ax1 = sc.pl.dotplot(adata, markers, groupby='bulk_labels', ax=ax1, dendrogram=True, show=False). ax2 = sc.pl.dotplot(adata, markers, groupby='bulk_labels', ax=ax2, dendrogram=True, show=False, return_fig=True).\. style(x_padding=0.5, y_padding=0.5, cmap='Reds').show(). ```. ![image](https://user-images.githubusercontent.com/4964309/87307385-c9e05d00-c519-11ea-92b0-43cd23b81e6b.png). The units for the `x_padding` and `y_padding` are in ticks distance.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1270
https://github.com/scverse/scanpy/pull/1270:22,usability,close,close,22,"I think we're good to close this PR then, right? Let me know if I should reopen it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1270
https://github.com/scverse/scanpy/pull/1271:49,deployability,version,version,49,This is awesome! And much more elaborate than my version of the same:. https://github.com/normjam/benchmark/blob/master/normbench/methods/ad2seurat.py,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1271
https://github.com/scverse/scanpy/pull/1271:49,integrability,version,version,49,This is awesome! And much more elaborate than my version of the same:. https://github.com/normjam/benchmark/blob/master/normbench/methods/ad2seurat.py,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1271
https://github.com/scverse/scanpy/pull/1271:49,modifiability,version,version,49,This is awesome! And much more elaborate than my version of the same:. https://github.com/normjam/benchmark/blob/master/normbench/methods/ad2seurat.py,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1271
https://github.com/scverse/scanpy/pull/1271:283,energy efficiency,cool,cool,283,"Do you guys think this PR makes sense or is it too much to add R packages to the travis setup? @ivirshup @flying-sheep . There are bunch of useful R packages out there that will most likely not be reimplemented in Python (limma-voom pseudobulk DE, Liger, MAST etc.). I think it'd be cool to revive rtools and add access to such packages. I'm not sure if this is the right way but, any guidance is appreciated :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1271
https://github.com/scverse/scanpy/pull/1271:65,modifiability,pac,packages,65,"Do you guys think this PR makes sense or is it too much to add R packages to the travis setup? @ivirshup @flying-sheep . There are bunch of useful R packages out there that will most likely not be reimplemented in Python (limma-voom pseudobulk DE, Liger, MAST etc.). I think it'd be cool to revive rtools and add access to such packages. I'm not sure if this is the right way but, any guidance is appreciated :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1271
https://github.com/scverse/scanpy/pull/1271:149,modifiability,pac,packages,149,"Do you guys think this PR makes sense or is it too much to add R packages to the travis setup? @ivirshup @flying-sheep . There are bunch of useful R packages out there that will most likely not be reimplemented in Python (limma-voom pseudobulk DE, Liger, MAST etc.). I think it'd be cool to revive rtools and add access to such packages. I'm not sure if this is the right way but, any guidance is appreciated :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1271
https://github.com/scverse/scanpy/pull/1271:328,modifiability,pac,packages,328,"Do you guys think this PR makes sense or is it too much to add R packages to the travis setup? @ivirshup @flying-sheep . There are bunch of useful R packages out there that will most likely not be reimplemented in Python (limma-voom pseudobulk DE, Liger, MAST etc.). I think it'd be cool to revive rtools and add access to such packages. I'm not sure if this is the right way but, any guidance is appreciated :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1271
https://github.com/scverse/scanpy/pull/1271:298,reliability,rto,rtools,298,"Do you guys think this PR makes sense or is it too much to add R packages to the travis setup? @ivirshup @flying-sheep . There are bunch of useful R packages out there that will most likely not be reimplemented in Python (limma-voom pseudobulk DE, Liger, MAST etc.). I think it'd be cool to revive rtools and add access to such packages. I'm not sure if this is the right way but, any guidance is appreciated :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1271
https://github.com/scverse/scanpy/pull/1271:313,security,access,access,313,"Do you guys think this PR makes sense or is it too much to add R packages to the travis setup? @ivirshup @flying-sheep . There are bunch of useful R packages out there that will most likely not be reimplemented in Python (limma-voom pseudobulk DE, Liger, MAST etc.). I think it'd be cool to revive rtools and add access to such packages. I'm not sure if this is the right way but, any guidance is appreciated :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1271
https://github.com/scverse/scanpy/pull/1271:385,usability,guidanc,guidance,385,"Do you guys think this PR makes sense or is it too much to add R packages to the travis setup? @ivirshup @flying-sheep . There are bunch of useful R packages out there that will most likely not be reimplemented in Python (limma-voom pseudobulk DE, Liger, MAST etc.). I think it'd be cool to revive rtools and add access to such packages. I'm not sure if this is the right way but, any guidance is appreciated :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1271
https://github.com/scverse/scanpy/pull/1271:144,deployability,depend,dependencies,144,I don't think we should have to worry about dealing with CI for R in this project. This only becomes harder if the intent is to have many other dependencies. I think doing anything like this makes much more sense in seperate dedicated package.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1271
https://github.com/scverse/scanpy/pull/1271:144,integrability,depend,dependencies,144,I don't think we should have to worry about dealing with CI for R in this project. This only becomes harder if the intent is to have many other dependencies. I think doing anything like this makes much more sense in seperate dedicated package.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1271
https://github.com/scverse/scanpy/pull/1271:144,modifiability,depend,dependencies,144,I don't think we should have to worry about dealing with CI for R in this project. This only becomes harder if the intent is to have many other dependencies. I think doing anything like this makes much more sense in seperate dedicated package.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1271
https://github.com/scverse/scanpy/pull/1271:235,modifiability,pac,package,235,I don't think we should have to worry about dealing with CI for R in this project. This only becomes harder if the intent is to have many other dependencies. I think doing anything like this makes much more sense in seperate dedicated package.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1271
https://github.com/scverse/scanpy/pull/1271:144,safety,depend,dependencies,144,I don't think we should have to worry about dealing with CI for R in this project. This only becomes harder if the intent is to have many other dependencies. I think doing anything like this makes much more sense in seperate dedicated package.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1271
https://github.com/scverse/scanpy/pull/1271:144,testability,depend,dependencies,144,I don't think we should have to worry about dealing with CI for R in this project. This only becomes harder if the intent is to have many other dependencies. I think doing anything like this makes much more sense in seperate dedicated package.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1271
https://github.com/scverse/scanpy/pull/1271:14,deployability,updat,updates,14,Are there any updates concerning this PR? scTransform functionality in scanpy would be much appreciated :),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1271
https://github.com/scverse/scanpy/pull/1271:22,modifiability,concern,concerning,22,Are there any updates concerning this PR? scTransform functionality in scanpy would be much appreciated :),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1271
https://github.com/scverse/scanpy/pull/1271:14,safety,updat,updates,14,Are there any updates concerning this PR? scTransform functionality in scanpy would be much appreciated :),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1271
https://github.com/scverse/scanpy/pull/1271:14,security,updat,updates,14,Are there any updates concerning this PR? scTransform functionality in scanpy would be much appreciated :),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1271
https://github.com/scverse/scanpy/pull/1271:22,testability,concern,concerning,22,Are there any updates concerning this PR? scTransform functionality in scanpy would be much appreciated :),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1271
https://github.com/scverse/scanpy/issues/1272:141,integrability,topic,topics,141,Hi @benxiahu I invite you to have a look at the tutorial here: https://scanpy.readthedocs.io/en/stable/tutorials.html and discussions on the topics in our discourse channel https://scanpy.discourse.group/. Hope those pointers are useful! Will close this for now,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1272
https://github.com/scverse/scanpy/issues/1272:243,usability,close,close,243,Hi @benxiahu I invite you to have a look at the tutorial here: https://scanpy.readthedocs.io/en/stable/tutorials.html and discussions on the topics in our discourse channel https://scanpy.discourse.group/. Hope those pointers are useful! Will close this for now,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1272
https://github.com/scverse/scanpy/issues/1273:50,deployability,version,versions,50,"I think your issue here is due to having multiple versions of various packages in your path. In general, that will cause problems. I think I can only recommend creating an isolated environment using something like `conda` or `virtualenv` and say that installing with `pip` tends to have the fewest problems.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:251,deployability,instal,installing,251,"I think your issue here is due to having multiple versions of various packages in your path. In general, that will cause problems. I think I can only recommend creating an isolated environment using something like `conda` or `virtualenv` and say that installing with `pip` tends to have the fewest problems.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:50,integrability,version,versions,50,"I think your issue here is due to having multiple versions of various packages in your path. In general, that will cause problems. I think I can only recommend creating an isolated environment using something like `conda` or `virtualenv` and say that installing with `pip` tends to have the fewest problems.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:50,modifiability,version,versions,50,"I think your issue here is due to having multiple versions of various packages in your path. In general, that will cause problems. I think I can only recommend creating an isolated environment using something like `conda` or `virtualenv` and say that installing with `pip` tends to have the fewest problems.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:70,modifiability,pac,packages,70,"I think your issue here is due to having multiple versions of various packages in your path. In general, that will cause problems. I think I can only recommend creating an isolated environment using something like `conda` or `virtualenv` and say that installing with `pip` tends to have the fewest problems.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:172,safety,isol,isolated,172,"I think your issue here is due to having multiple versions of various packages in your path. In general, that will cause problems. I think I can only recommend creating an isolated environment using something like `conda` or `virtualenv` and say that installing with `pip` tends to have the fewest problems.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:172,security,iso,isolated,172,"I think your issue here is due to having multiple versions of various packages in your path. In general, that will cause problems. I think I can only recommend creating an isolated environment using something like `conda` or `virtualenv` and say that installing with `pip` tends to have the fewest problems.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:172,testability,isol,isolated,172,"I think your issue here is due to having multiple versions of various packages in your path. In general, that will cause problems. I think I can only recommend creating an isolated environment using something like `conda` or `virtualenv` and say that installing with `pip` tends to have the fewest problems.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:161,availability,ERROR,ERROR,161,"It still does not work for me, even in a virtualenv. I always get:. ```. #Using legacy setup.py install for umap-learn, since package 'wheel' is not installed. #ERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 1.2.3 which is incompatible. cd /usr/common/lib/python3.6/Envs. rm -rf ~/.cache/pip #make download clearer. python3 -m venv scanpy_scripts. source scanpy_scripts/bin/activate. python -m pip install -U pip. python -m pip install scanpy_scripts. #same error. python -m pip install -U setuptools #39.2 -> 47.3.1. python -m pip install scanpy_scripts. #same error. python -m pip install -U wheel. python -m pip install scanpy_scripts. #same error. echo $PYTHONPATH. #is blank. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:327,availability,down,download,327,"It still does not work for me, even in a virtualenv. I always get:. ```. #Using legacy setup.py install for umap-learn, since package 'wheel' is not installed. #ERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 1.2.3 which is incompatible. cd /usr/common/lib/python3.6/Envs. rm -rf ~/.cache/pip #make download clearer. python3 -m venv scanpy_scripts. source scanpy_scripts/bin/activate. python -m pip install -U pip. python -m pip install scanpy_scripts. #same error. python -m pip install -U setuptools #39.2 -> 47.3.1. python -m pip install scanpy_scripts. #same error. python -m pip install -U wheel. python -m pip install scanpy_scripts. #same error. echo $PYTHONPATH. #is blank. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:487,availability,error,error,487,"It still does not work for me, even in a virtualenv. I always get:. ```. #Using legacy setup.py install for umap-learn, since package 'wheel' is not installed. #ERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 1.2.3 which is incompatible. cd /usr/common/lib/python3.6/Envs. rm -rf ~/.cache/pip #make download clearer. python3 -m venv scanpy_scripts. source scanpy_scripts/bin/activate. python -m pip install -U pip. python -m pip install scanpy_scripts. #same error. python -m pip install -U setuptools #39.2 -> 47.3.1. python -m pip install scanpy_scripts. #same error. python -m pip install -U wheel. python -m pip install scanpy_scripts. #same error. echo $PYTHONPATH. #is blank. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:591,availability,error,error,591,"It still does not work for me, even in a virtualenv. I always get:. ```. #Using legacy setup.py install for umap-learn, since package 'wheel' is not installed. #ERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 1.2.3 which is incompatible. cd /usr/common/lib/python3.6/Envs. rm -rf ~/.cache/pip #make download clearer. python3 -m venv scanpy_scripts. source scanpy_scripts/bin/activate. python -m pip install -U pip. python -m pip install scanpy_scripts. #same error. python -m pip install -U setuptools #39.2 -> 47.3.1. python -m pip install scanpy_scripts. #same error. python -m pip install -U wheel. python -m pip install scanpy_scripts. #same error. echo $PYTHONPATH. #is blank. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:674,availability,error,error,674,"It still does not work for me, even in a virtualenv. I always get:. ```. #Using legacy setup.py install for umap-learn, since package 'wheel' is not installed. #ERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 1.2.3 which is incompatible. cd /usr/common/lib/python3.6/Envs. rm -rf ~/.cache/pip #make download clearer. python3 -m venv scanpy_scripts. source scanpy_scripts/bin/activate. python -m pip install -U pip. python -m pip install scanpy_scripts. #same error. python -m pip install -U setuptools #39.2 -> 47.3.1. python -m pip install scanpy_scripts. #same error. python -m pip install -U wheel. python -m pip install scanpy_scripts. #same error. echo $PYTHONPATH. #is blank. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:681,availability,echo,echo,681,"It still does not work for me, even in a virtualenv. I always get:. ```. #Using legacy setup.py install for umap-learn, since package 'wheel' is not installed. #ERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 1.2.3 which is incompatible. cd /usr/common/lib/python3.6/Envs. rm -rf ~/.cache/pip #make download clearer. python3 -m venv scanpy_scripts. source scanpy_scripts/bin/activate. python -m pip install -U pip. python -m pip install scanpy_scripts. #same error. python -m pip install -U setuptools #39.2 -> 47.3.1. python -m pip install scanpy_scripts. #same error. python -m pip install -U wheel. python -m pip install scanpy_scripts. #same error. echo $PYTHONPATH. #is blank. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:96,deployability,instal,install,96,"It still does not work for me, even in a virtualenv. I always get:. ```. #Using legacy setup.py install for umap-learn, since package 'wheel' is not installed. #ERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 1.2.3 which is incompatible. cd /usr/common/lib/python3.6/Envs. rm -rf ~/.cache/pip #make download clearer. python3 -m venv scanpy_scripts. source scanpy_scripts/bin/activate. python -m pip install -U pip. python -m pip install scanpy_scripts. #same error. python -m pip install -U setuptools #39.2 -> 47.3.1. python -m pip install scanpy_scripts. #same error. python -m pip install -U wheel. python -m pip install scanpy_scripts. #same error. echo $PYTHONPATH. #is blank. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:149,deployability,instal,installed,149,"It still does not work for me, even in a virtualenv. I always get:. ```. #Using legacy setup.py install for umap-learn, since package 'wheel' is not installed. #ERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 1.2.3 which is incompatible. cd /usr/common/lib/python3.6/Envs. rm -rf ~/.cache/pip #make download clearer. python3 -m venv scanpy_scripts. source scanpy_scripts/bin/activate. python -m pip install -U pip. python -m pip install scanpy_scripts. #same error. python -m pip install -U setuptools #39.2 -> 47.3.1. python -m pip install scanpy_scripts. #same error. python -m pip install -U wheel. python -m pip install scanpy_scripts. #same error. echo $PYTHONPATH. #is blank. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:427,deployability,instal,install,427,"It still does not work for me, even in a virtualenv. I always get:. ```. #Using legacy setup.py install for umap-learn, since package 'wheel' is not installed. #ERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 1.2.3 which is incompatible. cd /usr/common/lib/python3.6/Envs. rm -rf ~/.cache/pip #make download clearer. python3 -m venv scanpy_scripts. source scanpy_scripts/bin/activate. python -m pip install -U pip. python -m pip install scanpy_scripts. #same error. python -m pip install -U setuptools #39.2 -> 47.3.1. python -m pip install scanpy_scripts. #same error. python -m pip install -U wheel. python -m pip install scanpy_scripts. #same error. echo $PYTHONPATH. #is blank. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:457,deployability,instal,install,457,"It still does not work for me, even in a virtualenv. I always get:. ```. #Using legacy setup.py install for umap-learn, since package 'wheel' is not installed. #ERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 1.2.3 which is incompatible. cd /usr/common/lib/python3.6/Envs. rm -rf ~/.cache/pip #make download clearer. python3 -m venv scanpy_scripts. source scanpy_scripts/bin/activate. python -m pip install -U pip. python -m pip install scanpy_scripts. #same error. python -m pip install -U setuptools #39.2 -> 47.3.1. python -m pip install scanpy_scripts. #same error. python -m pip install -U wheel. python -m pip install scanpy_scripts. #same error. echo $PYTHONPATH. #is blank. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:508,deployability,instal,install,508,"It still does not work for me, even in a virtualenv. I always get:. ```. #Using legacy setup.py install for umap-learn, since package 'wheel' is not installed. #ERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 1.2.3 which is incompatible. cd /usr/common/lib/python3.6/Envs. rm -rf ~/.cache/pip #make download clearer. python3 -m venv scanpy_scripts. source scanpy_scripts/bin/activate. python -m pip install -U pip. python -m pip install scanpy_scripts. #same error. python -m pip install -U setuptools #39.2 -> 47.3.1. python -m pip install scanpy_scripts. #same error. python -m pip install -U wheel. python -m pip install scanpy_scripts. #same error. echo $PYTHONPATH. #is blank. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:561,deployability,instal,install,561,"It still does not work for me, even in a virtualenv. I always get:. ```. #Using legacy setup.py install for umap-learn, since package 'wheel' is not installed. #ERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 1.2.3 which is incompatible. cd /usr/common/lib/python3.6/Envs. rm -rf ~/.cache/pip #make download clearer. python3 -m venv scanpy_scripts. source scanpy_scripts/bin/activate. python -m pip install -U pip. python -m pip install scanpy_scripts. #same error. python -m pip install -U setuptools #39.2 -> 47.3.1. python -m pip install scanpy_scripts. #same error. python -m pip install -U wheel. python -m pip install scanpy_scripts. #same error. echo $PYTHONPATH. #is blank. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:612,deployability,instal,install,612,"It still does not work for me, even in a virtualenv. I always get:. ```. #Using legacy setup.py install for umap-learn, since package 'wheel' is not installed. #ERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 1.2.3 which is incompatible. cd /usr/common/lib/python3.6/Envs. rm -rf ~/.cache/pip #make download clearer. python3 -m venv scanpy_scripts. source scanpy_scripts/bin/activate. python -m pip install -U pip. python -m pip install scanpy_scripts. #same error. python -m pip install -U setuptools #39.2 -> 47.3.1. python -m pip install scanpy_scripts. #same error. python -m pip install -U wheel. python -m pip install scanpy_scripts. #same error. echo $PYTHONPATH. #is blank. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:644,deployability,instal,install,644,"It still does not work for me, even in a virtualenv. I always get:. ```. #Using legacy setup.py install for umap-learn, since package 'wheel' is not installed. #ERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 1.2.3 which is incompatible. cd /usr/common/lib/python3.6/Envs. rm -rf ~/.cache/pip #make download clearer. python3 -m venv scanpy_scripts. source scanpy_scripts/bin/activate. python -m pip install -U pip. python -m pip install scanpy_scripts. #same error. python -m pip install -U setuptools #39.2 -> 47.3.1. python -m pip install scanpy_scripts. #same error. python -m pip install -U wheel. python -m pip install scanpy_scripts. #same error. echo $PYTHONPATH. #is blank. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:252,interoperability,incompatib,incompatible,252,"It still does not work for me, even in a virtualenv. I always get:. ```. #Using legacy setup.py install for umap-learn, since package 'wheel' is not installed. #ERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 1.2.3 which is incompatible. cd /usr/common/lib/python3.6/Envs. rm -rf ~/.cache/pip #make download clearer. python3 -m venv scanpy_scripts. source scanpy_scripts/bin/activate. python -m pip install -U pip. python -m pip install scanpy_scripts. #same error. python -m pip install -U setuptools #39.2 -> 47.3.1. python -m pip install scanpy_scripts. #same error. python -m pip install -U wheel. python -m pip install scanpy_scripts. #same error. echo $PYTHONPATH. #is blank. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:126,modifiability,pac,package,126,"It still does not work for me, even in a virtualenv. I always get:. ```. #Using legacy setup.py install for umap-learn, since package 'wheel' is not installed. #ERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 1.2.3 which is incompatible. cd /usr/common/lib/python3.6/Envs. rm -rf ~/.cache/pip #make download clearer. python3 -m venv scanpy_scripts. source scanpy_scripts/bin/activate. python -m pip install -U pip. python -m pip install scanpy_scripts. #same error. python -m pip install -U setuptools #39.2 -> 47.3.1. python -m pip install scanpy_scripts. #same error. python -m pip install -U wheel. python -m pip install scanpy_scripts. #same error. echo $PYTHONPATH. #is blank. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:161,performance,ERROR,ERROR,161,"It still does not work for me, even in a virtualenv. I always get:. ```. #Using legacy setup.py install for umap-learn, since package 'wheel' is not installed. #ERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 1.2.3 which is incompatible. cd /usr/common/lib/python3.6/Envs. rm -rf ~/.cache/pip #make download clearer. python3 -m venv scanpy_scripts. source scanpy_scripts/bin/activate. python -m pip install -U pip. python -m pip install scanpy_scripts. #same error. python -m pip install -U setuptools #39.2 -> 47.3.1. python -m pip install scanpy_scripts. #same error. python -m pip install -U wheel. python -m pip install scanpy_scripts. #same error. echo $PYTHONPATH. #is blank. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:311,performance,cach,cache,311,"It still does not work for me, even in a virtualenv. I always get:. ```. #Using legacy setup.py install for umap-learn, since package 'wheel' is not installed. #ERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 1.2.3 which is incompatible. cd /usr/common/lib/python3.6/Envs. rm -rf ~/.cache/pip #make download clearer. python3 -m venv scanpy_scripts. source scanpy_scripts/bin/activate. python -m pip install -U pip. python -m pip install scanpy_scripts. #same error. python -m pip install -U setuptools #39.2 -> 47.3.1. python -m pip install scanpy_scripts. #same error. python -m pip install -U wheel. python -m pip install scanpy_scripts. #same error. echo $PYTHONPATH. #is blank. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:487,performance,error,error,487,"It still does not work for me, even in a virtualenv. I always get:. ```. #Using legacy setup.py install for umap-learn, since package 'wheel' is not installed. #ERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 1.2.3 which is incompatible. cd /usr/common/lib/python3.6/Envs. rm -rf ~/.cache/pip #make download clearer. python3 -m venv scanpy_scripts. source scanpy_scripts/bin/activate. python -m pip install -U pip. python -m pip install scanpy_scripts. #same error. python -m pip install -U setuptools #39.2 -> 47.3.1. python -m pip install scanpy_scripts. #same error. python -m pip install -U wheel. python -m pip install scanpy_scripts. #same error. echo $PYTHONPATH. #is blank. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:591,performance,error,error,591,"It still does not work for me, even in a virtualenv. I always get:. ```. #Using legacy setup.py install for umap-learn, since package 'wheel' is not installed. #ERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 1.2.3 which is incompatible. cd /usr/common/lib/python3.6/Envs. rm -rf ~/.cache/pip #make download clearer. python3 -m venv scanpy_scripts. source scanpy_scripts/bin/activate. python -m pip install -U pip. python -m pip install scanpy_scripts. #same error. python -m pip install -U setuptools #39.2 -> 47.3.1. python -m pip install scanpy_scripts. #same error. python -m pip install -U wheel. python -m pip install scanpy_scripts. #same error. echo $PYTHONPATH. #is blank. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:674,performance,error,error,674,"It still does not work for me, even in a virtualenv. I always get:. ```. #Using legacy setup.py install for umap-learn, since package 'wheel' is not installed. #ERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 1.2.3 which is incompatible. cd /usr/common/lib/python3.6/Envs. rm -rf ~/.cache/pip #make download clearer. python3 -m venv scanpy_scripts. source scanpy_scripts/bin/activate. python -m pip install -U pip. python -m pip install scanpy_scripts. #same error. python -m pip install -U setuptools #39.2 -> 47.3.1. python -m pip install scanpy_scripts. #same error. python -m pip install -U wheel. python -m pip install scanpy_scripts. #same error. echo $PYTHONPATH. #is blank. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:9,reliability,doe,does,9,"It still does not work for me, even in a virtualenv. I always get:. ```. #Using legacy setup.py install for umap-learn, since package 'wheel' is not installed. #ERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 1.2.3 which is incompatible. cd /usr/common/lib/python3.6/Envs. rm -rf ~/.cache/pip #make download clearer. python3 -m venv scanpy_scripts. source scanpy_scripts/bin/activate. python -m pip install -U pip. python -m pip install scanpy_scripts. #same error. python -m pip install -U setuptools #39.2 -> 47.3.1. python -m pip install scanpy_scripts. #same error. python -m pip install -U wheel. python -m pip install scanpy_scripts. #same error. echo $PYTHONPATH. #is blank. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:161,safety,ERROR,ERROR,161,"It still does not work for me, even in a virtualenv. I always get:. ```. #Using legacy setup.py install for umap-learn, since package 'wheel' is not installed. #ERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 1.2.3 which is incompatible. cd /usr/common/lib/python3.6/Envs. rm -rf ~/.cache/pip #make download clearer. python3 -m venv scanpy_scripts. source scanpy_scripts/bin/activate. python -m pip install -U pip. python -m pip install scanpy_scripts. #same error. python -m pip install -U setuptools #39.2 -> 47.3.1. python -m pip install scanpy_scripts. #same error. python -m pip install -U wheel. python -m pip install scanpy_scripts. #same error. echo $PYTHONPATH. #is blank. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:487,safety,error,error,487,"It still does not work for me, even in a virtualenv. I always get:. ```. #Using legacy setup.py install for umap-learn, since package 'wheel' is not installed. #ERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 1.2.3 which is incompatible. cd /usr/common/lib/python3.6/Envs. rm -rf ~/.cache/pip #make download clearer. python3 -m venv scanpy_scripts. source scanpy_scripts/bin/activate. python -m pip install -U pip. python -m pip install scanpy_scripts. #same error. python -m pip install -U setuptools #39.2 -> 47.3.1. python -m pip install scanpy_scripts. #same error. python -m pip install -U wheel. python -m pip install scanpy_scripts. #same error. echo $PYTHONPATH. #is blank. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:591,safety,error,error,591,"It still does not work for me, even in a virtualenv. I always get:. ```. #Using legacy setup.py install for umap-learn, since package 'wheel' is not installed. #ERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 1.2.3 which is incompatible. cd /usr/common/lib/python3.6/Envs. rm -rf ~/.cache/pip #make download clearer. python3 -m venv scanpy_scripts. source scanpy_scripts/bin/activate. python -m pip install -U pip. python -m pip install scanpy_scripts. #same error. python -m pip install -U setuptools #39.2 -> 47.3.1. python -m pip install scanpy_scripts. #same error. python -m pip install -U wheel. python -m pip install scanpy_scripts. #same error. echo $PYTHONPATH. #is blank. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:674,safety,error,error,674,"It still does not work for me, even in a virtualenv. I always get:. ```. #Using legacy setup.py install for umap-learn, since package 'wheel' is not installed. #ERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 1.2.3 which is incompatible. cd /usr/common/lib/python3.6/Envs. rm -rf ~/.cache/pip #make download clearer. python3 -m venv scanpy_scripts. source scanpy_scripts/bin/activate. python -m pip install -U pip. python -m pip install scanpy_scripts. #same error. python -m pip install -U setuptools #39.2 -> 47.3.1. python -m pip install scanpy_scripts. #same error. python -m pip install -U wheel. python -m pip install scanpy_scripts. #same error. echo $PYTHONPATH. #is blank. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:113,usability,learn,learn,113,"It still does not work for me, even in a virtualenv. I always get:. ```. #Using legacy setup.py install for umap-learn, since package 'wheel' is not installed. #ERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 1.2.3 which is incompatible. cd /usr/common/lib/python3.6/Envs. rm -rf ~/.cache/pip #make download clearer. python3 -m venv scanpy_scripts. source scanpy_scripts/bin/activate. python -m pip install -U pip. python -m pip install scanpy_scripts. #same error. python -m pip install -U setuptools #39.2 -> 47.3.1. python -m pip install scanpy_scripts. #same error. python -m pip install -U wheel. python -m pip install scanpy_scripts. #same error. echo $PYTHONPATH. #is blank. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:161,usability,ERROR,ERROR,161,"It still does not work for me, even in a virtualenv. I always get:. ```. #Using legacy setup.py install for umap-learn, since package 'wheel' is not installed. #ERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 1.2.3 which is incompatible. cd /usr/common/lib/python3.6/Envs. rm -rf ~/.cache/pip #make download clearer. python3 -m venv scanpy_scripts. source scanpy_scripts/bin/activate. python -m pip install -U pip. python -m pip install scanpy_scripts. #same error. python -m pip install -U setuptools #39.2 -> 47.3.1. python -m pip install scanpy_scripts. #same error. python -m pip install -U wheel. python -m pip install scanpy_scripts. #same error. echo $PYTHONPATH. #is blank. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:173,usability,learn,learn,173,"It still does not work for me, even in a virtualenv. I always get:. ```. #Using legacy setup.py install for umap-learn, since package 'wheel' is not installed. #ERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 1.2.3 which is incompatible. cd /usr/common/lib/python3.6/Envs. rm -rf ~/.cache/pip #make download clearer. python3 -m venv scanpy_scripts. source scanpy_scripts/bin/activate. python -m pip install -U pip. python -m pip install scanpy_scripts. #same error. python -m pip install -U setuptools #39.2 -> 47.3.1. python -m pip install scanpy_scripts. #same error. python -m pip install -U wheel. python -m pip install scanpy_scripts. #same error. echo $PYTHONPATH. #is blank. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:336,usability,clear,clearer,336,"It still does not work for me, even in a virtualenv. I always get:. ```. #Using legacy setup.py install for umap-learn, since package 'wheel' is not installed. #ERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 1.2.3 which is incompatible. cd /usr/common/lib/python3.6/Envs. rm -rf ~/.cache/pip #make download clearer. python3 -m venv scanpy_scripts. source scanpy_scripts/bin/activate. python -m pip install -U pip. python -m pip install scanpy_scripts. #same error. python -m pip install -U setuptools #39.2 -> 47.3.1. python -m pip install scanpy_scripts. #same error. python -m pip install -U wheel. python -m pip install scanpy_scripts. #same error. echo $PYTHONPATH. #is blank. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:487,usability,error,error,487,"It still does not work for me, even in a virtualenv. I always get:. ```. #Using legacy setup.py install for umap-learn, since package 'wheel' is not installed. #ERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 1.2.3 which is incompatible. cd /usr/common/lib/python3.6/Envs. rm -rf ~/.cache/pip #make download clearer. python3 -m venv scanpy_scripts. source scanpy_scripts/bin/activate. python -m pip install -U pip. python -m pip install scanpy_scripts. #same error. python -m pip install -U setuptools #39.2 -> 47.3.1. python -m pip install scanpy_scripts. #same error. python -m pip install -U wheel. python -m pip install scanpy_scripts. #same error. echo $PYTHONPATH. #is blank. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:591,usability,error,error,591,"It still does not work for me, even in a virtualenv. I always get:. ```. #Using legacy setup.py install for umap-learn, since package 'wheel' is not installed. #ERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 1.2.3 which is incompatible. cd /usr/common/lib/python3.6/Envs. rm -rf ~/.cache/pip #make download clearer. python3 -m venv scanpy_scripts. source scanpy_scripts/bin/activate. python -m pip install -U pip. python -m pip install scanpy_scripts. #same error. python -m pip install -U setuptools #39.2 -> 47.3.1. python -m pip install scanpy_scripts. #same error. python -m pip install -U wheel. python -m pip install scanpy_scripts. #same error. echo $PYTHONPATH. #is blank. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:674,usability,error,error,674,"It still does not work for me, even in a virtualenv. I always get:. ```. #Using legacy setup.py install for umap-learn, since package 'wheel' is not installed. #ERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 1.2.3 which is incompatible. cd /usr/common/lib/python3.6/Envs. rm -rf ~/.cache/pip #make download clearer. python3 -m venv scanpy_scripts. source scanpy_scripts/bin/activate. python -m pip install -U pip. python -m pip install scanpy_scripts. #same error. python -m pip install -U setuptools #39.2 -> 47.3.1. python -m pip install scanpy_scripts. #same error. python -m pip install -U wheel. python -m pip install scanpy_scripts. #same error. echo $PYTHONPATH. #is blank. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:266,availability,ERROR,ERROR,266,"Also, set up johnnydep and then do:. `johnnydep --output-format pinned scanpy_scripts. `. and after trundling for a very long time and emitting a lot of messages it gives up with:. ```. Given no hashes to check 0 links for project 'scipy': discarding no candidates. ERROR: Could not find a version that satisfies the requirement scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0 (from versions: 0.8.0, 0.9.0, 0.10.0, 0.10.1, 0.11.0, 0.12.0, 0.12.1, 0.13.0, 0.13.1, 0.13.2, 0.13.3, 0.14.0, 0.14.1, 0.15.0, 0.15.1, 0.16.0, 0.16.1, 0.17.0, 0.17.1, 0.18.0rc2, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 1.0.0b1, 1.0.0rc1, 1.0.0rc2, 1.0.0, 1.0.1, 1.1.0rc1, 1.1.0, 1.2.0rc1, 1.2.0rc2, 1.2.0, 1.2.1, 1.2.2, 1.2.3, 1.3.0rc1, 1.3.0rc2, 1.3.0, 1.3.1, 1.3.2, 1.3.3, 1.4.0rc1, 1.4.0rc2, 1.4.0, 1.4.1, 1.5.0rc1, 1.5.0rc2, 1.5.0). ERROR: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:813,availability,ERROR,ERROR,813,"Also, set up johnnydep and then do:. `johnnydep --output-format pinned scanpy_scripts. `. and after trundling for a very long time and emitting a lot of messages it gives up with:. ```. Given no hashes to check 0 links for project 'scipy': discarding no candidates. ERROR: Could not find a version that satisfies the requirement scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0 (from versions: 0.8.0, 0.9.0, 0.10.0, 0.10.1, 0.11.0, 0.12.0, 0.12.1, 0.13.0, 0.13.1, 0.13.2, 0.13.3, 0.14.0, 0.14.1, 0.15.0, 0.15.1, 0.16.0, 0.16.1, 0.17.0, 0.17.1, 0.18.0rc2, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 1.0.0b1, 1.0.0rc1, 1.0.0rc2, 1.0.0, 1.0.1, 1.1.0rc1, 1.1.0, 1.2.0rc1, 1.2.0rc2, 1.2.0, 1.2.1, 1.2.2, 1.2.3, 1.3.0rc1, 1.3.0rc2, 1.3.0, 1.3.1, 1.3.2, 1.3.3, 1.4.0rc1, 1.4.0rc2, 1.4.0, 1.4.1, 1.5.0rc1, 1.5.0rc2, 1.5.0). ERROR: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:290,deployability,version,version,290,"Also, set up johnnydep and then do:. `johnnydep --output-format pinned scanpy_scripts. `. and after trundling for a very long time and emitting a lot of messages it gives up with:. ```. Given no hashes to check 0 links for project 'scipy': discarding no candidates. ERROR: Could not find a version that satisfies the requirement scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0 (from versions: 0.8.0, 0.9.0, 0.10.0, 0.10.1, 0.11.0, 0.12.0, 0.12.1, 0.13.0, 0.13.1, 0.13.2, 0.13.3, 0.14.0, 0.14.1, 0.15.0, 0.15.1, 0.16.0, 0.16.1, 0.17.0, 0.17.1, 0.18.0rc2, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 1.0.0b1, 1.0.0rc1, 1.0.0rc2, 1.0.0, 1.0.1, 1.1.0rc1, 1.1.0, 1.2.0rc1, 1.2.0rc2, 1.2.0, 1.2.1, 1.2.2, 1.2.3, 1.3.0rc1, 1.3.0rc2, 1.3.0, 1.3.1, 1.3.2, 1.3.3, 1.4.0rc1, 1.4.0rc2, 1.4.0, 1.4.1, 1.5.0rc1, 1.5.0rc2, 1.5.0). ERROR: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:392,deployability,version,versions,392,"Also, set up johnnydep and then do:. `johnnydep --output-format pinned scanpy_scripts. `. and after trundling for a very long time and emitting a lot of messages it gives up with:. ```. Given no hashes to check 0 links for project 'scipy': discarding no candidates. ERROR: Could not find a version that satisfies the requirement scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0 (from versions: 0.8.0, 0.9.0, 0.10.0, 0.10.1, 0.11.0, 0.12.0, 0.12.1, 0.13.0, 0.13.1, 0.13.2, 0.13.3, 0.14.0, 0.14.1, 0.15.0, 0.15.1, 0.16.0, 0.16.1, 0.17.0, 0.17.1, 0.18.0rc2, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 1.0.0b1, 1.0.0rc1, 1.0.0rc2, 1.0.0, 1.0.1, 1.1.0rc1, 1.1.0, 1.2.0rc1, 1.2.0rc2, 1.2.0, 1.2.1, 1.2.2, 1.2.3, 1.3.0rc1, 1.3.0rc2, 1.3.0, 1.3.1, 1.3.2, 1.3.3, 1.4.0rc1, 1.4.0rc2, 1.4.0, 1.4.1, 1.5.0rc1, 1.5.0rc2, 1.5.0). ERROR: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:153,integrability,messag,messages,153,"Also, set up johnnydep and then do:. `johnnydep --output-format pinned scanpy_scripts. `. and after trundling for a very long time and emitting a lot of messages it gives up with:. ```. Given no hashes to check 0 links for project 'scipy': discarding no candidates. ERROR: Could not find a version that satisfies the requirement scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0 (from versions: 0.8.0, 0.9.0, 0.10.0, 0.10.1, 0.11.0, 0.12.0, 0.12.1, 0.13.0, 0.13.1, 0.13.2, 0.13.3, 0.14.0, 0.14.1, 0.15.0, 0.15.1, 0.16.0, 0.16.1, 0.17.0, 0.17.1, 0.18.0rc2, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 1.0.0b1, 1.0.0rc1, 1.0.0rc2, 1.0.0, 1.0.1, 1.1.0rc1, 1.1.0, 1.2.0rc1, 1.2.0rc2, 1.2.0, 1.2.1, 1.2.2, 1.2.3, 1.3.0rc1, 1.3.0rc2, 1.3.0, 1.3.1, 1.3.2, 1.3.3, 1.4.0rc1, 1.4.0rc2, 1.4.0, 1.4.1, 1.5.0rc1, 1.5.0rc2, 1.5.0). ERROR: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:290,integrability,version,version,290,"Also, set up johnnydep and then do:. `johnnydep --output-format pinned scanpy_scripts. `. and after trundling for a very long time and emitting a lot of messages it gives up with:. ```. Given no hashes to check 0 links for project 'scipy': discarding no candidates. ERROR: Could not find a version that satisfies the requirement scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0 (from versions: 0.8.0, 0.9.0, 0.10.0, 0.10.1, 0.11.0, 0.12.0, 0.12.1, 0.13.0, 0.13.1, 0.13.2, 0.13.3, 0.14.0, 0.14.1, 0.15.0, 0.15.1, 0.16.0, 0.16.1, 0.17.0, 0.17.1, 0.18.0rc2, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 1.0.0b1, 1.0.0rc1, 1.0.0rc2, 1.0.0, 1.0.1, 1.1.0rc1, 1.1.0, 1.2.0rc1, 1.2.0rc2, 1.2.0, 1.2.1, 1.2.2, 1.2.3, 1.3.0rc1, 1.3.0rc2, 1.3.0, 1.3.1, 1.3.2, 1.3.3, 1.4.0rc1, 1.4.0rc2, 1.4.0, 1.4.1, 1.5.0rc1, 1.5.0rc2, 1.5.0). ERROR: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:392,integrability,version,versions,392,"Also, set up johnnydep and then do:. `johnnydep --output-format pinned scanpy_scripts. `. and after trundling for a very long time and emitting a lot of messages it gives up with:. ```. Given no hashes to check 0 links for project 'scipy': discarding no candidates. ERROR: Could not find a version that satisfies the requirement scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0 (from versions: 0.8.0, 0.9.0, 0.10.0, 0.10.1, 0.11.0, 0.12.0, 0.12.1, 0.13.0, 0.13.1, 0.13.2, 0.13.3, 0.14.0, 0.14.1, 0.15.0, 0.15.1, 0.16.0, 0.16.1, 0.17.0, 0.17.1, 0.18.0rc2, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 1.0.0b1, 1.0.0rc1, 1.0.0rc2, 1.0.0, 1.0.1, 1.1.0rc1, 1.1.0, 1.2.0rc1, 1.2.0rc2, 1.2.0, 1.2.1, 1.2.2, 1.2.3, 1.3.0rc1, 1.3.0rc2, 1.3.0, 1.3.1, 1.3.2, 1.3.3, 1.4.0rc1, 1.4.0rc2, 1.4.0, 1.4.1, 1.5.0rc1, 1.5.0rc2, 1.5.0). ERROR: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:57,interoperability,format,format,57,"Also, set up johnnydep and then do:. `johnnydep --output-format pinned scanpy_scripts. `. and after trundling for a very long time and emitting a lot of messages it gives up with:. ```. Given no hashes to check 0 links for project 'scipy': discarding no candidates. ERROR: Could not find a version that satisfies the requirement scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0 (from versions: 0.8.0, 0.9.0, 0.10.0, 0.10.1, 0.11.0, 0.12.0, 0.12.1, 0.13.0, 0.13.1, 0.13.2, 0.13.3, 0.14.0, 0.14.1, 0.15.0, 0.15.1, 0.16.0, 0.16.1, 0.17.0, 0.17.1, 0.18.0rc2, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 1.0.0b1, 1.0.0rc1, 1.0.0rc2, 1.0.0, 1.0.1, 1.1.0rc1, 1.1.0, 1.2.0rc1, 1.2.0rc2, 1.2.0, 1.2.1, 1.2.2, 1.2.3, 1.3.0rc1, 1.3.0rc2, 1.3.0, 1.3.1, 1.3.2, 1.3.3, 1.4.0rc1, 1.4.0rc2, 1.4.0, 1.4.1, 1.5.0rc1, 1.5.0rc2, 1.5.0). ERROR: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:153,interoperability,messag,messages,153,"Also, set up johnnydep and then do:. `johnnydep --output-format pinned scanpy_scripts. `. and after trundling for a very long time and emitting a lot of messages it gives up with:. ```. Given no hashes to check 0 links for project 'scipy': discarding no candidates. ERROR: Could not find a version that satisfies the requirement scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0 (from versions: 0.8.0, 0.9.0, 0.10.0, 0.10.1, 0.11.0, 0.12.0, 0.12.1, 0.13.0, 0.13.1, 0.13.2, 0.13.3, 0.14.0, 0.14.1, 0.15.0, 0.15.1, 0.16.0, 0.16.1, 0.17.0, 0.17.1, 0.18.0rc2, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 1.0.0b1, 1.0.0rc1, 1.0.0rc2, 1.0.0, 1.0.1, 1.1.0rc1, 1.1.0, 1.2.0rc1, 1.2.0rc2, 1.2.0, 1.2.1, 1.2.2, 1.2.3, 1.3.0rc1, 1.3.0rc2, 1.3.0, 1.3.1, 1.3.2, 1.3.3, 1.4.0rc1, 1.4.0rc2, 1.4.0, 1.4.1, 1.5.0rc1, 1.5.0rc2, 1.5.0). ERROR: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:832,interoperability,distribut,distribution,832,"Also, set up johnnydep and then do:. `johnnydep --output-format pinned scanpy_scripts. `. and after trundling for a very long time and emitting a lot of messages it gives up with:. ```. Given no hashes to check 0 links for project 'scipy': discarding no candidates. ERROR: Could not find a version that satisfies the requirement scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0 (from versions: 0.8.0, 0.9.0, 0.10.0, 0.10.1, 0.11.0, 0.12.0, 0.12.1, 0.13.0, 0.13.1, 0.13.2, 0.13.3, 0.14.0, 0.14.1, 0.15.0, 0.15.1, 0.16.0, 0.16.1, 0.17.0, 0.17.1, 0.18.0rc2, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 1.0.0b1, 1.0.0rc1, 1.0.0rc2, 1.0.0, 1.0.1, 1.1.0rc1, 1.1.0, 1.2.0rc1, 1.2.0rc2, 1.2.0, 1.2.1, 1.2.2, 1.2.3, 1.3.0rc1, 1.3.0rc2, 1.3.0, 1.3.1, 1.3.2, 1.3.3, 1.4.0rc1, 1.4.0rc2, 1.4.0, 1.4.1, 1.5.0rc1, 1.5.0rc2, 1.5.0). ERROR: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:290,modifiability,version,version,290,"Also, set up johnnydep and then do:. `johnnydep --output-format pinned scanpy_scripts. `. and after trundling for a very long time and emitting a lot of messages it gives up with:. ```. Given no hashes to check 0 links for project 'scipy': discarding no candidates. ERROR: Could not find a version that satisfies the requirement scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0 (from versions: 0.8.0, 0.9.0, 0.10.0, 0.10.1, 0.11.0, 0.12.0, 0.12.1, 0.13.0, 0.13.1, 0.13.2, 0.13.3, 0.14.0, 0.14.1, 0.15.0, 0.15.1, 0.16.0, 0.16.1, 0.17.0, 0.17.1, 0.18.0rc2, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 1.0.0b1, 1.0.0rc1, 1.0.0rc2, 1.0.0, 1.0.1, 1.1.0rc1, 1.1.0, 1.2.0rc1, 1.2.0rc2, 1.2.0, 1.2.1, 1.2.2, 1.2.3, 1.3.0rc1, 1.3.0rc2, 1.3.0, 1.3.1, 1.3.2, 1.3.3, 1.4.0rc1, 1.4.0rc2, 1.4.0, 1.4.1, 1.5.0rc1, 1.5.0rc2, 1.5.0). ERROR: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:392,modifiability,version,versions,392,"Also, set up johnnydep and then do:. `johnnydep --output-format pinned scanpy_scripts. `. and after trundling for a very long time and emitting a lot of messages it gives up with:. ```. Given no hashes to check 0 links for project 'scipy': discarding no candidates. ERROR: Could not find a version that satisfies the requirement scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0 (from versions: 0.8.0, 0.9.0, 0.10.0, 0.10.1, 0.11.0, 0.12.0, 0.12.1, 0.13.0, 0.13.1, 0.13.2, 0.13.3, 0.14.0, 0.14.1, 0.15.0, 0.15.1, 0.16.0, 0.16.1, 0.17.0, 0.17.1, 0.18.0rc2, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 1.0.0b1, 1.0.0rc1, 1.0.0rc2, 1.0.0, 1.0.1, 1.1.0rc1, 1.1.0, 1.2.0rc1, 1.2.0rc2, 1.2.0, 1.2.1, 1.2.2, 1.2.3, 1.3.0rc1, 1.3.0rc2, 1.3.0, 1.3.1, 1.3.2, 1.3.3, 1.4.0rc1, 1.4.0rc2, 1.4.0, 1.4.1, 1.5.0rc1, 1.5.0rc2, 1.5.0). ERROR: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:126,performance,time,time,126,"Also, set up johnnydep and then do:. `johnnydep --output-format pinned scanpy_scripts. `. and after trundling for a very long time and emitting a lot of messages it gives up with:. ```. Given no hashes to check 0 links for project 'scipy': discarding no candidates. ERROR: Could not find a version that satisfies the requirement scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0 (from versions: 0.8.0, 0.9.0, 0.10.0, 0.10.1, 0.11.0, 0.12.0, 0.12.1, 0.13.0, 0.13.1, 0.13.2, 0.13.3, 0.14.0, 0.14.1, 0.15.0, 0.15.1, 0.16.0, 0.16.1, 0.17.0, 0.17.1, 0.18.0rc2, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 1.0.0b1, 1.0.0rc1, 1.0.0rc2, 1.0.0, 1.0.1, 1.1.0rc1, 1.1.0, 1.2.0rc1, 1.2.0rc2, 1.2.0, 1.2.1, 1.2.2, 1.2.3, 1.3.0rc1, 1.3.0rc2, 1.3.0, 1.3.1, 1.3.2, 1.3.3, 1.4.0rc1, 1.4.0rc2, 1.4.0, 1.4.1, 1.5.0rc1, 1.5.0rc2, 1.5.0). ERROR: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:266,performance,ERROR,ERROR,266,"Also, set up johnnydep and then do:. `johnnydep --output-format pinned scanpy_scripts. `. and after trundling for a very long time and emitting a lot of messages it gives up with:. ```. Given no hashes to check 0 links for project 'scipy': discarding no candidates. ERROR: Could not find a version that satisfies the requirement scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0 (from versions: 0.8.0, 0.9.0, 0.10.0, 0.10.1, 0.11.0, 0.12.0, 0.12.1, 0.13.0, 0.13.1, 0.13.2, 0.13.3, 0.14.0, 0.14.1, 0.15.0, 0.15.1, 0.16.0, 0.16.1, 0.17.0, 0.17.1, 0.18.0rc2, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 1.0.0b1, 1.0.0rc1, 1.0.0rc2, 1.0.0, 1.0.1, 1.1.0rc1, 1.1.0, 1.2.0rc1, 1.2.0rc2, 1.2.0, 1.2.1, 1.2.2, 1.2.3, 1.3.0rc1, 1.3.0rc2, 1.3.0, 1.3.1, 1.3.2, 1.3.3, 1.4.0rc1, 1.4.0rc2, 1.4.0, 1.4.1, 1.5.0rc1, 1.5.0rc2, 1.5.0). ERROR: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:813,performance,ERROR,ERROR,813,"Also, set up johnnydep and then do:. `johnnydep --output-format pinned scanpy_scripts. `. and after trundling for a very long time and emitting a lot of messages it gives up with:. ```. Given no hashes to check 0 links for project 'scipy': discarding no candidates. ERROR: Could not find a version that satisfies the requirement scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0 (from versions: 0.8.0, 0.9.0, 0.10.0, 0.10.1, 0.11.0, 0.12.0, 0.12.1, 0.13.0, 0.13.1, 0.13.2, 0.13.3, 0.14.0, 0.14.1, 0.15.0, 0.15.1, 0.16.0, 0.16.1, 0.17.0, 0.17.1, 0.18.0rc2, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 1.0.0b1, 1.0.0rc1, 1.0.0rc2, 1.0.0, 1.0.1, 1.1.0rc1, 1.1.0, 1.2.0rc1, 1.2.0rc2, 1.2.0, 1.2.1, 1.2.2, 1.2.3, 1.3.0rc1, 1.3.0rc2, 1.3.0, 1.3.1, 1.3.2, 1.3.3, 1.4.0rc1, 1.4.0rc2, 1.4.0, 1.4.1, 1.5.0rc1, 1.5.0rc2, 1.5.0). ERROR: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:266,safety,ERROR,ERROR,266,"Also, set up johnnydep and then do:. `johnnydep --output-format pinned scanpy_scripts. `. and after trundling for a very long time and emitting a lot of messages it gives up with:. ```. Given no hashes to check 0 links for project 'scipy': discarding no candidates. ERROR: Could not find a version that satisfies the requirement scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0 (from versions: 0.8.0, 0.9.0, 0.10.0, 0.10.1, 0.11.0, 0.12.0, 0.12.1, 0.13.0, 0.13.1, 0.13.2, 0.13.3, 0.14.0, 0.14.1, 0.15.0, 0.15.1, 0.16.0, 0.16.1, 0.17.0, 0.17.1, 0.18.0rc2, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 1.0.0b1, 1.0.0rc1, 1.0.0rc2, 1.0.0, 1.0.1, 1.1.0rc1, 1.1.0, 1.2.0rc1, 1.2.0rc2, 1.2.0, 1.2.1, 1.2.2, 1.2.3, 1.3.0rc1, 1.3.0rc2, 1.3.0, 1.3.1, 1.3.2, 1.3.3, 1.4.0rc1, 1.4.0rc2, 1.4.0, 1.4.1, 1.5.0rc1, 1.5.0rc2, 1.5.0). ERROR: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:813,safety,ERROR,ERROR,813,"Also, set up johnnydep and then do:. `johnnydep --output-format pinned scanpy_scripts. `. and after trundling for a very long time and emitting a lot of messages it gives up with:. ```. Given no hashes to check 0 links for project 'scipy': discarding no candidates. ERROR: Could not find a version that satisfies the requirement scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0 (from versions: 0.8.0, 0.9.0, 0.10.0, 0.10.1, 0.11.0, 0.12.0, 0.12.1, 0.13.0, 0.13.1, 0.13.2, 0.13.3, 0.14.0, 0.14.1, 0.15.0, 0.15.1, 0.16.0, 0.16.1, 0.17.0, 0.17.1, 0.18.0rc2, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 1.0.0b1, 1.0.0rc1, 1.0.0rc2, 1.0.0, 1.0.1, 1.1.0rc1, 1.1.0, 1.2.0rc1, 1.2.0rc2, 1.2.0, 1.2.1, 1.2.2, 1.2.3, 1.3.0rc1, 1.3.0rc2, 1.3.0, 1.3.1, 1.3.2, 1.3.3, 1.4.0rc1, 1.4.0rc2, 1.4.0, 1.4.1, 1.5.0rc1, 1.5.0rc2, 1.5.0). ERROR: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:195,security,hash,hashes,195,"Also, set up johnnydep and then do:. `johnnydep --output-format pinned scanpy_scripts. `. and after trundling for a very long time and emitting a lot of messages it gives up with:. ```. Given no hashes to check 0 links for project 'scipy': discarding no candidates. ERROR: Could not find a version that satisfies the requirement scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0 (from versions: 0.8.0, 0.9.0, 0.10.0, 0.10.1, 0.11.0, 0.12.0, 0.12.1, 0.13.0, 0.13.1, 0.13.2, 0.13.3, 0.14.0, 0.14.1, 0.15.0, 0.15.1, 0.16.0, 0.16.1, 0.17.0, 0.17.1, 0.18.0rc2, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 1.0.0b1, 1.0.0rc1, 1.0.0rc2, 1.0.0, 1.0.1, 1.1.0rc1, 1.1.0, 1.2.0rc1, 1.2.0rc2, 1.2.0, 1.2.1, 1.2.2, 1.2.3, 1.3.0rc1, 1.3.0rc2, 1.3.0, 1.3.1, 1.3.2, 1.3.3, 1.4.0rc1, 1.4.0rc2, 1.4.0, 1.4.1, 1.5.0rc1, 1.5.0rc2, 1.5.0). ERROR: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:266,usability,ERROR,ERROR,266,"Also, set up johnnydep and then do:. `johnnydep --output-format pinned scanpy_scripts. `. and after trundling for a very long time and emitting a lot of messages it gives up with:. ```. Given no hashes to check 0 links for project 'scipy': discarding no candidates. ERROR: Could not find a version that satisfies the requirement scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0 (from versions: 0.8.0, 0.9.0, 0.10.0, 0.10.1, 0.11.0, 0.12.0, 0.12.1, 0.13.0, 0.13.1, 0.13.2, 0.13.3, 0.14.0, 0.14.1, 0.15.0, 0.15.1, 0.16.0, 0.16.1, 0.17.0, 0.17.1, 0.18.0rc2, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 1.0.0b1, 1.0.0rc1, 1.0.0rc2, 1.0.0, 1.0.1, 1.1.0rc1, 1.1.0, 1.2.0rc1, 1.2.0rc2, 1.2.0, 1.2.1, 1.2.2, 1.2.3, 1.3.0rc1, 1.3.0rc2, 1.3.0, 1.3.1, 1.3.2, 1.3.3, 1.4.0rc1, 1.4.0rc2, 1.4.0, 1.4.1, 1.5.0rc1, 1.5.0rc2, 1.5.0). ERROR: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:813,usability,ERROR,ERROR,813,"Also, set up johnnydep and then do:. `johnnydep --output-format pinned scanpy_scripts. `. and after trundling for a very long time and emitting a lot of messages it gives up with:. ```. Given no hashes to check 0 links for project 'scipy': discarding no candidates. ERROR: Could not find a version that satisfies the requirement scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0 (from versions: 0.8.0, 0.9.0, 0.10.0, 0.10.1, 0.11.0, 0.12.0, 0.12.1, 0.13.0, 0.13.1, 0.13.2, 0.13.3, 0.14.0, 0.14.1, 0.15.0, 0.15.1, 0.16.0, 0.16.1, 0.17.0, 0.17.1, 0.18.0rc2, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 1.0.0b1, 1.0.0rc1, 1.0.0rc2, 1.0.0, 1.0.1, 1.1.0rc1, 1.1.0, 1.2.0rc1, 1.2.0rc2, 1.2.0, 1.2.1, 1.2.2, 1.2.3, 1.3.0rc1, 1.3.0rc2, 1.3.0, 1.3.1, 1.3.2, 1.3.3, 1.4.0rc1, 1.4.0rc2, 1.4.0, 1.4.1, 1.5.0rc1, 1.5.0rc2, 1.5.0). ERROR: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:59,deployability,version,version,59,"It's definitely a problem that you are seeing all of these version restrictions at once. This may be related to having too many entries in your PYTHONPATH environment variable. `PYTHONPATH` should probably just be empty, since python already knows to look where pip installs packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:266,deployability,instal,installs,266,"It's definitely a problem that you are seeing all of these version restrictions at once. This may be related to having too many entries in your PYTHONPATH environment variable. `PYTHONPATH` should probably just be empty, since python already knows to look where pip installs packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:59,integrability,version,version,59,"It's definitely a problem that you are seeing all of these version restrictions at once. This may be related to having too many entries in your PYTHONPATH environment variable. `PYTHONPATH` should probably just be empty, since python already knows to look where pip installs packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:59,modifiability,version,version,59,"It's definitely a problem that you are seeing all of these version restrictions at once. This may be related to having too many entries in your PYTHONPATH environment variable. `PYTHONPATH` should probably just be empty, since python already knows to look where pip installs packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:167,modifiability,variab,variable,167,"It's definitely a problem that you are seeing all of these version restrictions at once. This may be related to having too many entries in your PYTHONPATH environment variable. `PYTHONPATH` should probably just be empty, since python already knows to look where pip installs packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:275,modifiability,pac,packages,275,"It's definitely a problem that you are seeing all of these version restrictions at once. This may be related to having too many entries in your PYTHONPATH environment variable. `PYTHONPATH` should probably just be empty, since python already knows to look where pip installs packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:122,availability,down,downloads,122,"Look at the virtualenv example - PYTHONPATH was empty. The johnnydep application does not actually do an install, it just downloads all the pieces a package calls for and looks at all the listed requirements - and it gives the same version restriction conflict as an actual installation attemp.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:105,deployability,instal,install,105,"Look at the virtualenv example - PYTHONPATH was empty. The johnnydep application does not actually do an install, it just downloads all the pieces a package calls for and looks at all the listed requirements - and it gives the same version restriction conflict as an actual installation attemp.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:232,deployability,version,version,232,"Look at the virtualenv example - PYTHONPATH was empty. The johnnydep application does not actually do an install, it just downloads all the pieces a package calls for and looks at all the listed requirements - and it gives the same version restriction conflict as an actual installation attemp.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:274,deployability,instal,installation,274,"Look at the virtualenv example - PYTHONPATH was empty. The johnnydep application does not actually do an install, it just downloads all the pieces a package calls for and looks at all the listed requirements - and it gives the same version restriction conflict as an actual installation attemp.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:232,integrability,version,version,232,"Look at the virtualenv example - PYTHONPATH was empty. The johnnydep application does not actually do an install, it just downloads all the pieces a package calls for and looks at all the listed requirements - and it gives the same version restriction conflict as an actual installation attemp.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:252,interoperability,conflict,conflict,252,"Look at the virtualenv example - PYTHONPATH was empty. The johnnydep application does not actually do an install, it just downloads all the pieces a package calls for and looks at all the listed requirements - and it gives the same version restriction conflict as an actual installation attemp.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:149,modifiability,pac,package,149,"Look at the virtualenv example - PYTHONPATH was empty. The johnnydep application does not actually do an install, it just downloads all the pieces a package calls for and looks at all the listed requirements - and it gives the same version restriction conflict as an actual installation attemp.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:232,modifiability,version,version,232,"Look at the virtualenv example - PYTHONPATH was empty. The johnnydep application does not actually do an install, it just downloads all the pieces a package calls for and looks at all the listed requirements - and it gives the same version restriction conflict as an actual installation attemp.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:81,reliability,doe,does,81,"Look at the virtualenv example - PYTHONPATH was empty. The johnnydep application does not actually do an install, it just downloads all the pieces a package calls for and looks at all the listed requirements - and it gives the same version restriction conflict as an actual installation attemp.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:36,deployability,depend,dependency,36,Which package has the `scipy<1.3.0` dependency?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:36,integrability,depend,dependency,36,Which package has the `scipy<1.3.0` dependency?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:6,modifiability,pac,package,6,Which package has the `scipy<1.3.0` dependency?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:36,modifiability,depend,dependency,36,Which package has the `scipy<1.3.0` dependency?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:36,safety,depend,dependency,36,Which package has the `scipy<1.3.0` dependency?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:36,testability,depend,dependency,36,Which package has the `scipy<1.3.0` dependency?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:920,availability,ERROR,ERROR,920,"It seems to be scanpy-scripts itself. johnnydep analysis shows these (99% of lines removed):. ```. 2020-07-20 18:57:50 [info ] init johnnydist [johnnydep.lib] dist=scipy<1.3.0,>=1.2.0 parent=scanpy-scripts. 2020-07-20 18:58:10 [info ] init johnnydist [johnnydep.lib] dist=scipy~=1.0 parent=anndata<0.6.20. 2020-07-20 18:59:17 [info ] init johnnydist [johnnydep.lib] dist=scipy~=1.0 parent=anndata>=0.6.15. 2020-07-20 18:59:26 [info ] init johnnydist [johnnydep.lib] dist=scipy>=0.19.1 parent=scikit-learn>=0.19.1. 2020-07-20 18:59:58 [info ] init johnnydist [johnnydep.lib] dist=scipy>=1.3.1 parent=umap-learn>=0.3.0. ```. and later. ```. 2020-07-20 19:00:14 [info ] merged specs [johnnydep.lib] dist=scanpy-scripts extras=. set() name=scipy spec=<SpecifierSet('<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0', prereleases=True)>. ```. It cannot match both <1.3.0 and >= 1.3.1, and eventually bails out with:. ```. ERROR: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. pip._internal.exceptions.DistributionNotFound: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. subprocess.CalledProcessError: Command '['/usr/bin/python3', '-m', 'pip', 'wheel', '-vvv', '--no-deps', '--no-cache-dir', '--disable-pip-version-check', '--pro. gress-bar=off', 'scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0']' returned non-zero exit status 1. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:1297,deployability,version,version-check,1297,"It seems to be scanpy-scripts itself. johnnydep analysis shows these (99% of lines removed):. ```. 2020-07-20 18:57:50 [info ] init johnnydist [johnnydep.lib] dist=scipy<1.3.0,>=1.2.0 parent=scanpy-scripts. 2020-07-20 18:58:10 [info ] init johnnydist [johnnydep.lib] dist=scipy~=1.0 parent=anndata<0.6.20. 2020-07-20 18:59:17 [info ] init johnnydist [johnnydep.lib] dist=scipy~=1.0 parent=anndata>=0.6.15. 2020-07-20 18:59:26 [info ] init johnnydist [johnnydep.lib] dist=scipy>=0.19.1 parent=scikit-learn>=0.19.1. 2020-07-20 18:59:58 [info ] init johnnydist [johnnydep.lib] dist=scipy>=1.3.1 parent=umap-learn>=0.3.0. ```. and later. ```. 2020-07-20 19:00:14 [info ] merged specs [johnnydep.lib] dist=scanpy-scripts extras=. set() name=scipy spec=<SpecifierSet('<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0', prereleases=True)>. ```. It cannot match both <1.3.0 and >= 1.3.1, and eventually bails out with:. ```. ERROR: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. pip._internal.exceptions.DistributionNotFound: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. subprocess.CalledProcessError: Command '['/usr/bin/python3', '-m', 'pip', 'wheel', '-vvv', '--no-deps', '--no-cache-dir', '--disable-pip-version-check', '--pro. gress-bar=off', 'scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0']' returned non-zero exit status 1. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:887,integrability,event,eventually,887,"It seems to be scanpy-scripts itself. johnnydep analysis shows these (99% of lines removed):. ```. 2020-07-20 18:57:50 [info ] init johnnydist [johnnydep.lib] dist=scipy<1.3.0,>=1.2.0 parent=scanpy-scripts. 2020-07-20 18:58:10 [info ] init johnnydist [johnnydep.lib] dist=scipy~=1.0 parent=anndata<0.6.20. 2020-07-20 18:59:17 [info ] init johnnydist [johnnydep.lib] dist=scipy~=1.0 parent=anndata>=0.6.15. 2020-07-20 18:59:26 [info ] init johnnydist [johnnydep.lib] dist=scipy>=0.19.1 parent=scikit-learn>=0.19.1. 2020-07-20 18:59:58 [info ] init johnnydist [johnnydep.lib] dist=scipy>=1.3.1 parent=umap-learn>=0.3.0. ```. and later. ```. 2020-07-20 19:00:14 [info ] merged specs [johnnydep.lib] dist=scanpy-scripts extras=. set() name=scipy spec=<SpecifierSet('<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0', prereleases=True)>. ```. It cannot match both <1.3.0 and >= 1.3.1, and eventually bails out with:. ```. ERROR: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. pip._internal.exceptions.DistributionNotFound: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. subprocess.CalledProcessError: Command '['/usr/bin/python3', '-m', 'pip', 'wheel', '-vvv', '--no-deps', '--no-cache-dir', '--disable-pip-version-check', '--pro. gress-bar=off', 'scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0']' returned non-zero exit status 1. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:1160,integrability,sub,subprocess,1160,"It seems to be scanpy-scripts itself. johnnydep analysis shows these (99% of lines removed):. ```. 2020-07-20 18:57:50 [info ] init johnnydist [johnnydep.lib] dist=scipy<1.3.0,>=1.2.0 parent=scanpy-scripts. 2020-07-20 18:58:10 [info ] init johnnydist [johnnydep.lib] dist=scipy~=1.0 parent=anndata<0.6.20. 2020-07-20 18:59:17 [info ] init johnnydist [johnnydep.lib] dist=scipy~=1.0 parent=anndata>=0.6.15. 2020-07-20 18:59:26 [info ] init johnnydist [johnnydep.lib] dist=scipy>=0.19.1 parent=scikit-learn>=0.19.1. 2020-07-20 18:59:58 [info ] init johnnydist [johnnydep.lib] dist=scipy>=1.3.1 parent=umap-learn>=0.3.0. ```. and later. ```. 2020-07-20 19:00:14 [info ] merged specs [johnnydep.lib] dist=scanpy-scripts extras=. set() name=scipy spec=<SpecifierSet('<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0', prereleases=True)>. ```. It cannot match both <1.3.0 and >= 1.3.1, and eventually bails out with:. ```. ERROR: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. pip._internal.exceptions.DistributionNotFound: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. subprocess.CalledProcessError: Command '['/usr/bin/python3', '-m', 'pip', 'wheel', '-vvv', '--no-deps', '--no-cache-dir', '--disable-pip-version-check', '--pro. gress-bar=off', 'scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0']' returned non-zero exit status 1. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:1297,integrability,version,version-check,1297,"It seems to be scanpy-scripts itself. johnnydep analysis shows these (99% of lines removed):. ```. 2020-07-20 18:57:50 [info ] init johnnydist [johnnydep.lib] dist=scipy<1.3.0,>=1.2.0 parent=scanpy-scripts. 2020-07-20 18:58:10 [info ] init johnnydist [johnnydep.lib] dist=scipy~=1.0 parent=anndata<0.6.20. 2020-07-20 18:59:17 [info ] init johnnydist [johnnydep.lib] dist=scipy~=1.0 parent=anndata>=0.6.15. 2020-07-20 18:59:26 [info ] init johnnydist [johnnydep.lib] dist=scipy>=0.19.1 parent=scikit-learn>=0.19.1. 2020-07-20 18:59:58 [info ] init johnnydist [johnnydep.lib] dist=scipy>=1.3.1 parent=umap-learn>=0.3.0. ```. and later. ```. 2020-07-20 19:00:14 [info ] merged specs [johnnydep.lib] dist=scanpy-scripts extras=. set() name=scipy spec=<SpecifierSet('<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0', prereleases=True)>. ```. It cannot match both <1.3.0 and >= 1.3.1, and eventually bails out with:. ```. ERROR: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. pip._internal.exceptions.DistributionNotFound: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. subprocess.CalledProcessError: Command '['/usr/bin/python3', '-m', 'pip', 'wheel', '-vvv', '--no-deps', '--no-cache-dir', '--disable-pip-version-check', '--pro. gress-bar=off', 'scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0']' returned non-zero exit status 1. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:748,interoperability,Specif,SpecifierSet,748,"It seems to be scanpy-scripts itself. johnnydep analysis shows these (99% of lines removed):. ```. 2020-07-20 18:57:50 [info ] init johnnydist [johnnydep.lib] dist=scipy<1.3.0,>=1.2.0 parent=scanpy-scripts. 2020-07-20 18:58:10 [info ] init johnnydist [johnnydep.lib] dist=scipy~=1.0 parent=anndata<0.6.20. 2020-07-20 18:59:17 [info ] init johnnydist [johnnydep.lib] dist=scipy~=1.0 parent=anndata>=0.6.15. 2020-07-20 18:59:26 [info ] init johnnydist [johnnydep.lib] dist=scipy>=0.19.1 parent=scikit-learn>=0.19.1. 2020-07-20 18:59:58 [info ] init johnnydist [johnnydep.lib] dist=scipy>=1.3.1 parent=umap-learn>=0.3.0. ```. and later. ```. 2020-07-20 19:00:14 [info ] merged specs [johnnydep.lib] dist=scanpy-scripts extras=. set() name=scipy spec=<SpecifierSet('<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0', prereleases=True)>. ```. It cannot match both <1.3.0 and >= 1.3.1, and eventually bails out with:. ```. ERROR: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. pip._internal.exceptions.DistributionNotFound: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. subprocess.CalledProcessError: Command '['/usr/bin/python3', '-m', 'pip', 'wheel', '-vvv', '--no-deps', '--no-cache-dir', '--disable-pip-version-check', '--pro. gress-bar=off', 'scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0']' returned non-zero exit status 1. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:939,interoperability,distribut,distribution,939,"It seems to be scanpy-scripts itself. johnnydep analysis shows these (99% of lines removed):. ```. 2020-07-20 18:57:50 [info ] init johnnydist [johnnydep.lib] dist=scipy<1.3.0,>=1.2.0 parent=scanpy-scripts. 2020-07-20 18:58:10 [info ] init johnnydist [johnnydep.lib] dist=scipy~=1.0 parent=anndata<0.6.20. 2020-07-20 18:59:17 [info ] init johnnydist [johnnydep.lib] dist=scipy~=1.0 parent=anndata>=0.6.15. 2020-07-20 18:59:26 [info ] init johnnydist [johnnydep.lib] dist=scipy>=0.19.1 parent=scikit-learn>=0.19.1. 2020-07-20 18:59:58 [info ] init johnnydist [johnnydep.lib] dist=scipy>=1.3.1 parent=umap-learn>=0.3.0. ```. and later. ```. 2020-07-20 19:00:14 [info ] merged specs [johnnydep.lib] dist=scanpy-scripts extras=. set() name=scipy spec=<SpecifierSet('<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0', prereleases=True)>. ```. It cannot match both <1.3.0 and >= 1.3.1, and eventually bails out with:. ```. ERROR: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. pip._internal.exceptions.DistributionNotFound: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. subprocess.CalledProcessError: Command '['/usr/bin/python3', '-m', 'pip', 'wheel', '-vvv', '--no-deps', '--no-cache-dir', '--disable-pip-version-check', '--pro. gress-bar=off', 'scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0']' returned non-zero exit status 1. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:1045,interoperability,Distribut,DistributionNotFound,1045,"It seems to be scanpy-scripts itself. johnnydep analysis shows these (99% of lines removed):. ```. 2020-07-20 18:57:50 [info ] init johnnydist [johnnydep.lib] dist=scipy<1.3.0,>=1.2.0 parent=scanpy-scripts. 2020-07-20 18:58:10 [info ] init johnnydist [johnnydep.lib] dist=scipy~=1.0 parent=anndata<0.6.20. 2020-07-20 18:59:17 [info ] init johnnydist [johnnydep.lib] dist=scipy~=1.0 parent=anndata>=0.6.15. 2020-07-20 18:59:26 [info ] init johnnydist [johnnydep.lib] dist=scipy>=0.19.1 parent=scikit-learn>=0.19.1. 2020-07-20 18:59:58 [info ] init johnnydist [johnnydep.lib] dist=scipy>=1.3.1 parent=umap-learn>=0.3.0. ```. and later. ```. 2020-07-20 19:00:14 [info ] merged specs [johnnydep.lib] dist=scanpy-scripts extras=. set() name=scipy spec=<SpecifierSet('<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0', prereleases=True)>. ```. It cannot match both <1.3.0 and >= 1.3.1, and eventually bails out with:. ```. ERROR: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. pip._internal.exceptions.DistributionNotFound: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. subprocess.CalledProcessError: Command '['/usr/bin/python3', '-m', 'pip', 'wheel', '-vvv', '--no-deps', '--no-cache-dir', '--disable-pip-version-check', '--pro. gress-bar=off', 'scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0']' returned non-zero exit status 1. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:1079,interoperability,distribut,distribution,1079,"It seems to be scanpy-scripts itself. johnnydep analysis shows these (99% of lines removed):. ```. 2020-07-20 18:57:50 [info ] init johnnydist [johnnydep.lib] dist=scipy<1.3.0,>=1.2.0 parent=scanpy-scripts. 2020-07-20 18:58:10 [info ] init johnnydist [johnnydep.lib] dist=scipy~=1.0 parent=anndata<0.6.20. 2020-07-20 18:59:17 [info ] init johnnydist [johnnydep.lib] dist=scipy~=1.0 parent=anndata>=0.6.15. 2020-07-20 18:59:26 [info ] init johnnydist [johnnydep.lib] dist=scipy>=0.19.1 parent=scikit-learn>=0.19.1. 2020-07-20 18:59:58 [info ] init johnnydist [johnnydep.lib] dist=scipy>=1.3.1 parent=umap-learn>=0.3.0. ```. and later. ```. 2020-07-20 19:00:14 [info ] merged specs [johnnydep.lib] dist=scanpy-scripts extras=. set() name=scipy spec=<SpecifierSet('<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0', prereleases=True)>. ```. It cannot match both <1.3.0 and >= 1.3.1, and eventually bails out with:. ```. ERROR: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. pip._internal.exceptions.DistributionNotFound: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. subprocess.CalledProcessError: Command '['/usr/bin/python3', '-m', 'pip', 'wheel', '-vvv', '--no-deps', '--no-cache-dir', '--disable-pip-version-check', '--pro. gress-bar=off', 'scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0']' returned non-zero exit status 1. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:1297,modifiability,version,version-check,1297,"It seems to be scanpy-scripts itself. johnnydep analysis shows these (99% of lines removed):. ```. 2020-07-20 18:57:50 [info ] init johnnydist [johnnydep.lib] dist=scipy<1.3.0,>=1.2.0 parent=scanpy-scripts. 2020-07-20 18:58:10 [info ] init johnnydist [johnnydep.lib] dist=scipy~=1.0 parent=anndata<0.6.20. 2020-07-20 18:59:17 [info ] init johnnydist [johnnydep.lib] dist=scipy~=1.0 parent=anndata>=0.6.15. 2020-07-20 18:59:26 [info ] init johnnydist [johnnydep.lib] dist=scipy>=0.19.1 parent=scikit-learn>=0.19.1. 2020-07-20 18:59:58 [info ] init johnnydist [johnnydep.lib] dist=scipy>=1.3.1 parent=umap-learn>=0.3.0. ```. and later. ```. 2020-07-20 19:00:14 [info ] merged specs [johnnydep.lib] dist=scanpy-scripts extras=. set() name=scipy spec=<SpecifierSet('<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0', prereleases=True)>. ```. It cannot match both <1.3.0 and >= 1.3.1, and eventually bails out with:. ```. ERROR: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. pip._internal.exceptions.DistributionNotFound: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. subprocess.CalledProcessError: Command '['/usr/bin/python3', '-m', 'pip', 'wheel', '-vvv', '--no-deps', '--no-cache-dir', '--disable-pip-version-check', '--pro. gress-bar=off', 'scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0']' returned non-zero exit status 1. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:920,performance,ERROR,ERROR,920,"It seems to be scanpy-scripts itself. johnnydep analysis shows these (99% of lines removed):. ```. 2020-07-20 18:57:50 [info ] init johnnydist [johnnydep.lib] dist=scipy<1.3.0,>=1.2.0 parent=scanpy-scripts. 2020-07-20 18:58:10 [info ] init johnnydist [johnnydep.lib] dist=scipy~=1.0 parent=anndata<0.6.20. 2020-07-20 18:59:17 [info ] init johnnydist [johnnydep.lib] dist=scipy~=1.0 parent=anndata>=0.6.15. 2020-07-20 18:59:26 [info ] init johnnydist [johnnydep.lib] dist=scipy>=0.19.1 parent=scikit-learn>=0.19.1. 2020-07-20 18:59:58 [info ] init johnnydist [johnnydep.lib] dist=scipy>=1.3.1 parent=umap-learn>=0.3.0. ```. and later. ```. 2020-07-20 19:00:14 [info ] merged specs [johnnydep.lib] dist=scanpy-scripts extras=. set() name=scipy spec=<SpecifierSet('<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0', prereleases=True)>. ```. It cannot match both <1.3.0 and >= 1.3.1, and eventually bails out with:. ```. ERROR: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. pip._internal.exceptions.DistributionNotFound: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. subprocess.CalledProcessError: Command '['/usr/bin/python3', '-m', 'pip', 'wheel', '-vvv', '--no-deps', '--no-cache-dir', '--disable-pip-version-check', '--pro. gress-bar=off', 'scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0']' returned non-zero exit status 1. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:1270,performance,cach,cache-dir,1270,"It seems to be scanpy-scripts itself. johnnydep analysis shows these (99% of lines removed):. ```. 2020-07-20 18:57:50 [info ] init johnnydist [johnnydep.lib] dist=scipy<1.3.0,>=1.2.0 parent=scanpy-scripts. 2020-07-20 18:58:10 [info ] init johnnydist [johnnydep.lib] dist=scipy~=1.0 parent=anndata<0.6.20. 2020-07-20 18:59:17 [info ] init johnnydist [johnnydep.lib] dist=scipy~=1.0 parent=anndata>=0.6.15. 2020-07-20 18:59:26 [info ] init johnnydist [johnnydep.lib] dist=scipy>=0.19.1 parent=scikit-learn>=0.19.1. 2020-07-20 18:59:58 [info ] init johnnydist [johnnydep.lib] dist=scipy>=1.3.1 parent=umap-learn>=0.3.0. ```. and later. ```. 2020-07-20 19:00:14 [info ] merged specs [johnnydep.lib] dist=scanpy-scripts extras=. set() name=scipy spec=<SpecifierSet('<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0', prereleases=True)>. ```. It cannot match both <1.3.0 and >= 1.3.1, and eventually bails out with:. ```. ERROR: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. pip._internal.exceptions.DistributionNotFound: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. subprocess.CalledProcessError: Command '['/usr/bin/python3', '-m', 'pip', 'wheel', '-vvv', '--no-deps', '--no-cache-dir', '--disable-pip-version-check', '--pro. gress-bar=off', 'scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0']' returned non-zero exit status 1. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:920,safety,ERROR,ERROR,920,"It seems to be scanpy-scripts itself. johnnydep analysis shows these (99% of lines removed):. ```. 2020-07-20 18:57:50 [info ] init johnnydist [johnnydep.lib] dist=scipy<1.3.0,>=1.2.0 parent=scanpy-scripts. 2020-07-20 18:58:10 [info ] init johnnydist [johnnydep.lib] dist=scipy~=1.0 parent=anndata<0.6.20. 2020-07-20 18:59:17 [info ] init johnnydist [johnnydep.lib] dist=scipy~=1.0 parent=anndata>=0.6.15. 2020-07-20 18:59:26 [info ] init johnnydist [johnnydep.lib] dist=scipy>=0.19.1 parent=scikit-learn>=0.19.1. 2020-07-20 18:59:58 [info ] init johnnydist [johnnydep.lib] dist=scipy>=1.3.1 parent=umap-learn>=0.3.0. ```. and later. ```. 2020-07-20 19:00:14 [info ] merged specs [johnnydep.lib] dist=scanpy-scripts extras=. set() name=scipy spec=<SpecifierSet('<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0', prereleases=True)>. ```. It cannot match both <1.3.0 and >= 1.3.1, and eventually bails out with:. ```. ERROR: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. pip._internal.exceptions.DistributionNotFound: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. subprocess.CalledProcessError: Command '['/usr/bin/python3', '-m', 'pip', 'wheel', '-vvv', '--no-deps', '--no-cache-dir', '--disable-pip-version-check', '--pro. gress-bar=off', 'scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0']' returned non-zero exit status 1. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:1034,safety,except,exceptions,1034,"It seems to be scanpy-scripts itself. johnnydep analysis shows these (99% of lines removed):. ```. 2020-07-20 18:57:50 [info ] init johnnydist [johnnydep.lib] dist=scipy<1.3.0,>=1.2.0 parent=scanpy-scripts. 2020-07-20 18:58:10 [info ] init johnnydist [johnnydep.lib] dist=scipy~=1.0 parent=anndata<0.6.20. 2020-07-20 18:59:17 [info ] init johnnydist [johnnydep.lib] dist=scipy~=1.0 parent=anndata>=0.6.15. 2020-07-20 18:59:26 [info ] init johnnydist [johnnydep.lib] dist=scipy>=0.19.1 parent=scikit-learn>=0.19.1. 2020-07-20 18:59:58 [info ] init johnnydist [johnnydep.lib] dist=scipy>=1.3.1 parent=umap-learn>=0.3.0. ```. and later. ```. 2020-07-20 19:00:14 [info ] merged specs [johnnydep.lib] dist=scanpy-scripts extras=. set() name=scipy spec=<SpecifierSet('<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0', prereleases=True)>. ```. It cannot match both <1.3.0 and >= 1.3.1, and eventually bails out with:. ```. ERROR: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. pip._internal.exceptions.DistributionNotFound: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. subprocess.CalledProcessError: Command '['/usr/bin/python3', '-m', 'pip', 'wheel', '-vvv', '--no-deps', '--no-cache-dir', '--disable-pip-version-check', '--pro. gress-bar=off', 'scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0']' returned non-zero exit status 1. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:499,usability,learn,learn,499,"It seems to be scanpy-scripts itself. johnnydep analysis shows these (99% of lines removed):. ```. 2020-07-20 18:57:50 [info ] init johnnydist [johnnydep.lib] dist=scipy<1.3.0,>=1.2.0 parent=scanpy-scripts. 2020-07-20 18:58:10 [info ] init johnnydist [johnnydep.lib] dist=scipy~=1.0 parent=anndata<0.6.20. 2020-07-20 18:59:17 [info ] init johnnydist [johnnydep.lib] dist=scipy~=1.0 parent=anndata>=0.6.15. 2020-07-20 18:59:26 [info ] init johnnydist [johnnydep.lib] dist=scipy>=0.19.1 parent=scikit-learn>=0.19.1. 2020-07-20 18:59:58 [info ] init johnnydist [johnnydep.lib] dist=scipy>=1.3.1 parent=umap-learn>=0.3.0. ```. and later. ```. 2020-07-20 19:00:14 [info ] merged specs [johnnydep.lib] dist=scanpy-scripts extras=. set() name=scipy spec=<SpecifierSet('<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0', prereleases=True)>. ```. It cannot match both <1.3.0 and >= 1.3.1, and eventually bails out with:. ```. ERROR: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. pip._internal.exceptions.DistributionNotFound: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. subprocess.CalledProcessError: Command '['/usr/bin/python3', '-m', 'pip', 'wheel', '-vvv', '--no-deps', '--no-cache-dir', '--disable-pip-version-check', '--pro. gress-bar=off', 'scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0']' returned non-zero exit status 1. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:604,usability,learn,learn,604,"It seems to be scanpy-scripts itself. johnnydep analysis shows these (99% of lines removed):. ```. 2020-07-20 18:57:50 [info ] init johnnydist [johnnydep.lib] dist=scipy<1.3.0,>=1.2.0 parent=scanpy-scripts. 2020-07-20 18:58:10 [info ] init johnnydist [johnnydep.lib] dist=scipy~=1.0 parent=anndata<0.6.20. 2020-07-20 18:59:17 [info ] init johnnydist [johnnydep.lib] dist=scipy~=1.0 parent=anndata>=0.6.15. 2020-07-20 18:59:26 [info ] init johnnydist [johnnydep.lib] dist=scipy>=0.19.1 parent=scikit-learn>=0.19.1. 2020-07-20 18:59:58 [info ] init johnnydist [johnnydep.lib] dist=scipy>=1.3.1 parent=umap-learn>=0.3.0. ```. and later. ```. 2020-07-20 19:00:14 [info ] merged specs [johnnydep.lib] dist=scanpy-scripts extras=. set() name=scipy spec=<SpecifierSet('<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0', prereleases=True)>. ```. It cannot match both <1.3.0 and >= 1.3.1, and eventually bails out with:. ```. ERROR: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. pip._internal.exceptions.DistributionNotFound: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. subprocess.CalledProcessError: Command '['/usr/bin/python3', '-m', 'pip', 'wheel', '-vvv', '--no-deps', '--no-cache-dir', '--disable-pip-version-check', '--pro. gress-bar=off', 'scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0']' returned non-zero exit status 1. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:920,usability,ERROR,ERROR,920,"It seems to be scanpy-scripts itself. johnnydep analysis shows these (99% of lines removed):. ```. 2020-07-20 18:57:50 [info ] init johnnydist [johnnydep.lib] dist=scipy<1.3.0,>=1.2.0 parent=scanpy-scripts. 2020-07-20 18:58:10 [info ] init johnnydist [johnnydep.lib] dist=scipy~=1.0 parent=anndata<0.6.20. 2020-07-20 18:59:17 [info ] init johnnydist [johnnydep.lib] dist=scipy~=1.0 parent=anndata>=0.6.15. 2020-07-20 18:59:26 [info ] init johnnydist [johnnydep.lib] dist=scipy>=0.19.1 parent=scikit-learn>=0.19.1. 2020-07-20 18:59:58 [info ] init johnnydist [johnnydep.lib] dist=scipy>=1.3.1 parent=umap-learn>=0.3.0. ```. and later. ```. 2020-07-20 19:00:14 [info ] merged specs [johnnydep.lib] dist=scanpy-scripts extras=. set() name=scipy spec=<SpecifierSet('<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0', prereleases=True)>. ```. It cannot match both <1.3.0 and >= 1.3.1, and eventually bails out with:. ```. ERROR: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. pip._internal.exceptions.DistributionNotFound: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. subprocess.CalledProcessError: Command '['/usr/bin/python3', '-m', 'pip', 'wheel', '-vvv', '--no-deps', '--no-cache-dir', '--disable-pip-version-check', '--pro. gress-bar=off', 'scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0']' returned non-zero exit status 1. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:1191,usability,Command,Command,1191,"It seems to be scanpy-scripts itself. johnnydep analysis shows these (99% of lines removed):. ```. 2020-07-20 18:57:50 [info ] init johnnydist [johnnydep.lib] dist=scipy<1.3.0,>=1.2.0 parent=scanpy-scripts. 2020-07-20 18:58:10 [info ] init johnnydist [johnnydep.lib] dist=scipy~=1.0 parent=anndata<0.6.20. 2020-07-20 18:59:17 [info ] init johnnydist [johnnydep.lib] dist=scipy~=1.0 parent=anndata>=0.6.15. 2020-07-20 18:59:26 [info ] init johnnydist [johnnydep.lib] dist=scipy>=0.19.1 parent=scikit-learn>=0.19.1. 2020-07-20 18:59:58 [info ] init johnnydist [johnnydep.lib] dist=scipy>=1.3.1 parent=umap-learn>=0.3.0. ```. and later. ```. 2020-07-20 19:00:14 [info ] merged specs [johnnydep.lib] dist=scanpy-scripts extras=. set() name=scipy spec=<SpecifierSet('<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0', prereleases=True)>. ```. It cannot match both <1.3.0 and >= 1.3.1, and eventually bails out with:. ```. ERROR: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. pip._internal.exceptions.DistributionNotFound: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. subprocess.CalledProcessError: Command '['/usr/bin/python3', '-m', 'pip', 'wheel', '-vvv', '--no-deps', '--no-cache-dir', '--disable-pip-version-check', '--pro. gress-bar=off', 'scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0']' returned non-zero exit status 1. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:1421,usability,statu,status,1421,"It seems to be scanpy-scripts itself. johnnydep analysis shows these (99% of lines removed):. ```. 2020-07-20 18:57:50 [info ] init johnnydist [johnnydep.lib] dist=scipy<1.3.0,>=1.2.0 parent=scanpy-scripts. 2020-07-20 18:58:10 [info ] init johnnydist [johnnydep.lib] dist=scipy~=1.0 parent=anndata<0.6.20. 2020-07-20 18:59:17 [info ] init johnnydist [johnnydep.lib] dist=scipy~=1.0 parent=anndata>=0.6.15. 2020-07-20 18:59:26 [info ] init johnnydist [johnnydep.lib] dist=scipy>=0.19.1 parent=scikit-learn>=0.19.1. 2020-07-20 18:59:58 [info ] init johnnydist [johnnydep.lib] dist=scipy>=1.3.1 parent=umap-learn>=0.3.0. ```. and later. ```. 2020-07-20 19:00:14 [info ] merged specs [johnnydep.lib] dist=scanpy-scripts extras=. set() name=scipy spec=<SpecifierSet('<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0', prereleases=True)>. ```. It cannot match both <1.3.0 and >= 1.3.1, and eventually bails out with:. ```. ERROR: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. pip._internal.exceptions.DistributionNotFound: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. subprocess.CalledProcessError: Command '['/usr/bin/python3', '-m', 'pip', 'wheel', '-vvv', '--no-deps', '--no-cache-dir', '--disable-pip-version-check', '--pro. gress-bar=off', 'scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0']' returned non-zero exit status 1. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:158,deployability,version,version,158,"Yeah, please file your issue with [scanpy-scripts](https://github.com/ebi-gene-expression-group/scanpy-scripts) then, and ask them why they want an old scipy version and if they can upgrade their code to work with scipy 1.3+",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:182,deployability,upgrad,upgrade,182,"Yeah, please file your issue with [scanpy-scripts](https://github.com/ebi-gene-expression-group/scanpy-scripts) then, and ask them why they want an old scipy version and if they can upgrade their code to work with scipy 1.3+",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:158,integrability,version,version,158,"Yeah, please file your issue with [scanpy-scripts](https://github.com/ebi-gene-expression-group/scanpy-scripts) then, and ask them why they want an old scipy version and if they can upgrade their code to work with scipy 1.3+",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:158,modifiability,version,version,158,"Yeah, please file your issue with [scanpy-scripts](https://github.com/ebi-gene-expression-group/scanpy-scripts) then, and ask them why they want an old scipy version and if they can upgrade their code to work with scipy 1.3+",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:182,modifiability,upgrad,upgrade,182,"Yeah, please file your issue with [scanpy-scripts](https://github.com/ebi-gene-expression-group/scanpy-scripts) then, and ask them why they want an old scipy version and if they can upgrade their code to work with scipy 1.3+",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1275:22,deployability,version,version,22,Could you report your version numbers? Could you also show us the `repr` of your anndata object?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:22,integrability,version,version,22,Could you report your version numbers? Could you also show us the `repr` of your anndata object?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:22,modifiability,version,version,22,Could you report your version numbers? Could you also show us the `repr` of your anndata object?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:73,usability,user,user-images,73,"<img width=""596"" alt=""Screen Shot 2020-06-19 at 8 10 37 AM"" src=""https://user-images.githubusercontent.com/47393421/85131254-6e65cc80-b204-11ea-9479-0551f05407ee.png"">. <img width=""1265"" alt=""Screen Shot 2020-06-19 at 8 10 52 AM"" src=""https://user-images.githubusercontent.com/47393421/85131263-7160bd00-b204-11ea-9a16-3741733ed919.png"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:243,usability,user,user-images,243,"<img width=""596"" alt=""Screen Shot 2020-06-19 at 8 10 37 AM"" src=""https://user-images.githubusercontent.com/47393421/85131254-6e65cc80-b204-11ea-9479-0551f05407ee.png"">. <img width=""1265"" alt=""Screen Shot 2020-06-19 at 8 10 52 AM"" src=""https://user-images.githubusercontent.com/47393421/85131263-7160bd00-b204-11ea-9a16-3741733ed919.png"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:7,deployability,version,version,7,"Oh, by version numbers I meant not just `anndata` but the dependencies as well. I'm wondering in particular about the version of `h5py`. The output of something like [`sinfo(dependencies=True)`](https://pypi.org/project/sinfo/) would be great. If you try writing to a different path, are you able too? It kind of looks like you're writing to a file that already exists, though that should just overwrite the file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:58,deployability,depend,dependencies,58,"Oh, by version numbers I meant not just `anndata` but the dependencies as well. I'm wondering in particular about the version of `h5py`. The output of something like [`sinfo(dependencies=True)`](https://pypi.org/project/sinfo/) would be great. If you try writing to a different path, are you able too? It kind of looks like you're writing to a file that already exists, though that should just overwrite the file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:118,deployability,version,version,118,"Oh, by version numbers I meant not just `anndata` but the dependencies as well. I'm wondering in particular about the version of `h5py`. The output of something like [`sinfo(dependencies=True)`](https://pypi.org/project/sinfo/) would be great. If you try writing to a different path, are you able too? It kind of looks like you're writing to a file that already exists, though that should just overwrite the file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:174,deployability,depend,dependencies,174,"Oh, by version numbers I meant not just `anndata` but the dependencies as well. I'm wondering in particular about the version of `h5py`. The output of something like [`sinfo(dependencies=True)`](https://pypi.org/project/sinfo/) would be great. If you try writing to a different path, are you able too? It kind of looks like you're writing to a file that already exists, though that should just overwrite the file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:7,integrability,version,version,7,"Oh, by version numbers I meant not just `anndata` but the dependencies as well. I'm wondering in particular about the version of `h5py`. The output of something like [`sinfo(dependencies=True)`](https://pypi.org/project/sinfo/) would be great. If you try writing to a different path, are you able too? It kind of looks like you're writing to a file that already exists, though that should just overwrite the file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:58,integrability,depend,dependencies,58,"Oh, by version numbers I meant not just `anndata` but the dependencies as well. I'm wondering in particular about the version of `h5py`. The output of something like [`sinfo(dependencies=True)`](https://pypi.org/project/sinfo/) would be great. If you try writing to a different path, are you able too? It kind of looks like you're writing to a file that already exists, though that should just overwrite the file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:118,integrability,version,version,118,"Oh, by version numbers I meant not just `anndata` but the dependencies as well. I'm wondering in particular about the version of `h5py`. The output of something like [`sinfo(dependencies=True)`](https://pypi.org/project/sinfo/) would be great. If you try writing to a different path, are you able too? It kind of looks like you're writing to a file that already exists, though that should just overwrite the file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:174,integrability,depend,dependencies,174,"Oh, by version numbers I meant not just `anndata` but the dependencies as well. I'm wondering in particular about the version of `h5py`. The output of something like [`sinfo(dependencies=True)`](https://pypi.org/project/sinfo/) would be great. If you try writing to a different path, are you able too? It kind of looks like you're writing to a file that already exists, though that should just overwrite the file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:7,modifiability,version,version,7,"Oh, by version numbers I meant not just `anndata` but the dependencies as well. I'm wondering in particular about the version of `h5py`. The output of something like [`sinfo(dependencies=True)`](https://pypi.org/project/sinfo/) would be great. If you try writing to a different path, are you able too? It kind of looks like you're writing to a file that already exists, though that should just overwrite the file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:58,modifiability,depend,dependencies,58,"Oh, by version numbers I meant not just `anndata` but the dependencies as well. I'm wondering in particular about the version of `h5py`. The output of something like [`sinfo(dependencies=True)`](https://pypi.org/project/sinfo/) would be great. If you try writing to a different path, are you able too? It kind of looks like you're writing to a file that already exists, though that should just overwrite the file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:118,modifiability,version,version,118,"Oh, by version numbers I meant not just `anndata` but the dependencies as well. I'm wondering in particular about the version of `h5py`. The output of something like [`sinfo(dependencies=True)`](https://pypi.org/project/sinfo/) would be great. If you try writing to a different path, are you able too? It kind of looks like you're writing to a file that already exists, though that should just overwrite the file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:174,modifiability,depend,dependencies,174,"Oh, by version numbers I meant not just `anndata` but the dependencies as well. I'm wondering in particular about the version of `h5py`. The output of something like [`sinfo(dependencies=True)`](https://pypi.org/project/sinfo/) would be great. If you try writing to a different path, are you able too? It kind of looks like you're writing to a file that already exists, though that should just overwrite the file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:58,safety,depend,dependencies,58,"Oh, by version numbers I meant not just `anndata` but the dependencies as well. I'm wondering in particular about the version of `h5py`. The output of something like [`sinfo(dependencies=True)`](https://pypi.org/project/sinfo/) would be great. If you try writing to a different path, are you able too? It kind of looks like you're writing to a file that already exists, though that should just overwrite the file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:174,safety,depend,dependencies,174,"Oh, by version numbers I meant not just `anndata` but the dependencies as well. I'm wondering in particular about the version of `h5py`. The output of something like [`sinfo(dependencies=True)`](https://pypi.org/project/sinfo/) would be great. If you try writing to a different path, are you able too? It kind of looks like you're writing to a file that already exists, though that should just overwrite the file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:58,testability,depend,dependencies,58,"Oh, by version numbers I meant not just `anndata` but the dependencies as well. I'm wondering in particular about the version of `h5py`. The output of something like [`sinfo(dependencies=True)`](https://pypi.org/project/sinfo/) would be great. If you try writing to a different path, are you able too? It kind of looks like you're writing to a file that already exists, though that should just overwrite the file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:174,testability,depend,dependencies,174,"Oh, by version numbers I meant not just `anndata` but the dependencies as well. I'm wondering in particular about the version of `h5py`. The output of something like [`sinfo(dependencies=True)`](https://pypi.org/project/sinfo/) would be great. If you try writing to a different path, are you able too? It kind of looks like you're writing to a file that already exists, though that should just overwrite the file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:36,availability,error,error,36,"I am not sure what was causing this error, but it must be somewhat idiosyncratic as the issue is resolved in a fresh env. Thanks! Closing this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:36,performance,error,error,36,"I am not sure what was causing this error, but it must be somewhat idiosyncratic as the issue is resolved in a fresh env. Thanks! Closing this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:36,safety,error,error,36,"I am not sure what was causing this error, but it must be somewhat idiosyncratic as the issue is resolved in a fresh env. Thanks! Closing this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:36,usability,error,error,36,"I am not sure what was causing this error, but it must be somewhat idiosyncratic as the issue is resolved in a fresh env. Thanks! Closing this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:38,availability,error,error,38,"> I am not sure what was causing this error, but it must be somewhat idiosyncratic as the issue is resolved in a fresh env. Thanks! Closing this. Hi, I met same problem, how did you solve it?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:38,performance,error,error,38,"> I am not sure what was causing this error, but it must be somewhat idiosyncratic as the issue is resolved in a fresh env. Thanks! Closing this. Hi, I met same problem, how did you solve it?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:38,safety,error,error,38,"> I am not sure what was causing this error, but it must be somewhat idiosyncratic as the issue is resolved in a fresh env. Thanks! Closing this. Hi, I met same problem, how did you solve it?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:38,usability,error,error,38,"> I am not sure what was causing this error, but it must be somewhat idiosyncratic as the issue is resolved in a fresh env. Thanks! Closing this. Hi, I met same problem, how did you solve it?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:52,availability,incid,incident,52,"Hi @GouQiao - it's been a while since this specific incident so I don't 100% remember / have the code anymore. However, I have run into this problem in general when using AnnData and it's usually resolved by one of two paths:. 1. Check the version of `h5py` that you have installed and perhaps it is too new and an older version resolves the issue. . 2. Some components of AnnData are not implemented in the function, `.write_h5ad()`. One example that comes to mind is the umap or pca transformer. These objects are not handled well by `.h5py` (at least natively in my experience) and are better off saved independently as dictionaries using `pickle`. That being said, I think there is probably a more robust solution I am not aware of - I know in several instances transformers are able to be saved (e.g., the Scanpy tutorials). . Does this help at all? Happy to be of further assistance if possible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:702,availability,robust,robust,702,"Hi @GouQiao - it's been a while since this specific incident so I don't 100% remember / have the code anymore. However, I have run into this problem in general when using AnnData and it's usually resolved by one of two paths:. 1. Check the version of `h5py` that you have installed and perhaps it is too new and an older version resolves the issue. . 2. Some components of AnnData are not implemented in the function, `.write_h5ad()`. One example that comes to mind is the umap or pca transformer. These objects are not handled well by `.h5py` (at least natively in my experience) and are better off saved independently as dictionaries using `pickle`. That being said, I think there is probably a more robust solution I am not aware of - I know in several instances transformers are able to be saved (e.g., the Scanpy tutorials). . Does this help at all? Happy to be of further assistance if possible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:240,deployability,version,version,240,"Hi @GouQiao - it's been a while since this specific incident so I don't 100% remember / have the code anymore. However, I have run into this problem in general when using AnnData and it's usually resolved by one of two paths:. 1. Check the version of `h5py` that you have installed and perhaps it is too new and an older version resolves the issue. . 2. Some components of AnnData are not implemented in the function, `.write_h5ad()`. One example that comes to mind is the umap or pca transformer. These objects are not handled well by `.h5py` (at least natively in my experience) and are better off saved independently as dictionaries using `pickle`. That being said, I think there is probably a more robust solution I am not aware of - I know in several instances transformers are able to be saved (e.g., the Scanpy tutorials). . Does this help at all? Happy to be of further assistance if possible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:272,deployability,instal,installed,272,"Hi @GouQiao - it's been a while since this specific incident so I don't 100% remember / have the code anymore. However, I have run into this problem in general when using AnnData and it's usually resolved by one of two paths:. 1. Check the version of `h5py` that you have installed and perhaps it is too new and an older version resolves the issue. . 2. Some components of AnnData are not implemented in the function, `.write_h5ad()`. One example that comes to mind is the umap or pca transformer. These objects are not handled well by `.h5py` (at least natively in my experience) and are better off saved independently as dictionaries using `pickle`. That being said, I think there is probably a more robust solution I am not aware of - I know in several instances transformers are able to be saved (e.g., the Scanpy tutorials). . Does this help at all? Happy to be of further assistance if possible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:321,deployability,version,version,321,"Hi @GouQiao - it's been a while since this specific incident so I don't 100% remember / have the code anymore. However, I have run into this problem in general when using AnnData and it's usually resolved by one of two paths:. 1. Check the version of `h5py` that you have installed and perhaps it is too new and an older version resolves the issue. . 2. Some components of AnnData are not implemented in the function, `.write_h5ad()`. One example that comes to mind is the umap or pca transformer. These objects are not handled well by `.h5py` (at least natively in my experience) and are better off saved independently as dictionaries using `pickle`. That being said, I think there is probably a more robust solution I am not aware of - I know in several instances transformers are able to be saved (e.g., the Scanpy tutorials). . Does this help at all? Happy to be of further assistance if possible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:240,integrability,version,version,240,"Hi @GouQiao - it's been a while since this specific incident so I don't 100% remember / have the code anymore. However, I have run into this problem in general when using AnnData and it's usually resolved by one of two paths:. 1. Check the version of `h5py` that you have installed and perhaps it is too new and an older version resolves the issue. . 2. Some components of AnnData are not implemented in the function, `.write_h5ad()`. One example that comes to mind is the umap or pca transformer. These objects are not handled well by `.h5py` (at least natively in my experience) and are better off saved independently as dictionaries using `pickle`. That being said, I think there is probably a more robust solution I am not aware of - I know in several instances transformers are able to be saved (e.g., the Scanpy tutorials). . Does this help at all? Happy to be of further assistance if possible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:321,integrability,version,version,321,"Hi @GouQiao - it's been a while since this specific incident so I don't 100% remember / have the code anymore. However, I have run into this problem in general when using AnnData and it's usually resolved by one of two paths:. 1. Check the version of `h5py` that you have installed and perhaps it is too new and an older version resolves the issue. . 2. Some components of AnnData are not implemented in the function, `.write_h5ad()`. One example that comes to mind is the umap or pca transformer. These objects are not handled well by `.h5py` (at least natively in my experience) and are better off saved independently as dictionaries using `pickle`. That being said, I think there is probably a more robust solution I am not aware of - I know in several instances transformers are able to be saved (e.g., the Scanpy tutorials). . Does this help at all? Happy to be of further assistance if possible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:359,integrability,compon,components,359,"Hi @GouQiao - it's been a while since this specific incident so I don't 100% remember / have the code anymore. However, I have run into this problem in general when using AnnData and it's usually resolved by one of two paths:. 1. Check the version of `h5py` that you have installed and perhaps it is too new and an older version resolves the issue. . 2. Some components of AnnData are not implemented in the function, `.write_h5ad()`. One example that comes to mind is the umap or pca transformer. These objects are not handled well by `.h5py` (at least natively in my experience) and are better off saved independently as dictionaries using `pickle`. That being said, I think there is probably a more robust solution I am not aware of - I know in several instances transformers are able to be saved (e.g., the Scanpy tutorials). . Does this help at all? Happy to be of further assistance if possible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:485,integrability,transform,transformer,485,"Hi @GouQiao - it's been a while since this specific incident so I don't 100% remember / have the code anymore. However, I have run into this problem in general when using AnnData and it's usually resolved by one of two paths:. 1. Check the version of `h5py` that you have installed and perhaps it is too new and an older version resolves the issue. . 2. Some components of AnnData are not implemented in the function, `.write_h5ad()`. One example that comes to mind is the umap or pca transformer. These objects are not handled well by `.h5py` (at least natively in my experience) and are better off saved independently as dictionaries using `pickle`. That being said, I think there is probably a more robust solution I am not aware of - I know in several instances transformers are able to be saved (e.g., the Scanpy tutorials). . Does this help at all? Happy to be of further assistance if possible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:766,integrability,transform,transformers,766,"Hi @GouQiao - it's been a while since this specific incident so I don't 100% remember / have the code anymore. However, I have run into this problem in general when using AnnData and it's usually resolved by one of two paths:. 1. Check the version of `h5py` that you have installed and perhaps it is too new and an older version resolves the issue. . 2. Some components of AnnData are not implemented in the function, `.write_h5ad()`. One example that comes to mind is the umap or pca transformer. These objects are not handled well by `.h5py` (at least natively in my experience) and are better off saved independently as dictionaries using `pickle`. That being said, I think there is probably a more robust solution I am not aware of - I know in several instances transformers are able to be saved (e.g., the Scanpy tutorials). . Does this help at all? Happy to be of further assistance if possible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:43,interoperability,specif,specific,43,"Hi @GouQiao - it's been a while since this specific incident so I don't 100% remember / have the code anymore. However, I have run into this problem in general when using AnnData and it's usually resolved by one of two paths:. 1. Check the version of `h5py` that you have installed and perhaps it is too new and an older version resolves the issue. . 2. Some components of AnnData are not implemented in the function, `.write_h5ad()`. One example that comes to mind is the umap or pca transformer. These objects are not handled well by `.h5py` (at least natively in my experience) and are better off saved independently as dictionaries using `pickle`. That being said, I think there is probably a more robust solution I am not aware of - I know in several instances transformers are able to be saved (e.g., the Scanpy tutorials). . Does this help at all? Happy to be of further assistance if possible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:359,interoperability,compon,components,359,"Hi @GouQiao - it's been a while since this specific incident so I don't 100% remember / have the code anymore. However, I have run into this problem in general when using AnnData and it's usually resolved by one of two paths:. 1. Check the version of `h5py` that you have installed and perhaps it is too new and an older version resolves the issue. . 2. Some components of AnnData are not implemented in the function, `.write_h5ad()`. One example that comes to mind is the umap or pca transformer. These objects are not handled well by `.h5py` (at least natively in my experience) and are better off saved independently as dictionaries using `pickle`. That being said, I think there is probably a more robust solution I am not aware of - I know in several instances transformers are able to be saved (e.g., the Scanpy tutorials). . Does this help at all? Happy to be of further assistance if possible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:485,interoperability,transform,transformer,485,"Hi @GouQiao - it's been a while since this specific incident so I don't 100% remember / have the code anymore. However, I have run into this problem in general when using AnnData and it's usually resolved by one of two paths:. 1. Check the version of `h5py` that you have installed and perhaps it is too new and an older version resolves the issue. . 2. Some components of AnnData are not implemented in the function, `.write_h5ad()`. One example that comes to mind is the umap or pca transformer. These objects are not handled well by `.h5py` (at least natively in my experience) and are better off saved independently as dictionaries using `pickle`. That being said, I think there is probably a more robust solution I am not aware of - I know in several instances transformers are able to be saved (e.g., the Scanpy tutorials). . Does this help at all? Happy to be of further assistance if possible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:766,interoperability,transform,transformers,766,"Hi @GouQiao - it's been a while since this specific incident so I don't 100% remember / have the code anymore. However, I have run into this problem in general when using AnnData and it's usually resolved by one of two paths:. 1. Check the version of `h5py` that you have installed and perhaps it is too new and an older version resolves the issue. . 2. Some components of AnnData are not implemented in the function, `.write_h5ad()`. One example that comes to mind is the umap or pca transformer. These objects are not handled well by `.h5py` (at least natively in my experience) and are better off saved independently as dictionaries using `pickle`. That being said, I think there is probably a more robust solution I am not aware of - I know in several instances transformers are able to be saved (e.g., the Scanpy tutorials). . Does this help at all? Happy to be of further assistance if possible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:240,modifiability,version,version,240,"Hi @GouQiao - it's been a while since this specific incident so I don't 100% remember / have the code anymore. However, I have run into this problem in general when using AnnData and it's usually resolved by one of two paths:. 1. Check the version of `h5py` that you have installed and perhaps it is too new and an older version resolves the issue. . 2. Some components of AnnData are not implemented in the function, `.write_h5ad()`. One example that comes to mind is the umap or pca transformer. These objects are not handled well by `.h5py` (at least natively in my experience) and are better off saved independently as dictionaries using `pickle`. That being said, I think there is probably a more robust solution I am not aware of - I know in several instances transformers are able to be saved (e.g., the Scanpy tutorials). . Does this help at all? Happy to be of further assistance if possible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:321,modifiability,version,version,321,"Hi @GouQiao - it's been a while since this specific incident so I don't 100% remember / have the code anymore. However, I have run into this problem in general when using AnnData and it's usually resolved by one of two paths:. 1. Check the version of `h5py` that you have installed and perhaps it is too new and an older version resolves the issue. . 2. Some components of AnnData are not implemented in the function, `.write_h5ad()`. One example that comes to mind is the umap or pca transformer. These objects are not handled well by `.h5py` (at least natively in my experience) and are better off saved independently as dictionaries using `pickle`. That being said, I think there is probably a more robust solution I am not aware of - I know in several instances transformers are able to be saved (e.g., the Scanpy tutorials). . Does this help at all? Happy to be of further assistance if possible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:359,modifiability,compon,components,359,"Hi @GouQiao - it's been a while since this specific incident so I don't 100% remember / have the code anymore. However, I have run into this problem in general when using AnnData and it's usually resolved by one of two paths:. 1. Check the version of `h5py` that you have installed and perhaps it is too new and an older version resolves the issue. . 2. Some components of AnnData are not implemented in the function, `.write_h5ad()`. One example that comes to mind is the umap or pca transformer. These objects are not handled well by `.h5py` (at least natively in my experience) and are better off saved independently as dictionaries using `pickle`. That being said, I think there is probably a more robust solution I am not aware of - I know in several instances transformers are able to be saved (e.g., the Scanpy tutorials). . Does this help at all? Happy to be of further assistance if possible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:52,reliability,incid,incident,52,"Hi @GouQiao - it's been a while since this specific incident so I don't 100% remember / have the code anymore. However, I have run into this problem in general when using AnnData and it's usually resolved by one of two paths:. 1. Check the version of `h5py` that you have installed and perhaps it is too new and an older version resolves the issue. . 2. Some components of AnnData are not implemented in the function, `.write_h5ad()`. One example that comes to mind is the umap or pca transformer. These objects are not handled well by `.h5py` (at least natively in my experience) and are better off saved independently as dictionaries using `pickle`. That being said, I think there is probably a more robust solution I am not aware of - I know in several instances transformers are able to be saved (e.g., the Scanpy tutorials). . Does this help at all? Happy to be of further assistance if possible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:702,reliability,robust,robust,702,"Hi @GouQiao - it's been a while since this specific incident so I don't 100% remember / have the code anymore. However, I have run into this problem in general when using AnnData and it's usually resolved by one of two paths:. 1. Check the version of `h5py` that you have installed and perhaps it is too new and an older version resolves the issue. . 2. Some components of AnnData are not implemented in the function, `.write_h5ad()`. One example that comes to mind is the umap or pca transformer. These objects are not handled well by `.h5py` (at least natively in my experience) and are better off saved independently as dictionaries using `pickle`. That being said, I think there is probably a more robust solution I am not aware of - I know in several instances transformers are able to be saved (e.g., the Scanpy tutorials). . Does this help at all? Happy to be of further assistance if possible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:832,reliability,Doe,Does,832,"Hi @GouQiao - it's been a while since this specific incident so I don't 100% remember / have the code anymore. However, I have run into this problem in general when using AnnData and it's usually resolved by one of two paths:. 1. Check the version of `h5py` that you have installed and perhaps it is too new and an older version resolves the issue. . 2. Some components of AnnData are not implemented in the function, `.write_h5ad()`. One example that comes to mind is the umap or pca transformer. These objects are not handled well by `.h5py` (at least natively in my experience) and are better off saved independently as dictionaries using `pickle`. That being said, I think there is probably a more robust solution I am not aware of - I know in several instances transformers are able to be saved (e.g., the Scanpy tutorials). . Does this help at all? Happy to be of further assistance if possible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:77,safety,reme,remember,77,"Hi @GouQiao - it's been a while since this specific incident so I don't 100% remember / have the code anymore. However, I have run into this problem in general when using AnnData and it's usually resolved by one of two paths:. 1. Check the version of `h5py` that you have installed and perhaps it is too new and an older version resolves the issue. . 2. Some components of AnnData are not implemented in the function, `.write_h5ad()`. One example that comes to mind is the umap or pca transformer. These objects are not handled well by `.h5py` (at least natively in my experience) and are better off saved independently as dictionaries using `pickle`. That being said, I think there is probably a more robust solution I am not aware of - I know in several instances transformers are able to be saved (e.g., the Scanpy tutorials). . Does this help at all? Happy to be of further assistance if possible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:702,safety,robust,robust,702,"Hi @GouQiao - it's been a while since this specific incident so I don't 100% remember / have the code anymore. However, I have run into this problem in general when using AnnData and it's usually resolved by one of two paths:. 1. Check the version of `h5py` that you have installed and perhaps it is too new and an older version resolves the issue. . 2. Some components of AnnData are not implemented in the function, `.write_h5ad()`. One example that comes to mind is the umap or pca transformer. These objects are not handled well by `.h5py` (at least natively in my experience) and are better off saved independently as dictionaries using `pickle`. That being said, I think there is probably a more robust solution I am not aware of - I know in several instances transformers are able to be saved (e.g., the Scanpy tutorials). . Does this help at all? Happy to be of further assistance if possible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:569,usability,experien,experience,569,"Hi @GouQiao - it's been a while since this specific incident so I don't 100% remember / have the code anymore. However, I have run into this problem in general when using AnnData and it's usually resolved by one of two paths:. 1. Check the version of `h5py` that you have installed and perhaps it is too new and an older version resolves the issue. . 2. Some components of AnnData are not implemented in the function, `.write_h5ad()`. One example that comes to mind is the umap or pca transformer. These objects are not handled well by `.h5py` (at least natively in my experience) and are better off saved independently as dictionaries using `pickle`. That being said, I think there is probably a more robust solution I am not aware of - I know in several instances transformers are able to be saved (e.g., the Scanpy tutorials). . Does this help at all? Happy to be of further assistance if possible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:842,usability,help,help,842,"Hi @GouQiao - it's been a while since this specific incident so I don't 100% remember / have the code anymore. However, I have run into this problem in general when using AnnData and it's usually resolved by one of two paths:. 1. Check the version of `h5py` that you have installed and perhaps it is too new and an older version resolves the issue. . 2. Some components of AnnData are not implemented in the function, `.write_h5ad()`. One example that comes to mind is the umap or pca transformer. These objects are not handled well by `.h5py` (at least natively in my experience) and are better off saved independently as dictionaries using `pickle`. That being said, I think there is probably a more robust solution I am not aware of - I know in several instances transformers are able to be saved (e.g., the Scanpy tutorials). . Does this help at all? Happy to be of further assistance if possible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1276:60,deployability,api,api,60,"Hi Stephen, I think https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.embedding.html#scanpy.pl.embedding is what you are looking for.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1276
https://github.com/scverse/scanpy/issues/1276:60,integrability,api,api,60,"Hi Stephen, I think https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.embedding.html#scanpy.pl.embedding is what you are looking for.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1276
https://github.com/scverse/scanpy/issues/1276:60,interoperability,api,api,60,"Hi Stephen, I think https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.embedding.html#scanpy.pl.embedding is what you are looking for.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1276
https://github.com/scverse/scanpy/issues/1277:114,availability,error,error,114,This feature is not used by pl.umap() or pl.draw_graph(). These functions do not search in the raw and return the error` IndexError: index 0 is out of bounds for axis 0 with size 0` when using gene_symbols that are only present in raw. Could this feature also be implemented for these funtions?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:114,performance,error,error,114,This feature is not used by pl.umap() or pl.draw_graph(). These functions do not search in the raw and return the error` IndexError: index 0 is out of bounds for axis 0 with size 0` when using gene_symbols that are only present in raw. Could this feature also be implemented for these funtions?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:114,safety,error,error,114,This feature is not used by pl.umap() or pl.draw_graph(). These functions do not search in the raw and return the error` IndexError: index 0 is out of bounds for axis 0 with size 0` when using gene_symbols that are only present in raw. Could this feature also be implemented for these funtions?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:114,usability,error,error,114,This feature is not used by pl.umap() or pl.draw_graph(). These functions do not search in the raw and return the error` IndexError: index 0 is out of bounds for axis 0 with size 0` when using gene_symbols that are only present in raw. Could this feature also be implemented for these funtions?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:102,availability,error,error,102,"Sure, I can do this. I'll submit a PR in a bit. @bfurtwa could you post the full stack trace for this error to help me find the problem please? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:81,deployability,stack,stack,81,"Sure, I can do this. I'll submit a PR in a bit. @bfurtwa could you post the full stack trace for this error to help me find the problem please? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:26,integrability,sub,submit,26,"Sure, I can do this. I'll submit a PR in a bit. @bfurtwa could you post the full stack trace for this error to help me find the problem please? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:102,performance,error,error,102,"Sure, I can do this. I'll submit a PR in a bit. @bfurtwa could you post the full stack trace for this error to help me find the problem please? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:102,safety,error,error,102,"Sure, I can do this. I'll submit a PR in a bit. @bfurtwa could you post the full stack trace for this error to help me find the problem please? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:87,testability,trace,trace,87,"Sure, I can do this. I'll submit a PR in a bit. @bfurtwa could you post the full stack trace for this error to help me find the problem please? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:102,usability,error,error,102,"Sure, I can do this. I'll submit a PR in a bit. @bfurtwa could you post the full stack trace for this error to help me find the problem please? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:111,usability,help,help,111,"Sure, I can do this. I'll submit a PR in a bit. @bfurtwa could you post the full stack trace for this error to help me find the problem please? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:1648,availability,error,error,1648,"Sure:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-161-7b672fc51046> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:1923,availability,sli,slice,1923,"Sure:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-161-7b672fc51046> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:172,deployability,modul,module,172,"Sure:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-161-7b672fc51046> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:1732,energy efficiency,core,core,1732,"Sure:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-161-7b672fc51046> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:812,integrability,compon,components,812,"Sure:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-161-7b672fc51046> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:812,interoperability,compon,components,812,"Sure:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-161-7b672fc51046> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:1507,interoperability,share,share,1507,"Sure:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-161-7b672fc51046> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:172,modifiability,modul,module,172,"Sure:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-161-7b672fc51046> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:363,modifiability,pac,packages,363,"Sure:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-161-7b672fc51046> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:618,modifiability,pac,packages,618,"Sure:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-161-7b672fc51046> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:812,modifiability,compon,components,812,"Sure:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-161-7b672fc51046> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:824,modifiability,layer,layer,824,"Sure:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-161-7b672fc51046> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:1300,modifiability,pac,packages,1300,"Sure:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-161-7b672fc51046> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:1431,modifiability,layer,layer,1431,"Sure:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-161-7b672fc51046> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:1716,modifiability,pac,packages,1716,"Sure:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-161-7b672fc51046> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:1648,performance,error,error,1648,"Sure:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-161-7b672fc51046> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:1662,reliability,doe,doesn,1662,"Sure:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-161-7b672fc51046> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:1923,reliability,sli,slice,1923,"Sure:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-161-7b672fc51046> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:144,safety,input,input-,144,"Sure:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-161-7b672fc51046> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:172,safety,modul,module,172,"Sure:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-161-7b672fc51046> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:1648,safety,error,error,1648,"Sure:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-161-7b672fc51046> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:244,security,Access,Accession,244,"Sure:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-161-7b672fc51046> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:100,testability,Trace,Traceback,100,"Sure:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-161-7b672fc51046> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:144,usability,input,input-,144,"Sure:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-161-7b672fc51046> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:1640,usability,help,helpful,1640,"Sure:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-161-7b672fc51046> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:1648,usability,error,error,1648,"Sure:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-161-7b672fc51046> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:111,availability,error,error,111,It looks like in your initial call to `sc.pl.pca` you are not specifying `use_raw=True`. Do you still get this error when you do?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:62,interoperability,specif,specifying,62,It looks like in your initial call to `sc.pl.pca` you are not specifying `use_raw=True`. Do you still get this error when you do?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:111,performance,error,error,111,It looks like in your initial call to `sc.pl.pca` you are not specifying `use_raw=True`. Do you still get this error when you do?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:111,safety,error,error,111,It looks like in your initial call to `sc.pl.pca` you are not specifying `use_raw=True`. Do you still get this error when you do?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:111,usability,error,error,111,It looks like in your initial call to `sc.pl.pca` you are not specifying `use_raw=True`. Do you still get this error when you do?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:1660,availability,error,error,1660,"`. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-39-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:1935,availability,sli,slice,1935,"`. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-39-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:170,deployability,modul,module,170,"Yes:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-39-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with siz",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:1744,energy efficiency,core,core,1744,"`. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-39-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:824,integrability,compon,components,824,"Yes:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-39-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with siz",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:824,interoperability,compon,components,824,"Yes:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-39-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with siz",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:1519,interoperability,share,share,1519,"`. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-39-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:170,modifiability,modul,module,170,"Yes:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-39-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with siz",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:375,modifiability,pac,packages,375,"Yes:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-39-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with siz",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:630,modifiability,pac,packages,630,"Yes:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-39-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with siz",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:824,modifiability,compon,components,824,"Yes:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-39-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with siz",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:836,modifiability,layer,layer,836,"Yes:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-39-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with siz",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:1312,modifiability,pac,packages,1312,"`. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-39-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:1443,modifiability,layer,layer,1443,"`. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-39-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:1728,modifiability,pac,packages,1728,"`. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-39-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:1660,performance,error,error,1660,"`. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-39-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:1674,reliability,doe,doesn,1674,"`. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-39-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:1935,reliability,sli,slice,1935,"`. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-39-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:143,safety,input,input-,143,"Yes:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-39-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with siz",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:170,safety,modul,module,170,"Yes:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-39-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with siz",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:1660,safety,error,error,1660,"`. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-39-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:242,security,Access,Accession,242,"Yes:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-39-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with siz",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:99,testability,Trace,Traceback,99,"Yes:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-39-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with siz",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:143,usability,input,input-,143,"Yes:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-39-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with siz",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:1652,usability,help,helpful,1652,"`. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-39-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:1660,usability,error,error,1660,"`. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-39-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 725 """""". --> 726 return embedding(adata, 'pca', **kwargs). 727 . 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 226 itertools.product(color, idx_components). 227 ):. --> 228 color_vector, categorical = _get_color_values(. 229 adata,. 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer). 1031 ):. 1032 # We should probably just make an index for this, and share it over runs. -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1034 0. 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:208,availability,error,error,208,What version of scanpy are you using? I don't see a function called `_get_color_values` in `scatterplots.py` in the HEAD version. Can you try installing the development version and seeing if you get the same error? The issue might be that the version you are currently using does not include the fix I made above. ```. git clone https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:5,deployability,version,version,5,What version of scanpy are you using? I don't see a function called `_get_color_values` in `scatterplots.py` in the HEAD version. Can you try installing the development version and seeing if you get the same error? The issue might be that the version you are currently using does not include the fix I made above. ```. git clone https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:121,deployability,version,version,121,What version of scanpy are you using? I don't see a function called `_get_color_values` in `scatterplots.py` in the HEAD version. Can you try installing the development version and seeing if you get the same error? The issue might be that the version you are currently using does not include the fix I made above. ```. git clone https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:142,deployability,instal,installing,142,What version of scanpy are you using? I don't see a function called `_get_color_values` in `scatterplots.py` in the HEAD version. Can you try installing the development version and seeing if you get the same error? The issue might be that the version you are currently using does not include the fix I made above. ```. git clone https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:169,deployability,version,version,169,What version of scanpy are you using? I don't see a function called `_get_color_values` in `scatterplots.py` in the HEAD version. Can you try installing the development version and seeing if you get the same error? The issue might be that the version you are currently using does not include the fix I made above. ```. git clone https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:243,deployability,version,version,243,What version of scanpy are you using? I don't see a function called `_get_color_values` in `scatterplots.py` in the HEAD version. Can you try installing the development version and seeing if you get the same error? The issue might be that the version you are currently using does not include the fix I made above. ```. git clone https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:384,deployability,instal,install,384,What version of scanpy are you using? I don't see a function called `_get_color_values` in `scatterplots.py` in the HEAD version. Can you try installing the development version and seeing if you get the same error? The issue might be that the version you are currently using does not include the fix I made above. ```. git clone https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:259,energy efficiency,current,currently,259,What version of scanpy are you using? I don't see a function called `_get_color_values` in `scatterplots.py` in the HEAD version. Can you try installing the development version and seeing if you get the same error? The issue might be that the version you are currently using does not include the fix I made above. ```. git clone https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:5,integrability,version,version,5,What version of scanpy are you using? I don't see a function called `_get_color_values` in `scatterplots.py` in the HEAD version. Can you try installing the development version and seeing if you get the same error? The issue might be that the version you are currently using does not include the fix I made above. ```. git clone https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:121,integrability,version,version,121,What version of scanpy are you using? I don't see a function called `_get_color_values` in `scatterplots.py` in the HEAD version. Can you try installing the development version and seeing if you get the same error? The issue might be that the version you are currently using does not include the fix I made above. ```. git clone https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:169,integrability,version,version,169,What version of scanpy are you using? I don't see a function called `_get_color_values` in `scatterplots.py` in the HEAD version. Can you try installing the development version and seeing if you get the same error? The issue might be that the version you are currently using does not include the fix I made above. ```. git clone https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:243,integrability,version,version,243,What version of scanpy are you using? I don't see a function called `_get_color_values` in `scatterplots.py` in the HEAD version. Can you try installing the development version and seeing if you get the same error? The issue might be that the version you are currently using does not include the fix I made above. ```. git clone https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:5,modifiability,version,version,5,What version of scanpy are you using? I don't see a function called `_get_color_values` in `scatterplots.py` in the HEAD version. Can you try installing the development version and seeing if you get the same error? The issue might be that the version you are currently using does not include the fix I made above. ```. git clone https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:121,modifiability,version,version,121,What version of scanpy are you using? I don't see a function called `_get_color_values` in `scatterplots.py` in the HEAD version. Can you try installing the development version and seeing if you get the same error? The issue might be that the version you are currently using does not include the fix I made above. ```. git clone https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:169,modifiability,version,version,169,What version of scanpy are you using? I don't see a function called `_get_color_values` in `scatterplots.py` in the HEAD version. Can you try installing the development version and seeing if you get the same error? The issue might be that the version you are currently using does not include the fix I made above. ```. git clone https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:243,modifiability,version,version,243,What version of scanpy are you using? I don't see a function called `_get_color_values` in `scatterplots.py` in the HEAD version. Can you try installing the development version and seeing if you get the same error? The issue might be that the version you are currently using does not include the fix I made above. ```. git clone https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:208,performance,error,error,208,What version of scanpy are you using? I don't see a function called `_get_color_values` in `scatterplots.py` in the HEAD version. Can you try installing the development version and seeing if you get the same error? The issue might be that the version you are currently using does not include the fix I made above. ```. git clone https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:275,reliability,doe,does,275,What version of scanpy are you using? I don't see a function called `_get_color_values` in `scatterplots.py` in the HEAD version. Can you try installing the development version and seeing if you get the same error? The issue might be that the version you are currently using does not include the fix I made above. ```. git clone https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:208,safety,error,error,208,What version of scanpy are you using? I don't see a function called `_get_color_values` in `scatterplots.py` in the HEAD version. Can you try installing the development version and seeing if you get the same error? The issue might be that the version you are currently using does not include the fix I made above. ```. git clone https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:208,usability,error,error,208,What version of scanpy are you using? I don't see a function called `_get_color_values` in `scatterplots.py` in the HEAD version. Can you try installing the development version and seeing if you get the same error? The issue might be that the version you are currently using does not include the fix I made above. ```. git clone https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:12,availability,error,error,12,"This is the error with the development version:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-36-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 732 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 733 """""". --> 734 return embedding(adata, 'pca', **kwargs). 735 . 736 . /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 243 itertools.product(color, idx_components). 244 ):. --> 245 color_source_vector = _get_color_source_vector(. 246 adata,. 247 value_to_plot,. /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1016 ):. 1017 # We should probably just make an index for this, and share it over runs. -> 1018 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1019 0. 1020 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bound",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:393,availability,Down,Downloads,393,"This is the error with the development version:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-36-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 732 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 733 """""". --> 734 return embedding(adata, 'pca', **kwargs). 735 . 736 . /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 243 itertools.product(color, idx_components). 244 ):. --> 245 color_source_vector = _get_color_source_vector(. 246 adata,. 247 value_to_plot,. /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1016 ):. 1017 # We should probably just make an index for this, and share it over runs. -> 1018 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1019 0. 1020 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bound",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:631,availability,Down,Downloads,631,"This is the error with the development version:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-36-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 732 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 733 """""". --> 734 return embedding(adata, 'pca', **kwargs). 735 . 736 . /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 243 itertools.product(color, idx_components). 244 ):. --> 245 color_source_vector = _get_color_source_vector(. 246 adata,. 247 value_to_plot,. /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1016 ):. 1017 # We should probably just make an index for this, and share it over runs. -> 1018 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1019 0. 1020 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bound",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:1327,availability,Down,Downloads,1327,"velopment version:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-36-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 732 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 733 """""". --> 734 return embedding(adata, 'pca', **kwargs). 735 . 736 . /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 243 itertools.product(color, idx_components). 244 ):. --> 245 color_source_vector = _get_color_source_vector(. 246 adata,. 247 value_to_plot,. /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1016 ):. 1017 # We should probably just make an index for this, and share it over runs. -> 1018 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1019 0. 1020 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:1681,availability,error,error,1681,"velopment version:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-36-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 732 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 733 """""". --> 734 return embedding(adata, 'pca', **kwargs). 735 . 736 . /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 243 itertools.product(color, idx_components). 244 ):. --> 245 color_source_vector = _get_color_source_vector(. 246 adata,. 247 value_to_plot,. /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1016 ):. 1017 # We should probably just make an index for this, and share it over runs. -> 1018 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1019 0. 1020 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:1956,availability,sli,slice,1956,"velopment version:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-36-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 732 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 733 """""". --> 734 return embedding(adata, 'pca', **kwargs). 735 . 736 . /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 243 itertools.product(color, idx_components). 244 ):. --> 245 color_source_vector = _get_color_source_vector(. 246 adata,. 247 value_to_plot,. /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1016 ):. 1017 # We should probably just make an index for this, and share it over runs. -> 1018 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1019 0. 1020 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:39,deployability,version,version,39,"This is the error with the development version:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-36-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 732 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 733 """""". --> 734 return embedding(adata, 'pca', **kwargs). 735 . 736 . /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 243 itertools.product(color, idx_components). 244 ):. --> 245 color_source_vector = _get_color_source_vector(. 246 adata,. 247 value_to_plot,. /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1016 ):. 1017 # We should probably just make an index for this, and share it over runs. -> 1018 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1019 0. 1020 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bound",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:213,deployability,modul,module,213,"This is the error with the development version:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-36-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 732 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 733 """""". --> 734 return embedding(adata, 'pca', **kwargs). 735 . 736 . /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 243 itertools.product(color, idx_components). 244 ):. --> 245 color_source_vector = _get_color_source_vector(. 246 adata,. 247 value_to_plot,. /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1016 ):. 1017 # We should probably just make an index for this, and share it over runs. -> 1018 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1019 0. 1020 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bound",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:1765,energy efficiency,core,core,1765,"velopment version:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-36-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 732 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 733 """""". --> 734 return embedding(adata, 'pca', **kwargs). 735 . 736 . /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 243 itertools.product(color, idx_components). 244 ):. --> 245 color_source_vector = _get_color_source_vector(. 246 adata,. 247 value_to_plot,. /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1016 ):. 1017 # We should probably just make an index for this, and share it over runs. -> 1018 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1019 0. 1020 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:39,integrability,version,version,39,"This is the error with the development version:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-36-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 732 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 733 """""". --> 734 return embedding(adata, 'pca', **kwargs). 735 . 736 . /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 243 itertools.product(color, idx_components). 244 ):. --> 245 color_source_vector = _get_color_source_vector(. 246 adata,. 247 value_to_plot,. /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1016 ):. 1017 # We should probably just make an index for this, and share it over runs. -> 1018 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1019 0. 1020 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bound",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:833,integrability,compon,components,833,"This is the error with the development version:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-36-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 732 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 733 """""". --> 734 return embedding(adata, 'pca', **kwargs). 735 . 736 . /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 243 itertools.product(color, idx_components). 244 ):. --> 245 color_source_vector = _get_color_source_vector(. 246 adata,. 247 value_to_plot,. /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1016 ):. 1017 # We should probably just make an index for this, and share it over runs. -> 1018 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1019 0. 1020 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bound",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:833,interoperability,compon,components,833,"This is the error with the development version:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-36-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 732 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 733 """""". --> 734 return embedding(adata, 'pca', **kwargs). 735 . 736 . /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 243 itertools.product(color, idx_components). 244 ):. --> 245 color_source_vector = _get_color_source_vector(. 246 adata,. 247 value_to_plot,. /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1016 ):. 1017 # We should probably just make an index for this, and share it over runs. -> 1018 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1019 0. 1020 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bound",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:1540,interoperability,share,share,1540,"velopment version:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-36-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 732 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 733 """""". --> 734 return embedding(adata, 'pca', **kwargs). 735 . 736 . /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 243 itertools.product(color, idx_components). 244 ):. --> 245 color_source_vector = _get_color_source_vector(. 246 adata,. 247 value_to_plot,. /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1016 ):. 1017 # We should probably just make an index for this, and share it over runs. -> 1018 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1019 0. 1020 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:39,modifiability,version,version,39,"This is the error with the development version:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-36-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 732 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 733 """""". --> 734 return embedding(adata, 'pca', **kwargs). 735 . 736 . /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 243 itertools.product(color, idx_components). 244 ):. --> 245 color_source_vector = _get_color_source_vector(. 246 adata,. 247 value_to_plot,. /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1016 ):. 1017 # We should probably just make an index for this, and share it over runs. -> 1018 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1019 0. 1020 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bound",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:213,modifiability,modul,module,213,"This is the error with the development version:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-36-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 732 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 733 """""". --> 734 return embedding(adata, 'pca', **kwargs). 735 . 736 . /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 243 itertools.product(color, idx_components). 244 ):. --> 245 color_source_vector = _get_color_source_vector(. 246 adata,. 247 value_to_plot,. /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1016 ):. 1017 # We should probably just make an index for this, and share it over runs. -> 1018 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1019 0. 1020 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bound",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:833,modifiability,compon,components,833,"This is the error with the development version:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-36-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 732 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 733 """""". --> 734 return embedding(adata, 'pca', **kwargs). 735 . 736 . /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 243 itertools.product(color, idx_components). 244 ):. --> 245 color_source_vector = _get_color_source_vector(. 246 adata,. 247 value_to_plot,. /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1016 ):. 1017 # We should probably just make an index for this, and share it over runs. -> 1018 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1019 0. 1020 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bound",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:845,modifiability,layer,layer,845,"This is the error with the development version:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-36-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 732 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 733 """""". --> 734 return embedding(adata, 'pca', **kwargs). 735 . 736 . /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 243 itertools.product(color, idx_components). 244 ):. --> 245 color_source_vector = _get_color_source_vector(. 246 adata,. 247 value_to_plot,. /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1016 ):. 1017 # We should probably just make an index for this, and share it over runs. -> 1018 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1019 0. 1020 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bound",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:1456,modifiability,layer,layer,1456,"velopment version:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-36-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 732 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 733 """""". --> 734 return embedding(adata, 'pca', **kwargs). 735 . 736 . /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 243 itertools.product(color, idx_components). 244 ):. --> 245 color_source_vector = _get_color_source_vector(. 246 adata,. 247 value_to_plot,. /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1016 ):. 1017 # We should probably just make an index for this, and share it over runs. -> 1018 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1019 0. 1020 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:1749,modifiability,pac,packages,1749,"velopment version:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-36-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 732 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 733 """""". --> 734 return embedding(adata, 'pca', **kwargs). 735 . 736 . /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 243 itertools.product(color, idx_components). 244 ):. --> 245 color_source_vector = _get_color_source_vector(. 246 adata,. 247 value_to_plot,. /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1016 ):. 1017 # We should probably just make an index for this, and share it over runs. -> 1018 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1019 0. 1020 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:12,performance,error,error,12,"This is the error with the development version:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-36-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 732 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 733 """""". --> 734 return embedding(adata, 'pca', **kwargs). 735 . 736 . /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 243 itertools.product(color, idx_components). 244 ):. --> 245 color_source_vector = _get_color_source_vector(. 246 adata,. 247 value_to_plot,. /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1016 ):. 1017 # We should probably just make an index for this, and share it over runs. -> 1018 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1019 0. 1020 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bound",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:1681,performance,error,error,1681,"velopment version:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-36-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 732 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 733 """""". --> 734 return embedding(adata, 'pca', **kwargs). 735 . 736 . /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 243 itertools.product(color, idx_components). 244 ):. --> 245 color_source_vector = _get_color_source_vector(. 246 adata,. 247 value_to_plot,. /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1016 ):. 1017 # We should probably just make an index for this, and share it over runs. -> 1018 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1019 0. 1020 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:1695,reliability,doe,doesn,1695,"velopment version:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-36-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 732 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 733 """""". --> 734 return embedding(adata, 'pca', **kwargs). 735 . 736 . /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 243 itertools.product(color, idx_components). 244 ):. --> 245 color_source_vector = _get_color_source_vector(. 246 adata,. 247 value_to_plot,. /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1016 ):. 1017 # We should probably just make an index for this, and share it over runs. -> 1018 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1019 0. 1020 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:1956,reliability,sli,slice,1956,"velopment version:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-36-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 732 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 733 """""". --> 734 return embedding(adata, 'pca', **kwargs). 735 . 736 . /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 243 itertools.product(color, idx_components). 244 ):. --> 245 color_source_vector = _get_color_source_vector(. 246 adata,. 247 value_to_plot,. /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1016 ):. 1017 # We should probably just make an index for this, and share it over runs. -> 1018 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1019 0. 1020 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:12,safety,error,error,12,"This is the error with the development version:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-36-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 732 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 733 """""". --> 734 return embedding(adata, 'pca', **kwargs). 735 . 736 . /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 243 itertools.product(color, idx_components). 244 ):. --> 245 color_source_vector = _get_color_source_vector(. 246 adata,. 247 value_to_plot,. /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1016 ):. 1017 # We should probably just make an index for this, and share it over runs. -> 1018 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1019 0. 1020 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bound",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:186,safety,input,input-,186,"This is the error with the development version:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-36-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 732 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 733 """""". --> 734 return embedding(adata, 'pca', **kwargs). 735 . 736 . /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 243 itertools.product(color, idx_components). 244 ):. --> 245 color_source_vector = _get_color_source_vector(. 246 adata,. 247 value_to_plot,. /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1016 ):. 1017 # We should probably just make an index for this, and share it over runs. -> 1018 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1019 0. 1020 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bound",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:213,safety,modul,module,213,"This is the error with the development version:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-36-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 732 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 733 """""". --> 734 return embedding(adata, 'pca', **kwargs). 735 . 736 . /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 243 itertools.product(color, idx_components). 244 ):. --> 245 color_source_vector = _get_color_source_vector(. 246 adata,. 247 value_to_plot,. /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1016 ):. 1017 # We should probably just make an index for this, and share it over runs. -> 1018 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1019 0. 1020 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bound",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:1681,safety,error,error,1681,"velopment version:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-36-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 732 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 733 """""". --> 734 return embedding(adata, 'pca', **kwargs). 735 . 736 . /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 243 itertools.product(color, idx_components). 244 ):. --> 245 color_source_vector = _get_color_source_vector(. 246 adata,. 247 value_to_plot,. /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1016 ):. 1017 # We should probably just make an index for this, and share it over runs. -> 1018 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1019 0. 1020 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:285,security,Access,Accession,285,"This is the error with the development version:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-36-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 732 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 733 """""". --> 734 return embedding(adata, 'pca', **kwargs). 735 . 736 . /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 243 itertools.product(color, idx_components). 244 ):. --> 245 color_source_vector = _get_color_source_vector(. 246 adata,. 247 value_to_plot,. /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1016 ):. 1017 # We should probably just make an index for this, and share it over runs. -> 1018 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1019 0. 1020 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bound",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:142,testability,Trace,Traceback,142,"This is the error with the development version:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-36-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 732 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 733 """""". --> 734 return embedding(adata, 'pca', **kwargs). 735 . 736 . /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 243 itertools.product(color, idx_components). 244 ):. --> 245 color_source_vector = _get_color_source_vector(. 246 adata,. 247 value_to_plot,. /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1016 ):. 1017 # We should probably just make an index for this, and share it over runs. -> 1018 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1019 0. 1020 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bound",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:12,usability,error,error,12,"This is the error with the development version:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-36-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 732 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 733 """""". --> 734 return embedding(adata, 'pca', **kwargs). 735 . 736 . /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 243 itertools.product(color, idx_components). 244 ):. --> 245 color_source_vector = _get_color_source_vector(. 246 adata,. 247 value_to_plot,. /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1016 ):. 1017 # We should probably just make an index for this, and share it over runs. -> 1018 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1019 0. 1020 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bound",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:186,usability,input,input-,186,"This is the error with the development version:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-36-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 732 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 733 """""". --> 734 return embedding(adata, 'pca', **kwargs). 735 . 736 . /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 243 itertools.product(color, idx_components). 244 ):. --> 245 color_source_vector = _get_color_source_vector(. 246 adata,. 247 value_to_plot,. /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1016 ):. 1017 # We should probably just make an index for this, and share it over runs. -> 1018 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1019 0. 1020 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bound",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:385,usability,User,Users,385,"This is the error with the development version:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-36-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 732 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 733 """""". --> 734 return embedding(adata, 'pca', **kwargs). 735 . 736 . /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 243 itertools.product(color, idx_components). 244 ):. --> 245 color_source_vector = _get_color_source_vector(. 246 adata,. 247 value_to_plot,. /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1016 ):. 1017 # We should probably just make an index for this, and share it over runs. -> 1018 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1019 0. 1020 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bound",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:623,usability,User,Users,623,"This is the error with the development version:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-36-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 732 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 733 """""". --> 734 return embedding(adata, 'pca', **kwargs). 735 . 736 . /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 243 itertools.product(color, idx_components). 244 ):. --> 245 color_source_vector = _get_color_source_vector(. 246 adata,. 247 value_to_plot,. /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1016 ):. 1017 # We should probably just make an index for this, and share it over runs. -> 1018 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1019 0. 1020 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bound",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:1319,usability,User,Users,1319,"velopment version:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-36-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 732 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 733 """""". --> 734 return embedding(adata, 'pca', **kwargs). 735 . 736 . /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 243 itertools.product(color, idx_components). 244 ):. --> 245 color_source_vector = _get_color_source_vector(. 246 adata,. 247 value_to_plot,. /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1016 ):. 1017 # We should probably just make an index for this, and share it over runs. -> 1018 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1019 0. 1020 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:1673,usability,help,helpful,1673,"velopment version:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-36-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 732 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 733 """""". --> 734 return embedding(adata, 'pca', **kwargs). 735 . 736 . /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 243 itertools.product(color, idx_components). 244 ):. --> 245 color_source_vector = _get_color_source_vector(. 246 adata,. 247 value_to_plot,. /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1016 ):. 1017 # We should probably just make an index for this, and share it over runs. -> 1018 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1019 0. 1020 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:1681,usability,error,error,1681,"velopment version:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-36-2ee11f6b7699> in <module>. ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs). 732 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 733 """""". --> 734 return embedding(adata, 'pca', **kwargs). 735 . 736 . /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 243 itertools.product(color, idx_components). 244 ):. --> 245 color_source_vector = _get_color_source_vector(. 246 adata,. 247 value_to_plot,. /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups). 1016 ):. 1017 # We should probably just make an index for this, and share it over runs. -> 1018 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][. 1019 0. 1020 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key). 4095 if is_scalar(key):. 4096 key = com.cast_scalar_indexer(key, warn_float=True). -> 4097 return getitem(key). 4098 . 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:312,deployability,instal,install,312,"Alright, I think I found the problem and hopefully fixed it, although I am not sure as I don't completely understand how the `_get_color_source_vector` function works. If you'd like to try my fix, it's in my fork:. ```. git clone https://github.com/WarrenLab/scanpy.git. cd scanpy. git checkout use_raw_fix. pip install . ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:95,safety,compl,completely,95,"Alright, I think I found the problem and hopefully fixed it, although I am not sure as I don't completely understand how the `_get_color_source_vector` function works. If you'd like to try my fix, it's in my fork:. ```. git clone https://github.com/WarrenLab/scanpy.git. cd scanpy. git checkout use_raw_fix. pip install . ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:95,security,compl,completely,95,"Alright, I think I found the problem and hopefully fixed it, although I am not sure as I don't completely understand how the `_get_color_source_vector` function works. If you'd like to try my fix, it's in my fork:. ```. git clone https://github.com/WarrenLab/scanpy.git. cd scanpy. git checkout use_raw_fix. pip install . ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:106,testability,understand,understand,106,"Alright, I think I found the problem and hopefully fixed it, although I am not sure as I don't completely understand how the `_get_color_source_vector` function works. If you'd like to try my fix, it's in my fork:. ```. git clone https://github.com/WarrenLab/scanpy.git. cd scanpy. git checkout use_raw_fix. pip install . ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1281:42,integrability,sub,subsetting,42,"And I just saw #1267, which mentioned the subsetting option and totally solves the problem. If you all are interested in having this functionality as an option, leave this open, let me know, and I'll work on a pull request. Otherwise, feel free to close it. Sorry for the (sort of) repeat.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1281
https://github.com/scverse/scanpy/issues/1281:248,usability,close,close,248,"And I just saw #1267, which mentioned the subsetting option and totally solves the problem. If you all are interested in having this functionality as an option, leave this open, let me know, and I'll work on a pull request. Otherwise, feel free to close it. Sorry for the (sort of) repeat.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1281
https://github.com/scverse/scanpy/issues/1282:119,integrability,sub,subheadings,119,"@ivirshup thanks for getting back to me, sure, will do. @michalk8 , could you take care of this? I would add three new subheadings to the `ecosystem` page in the docs, ""Caching"", ""Interactive Plotting"" and ""Fate mapping"" where I would link the respective packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1282
https://github.com/scverse/scanpy/issues/1282:255,modifiability,pac,packages,255,"@ivirshup thanks for getting back to me, sure, will do. @michalk8 , could you take care of this? I would add three new subheadings to the `ecosystem` page in the docs, ""Caching"", ""Interactive Plotting"" and ""Fate mapping"" where I would link the respective packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1282
https://github.com/scverse/scanpy/issues/1282:169,performance,Cach,Caching,169,"@ivirshup thanks for getting back to me, sure, will do. @michalk8 , could you take care of this? I would add three new subheadings to the `ecosystem` page in the docs, ""Caching"", ""Interactive Plotting"" and ""Fate mapping"" where I would link the respective packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1282
https://github.com/scverse/scanpy/issues/1282:180,usability,Interact,Interactive,180,"@ivirshup thanks for getting back to me, sure, will do. @michalk8 , could you take care of this? I would add three new subheadings to the `ecosystem` page in the docs, ""Caching"", ""Interactive Plotting"" and ""Fate mapping"" where I would link the respective packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1282
https://github.com/scverse/scanpy/issues/1283:14,deployability,instal,install,14,just use `pip install louvain` to install the louvain package and use this functionality. . @ivirshup @flying-sheep I noticed that the louvain install suggestion in the documentation has been replaced by a `pip install scanpy[leiden]` suggestion. However `louvain` is still the default in the tutorials. Maybe the louvain install should be added again?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:34,deployability,instal,install,34,just use `pip install louvain` to install the louvain package and use this functionality. . @ivirshup @flying-sheep I noticed that the louvain install suggestion in the documentation has been replaced by a `pip install scanpy[leiden]` suggestion. However `louvain` is still the default in the tutorials. Maybe the louvain install should be added again?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:143,deployability,instal,install,143,just use `pip install louvain` to install the louvain package and use this functionality. . @ivirshup @flying-sheep I noticed that the louvain install suggestion in the documentation has been replaced by a `pip install scanpy[leiden]` suggestion. However `louvain` is still the default in the tutorials. Maybe the louvain install should be added again?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:211,deployability,instal,install,211,just use `pip install louvain` to install the louvain package and use this functionality. . @ivirshup @flying-sheep I noticed that the louvain install suggestion in the documentation has been replaced by a `pip install scanpy[leiden]` suggestion. However `louvain` is still the default in the tutorials. Maybe the louvain install should be added again?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:322,deployability,instal,install,322,just use `pip install louvain` to install the louvain package and use this functionality. . @ivirshup @flying-sheep I noticed that the louvain install suggestion in the documentation has been replaced by a `pip install scanpy[leiden]` suggestion. However `louvain` is still the default in the tutorials. Maybe the louvain install should be added again?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:54,modifiability,pac,package,54,just use `pip install louvain` to install the louvain package and use this functionality. . @ivirshup @flying-sheep I noticed that the louvain install suggestion in the documentation has been replaced by a `pip install scanpy[leiden]` suggestion. However `louvain` is still the default in the tutorials. Maybe the louvain install should be added again?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:169,usability,document,documentation,169,just use `pip install louvain` to install the louvain package and use this functionality. . @ivirshup @flying-sheep I noticed that the louvain install suggestion in the documentation has been replaced by a `pip install scanpy[leiden]` suggestion. However `louvain` is still the default in the tutorials. Maybe the louvain install should be added again?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:132,availability,failur,failure,132,"I also have the same problem and I tried to use `pip install louvain`, but I cannot install the package and it says `legacy-install-failure`. The GitHub for the [louvain](https://github.com/vtraag/louvain-igraph/tree/master) says,. > Warning. > . > This package has been superseded by the [leidenalg](https://github.com/vtraag/leidenalg) package and will no longer be maintained.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:53,deployability,instal,install,53,"I also have the same problem and I tried to use `pip install louvain`, but I cannot install the package and it says `legacy-install-failure`. The GitHub for the [louvain](https://github.com/vtraag/louvain-igraph/tree/master) says,. > Warning. > . > This package has been superseded by the [leidenalg](https://github.com/vtraag/leidenalg) package and will no longer be maintained.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:84,deployability,instal,install,84,"I also have the same problem and I tried to use `pip install louvain`, but I cannot install the package and it says `legacy-install-failure`. The GitHub for the [louvain](https://github.com/vtraag/louvain-igraph/tree/master) says,. > Warning. > . > This package has been superseded by the [leidenalg](https://github.com/vtraag/leidenalg) package and will no longer be maintained.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:124,deployability,instal,install-failure,124,"I also have the same problem and I tried to use `pip install louvain`, but I cannot install the package and it says `legacy-install-failure`. The GitHub for the [louvain](https://github.com/vtraag/louvain-igraph/tree/master) says,. > Warning. > . > This package has been superseded by the [leidenalg](https://github.com/vtraag/leidenalg) package and will no longer be maintained.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:96,modifiability,pac,package,96,"I also have the same problem and I tried to use `pip install louvain`, but I cannot install the package and it says `legacy-install-failure`. The GitHub for the [louvain](https://github.com/vtraag/louvain-igraph/tree/master) says,. > Warning. > . > This package has been superseded by the [leidenalg](https://github.com/vtraag/leidenalg) package and will no longer be maintained.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:254,modifiability,pac,package,254,"I also have the same problem and I tried to use `pip install louvain`, but I cannot install the package and it says `legacy-install-failure`. The GitHub for the [louvain](https://github.com/vtraag/louvain-igraph/tree/master) says,. > Warning. > . > This package has been superseded by the [leidenalg](https://github.com/vtraag/leidenalg) package and will no longer be maintained.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:338,modifiability,pac,package,338,"I also have the same problem and I tried to use `pip install louvain`, but I cannot install the package and it says `legacy-install-failure`. The GitHub for the [louvain](https://github.com/vtraag/louvain-igraph/tree/master) says,. > Warning. > . > This package has been superseded by the [leidenalg](https://github.com/vtraag/leidenalg) package and will no longer be maintained.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:368,modifiability,maintain,maintained,368,"I also have the same problem and I tried to use `pip install louvain`, but I cannot install the package and it says `legacy-install-failure`. The GitHub for the [louvain](https://github.com/vtraag/louvain-igraph/tree/master) says,. > Warning. > . > This package has been superseded by the [leidenalg](https://github.com/vtraag/leidenalg) package and will no longer be maintained.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:132,performance,failur,failure,132,"I also have the same problem and I tried to use `pip install louvain`, but I cannot install the package and it says `legacy-install-failure`. The GitHub for the [louvain](https://github.com/vtraag/louvain-igraph/tree/master) says,. > Warning. > . > This package has been superseded by the [leidenalg](https://github.com/vtraag/leidenalg) package and will no longer be maintained.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:132,reliability,fail,failure,132,"I also have the same problem and I tried to use `pip install louvain`, but I cannot install the package and it says `legacy-install-failure`. The GitHub for the [louvain](https://github.com/vtraag/louvain-igraph/tree/master) says,. > Warning. > . > This package has been superseded by the [leidenalg](https://github.com/vtraag/leidenalg) package and will no longer be maintained.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:368,safety,maintain,maintained,368,"I also have the same problem and I tried to use `pip install louvain`, but I cannot install the package and it says `legacy-install-failure`. The GitHub for the [louvain](https://github.com/vtraag/louvain-igraph/tree/master) says,. > Warning. > . > This package has been superseded by the [leidenalg](https://github.com/vtraag/leidenalg) package and will no longer be maintained.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:183,deployability,instal,install,183,"Check out scanpys optional features:. https://github.com/scverse/scanpy/blob/21ca328672646d7d0ba42b64eee2823babc2d2ed/pyproject.toml#L133-L145. as you can see `scanpy[louvain]` will install it, while `scanpy[leiden]` will install the successor.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:223,deployability,instal,install,223,"Check out scanpys optional features:. https://github.com/scverse/scanpy/blob/21ca328672646d7d0ba42b64eee2823babc2d2ed/pyproject.toml#L133-L145. as you can see `scanpy[louvain]` will install it, while `scanpy[leiden]` will install the successor.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:62,deployability,instal,installed,62,"Thank you for the comment. Do you mean these packages will be installed when we install Scanpy? Sorry that I don't understand. When I try to use `scanpy.tl.louvain`, it says `ModuleNotFoundError: No module named 'louvain'`, and I don't know how to solve it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:80,deployability,instal,install,80,"Thank you for the comment. Do you mean these packages will be installed when we install Scanpy? Sorry that I don't understand. When I try to use `scanpy.tl.louvain`, it says `ModuleNotFoundError: No module named 'louvain'`, and I don't know how to solve it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:175,deployability,Modul,ModuleNotFoundError,175,"Thank you for the comment. Do you mean these packages will be installed when we install Scanpy? Sorry that I don't understand. When I try to use `scanpy.tl.louvain`, it says `ModuleNotFoundError: No module named 'louvain'`, and I don't know how to solve it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:199,deployability,modul,module,199,"Thank you for the comment. Do you mean these packages will be installed when we install Scanpy? Sorry that I don't understand. When I try to use `scanpy.tl.louvain`, it says `ModuleNotFoundError: No module named 'louvain'`, and I don't know how to solve it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:45,modifiability,pac,packages,45,"Thank you for the comment. Do you mean these packages will be installed when we install Scanpy? Sorry that I don't understand. When I try to use `scanpy.tl.louvain`, it says `ModuleNotFoundError: No module named 'louvain'`, and I don't know how to solve it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:175,modifiability,Modul,ModuleNotFoundError,175,"Thank you for the comment. Do you mean these packages will be installed when we install Scanpy? Sorry that I don't understand. When I try to use `scanpy.tl.louvain`, it says `ModuleNotFoundError: No module named 'louvain'`, and I don't know how to solve it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:199,modifiability,modul,module,199,"Thank you for the comment. Do you mean these packages will be installed when we install Scanpy? Sorry that I don't understand. When I try to use `scanpy.tl.louvain`, it says `ModuleNotFoundError: No module named 'louvain'`, and I don't know how to solve it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:175,safety,Modul,ModuleNotFoundError,175,"Thank you for the comment. Do you mean these packages will be installed when we install Scanpy? Sorry that I don't understand. When I try to use `scanpy.tl.louvain`, it says `ModuleNotFoundError: No module named 'louvain'`, and I don't know how to solve it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:199,safety,modul,module,199,"Thank you for the comment. Do you mean these packages will be installed when we install Scanpy? Sorry that I don't understand. When I try to use `scanpy.tl.louvain`, it says `ModuleNotFoundError: No module named 'louvain'`, and I don't know how to solve it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:115,testability,understand,understand,115,"Thank you for the comment. Do you mean these packages will be installed when we install Scanpy? Sorry that I don't understand. When I try to use `scanpy.tl.louvain`, it says `ModuleNotFoundError: No module named 'louvain'`, and I don't know how to solve it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:14,deployability,instal,install,14,"As said: `pip install scanpy[leiden]`, and use `scanpy.tl.leiden()` instead. See here for how to install scanpy and its dependencies: https://scanpy.readthedocs.io/en/stable/installation.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:97,deployability,instal,install,97,"As said: `pip install scanpy[leiden]`, and use `scanpy.tl.leiden()` instead. See here for how to install scanpy and its dependencies: https://scanpy.readthedocs.io/en/stable/installation.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:120,deployability,depend,dependencies,120,"As said: `pip install scanpy[leiden]`, and use `scanpy.tl.leiden()` instead. See here for how to install scanpy and its dependencies: https://scanpy.readthedocs.io/en/stable/installation.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:174,deployability,instal,installation,174,"As said: `pip install scanpy[leiden]`, and use `scanpy.tl.leiden()` instead. See here for how to install scanpy and its dependencies: https://scanpy.readthedocs.io/en/stable/installation.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:120,integrability,depend,dependencies,120,"As said: `pip install scanpy[leiden]`, and use `scanpy.tl.leiden()` instead. See here for how to install scanpy and its dependencies: https://scanpy.readthedocs.io/en/stable/installation.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:120,modifiability,depend,dependencies,120,"As said: `pip install scanpy[leiden]`, and use `scanpy.tl.leiden()` instead. See here for how to install scanpy and its dependencies: https://scanpy.readthedocs.io/en/stable/installation.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:120,safety,depend,dependencies,120,"As said: `pip install scanpy[leiden]`, and use `scanpy.tl.leiden()` instead. See here for how to install scanpy and its dependencies: https://scanpy.readthedocs.io/en/stable/installation.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:120,testability,depend,dependencies,120,"As said: `pip install scanpy[leiden]`, and use `scanpy.tl.leiden()` instead. See here for how to install scanpy and its dependencies: https://scanpy.readthedocs.io/en/stable/installation.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:158,availability,error,error,158,"Do you mean that If I want to do use `scanpy.tl.louvain`, I can use `scanpy.tl.leiden` instead? I can `pip install scanpy[leiden]` but it will not change the error message in `scanpy.tl.louvain` with option `flavor='vtraag'`. When I try `pip install scanpy[louvain]`, it has the error `legacy-install-failure`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:279,availability,error,error,279,"Do you mean that If I want to do use `scanpy.tl.louvain`, I can use `scanpy.tl.leiden` instead? I can `pip install scanpy[leiden]` but it will not change the error message in `scanpy.tl.louvain` with option `flavor='vtraag'`. When I try `pip install scanpy[louvain]`, it has the error `legacy-install-failure`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:301,availability,failur,failure,301,"Do you mean that If I want to do use `scanpy.tl.louvain`, I can use `scanpy.tl.leiden` instead? I can `pip install scanpy[leiden]` but it will not change the error message in `scanpy.tl.louvain` with option `flavor='vtraag'`. When I try `pip install scanpy[louvain]`, it has the error `legacy-install-failure`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:107,deployability,instal,install,107,"Do you mean that If I want to do use `scanpy.tl.louvain`, I can use `scanpy.tl.leiden` instead? I can `pip install scanpy[leiden]` but it will not change the error message in `scanpy.tl.louvain` with option `flavor='vtraag'`. When I try `pip install scanpy[louvain]`, it has the error `legacy-install-failure`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:242,deployability,instal,install,242,"Do you mean that If I want to do use `scanpy.tl.louvain`, I can use `scanpy.tl.leiden` instead? I can `pip install scanpy[leiden]` but it will not change the error message in `scanpy.tl.louvain` with option `flavor='vtraag'`. When I try `pip install scanpy[louvain]`, it has the error `legacy-install-failure`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:293,deployability,instal,install-failure,293,"Do you mean that If I want to do use `scanpy.tl.louvain`, I can use `scanpy.tl.leiden` instead? I can `pip install scanpy[leiden]` but it will not change the error message in `scanpy.tl.louvain` with option `flavor='vtraag'`. When I try `pip install scanpy[louvain]`, it has the error `legacy-install-failure`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:164,integrability,messag,message,164,"Do you mean that If I want to do use `scanpy.tl.louvain`, I can use `scanpy.tl.leiden` instead? I can `pip install scanpy[leiden]` but it will not change the error message in `scanpy.tl.louvain` with option `flavor='vtraag'`. When I try `pip install scanpy[louvain]`, it has the error `legacy-install-failure`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:164,interoperability,messag,message,164,"Do you mean that If I want to do use `scanpy.tl.louvain`, I can use `scanpy.tl.leiden` instead? I can `pip install scanpy[leiden]` but it will not change the error message in `scanpy.tl.louvain` with option `flavor='vtraag'`. When I try `pip install scanpy[louvain]`, it has the error `legacy-install-failure`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:158,performance,error,error,158,"Do you mean that If I want to do use `scanpy.tl.louvain`, I can use `scanpy.tl.leiden` instead? I can `pip install scanpy[leiden]` but it will not change the error message in `scanpy.tl.louvain` with option `flavor='vtraag'`. When I try `pip install scanpy[louvain]`, it has the error `legacy-install-failure`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:279,performance,error,error,279,"Do you mean that If I want to do use `scanpy.tl.louvain`, I can use `scanpy.tl.leiden` instead? I can `pip install scanpy[leiden]` but it will not change the error message in `scanpy.tl.louvain` with option `flavor='vtraag'`. When I try `pip install scanpy[louvain]`, it has the error `legacy-install-failure`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:301,performance,failur,failure,301,"Do you mean that If I want to do use `scanpy.tl.louvain`, I can use `scanpy.tl.leiden` instead? I can `pip install scanpy[leiden]` but it will not change the error message in `scanpy.tl.louvain` with option `flavor='vtraag'`. When I try `pip install scanpy[louvain]`, it has the error `legacy-install-failure`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:301,reliability,fail,failure,301,"Do you mean that If I want to do use `scanpy.tl.louvain`, I can use `scanpy.tl.leiden` instead? I can `pip install scanpy[leiden]` but it will not change the error message in `scanpy.tl.louvain` with option `flavor='vtraag'`. When I try `pip install scanpy[louvain]`, it has the error `legacy-install-failure`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:158,safety,error,error,158,"Do you mean that If I want to do use `scanpy.tl.louvain`, I can use `scanpy.tl.leiden` instead? I can `pip install scanpy[leiden]` but it will not change the error message in `scanpy.tl.louvain` with option `flavor='vtraag'`. When I try `pip install scanpy[louvain]`, it has the error `legacy-install-failure`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:279,safety,error,error,279,"Do you mean that If I want to do use `scanpy.tl.louvain`, I can use `scanpy.tl.leiden` instead? I can `pip install scanpy[leiden]` but it will not change the error message in `scanpy.tl.louvain` with option `flavor='vtraag'`. When I try `pip install scanpy[louvain]`, it has the error `legacy-install-failure`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:158,usability,error,error,158,"Do you mean that If I want to do use `scanpy.tl.louvain`, I can use `scanpy.tl.leiden` instead? I can `pip install scanpy[leiden]` but it will not change the error message in `scanpy.tl.louvain` with option `flavor='vtraag'`. When I try `pip install scanpy[louvain]`, it has the error `legacy-install-failure`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:279,usability,error,error,279,"Do you mean that If I want to do use `scanpy.tl.louvain`, I can use `scanpy.tl.leiden` instead? I can `pip install scanpy[leiden]` but it will not change the error message in `scanpy.tl.louvain` with option `flavor='vtraag'`. When I try `pip install scanpy[louvain]`, it has the error `legacy-install-failure`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:95,safety,detect,detection,95,"louvain is deprecated. leiden is its successor. So unless you want compare different community detection methods, you should use leiden instead of louvain. Just leave out the `flavor`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:95,security,detect,detection,95,"louvain is deprecated. leiden is its successor. So unless you want compare different community detection methods, you should use leiden instead of louvain. Just leave out the `flavor`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:2,testability,understand,understand,2,"I understand that leiden is the newer method, but I want to reproduce the old analysis that is already done in the paper I am looking. I will use diffenret `flavor` if I want to use louvain for now. Thank you for all the comment.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1284:96,deployability,instal,installation,96,"Are you able to run `import tables` in this environment? If not, I think the issue will be with installation of the `pytables` package.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1284
https://github.com/scverse/scanpy/issues/1284:127,modifiability,pac,package,127,"Are you able to run `import tables` in this environment? If not, I think the issue will be with installation of the `pytables` package.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1284
https://github.com/scverse/scanpy/issues/1285:79,deployability,releas,release,79,"Hi, @AlejandraRodelaRo . It was fixed on github master. You can wait for a new release or install scanpy from github.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1285
https://github.com/scverse/scanpy/issues/1285:90,deployability,instal,install,90,"Hi, @AlejandraRodelaRo . It was fixed on github master. You can wait for a new release or install scanpy from github.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1285
https://github.com/scverse/scanpy/issues/1285:35,deployability,releas,release,35,"Hi @Koncopd, any idea when the new release will be out?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1285
https://github.com/scverse/scanpy/issues/1285:73,deployability,releas,release,73,"Yes, this is a duplicate of #1260. Please follow #1319 to track the next release",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1285
https://github.com/scverse/scanpy/issues/1286:181,deployability,Instal,Installed,181,"I'm not able to reproduce this. Here's what I tried. * Made a conda environment with `conda create -yn torch-scanpy ""python=3.8""`, and activated it `conda activate torch-scanpy`. * Installed: `pip install scanpy torch`. * Imported: `python3 -c ""import torch; import scanpy""`. IIRC, there has been an issue with the order of importing numba and pytorch due to how they require their LLVM dependency. I would make sure your version of pytorch and numba are up to date (I believe your pytorch is a few versions old) and trying again. If the issue persists, could you check if you run into problems with this? ```python. import torch. import numba. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1286
https://github.com/scverse/scanpy/issues/1286:197,deployability,instal,install,197,"I'm not able to reproduce this. Here's what I tried. * Made a conda environment with `conda create -yn torch-scanpy ""python=3.8""`, and activated it `conda activate torch-scanpy`. * Installed: `pip install scanpy torch`. * Imported: `python3 -c ""import torch; import scanpy""`. IIRC, there has been an issue with the order of importing numba and pytorch due to how they require their LLVM dependency. I would make sure your version of pytorch and numba are up to date (I believe your pytorch is a few versions old) and trying again. If the issue persists, could you check if you run into problems with this? ```python. import torch. import numba. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1286
https://github.com/scverse/scanpy/issues/1286:387,deployability,depend,dependency,387,"I'm not able to reproduce this. Here's what I tried. * Made a conda environment with `conda create -yn torch-scanpy ""python=3.8""`, and activated it `conda activate torch-scanpy`. * Installed: `pip install scanpy torch`. * Imported: `python3 -c ""import torch; import scanpy""`. IIRC, there has been an issue with the order of importing numba and pytorch due to how they require their LLVM dependency. I would make sure your version of pytorch and numba are up to date (I believe your pytorch is a few versions old) and trying again. If the issue persists, could you check if you run into problems with this? ```python. import torch. import numba. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1286
https://github.com/scverse/scanpy/issues/1286:422,deployability,version,version,422,"I'm not able to reproduce this. Here's what I tried. * Made a conda environment with `conda create -yn torch-scanpy ""python=3.8""`, and activated it `conda activate torch-scanpy`. * Installed: `pip install scanpy torch`. * Imported: `python3 -c ""import torch; import scanpy""`. IIRC, there has been an issue with the order of importing numba and pytorch due to how they require their LLVM dependency. I would make sure your version of pytorch and numba are up to date (I believe your pytorch is a few versions old) and trying again. If the issue persists, could you check if you run into problems with this? ```python. import torch. import numba. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1286
https://github.com/scverse/scanpy/issues/1286:499,deployability,version,versions,499,"I'm not able to reproduce this. Here's what I tried. * Made a conda environment with `conda create -yn torch-scanpy ""python=3.8""`, and activated it `conda activate torch-scanpy`. * Installed: `pip install scanpy torch`. * Imported: `python3 -c ""import torch; import scanpy""`. IIRC, there has been an issue with the order of importing numba and pytorch due to how they require their LLVM dependency. I would make sure your version of pytorch and numba are up to date (I believe your pytorch is a few versions old) and trying again. If the issue persists, could you check if you run into problems with this? ```python. import torch. import numba. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1286
https://github.com/scverse/scanpy/issues/1286:387,integrability,depend,dependency,387,"I'm not able to reproduce this. Here's what I tried. * Made a conda environment with `conda create -yn torch-scanpy ""python=3.8""`, and activated it `conda activate torch-scanpy`. * Installed: `pip install scanpy torch`. * Imported: `python3 -c ""import torch; import scanpy""`. IIRC, there has been an issue with the order of importing numba and pytorch due to how they require their LLVM dependency. I would make sure your version of pytorch and numba are up to date (I believe your pytorch is a few versions old) and trying again. If the issue persists, could you check if you run into problems with this? ```python. import torch. import numba. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1286
https://github.com/scverse/scanpy/issues/1286:422,integrability,version,version,422,"I'm not able to reproduce this. Here's what I tried. * Made a conda environment with `conda create -yn torch-scanpy ""python=3.8""`, and activated it `conda activate torch-scanpy`. * Installed: `pip install scanpy torch`. * Imported: `python3 -c ""import torch; import scanpy""`. IIRC, there has been an issue with the order of importing numba and pytorch due to how they require their LLVM dependency. I would make sure your version of pytorch and numba are up to date (I believe your pytorch is a few versions old) and trying again. If the issue persists, could you check if you run into problems with this? ```python. import torch. import numba. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1286
https://github.com/scverse/scanpy/issues/1286:499,integrability,version,versions,499,"I'm not able to reproduce this. Here's what I tried. * Made a conda environment with `conda create -yn torch-scanpy ""python=3.8""`, and activated it `conda activate torch-scanpy`. * Installed: `pip install scanpy torch`. * Imported: `python3 -c ""import torch; import scanpy""`. IIRC, there has been an issue with the order of importing numba and pytorch due to how they require their LLVM dependency. I would make sure your version of pytorch and numba are up to date (I believe your pytorch is a few versions old) and trying again. If the issue persists, could you check if you run into problems with this? ```python. import torch. import numba. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1286
https://github.com/scverse/scanpy/issues/1286:387,modifiability,depend,dependency,387,"I'm not able to reproduce this. Here's what I tried. * Made a conda environment with `conda create -yn torch-scanpy ""python=3.8""`, and activated it `conda activate torch-scanpy`. * Installed: `pip install scanpy torch`. * Imported: `python3 -c ""import torch; import scanpy""`. IIRC, there has been an issue with the order of importing numba and pytorch due to how they require their LLVM dependency. I would make sure your version of pytorch and numba are up to date (I believe your pytorch is a few versions old) and trying again. If the issue persists, could you check if you run into problems with this? ```python. import torch. import numba. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1286
https://github.com/scverse/scanpy/issues/1286:422,modifiability,version,version,422,"I'm not able to reproduce this. Here's what I tried. * Made a conda environment with `conda create -yn torch-scanpy ""python=3.8""`, and activated it `conda activate torch-scanpy`. * Installed: `pip install scanpy torch`. * Imported: `python3 -c ""import torch; import scanpy""`. IIRC, there has been an issue with the order of importing numba and pytorch due to how they require their LLVM dependency. I would make sure your version of pytorch and numba are up to date (I believe your pytorch is a few versions old) and trying again. If the issue persists, could you check if you run into problems with this? ```python. import torch. import numba. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1286
https://github.com/scverse/scanpy/issues/1286:499,modifiability,version,versions,499,"I'm not able to reproduce this. Here's what I tried. * Made a conda environment with `conda create -yn torch-scanpy ""python=3.8""`, and activated it `conda activate torch-scanpy`. * Installed: `pip install scanpy torch`. * Imported: `python3 -c ""import torch; import scanpy""`. IIRC, there has been an issue with the order of importing numba and pytorch due to how they require their LLVM dependency. I would make sure your version of pytorch and numba are up to date (I believe your pytorch is a few versions old) and trying again. If the issue persists, could you check if you run into problems with this? ```python. import torch. import numba. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1286
https://github.com/scverse/scanpy/issues/1286:387,safety,depend,dependency,387,"I'm not able to reproduce this. Here's what I tried. * Made a conda environment with `conda create -yn torch-scanpy ""python=3.8""`, and activated it `conda activate torch-scanpy`. * Installed: `pip install scanpy torch`. * Imported: `python3 -c ""import torch; import scanpy""`. IIRC, there has been an issue with the order of importing numba and pytorch due to how they require their LLVM dependency. I would make sure your version of pytorch and numba are up to date (I believe your pytorch is a few versions old) and trying again. If the issue persists, could you check if you run into problems with this? ```python. import torch. import numba. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1286
https://github.com/scverse/scanpy/issues/1286:387,testability,depend,dependency,387,"I'm not able to reproduce this. Here's what I tried. * Made a conda environment with `conda create -yn torch-scanpy ""python=3.8""`, and activated it `conda activate torch-scanpy`. * Installed: `pip install scanpy torch`. * Imported: `python3 -c ""import torch; import scanpy""`. IIRC, there has been an issue with the order of importing numba and pytorch due to how they require their LLVM dependency. I would make sure your version of pytorch and numba are up to date (I believe your pytorch is a few versions old) and trying again. If the issue persists, could you check if you run into problems with this? ```python. import torch. import numba. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1286
https://github.com/scverse/scanpy/issues/1286:144,reliability,doe,does,144,"I have pytorch and tensorflow alongside scanpy in several conda envs. I would close this for now, also because it's not clear what ""probably it does not finish"" means. . Feel free to reopen it if problem persists.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1286
https://github.com/scverse/scanpy/issues/1286:78,usability,close,close,78,"I have pytorch and tensorflow alongside scanpy in several conda envs. I would close this for now, also because it's not clear what ""probably it does not finish"" means. . Feel free to reopen it if problem persists.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1286
https://github.com/scverse/scanpy/issues/1286:120,usability,clear,clear,120,"I have pytorch and tensorflow alongside scanpy in several conda envs. I would close this for now, also because it's not clear what ""probably it does not finish"" means. . Feel free to reopen it if problem persists.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1286
https://github.com/scverse/scanpy/issues/1287:262,deployability,continu,continue,262,"Hi @AdemS80 ,. I would be really curious to hear more about this but would need some examples. Also, if you are interested in contributing and need help with PR can definitely support you with that. . I'll close this due to inactivity but feel free to reopen or continue discussion. I will get notification and reply straight away!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1287
https://github.com/scverse/scanpy/issues/1287:148,usability,help,help,148,"Hi @AdemS80 ,. I would be really curious to hear more about this but would need some examples. Also, if you are interested in contributing and need help with PR can definitely support you with that. . I'll close this due to inactivity but feel free to reopen or continue discussion. I will get notification and reply straight away!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1287
https://github.com/scverse/scanpy/issues/1287:176,usability,support,support,176,"Hi @AdemS80 ,. I would be really curious to hear more about this but would need some examples. Also, if you are interested in contributing and need help with PR can definitely support you with that. . I'll close this due to inactivity but feel free to reopen or continue discussion. I will get notification and reply straight away!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1287
https://github.com/scverse/scanpy/issues/1287:206,usability,close,close,206,"Hi @AdemS80 ,. I would be really curious to hear more about this but would need some examples. Also, if you are interested in contributing and need help with PR can definitely support you with that. . I'll close this due to inactivity but feel free to reopen or continue discussion. I will get notification and reply straight away!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1287
https://github.com/scverse/scanpy/issues/1287:346,testability,simpl,simply,346,"Sounds like a good idea. Since we have a hexagonal grid, we can just connect the centers of the hexagons in a regular fashion instead of running delauney triangulation. But its fast enough to do that too if we want to have it easy and theres a delauney implementation in something we already import (e.g. scipy maybe?). @giovp the result would simply be a smoothly changing shading. Like this, but with a hex grid instead of a square grid:. ![](https://upload.wikimedia.org/wikipedia/commons/f/f5/Interpolation-bicubic.svg)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1287
https://github.com/scverse/scanpy/issues/1287:346,usability,simpl,simply,346,"Sounds like a good idea. Since we have a hexagonal grid, we can just connect the centers of the hexagons in a regular fashion instead of running delauney triangulation. But its fast enough to do that too if we want to have it easy and theres a delauney implementation in something we already import (e.g. scipy maybe?). @giovp the result would simply be a smoothly changing shading. Like this, but with a hex grid instead of a square grid:. ![](https://upload.wikimedia.org/wikipedia/commons/f/f5/Interpolation-bicubic.svg)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1287
https://github.com/scverse/scanpy/issues/1287:224,availability,avail,available,224,"Hello,. Yes that is exactly what @flying-sheep mentioned. Instead of having a dot plot of gene expression, we would have the option of a surface plot with smoothed gene expression values. I will try to run this on a pubicly available Visium dataset (mentioned in one of the scanpy tutorials) to show the outcome. On the other hand, it is not necessary to limit this option to regular grids (although in Visium datasets, it is regular). In this way, the function can be used in a more general case.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1287
https://github.com/scverse/scanpy/issues/1287:216,integrability,pub,pubicly,216,"Hello,. Yes that is exactly what @flying-sheep mentioned. Instead of having a dot plot of gene expression, we would have the option of a surface plot with smoothed gene expression values. I will try to run this on a pubicly available Visium dataset (mentioned in one of the scanpy tutorials) to show the outcome. On the other hand, it is not necessary to limit this option to regular grids (although in Visium datasets, it is regular). In this way, the function can be used in a more general case.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1287
https://github.com/scverse/scanpy/issues/1287:224,reliability,availab,available,224,"Hello,. Yes that is exactly what @flying-sheep mentioned. Instead of having a dot plot of gene expression, we would have the option of a surface plot with smoothed gene expression values. I will try to run this on a pubicly available Visium dataset (mentioned in one of the scanpy tutorials) to show the outcome. On the other hand, it is not necessary to limit this option to regular grids (although in Visium datasets, it is regular). In this way, the function can be used in a more general case.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1287
https://github.com/scverse/scanpy/issues/1287:224,safety,avail,available,224,"Hello,. Yes that is exactly what @flying-sheep mentioned. Instead of having a dot plot of gene expression, we would have the option of a surface plot with smoothed gene expression values. I will try to run this on a pubicly available Visium dataset (mentioned in one of the scanpy tutorials) to show the outcome. On the other hand, it is not necessary to limit this option to regular grids (although in Visium datasets, it is regular). In this way, the function can be used in a more general case.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1287
https://github.com/scverse/scanpy/issues/1287:224,security,availab,available,224,"Hello,. Yes that is exactly what @flying-sheep mentioned. Instead of having a dot plot of gene expression, we would have the option of a surface plot with smoothed gene expression values. I will try to run this on a pubicly available Visium dataset (mentioned in one of the scanpy tutorials) to show the outcome. On the other hand, it is not necessary to limit this option to regular grids (although in Visium datasets, it is regular). In this way, the function can be used in a more general case.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1287
https://github.com/scverse/scanpy/issues/1288:53,availability,ping,ping,53,mmh true that should probably be 1-corr_matrix. I'll ping @flying-sheep he might have a better answer,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1288
https://github.com/scverse/scanpy/issues/1289:183,availability,ping,pinging,183,"Hi, thanks for the suggestion! Are you referring to [this function](https://rdrr.io/bioc/batchelor/man/multiBatchPCA.html) ? It sounds a bit like `ingest` but with multiple datasets, pinging @Koncopd to see what's his take on this",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:89,integrability,batch,batchelor,89,"Hi, thanks for the suggestion! Are you referring to [this function](https://rdrr.io/bioc/batchelor/man/multiBatchPCA.html) ? It sounds a bit like `ingest` but with multiple datasets, pinging @Koncopd to see what's his take on this",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:89,performance,batch,batchelor,89,"Hi, thanks for the suggestion! Are you referring to [this function](https://rdrr.io/bioc/batchelor/man/multiBatchPCA.html) ? It sounds a bit like `ingest` but with multiple datasets, pinging @Koncopd to see what's his take on this",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:187,availability,ping,pinging,187,"> Hi, thanks for the suggestion! Are you referring to [this function](https://rdrr.io/bioc/batchelor/man/multiBatchPCA.html) ? > It sounds a bit like `ingest` but with multiple datasets, pinging @Koncopd to see what's his take on this. Yes that's the function. I think it is doing something similar to `ingest`. I think this sort of batch-balanced PCA could be a useful addition addition where batches are very uneven in terms of number of cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:91,integrability,batch,batchelor,91,"> Hi, thanks for the suggestion! Are you referring to [this function](https://rdrr.io/bioc/batchelor/man/multiBatchPCA.html) ? > It sounds a bit like `ingest` but with multiple datasets, pinging @Koncopd to see what's his take on this. Yes that's the function. I think it is doing something similar to `ingest`. I think this sort of batch-balanced PCA could be a useful addition addition where batches are very uneven in terms of number of cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:333,integrability,batch,batch-balanced,333,"> Hi, thanks for the suggestion! Are you referring to [this function](https://rdrr.io/bioc/batchelor/man/multiBatchPCA.html) ? > It sounds a bit like `ingest` but with multiple datasets, pinging @Koncopd to see what's his take on this. Yes that's the function. I think it is doing something similar to `ingest`. I think this sort of batch-balanced PCA could be a useful addition addition where batches are very uneven in terms of number of cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:394,integrability,batch,batches,394,"> Hi, thanks for the suggestion! Are you referring to [this function](https://rdrr.io/bioc/batchelor/man/multiBatchPCA.html) ? > It sounds a bit like `ingest` but with multiple datasets, pinging @Koncopd to see what's his take on this. Yes that's the function. I think it is doing something similar to `ingest`. I think this sort of batch-balanced PCA could be a useful addition addition where batches are very uneven in terms of number of cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:91,performance,batch,batchelor,91,"> Hi, thanks for the suggestion! Are you referring to [this function](https://rdrr.io/bioc/batchelor/man/multiBatchPCA.html) ? > It sounds a bit like `ingest` but with multiple datasets, pinging @Koncopd to see what's his take on this. Yes that's the function. I think it is doing something similar to `ingest`. I think this sort of batch-balanced PCA could be a useful addition addition where batches are very uneven in terms of number of cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:333,performance,batch,batch-balanced,333,"> Hi, thanks for the suggestion! Are you referring to [this function](https://rdrr.io/bioc/batchelor/man/multiBatchPCA.html) ? > It sounds a bit like `ingest` but with multiple datasets, pinging @Koncopd to see what's his take on this. Yes that's the function. I think it is doing something similar to `ingest`. I think this sort of batch-balanced PCA could be a useful addition addition where batches are very uneven in terms of number of cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:394,performance,batch,batches,394,"> Hi, thanks for the suggestion! Are you referring to [this function](https://rdrr.io/bioc/batchelor/man/multiBatchPCA.html) ? > It sounds a bit like `ingest` but with multiple datasets, pinging @Koncopd to see what's his take on this. Yes that's the function. I think it is doing something similar to `ingest`. I think this sort of batch-balanced PCA could be a useful addition addition where batches are very uneven in terms of number of cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:40,integrability,batch,batch,40,"`ingest` uses pca only from a reference batch, so it is a bit different. Does this `multiBatchPCA` work well?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:40,performance,batch,batch,40,"`ingest` uses pca only from a reference batch, so it is a bit different. Does this `multiBatchPCA` work well?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:73,reliability,Doe,Does,73,"`ingest` uses pca only from a reference batch, so it is a bit different. Does this `multiBatchPCA` work well?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:309,availability,avail,available,309,"Like you say, the difference between this and `ingest` is joint PCA calculation vs asymmetric batch integration. This function is the first step in the `fastMNN` function, which I have found in some cases yields very sensible batch correction results. It would be awesome to see `multiBatchPCA` +/- `fastMNN` available in scanpy. I am aware of the python implementation of `mnncorrect`, but I think this still operates on expression values rather than a PCA representation (correct me if I am wrong..). Without going all the way the batch correction, `multiBatchPCA` is useful where different experiments have very different numbers of cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:410,availability,operat,operates,410,"Like you say, the difference between this and `ingest` is joint PCA calculation vs asymmetric batch integration. This function is the first step in the `fastMNN` function, which I have found in some cases yields very sensible batch correction results. It would be awesome to see `multiBatchPCA` +/- `fastMNN` available in scanpy. I am aware of the python implementation of `mnncorrect`, but I think this still operates on expression values rather than a PCA representation (correct me if I am wrong..). Without going all the way the batch correction, `multiBatchPCA` is useful where different experiments have very different numbers of cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:100,deployability,integr,integration,100,"Like you say, the difference between this and `ingest` is joint PCA calculation vs asymmetric batch integration. This function is the first step in the `fastMNN` function, which I have found in some cases yields very sensible batch correction results. It would be awesome to see `multiBatchPCA` +/- `fastMNN` available in scanpy. I am aware of the python implementation of `mnncorrect`, but I think this still operates on expression values rather than a PCA representation (correct me if I am wrong..). Without going all the way the batch correction, `multiBatchPCA` is useful where different experiments have very different numbers of cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:94,integrability,batch,batch,94,"Like you say, the difference between this and `ingest` is joint PCA calculation vs asymmetric batch integration. This function is the first step in the `fastMNN` function, which I have found in some cases yields very sensible batch correction results. It would be awesome to see `multiBatchPCA` +/- `fastMNN` available in scanpy. I am aware of the python implementation of `mnncorrect`, but I think this still operates on expression values rather than a PCA representation (correct me if I am wrong..). Without going all the way the batch correction, `multiBatchPCA` is useful where different experiments have very different numbers of cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:100,integrability,integr,integration,100,"Like you say, the difference between this and `ingest` is joint PCA calculation vs asymmetric batch integration. This function is the first step in the `fastMNN` function, which I have found in some cases yields very sensible batch correction results. It would be awesome to see `multiBatchPCA` +/- `fastMNN` available in scanpy. I am aware of the python implementation of `mnncorrect`, but I think this still operates on expression values rather than a PCA representation (correct me if I am wrong..). Without going all the way the batch correction, `multiBatchPCA` is useful where different experiments have very different numbers of cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:226,integrability,batch,batch,226,"Like you say, the difference between this and `ingest` is joint PCA calculation vs asymmetric batch integration. This function is the first step in the `fastMNN` function, which I have found in some cases yields very sensible batch correction results. It would be awesome to see `multiBatchPCA` +/- `fastMNN` available in scanpy. I am aware of the python implementation of `mnncorrect`, but I think this still operates on expression values rather than a PCA representation (correct me if I am wrong..). Without going all the way the batch correction, `multiBatchPCA` is useful where different experiments have very different numbers of cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:533,integrability,batch,batch,533,"Like you say, the difference between this and `ingest` is joint PCA calculation vs asymmetric batch integration. This function is the first step in the `fastMNN` function, which I have found in some cases yields very sensible batch correction results. It would be awesome to see `multiBatchPCA` +/- `fastMNN` available in scanpy. I am aware of the python implementation of `mnncorrect`, but I think this still operates on expression values rather than a PCA representation (correct me if I am wrong..). Without going all the way the batch correction, `multiBatchPCA` is useful where different experiments have very different numbers of cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:100,interoperability,integr,integration,100,"Like you say, the difference between this and `ingest` is joint PCA calculation vs asymmetric batch integration. This function is the first step in the `fastMNN` function, which I have found in some cases yields very sensible batch correction results. It would be awesome to see `multiBatchPCA` +/- `fastMNN` available in scanpy. I am aware of the python implementation of `mnncorrect`, but I think this still operates on expression values rather than a PCA representation (correct me if I am wrong..). Without going all the way the batch correction, `multiBatchPCA` is useful where different experiments have very different numbers of cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:100,modifiability,integr,integration,100,"Like you say, the difference between this and `ingest` is joint PCA calculation vs asymmetric batch integration. This function is the first step in the `fastMNN` function, which I have found in some cases yields very sensible batch correction results. It would be awesome to see `multiBatchPCA` +/- `fastMNN` available in scanpy. I am aware of the python implementation of `mnncorrect`, but I think this still operates on expression values rather than a PCA representation (correct me if I am wrong..). Without going all the way the batch correction, `multiBatchPCA` is useful where different experiments have very different numbers of cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:94,performance,batch,batch,94,"Like you say, the difference between this and `ingest` is joint PCA calculation vs asymmetric batch integration. This function is the first step in the `fastMNN` function, which I have found in some cases yields very sensible batch correction results. It would be awesome to see `multiBatchPCA` +/- `fastMNN` available in scanpy. I am aware of the python implementation of `mnncorrect`, but I think this still operates on expression values rather than a PCA representation (correct me if I am wrong..). Without going all the way the batch correction, `multiBatchPCA` is useful where different experiments have very different numbers of cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:226,performance,batch,batch,226,"Like you say, the difference between this and `ingest` is joint PCA calculation vs asymmetric batch integration. This function is the first step in the `fastMNN` function, which I have found in some cases yields very sensible batch correction results. It would be awesome to see `multiBatchPCA` +/- `fastMNN` available in scanpy. I am aware of the python implementation of `mnncorrect`, but I think this still operates on expression values rather than a PCA representation (correct me if I am wrong..). Without going all the way the batch correction, `multiBatchPCA` is useful where different experiments have very different numbers of cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:533,performance,batch,batch,533,"Like you say, the difference between this and `ingest` is joint PCA calculation vs asymmetric batch integration. This function is the first step in the `fastMNN` function, which I have found in some cases yields very sensible batch correction results. It would be awesome to see `multiBatchPCA` +/- `fastMNN` available in scanpy. I am aware of the python implementation of `mnncorrect`, but I think this still operates on expression values rather than a PCA representation (correct me if I am wrong..). Without going all the way the batch correction, `multiBatchPCA` is useful where different experiments have very different numbers of cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:100,reliability,integr,integration,100,"Like you say, the difference between this and `ingest` is joint PCA calculation vs asymmetric batch integration. This function is the first step in the `fastMNN` function, which I have found in some cases yields very sensible batch correction results. It would be awesome to see `multiBatchPCA` +/- `fastMNN` available in scanpy. I am aware of the python implementation of `mnncorrect`, but I think this still operates on expression values rather than a PCA representation (correct me if I am wrong..). Without going all the way the batch correction, `multiBatchPCA` is useful where different experiments have very different numbers of cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:309,reliability,availab,available,309,"Like you say, the difference between this and `ingest` is joint PCA calculation vs asymmetric batch integration. This function is the first step in the `fastMNN` function, which I have found in some cases yields very sensible batch correction results. It would be awesome to see `multiBatchPCA` +/- `fastMNN` available in scanpy. I am aware of the python implementation of `mnncorrect`, but I think this still operates on expression values rather than a PCA representation (correct me if I am wrong..). Without going all the way the batch correction, `multiBatchPCA` is useful where different experiments have very different numbers of cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:309,safety,avail,available,309,"Like you say, the difference between this and `ingest` is joint PCA calculation vs asymmetric batch integration. This function is the first step in the `fastMNN` function, which I have found in some cases yields very sensible batch correction results. It would be awesome to see `multiBatchPCA` +/- `fastMNN` available in scanpy. I am aware of the python implementation of `mnncorrect`, but I think this still operates on expression values rather than a PCA representation (correct me if I am wrong..). Without going all the way the batch correction, `multiBatchPCA` is useful where different experiments have very different numbers of cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:100,security,integr,integration,100,"Like you say, the difference between this and `ingest` is joint PCA calculation vs asymmetric batch integration. This function is the first step in the `fastMNN` function, which I have found in some cases yields very sensible batch correction results. It would be awesome to see `multiBatchPCA` +/- `fastMNN` available in scanpy. I am aware of the python implementation of `mnncorrect`, but I think this still operates on expression values rather than a PCA representation (correct me if I am wrong..). Without going all the way the batch correction, `multiBatchPCA` is useful where different experiments have very different numbers of cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:309,security,availab,available,309,"Like you say, the difference between this and `ingest` is joint PCA calculation vs asymmetric batch integration. This function is the first step in the `fastMNN` function, which I have found in some cases yields very sensible batch correction results. It would be awesome to see `multiBatchPCA` +/- `fastMNN` available in scanpy. I am aware of the python implementation of `mnncorrect`, but I think this still operates on expression values rather than a PCA representation (correct me if I am wrong..). Without going all the way the batch correction, `multiBatchPCA` is useful where different experiments have very different numbers of cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:100,testability,integr,integration,100,"Like you say, the difference between this and `ingest` is joint PCA calculation vs asymmetric batch integration. This function is the first step in the `fastMNN` function, which I have found in some cases yields very sensible batch correction results. It would be awesome to see `multiBatchPCA` +/- `fastMNN` available in scanpy. I am aware of the python implementation of `mnncorrect`, but I think this still operates on expression values rather than a PCA representation (correct me if I am wrong..). Without going all the way the batch correction, `multiBatchPCA` is useful where different experiments have very different numbers of cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:243,availability,state,stated,243,"Hi all,. I am trying to use ScanPy for integrating multiple scRNA-Seq samples (~20). Doing so that I can look at RNA Velocity with SCVelo, and want to use MNN as I got good batch effect removal previously in monocle using MNN. Is it true - as stated above, that the current implementation of mnncorrect with ScanPy is only operating on expression values? I have run through a ScanPy MNN [tutorial ](https://nbisweden.github.io/workshop-scRNAseq/labs/compiled/scanpy/scanpy_03_integration.html) provided by NBI Sweden. The results are improved, but it doesn't appear to work as well as in monocle - some separation by batch is still going on. . I'm wondering what the difference might be? Whether it could be due to the difference in PCA (multi-batch), or the actual MNN / batch effect removal step. Alternatively, I could use the corrected expression matrix, and add the UMAP coordinates/clusters from monocle, although I wonder if this is advisable. . If you have any info please let me know, or if I should raise a separate issue etc.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:323,availability,operat,operating,323,"Hi all,. I am trying to use ScanPy for integrating multiple scRNA-Seq samples (~20). Doing so that I can look at RNA Velocity with SCVelo, and want to use MNN as I got good batch effect removal previously in monocle using MNN. Is it true - as stated above, that the current implementation of mnncorrect with ScanPy is only operating on expression values? I have run through a ScanPy MNN [tutorial ](https://nbisweden.github.io/workshop-scRNAseq/labs/compiled/scanpy/scanpy_03_integration.html) provided by NBI Sweden. The results are improved, but it doesn't appear to work as well as in monocle - some separation by batch is still going on. . I'm wondering what the difference might be? Whether it could be due to the difference in PCA (multi-batch), or the actual MNN / batch effect removal step. Alternatively, I could use the corrected expression matrix, and add the UMAP coordinates/clusters from monocle, although I wonder if this is advisable. . If you have any info please let me know, or if I should raise a separate issue etc.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:888,availability,cluster,clusters,888,"Hi all,. I am trying to use ScanPy for integrating multiple scRNA-Seq samples (~20). Doing so that I can look at RNA Velocity with SCVelo, and want to use MNN as I got good batch effect removal previously in monocle using MNN. Is it true - as stated above, that the current implementation of mnncorrect with ScanPy is only operating on expression values? I have run through a ScanPy MNN [tutorial ](https://nbisweden.github.io/workshop-scRNAseq/labs/compiled/scanpy/scanpy_03_integration.html) provided by NBI Sweden. The results are improved, but it doesn't appear to work as well as in monocle - some separation by batch is still going on. . I'm wondering what the difference might be? Whether it could be due to the difference in PCA (multi-batch), or the actual MNN / batch effect removal step. Alternatively, I could use the corrected expression matrix, and add the UMAP coordinates/clusters from monocle, although I wonder if this is advisable. . If you have any info please let me know, or if I should raise a separate issue etc.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:39,deployability,integr,integrating,39,"Hi all,. I am trying to use ScanPy for integrating multiple scRNA-Seq samples (~20). Doing so that I can look at RNA Velocity with SCVelo, and want to use MNN as I got good batch effect removal previously in monocle using MNN. Is it true - as stated above, that the current implementation of mnncorrect with ScanPy is only operating on expression values? I have run through a ScanPy MNN [tutorial ](https://nbisweden.github.io/workshop-scRNAseq/labs/compiled/scanpy/scanpy_03_integration.html) provided by NBI Sweden. The results are improved, but it doesn't appear to work as well as in monocle - some separation by batch is still going on. . I'm wondering what the difference might be? Whether it could be due to the difference in PCA (multi-batch), or the actual MNN / batch effect removal step. Alternatively, I could use the corrected expression matrix, and add the UMAP coordinates/clusters from monocle, although I wonder if this is advisable. . If you have any info please let me know, or if I should raise a separate issue etc.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:888,deployability,cluster,clusters,888,"Hi all,. I am trying to use ScanPy for integrating multiple scRNA-Seq samples (~20). Doing so that I can look at RNA Velocity with SCVelo, and want to use MNN as I got good batch effect removal previously in monocle using MNN. Is it true - as stated above, that the current implementation of mnncorrect with ScanPy is only operating on expression values? I have run through a ScanPy MNN [tutorial ](https://nbisweden.github.io/workshop-scRNAseq/labs/compiled/scanpy/scanpy_03_integration.html) provided by NBI Sweden. The results are improved, but it doesn't appear to work as well as in monocle - some separation by batch is still going on. . I'm wondering what the difference might be? Whether it could be due to the difference in PCA (multi-batch), or the actual MNN / batch effect removal step. Alternatively, I could use the corrected expression matrix, and add the UMAP coordinates/clusters from monocle, although I wonder if this is advisable. . If you have any info please let me know, or if I should raise a separate issue etc.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:266,energy efficiency,current,current,266,"Hi all,. I am trying to use ScanPy for integrating multiple scRNA-Seq samples (~20). Doing so that I can look at RNA Velocity with SCVelo, and want to use MNN as I got good batch effect removal previously in monocle using MNN. Is it true - as stated above, that the current implementation of mnncorrect with ScanPy is only operating on expression values? I have run through a ScanPy MNN [tutorial ](https://nbisweden.github.io/workshop-scRNAseq/labs/compiled/scanpy/scanpy_03_integration.html) provided by NBI Sweden. The results are improved, but it doesn't appear to work as well as in monocle - some separation by batch is still going on. . I'm wondering what the difference might be? Whether it could be due to the difference in PCA (multi-batch), or the actual MNN / batch effect removal step. Alternatively, I could use the corrected expression matrix, and add the UMAP coordinates/clusters from monocle, although I wonder if this is advisable. . If you have any info please let me know, or if I should raise a separate issue etc.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:39,integrability,integr,integrating,39,"Hi all,. I am trying to use ScanPy for integrating multiple scRNA-Seq samples (~20). Doing so that I can look at RNA Velocity with SCVelo, and want to use MNN as I got good batch effect removal previously in monocle using MNN. Is it true - as stated above, that the current implementation of mnncorrect with ScanPy is only operating on expression values? I have run through a ScanPy MNN [tutorial ](https://nbisweden.github.io/workshop-scRNAseq/labs/compiled/scanpy/scanpy_03_integration.html) provided by NBI Sweden. The results are improved, but it doesn't appear to work as well as in monocle - some separation by batch is still going on. . I'm wondering what the difference might be? Whether it could be due to the difference in PCA (multi-batch), or the actual MNN / batch effect removal step. Alternatively, I could use the corrected expression matrix, and add the UMAP coordinates/clusters from monocle, although I wonder if this is advisable. . If you have any info please let me know, or if I should raise a separate issue etc.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:173,integrability,batch,batch,173,"Hi all,. I am trying to use ScanPy for integrating multiple scRNA-Seq samples (~20). Doing so that I can look at RNA Velocity with SCVelo, and want to use MNN as I got good batch effect removal previously in monocle using MNN. Is it true - as stated above, that the current implementation of mnncorrect with ScanPy is only operating on expression values? I have run through a ScanPy MNN [tutorial ](https://nbisweden.github.io/workshop-scRNAseq/labs/compiled/scanpy/scanpy_03_integration.html) provided by NBI Sweden. The results are improved, but it doesn't appear to work as well as in monocle - some separation by batch is still going on. . I'm wondering what the difference might be? Whether it could be due to the difference in PCA (multi-batch), or the actual MNN / batch effect removal step. Alternatively, I could use the corrected expression matrix, and add the UMAP coordinates/clusters from monocle, although I wonder if this is advisable. . If you have any info please let me know, or if I should raise a separate issue etc.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:243,integrability,state,stated,243,"Hi all,. I am trying to use ScanPy for integrating multiple scRNA-Seq samples (~20). Doing so that I can look at RNA Velocity with SCVelo, and want to use MNN as I got good batch effect removal previously in monocle using MNN. Is it true - as stated above, that the current implementation of mnncorrect with ScanPy is only operating on expression values? I have run through a ScanPy MNN [tutorial ](https://nbisweden.github.io/workshop-scRNAseq/labs/compiled/scanpy/scanpy_03_integration.html) provided by NBI Sweden. The results are improved, but it doesn't appear to work as well as in monocle - some separation by batch is still going on. . I'm wondering what the difference might be? Whether it could be due to the difference in PCA (multi-batch), or the actual MNN / batch effect removal step. Alternatively, I could use the corrected expression matrix, and add the UMAP coordinates/clusters from monocle, although I wonder if this is advisable. . If you have any info please let me know, or if I should raise a separate issue etc.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:617,integrability,batch,batch,617,"Hi all,. I am trying to use ScanPy for integrating multiple scRNA-Seq samples (~20). Doing so that I can look at RNA Velocity with SCVelo, and want to use MNN as I got good batch effect removal previously in monocle using MNN. Is it true - as stated above, that the current implementation of mnncorrect with ScanPy is only operating on expression values? I have run through a ScanPy MNN [tutorial ](https://nbisweden.github.io/workshop-scRNAseq/labs/compiled/scanpy/scanpy_03_integration.html) provided by NBI Sweden. The results are improved, but it doesn't appear to work as well as in monocle - some separation by batch is still going on. . I'm wondering what the difference might be? Whether it could be due to the difference in PCA (multi-batch), or the actual MNN / batch effect removal step. Alternatively, I could use the corrected expression matrix, and add the UMAP coordinates/clusters from monocle, although I wonder if this is advisable. . If you have any info please let me know, or if I should raise a separate issue etc.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:744,integrability,batch,batch,744,"Hi all,. I am trying to use ScanPy for integrating multiple scRNA-Seq samples (~20). Doing so that I can look at RNA Velocity with SCVelo, and want to use MNN as I got good batch effect removal previously in monocle using MNN. Is it true - as stated above, that the current implementation of mnncorrect with ScanPy is only operating on expression values? I have run through a ScanPy MNN [tutorial ](https://nbisweden.github.io/workshop-scRNAseq/labs/compiled/scanpy/scanpy_03_integration.html) provided by NBI Sweden. The results are improved, but it doesn't appear to work as well as in monocle - some separation by batch is still going on. . I'm wondering what the difference might be? Whether it could be due to the difference in PCA (multi-batch), or the actual MNN / batch effect removal step. Alternatively, I could use the corrected expression matrix, and add the UMAP coordinates/clusters from monocle, although I wonder if this is advisable. . If you have any info please let me know, or if I should raise a separate issue etc.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:772,integrability,batch,batch,772,"Hi all,. I am trying to use ScanPy for integrating multiple scRNA-Seq samples (~20). Doing so that I can look at RNA Velocity with SCVelo, and want to use MNN as I got good batch effect removal previously in monocle using MNN. Is it true - as stated above, that the current implementation of mnncorrect with ScanPy is only operating on expression values? I have run through a ScanPy MNN [tutorial ](https://nbisweden.github.io/workshop-scRNAseq/labs/compiled/scanpy/scanpy_03_integration.html) provided by NBI Sweden. The results are improved, but it doesn't appear to work as well as in monocle - some separation by batch is still going on. . I'm wondering what the difference might be? Whether it could be due to the difference in PCA (multi-batch), or the actual MNN / batch effect removal step. Alternatively, I could use the corrected expression matrix, and add the UMAP coordinates/clusters from monocle, although I wonder if this is advisable. . If you have any info please let me know, or if I should raise a separate issue etc.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:39,interoperability,integr,integrating,39,"Hi all,. I am trying to use ScanPy for integrating multiple scRNA-Seq samples (~20). Doing so that I can look at RNA Velocity with SCVelo, and want to use MNN as I got good batch effect removal previously in monocle using MNN. Is it true - as stated above, that the current implementation of mnncorrect with ScanPy is only operating on expression values? I have run through a ScanPy MNN [tutorial ](https://nbisweden.github.io/workshop-scRNAseq/labs/compiled/scanpy/scanpy_03_integration.html) provided by NBI Sweden. The results are improved, but it doesn't appear to work as well as in monocle - some separation by batch is still going on. . I'm wondering what the difference might be? Whether it could be due to the difference in PCA (multi-batch), or the actual MNN / batch effect removal step. Alternatively, I could use the corrected expression matrix, and add the UMAP coordinates/clusters from monocle, although I wonder if this is advisable. . If you have any info please let me know, or if I should raise a separate issue etc.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:876,interoperability,coordinat,coordinates,876,"Hi all,. I am trying to use ScanPy for integrating multiple scRNA-Seq samples (~20). Doing so that I can look at RNA Velocity with SCVelo, and want to use MNN as I got good batch effect removal previously in monocle using MNN. Is it true - as stated above, that the current implementation of mnncorrect with ScanPy is only operating on expression values? I have run through a ScanPy MNN [tutorial ](https://nbisweden.github.io/workshop-scRNAseq/labs/compiled/scanpy/scanpy_03_integration.html) provided by NBI Sweden. The results are improved, but it doesn't appear to work as well as in monocle - some separation by batch is still going on. . I'm wondering what the difference might be? Whether it could be due to the difference in PCA (multi-batch), or the actual MNN / batch effect removal step. Alternatively, I could use the corrected expression matrix, and add the UMAP coordinates/clusters from monocle, although I wonder if this is advisable. . If you have any info please let me know, or if I should raise a separate issue etc.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:39,modifiability,integr,integrating,39,"Hi all,. I am trying to use ScanPy for integrating multiple scRNA-Seq samples (~20). Doing so that I can look at RNA Velocity with SCVelo, and want to use MNN as I got good batch effect removal previously in monocle using MNN. Is it true - as stated above, that the current implementation of mnncorrect with ScanPy is only operating on expression values? I have run through a ScanPy MNN [tutorial ](https://nbisweden.github.io/workshop-scRNAseq/labs/compiled/scanpy/scanpy_03_integration.html) provided by NBI Sweden. The results are improved, but it doesn't appear to work as well as in monocle - some separation by batch is still going on. . I'm wondering what the difference might be? Whether it could be due to the difference in PCA (multi-batch), or the actual MNN / batch effect removal step. Alternatively, I could use the corrected expression matrix, and add the UMAP coordinates/clusters from monocle, although I wonder if this is advisable. . If you have any info please let me know, or if I should raise a separate issue etc.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:173,performance,batch,batch,173,"Hi all,. I am trying to use ScanPy for integrating multiple scRNA-Seq samples (~20). Doing so that I can look at RNA Velocity with SCVelo, and want to use MNN as I got good batch effect removal previously in monocle using MNN. Is it true - as stated above, that the current implementation of mnncorrect with ScanPy is only operating on expression values? I have run through a ScanPy MNN [tutorial ](https://nbisweden.github.io/workshop-scRNAseq/labs/compiled/scanpy/scanpy_03_integration.html) provided by NBI Sweden. The results are improved, but it doesn't appear to work as well as in monocle - some separation by batch is still going on. . I'm wondering what the difference might be? Whether it could be due to the difference in PCA (multi-batch), or the actual MNN / batch effect removal step. Alternatively, I could use the corrected expression matrix, and add the UMAP coordinates/clusters from monocle, although I wonder if this is advisable. . If you have any info please let me know, or if I should raise a separate issue etc.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:617,performance,batch,batch,617,"Hi all,. I am trying to use ScanPy for integrating multiple scRNA-Seq samples (~20). Doing so that I can look at RNA Velocity with SCVelo, and want to use MNN as I got good batch effect removal previously in monocle using MNN. Is it true - as stated above, that the current implementation of mnncorrect with ScanPy is only operating on expression values? I have run through a ScanPy MNN [tutorial ](https://nbisweden.github.io/workshop-scRNAseq/labs/compiled/scanpy/scanpy_03_integration.html) provided by NBI Sweden. The results are improved, but it doesn't appear to work as well as in monocle - some separation by batch is still going on. . I'm wondering what the difference might be? Whether it could be due to the difference in PCA (multi-batch), or the actual MNN / batch effect removal step. Alternatively, I could use the corrected expression matrix, and add the UMAP coordinates/clusters from monocle, although I wonder if this is advisable. . If you have any info please let me know, or if I should raise a separate issue etc.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:744,performance,batch,batch,744,"Hi all,. I am trying to use ScanPy for integrating multiple scRNA-Seq samples (~20). Doing so that I can look at RNA Velocity with SCVelo, and want to use MNN as I got good batch effect removal previously in monocle using MNN. Is it true - as stated above, that the current implementation of mnncorrect with ScanPy is only operating on expression values? I have run through a ScanPy MNN [tutorial ](https://nbisweden.github.io/workshop-scRNAseq/labs/compiled/scanpy/scanpy_03_integration.html) provided by NBI Sweden. The results are improved, but it doesn't appear to work as well as in monocle - some separation by batch is still going on. . I'm wondering what the difference might be? Whether it could be due to the difference in PCA (multi-batch), or the actual MNN / batch effect removal step. Alternatively, I could use the corrected expression matrix, and add the UMAP coordinates/clusters from monocle, although I wonder if this is advisable. . If you have any info please let me know, or if I should raise a separate issue etc.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:772,performance,batch,batch,772,"Hi all,. I am trying to use ScanPy for integrating multiple scRNA-Seq samples (~20). Doing so that I can look at RNA Velocity with SCVelo, and want to use MNN as I got good batch effect removal previously in monocle using MNN. Is it true - as stated above, that the current implementation of mnncorrect with ScanPy is only operating on expression values? I have run through a ScanPy MNN [tutorial ](https://nbisweden.github.io/workshop-scRNAseq/labs/compiled/scanpy/scanpy_03_integration.html) provided by NBI Sweden. The results are improved, but it doesn't appear to work as well as in monocle - some separation by batch is still going on. . I'm wondering what the difference might be? Whether it could be due to the difference in PCA (multi-batch), or the actual MNN / batch effect removal step. Alternatively, I could use the corrected expression matrix, and add the UMAP coordinates/clusters from monocle, although I wonder if this is advisable. . If you have any info please let me know, or if I should raise a separate issue etc.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:39,reliability,integr,integrating,39,"Hi all,. I am trying to use ScanPy for integrating multiple scRNA-Seq samples (~20). Doing so that I can look at RNA Velocity with SCVelo, and want to use MNN as I got good batch effect removal previously in monocle using MNN. Is it true - as stated above, that the current implementation of mnncorrect with ScanPy is only operating on expression values? I have run through a ScanPy MNN [tutorial ](https://nbisweden.github.io/workshop-scRNAseq/labs/compiled/scanpy/scanpy_03_integration.html) provided by NBI Sweden. The results are improved, but it doesn't appear to work as well as in monocle - some separation by batch is still going on. . I'm wondering what the difference might be? Whether it could be due to the difference in PCA (multi-batch), or the actual MNN / batch effect removal step. Alternatively, I could use the corrected expression matrix, and add the UMAP coordinates/clusters from monocle, although I wonder if this is advisable. . If you have any info please let me know, or if I should raise a separate issue etc.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:551,reliability,doe,doesn,551,"Hi all,. I am trying to use ScanPy for integrating multiple scRNA-Seq samples (~20). Doing so that I can look at RNA Velocity with SCVelo, and want to use MNN as I got good batch effect removal previously in monocle using MNN. Is it true - as stated above, that the current implementation of mnncorrect with ScanPy is only operating on expression values? I have run through a ScanPy MNN [tutorial ](https://nbisweden.github.io/workshop-scRNAseq/labs/compiled/scanpy/scanpy_03_integration.html) provided by NBI Sweden. The results are improved, but it doesn't appear to work as well as in monocle - some separation by batch is still going on. . I'm wondering what the difference might be? Whether it could be due to the difference in PCA (multi-batch), or the actual MNN / batch effect removal step. Alternatively, I could use the corrected expression matrix, and add the UMAP coordinates/clusters from monocle, although I wonder if this is advisable. . If you have any info please let me know, or if I should raise a separate issue etc.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:39,security,integr,integrating,39,"Hi all,. I am trying to use ScanPy for integrating multiple scRNA-Seq samples (~20). Doing so that I can look at RNA Velocity with SCVelo, and want to use MNN as I got good batch effect removal previously in monocle using MNN. Is it true - as stated above, that the current implementation of mnncorrect with ScanPy is only operating on expression values? I have run through a ScanPy MNN [tutorial ](https://nbisweden.github.io/workshop-scRNAseq/labs/compiled/scanpy/scanpy_03_integration.html) provided by NBI Sweden. The results are improved, but it doesn't appear to work as well as in monocle - some separation by batch is still going on. . I'm wondering what the difference might be? Whether it could be due to the difference in PCA (multi-batch), or the actual MNN / batch effect removal step. Alternatively, I could use the corrected expression matrix, and add the UMAP coordinates/clusters from monocle, although I wonder if this is advisable. . If you have any info please let me know, or if I should raise a separate issue etc.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:39,testability,integr,integrating,39,"Hi all,. I am trying to use ScanPy for integrating multiple scRNA-Seq samples (~20). Doing so that I can look at RNA Velocity with SCVelo, and want to use MNN as I got good batch effect removal previously in monocle using MNN. Is it true - as stated above, that the current implementation of mnncorrect with ScanPy is only operating on expression values? I have run through a ScanPy MNN [tutorial ](https://nbisweden.github.io/workshop-scRNAseq/labs/compiled/scanpy/scanpy_03_integration.html) provided by NBI Sweden. The results are improved, but it doesn't appear to work as well as in monocle - some separation by batch is still going on. . I'm wondering what the difference might be? Whether it could be due to the difference in PCA (multi-batch), or the actual MNN / batch effect removal step. Alternatively, I could use the corrected expression matrix, and add the UMAP coordinates/clusters from monocle, although I wonder if this is advisable. . If you have any info please let me know, or if I should raise a separate issue etc.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:11,deployability,stage,stage,11,what's the stage of this @Koncopd @Mirkazemi ?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:484,deployability,integr,integration,484,"Hi @r-reeves,. Maybe this is indeed a separate issue. `mnnpy` is indeed working on the gene expression matrix, and not on a low dimensional embedding like `FastMNN` (which is what I assume you might have been using?). You could try [Scanorama](https://github.com/brianhie/scanorama) which is a method similar to FastMNN, using a sped up algorithm and no iterative merging of batches, but a method they call ""panoramic stitching"". It has performed quite well in our [benchmark of data integration methods](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2), and is in the scanpy ecosystem and therefore should work seamlessly in a Scanpy workflow. All of this being said, you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. @VolkerBergen has been thinking a bit about how to perform batch correction in an scvelo model, maybe he could chime in, or you could post an issue in the scvelo repo.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:702,deployability,integr,integrated,702,"Hi @r-reeves,. Maybe this is indeed a separate issue. `mnnpy` is indeed working on the gene expression matrix, and not on a low dimensional embedding like `FastMNN` (which is what I assume you might have been using?). You could try [Scanorama](https://github.com/brianhie/scanorama) which is a method similar to FastMNN, using a sped up algorithm and no iterative merging of batches, but a method they call ""panoramic stitching"". It has performed quite well in our [benchmark of data integration methods](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2), and is in the scanpy ecosystem and therefore should work seamlessly in a Scanpy workflow. All of this being said, you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. @VolkerBergen has been thinking a bit about how to perform batch correction in an scvelo model, maybe he could chime in, or you could post an issue in the scvelo repo.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:895,deployability,pipelin,pipeline,895,"Hi @r-reeves,. Maybe this is indeed a separate issue. `mnnpy` is indeed working on the gene expression matrix, and not on a low dimensional embedding like `FastMNN` (which is what I assume you might have been using?). You could try [Scanorama](https://github.com/brianhie/scanorama) which is a method similar to FastMNN, using a sped up algorithm and no iterative merging of batches, but a method they call ""panoramic stitching"". It has performed quite well in our [benchmark of data integration methods](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2), and is in the scanpy ecosystem and therefore should work seamlessly in a Scanpy workflow. All of this being said, you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. @VolkerBergen has been thinking a bit about how to perform batch correction in an scvelo model, maybe he could chime in, or you could post an issue in the scvelo repo.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:855,energy efficiency,current,currently,855,"Hi @r-reeves,. Maybe this is indeed a separate issue. `mnnpy` is indeed working on the gene expression matrix, and not on a low dimensional embedding like `FastMNN` (which is what I assume you might have been using?). You could try [Scanorama](https://github.com/brianhie/scanorama) which is a method similar to FastMNN, using a sped up algorithm and no iterative merging of batches, but a method they call ""panoramic stitching"". It has performed quite well in our [benchmark of data integration methods](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2), and is in the scanpy ecosystem and therefore should work seamlessly in a Scanpy workflow. All of this being said, you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. @VolkerBergen has been thinking a bit about how to perform batch correction in an scvelo model, maybe he could chime in, or you could post an issue in the scvelo repo.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:999,energy efficiency,model,model,999,"Hi @r-reeves,. Maybe this is indeed a separate issue. `mnnpy` is indeed working on the gene expression matrix, and not on a low dimensional embedding like `FastMNN` (which is what I assume you might have been using?). You could try [Scanorama](https://github.com/brianhie/scanorama) which is a method similar to FastMNN, using a sped up algorithm and no iterative merging of batches, but a method they call ""panoramic stitching"". It has performed quite well in our [benchmark of data integration methods](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2), and is in the scanpy ecosystem and therefore should work seamlessly in a Scanpy workflow. All of this being said, you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. @VolkerBergen has been thinking a bit about how to perform batch correction in an scvelo model, maybe he could chime in, or you could post an issue in the scvelo repo.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:1104,energy efficiency,model,model,1104,"Hi @r-reeves,. Maybe this is indeed a separate issue. `mnnpy` is indeed working on the gene expression matrix, and not on a low dimensional embedding like `FastMNN` (which is what I assume you might have been using?). You could try [Scanorama](https://github.com/brianhie/scanorama) which is a method similar to FastMNN, using a sped up algorithm and no iterative merging of batches, but a method they call ""panoramic stitching"". It has performed quite well in our [benchmark of data integration methods](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2), and is in the scanpy ecosystem and therefore should work seamlessly in a Scanpy workflow. All of this being said, you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. @VolkerBergen has been thinking a bit about how to perform batch correction in an scvelo model, maybe he could chime in, or you could post an issue in the scvelo repo.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:375,integrability,batch,batches,375,"Hi @r-reeves,. Maybe this is indeed a separate issue. `mnnpy` is indeed working on the gene expression matrix, and not on a low dimensional embedding like `FastMNN` (which is what I assume you might have been using?). You could try [Scanorama](https://github.com/brianhie/scanorama) which is a method similar to FastMNN, using a sped up algorithm and no iterative merging of batches, but a method they call ""panoramic stitching"". It has performed quite well in our [benchmark of data integration methods](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2), and is in the scanpy ecosystem and therefore should work seamlessly in a Scanpy workflow. All of this being said, you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. @VolkerBergen has been thinking a bit about how to perform batch correction in an scvelo model, maybe he could chime in, or you could post an issue in the scvelo repo.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:484,integrability,integr,integration,484,"Hi @r-reeves,. Maybe this is indeed a separate issue. `mnnpy` is indeed working on the gene expression matrix, and not on a low dimensional embedding like `FastMNN` (which is what I assume you might have been using?). You could try [Scanorama](https://github.com/brianhie/scanorama) which is a method similar to FastMNN, using a sped up algorithm and no iterative merging of batches, but a method they call ""panoramic stitching"". It has performed quite well in our [benchmark of data integration methods](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2), and is in the scanpy ecosystem and therefore should work seamlessly in a Scanpy workflow. All of this being said, you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. @VolkerBergen has been thinking a bit about how to perform batch correction in an scvelo model, maybe he could chime in, or you could post an issue in the scvelo repo.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:702,integrability,integr,integrated,702,"Hi @r-reeves,. Maybe this is indeed a separate issue. `mnnpy` is indeed working on the gene expression matrix, and not on a low dimensional embedding like `FastMNN` (which is what I assume you might have been using?). You could try [Scanorama](https://github.com/brianhie/scanorama) which is a method similar to FastMNN, using a sped up algorithm and no iterative merging of batches, but a method they call ""panoramic stitching"". It has performed quite well in our [benchmark of data integration methods](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2), and is in the scanpy ecosystem and therefore should work seamlessly in a Scanpy workflow. All of this being said, you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. @VolkerBergen has been thinking a bit about how to perform batch correction in an scvelo model, maybe he could chime in, or you could post an issue in the scvelo repo.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:797,integrability,batch,batch,797,"Hi @r-reeves,. Maybe this is indeed a separate issue. `mnnpy` is indeed working on the gene expression matrix, and not on a low dimensional embedding like `FastMNN` (which is what I assume you might have been using?). You could try [Scanorama](https://github.com/brianhie/scanorama) which is a method similar to FastMNN, using a sped up algorithm and no iterative merging of batches, but a method they call ""panoramic stitching"". It has performed quite well in our [benchmark of data integration methods](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2), and is in the scanpy ecosystem and therefore should work seamlessly in a Scanpy workflow. All of this being said, you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. @VolkerBergen has been thinking a bit about how to perform batch correction in an scvelo model, maybe he could chime in, or you could post an issue in the scvelo repo.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:874,integrability,batch,batch,874,"Hi @r-reeves,. Maybe this is indeed a separate issue. `mnnpy` is indeed working on the gene expression matrix, and not on a low dimensional embedding like `FastMNN` (which is what I assume you might have been using?). You could try [Scanorama](https://github.com/brianhie/scanorama) which is a method similar to FastMNN, using a sped up algorithm and no iterative merging of batches, but a method they call ""panoramic stitching"". It has performed quite well in our [benchmark of data integration methods](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2), and is in the scanpy ecosystem and therefore should work seamlessly in a Scanpy workflow. All of this being said, you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. @VolkerBergen has been thinking a bit about how to perform batch correction in an scvelo model, maybe he could chime in, or you could post an issue in the scvelo repo.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:895,integrability,pipelin,pipeline,895,"Hi @r-reeves,. Maybe this is indeed a separate issue. `mnnpy` is indeed working on the gene expression matrix, and not on a low dimensional embedding like `FastMNN` (which is what I assume you might have been using?). You could try [Scanorama](https://github.com/brianhie/scanorama) which is a method similar to FastMNN, using a sped up algorithm and no iterative merging of batches, but a method they call ""panoramic stitching"". It has performed quite well in our [benchmark of data integration methods](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2), and is in the scanpy ecosystem and therefore should work seamlessly in a Scanpy workflow. All of this being said, you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. @VolkerBergen has been thinking a bit about how to perform batch correction in an scvelo model, maybe he could chime in, or you could post an issue in the scvelo repo.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:1074,integrability,batch,batch,1074,"Hi @r-reeves,. Maybe this is indeed a separate issue. `mnnpy` is indeed working on the gene expression matrix, and not on a low dimensional embedding like `FastMNN` (which is what I assume you might have been using?). You could try [Scanorama](https://github.com/brianhie/scanorama) which is a method similar to FastMNN, using a sped up algorithm and no iterative merging of batches, but a method they call ""panoramic stitching"". It has performed quite well in our [benchmark of data integration methods](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2), and is in the scanpy ecosystem and therefore should work seamlessly in a Scanpy workflow. All of this being said, you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. @VolkerBergen has been thinking a bit about how to perform batch correction in an scvelo model, maybe he could chime in, or you could post an issue in the scvelo repo.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:484,interoperability,integr,integration,484,"Hi @r-reeves,. Maybe this is indeed a separate issue. `mnnpy` is indeed working on the gene expression matrix, and not on a low dimensional embedding like `FastMNN` (which is what I assume you might have been using?). You could try [Scanorama](https://github.com/brianhie/scanorama) which is a method similar to FastMNN, using a sped up algorithm and no iterative merging of batches, but a method they call ""panoramic stitching"". It has performed quite well in our [benchmark of data integration methods](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2), and is in the scanpy ecosystem and therefore should work seamlessly in a Scanpy workflow. All of this being said, you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. @VolkerBergen has been thinking a bit about how to perform batch correction in an scvelo model, maybe he could chime in, or you could post an issue in the scvelo repo.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:702,interoperability,integr,integrated,702,"Hi @r-reeves,. Maybe this is indeed a separate issue. `mnnpy` is indeed working on the gene expression matrix, and not on a low dimensional embedding like `FastMNN` (which is what I assume you might have been using?). You could try [Scanorama](https://github.com/brianhie/scanorama) which is a method similar to FastMNN, using a sped up algorithm and no iterative merging of batches, but a method they call ""panoramic stitching"". It has performed quite well in our [benchmark of data integration methods](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2), and is in the scanpy ecosystem and therefore should work seamlessly in a Scanpy workflow. All of this being said, you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. @VolkerBergen has been thinking a bit about how to perform batch correction in an scvelo model, maybe he could chime in, or you could post an issue in the scvelo repo.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:484,modifiability,integr,integration,484,"Hi @r-reeves,. Maybe this is indeed a separate issue. `mnnpy` is indeed working on the gene expression matrix, and not on a low dimensional embedding like `FastMNN` (which is what I assume you might have been using?). You could try [Scanorama](https://github.com/brianhie/scanorama) which is a method similar to FastMNN, using a sped up algorithm and no iterative merging of batches, but a method they call ""panoramic stitching"". It has performed quite well in our [benchmark of data integration methods](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2), and is in the scanpy ecosystem and therefore should work seamlessly in a Scanpy workflow. All of this being said, you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. @VolkerBergen has been thinking a bit about how to perform batch correction in an scvelo model, maybe he could chime in, or you could post an issue in the scvelo repo.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:702,modifiability,integr,integrated,702,"Hi @r-reeves,. Maybe this is indeed a separate issue. `mnnpy` is indeed working on the gene expression matrix, and not on a low dimensional embedding like `FastMNN` (which is what I assume you might have been using?). You could try [Scanorama](https://github.com/brianhie/scanorama) which is a method similar to FastMNN, using a sped up algorithm and no iterative merging of batches, but a method they call ""panoramic stitching"". It has performed quite well in our [benchmark of data integration methods](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2), and is in the scanpy ecosystem and therefore should work seamlessly in a Scanpy workflow. All of this being said, you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. @VolkerBergen has been thinking a bit about how to perform batch correction in an scvelo model, maybe he could chime in, or you could post an issue in the scvelo repo.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:375,performance,batch,batches,375,"Hi @r-reeves,. Maybe this is indeed a separate issue. `mnnpy` is indeed working on the gene expression matrix, and not on a low dimensional embedding like `FastMNN` (which is what I assume you might have been using?). You could try [Scanorama](https://github.com/brianhie/scanorama) which is a method similar to FastMNN, using a sped up algorithm and no iterative merging of batches, but a method they call ""panoramic stitching"". It has performed quite well in our [benchmark of data integration methods](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2), and is in the scanpy ecosystem and therefore should work seamlessly in a Scanpy workflow. All of this being said, you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. @VolkerBergen has been thinking a bit about how to perform batch correction in an scvelo model, maybe he could chime in, or you could post an issue in the scvelo repo.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:437,performance,perform,performed,437,"Hi @r-reeves,. Maybe this is indeed a separate issue. `mnnpy` is indeed working on the gene expression matrix, and not on a low dimensional embedding like `FastMNN` (which is what I assume you might have been using?). You could try [Scanorama](https://github.com/brianhie/scanorama) which is a method similar to FastMNN, using a sped up algorithm and no iterative merging of batches, but a method they call ""panoramic stitching"". It has performed quite well in our [benchmark of data integration methods](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2), and is in the scanpy ecosystem and therefore should work seamlessly in a Scanpy workflow. All of this being said, you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. @VolkerBergen has been thinking a bit about how to perform batch correction in an scvelo model, maybe he could chime in, or you could post an issue in the scvelo repo.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:529,performance,content,content,529,"Hi @r-reeves,. Maybe this is indeed a separate issue. `mnnpy` is indeed working on the gene expression matrix, and not on a low dimensional embedding like `FastMNN` (which is what I assume you might have been using?). You could try [Scanorama](https://github.com/brianhie/scanorama) which is a method similar to FastMNN, using a sped up algorithm and no iterative merging of batches, but a method they call ""panoramic stitching"". It has performed quite well in our [benchmark of data integration methods](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2), and is in the scanpy ecosystem and therefore should work seamlessly in a Scanpy workflow. All of this being said, you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. @VolkerBergen has been thinking a bit about how to perform batch correction in an scvelo model, maybe he could chime in, or you could post an issue in the scvelo repo.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:797,performance,batch,batch,797,"Hi @r-reeves,. Maybe this is indeed a separate issue. `mnnpy` is indeed working on the gene expression matrix, and not on a low dimensional embedding like `FastMNN` (which is what I assume you might have been using?). You could try [Scanorama](https://github.com/brianhie/scanorama) which is a method similar to FastMNN, using a sped up algorithm and no iterative merging of batches, but a method they call ""panoramic stitching"". It has performed quite well in our [benchmark of data integration methods](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2), and is in the scanpy ecosystem and therefore should work seamlessly in a Scanpy workflow. All of this being said, you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. @VolkerBergen has been thinking a bit about how to perform batch correction in an scvelo model, maybe he could chime in, or you could post an issue in the scvelo repo.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:874,performance,batch,batch,874,"Hi @r-reeves,. Maybe this is indeed a separate issue. `mnnpy` is indeed working on the gene expression matrix, and not on a low dimensional embedding like `FastMNN` (which is what I assume you might have been using?). You could try [Scanorama](https://github.com/brianhie/scanorama) which is a method similar to FastMNN, using a sped up algorithm and no iterative merging of batches, but a method they call ""panoramic stitching"". It has performed quite well in our [benchmark of data integration methods](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2), and is in the scanpy ecosystem and therefore should work seamlessly in a Scanpy workflow. All of this being said, you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. @VolkerBergen has been thinking a bit about how to perform batch correction in an scvelo model, maybe he could chime in, or you could post an issue in the scvelo repo.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:1066,performance,perform,perform,1066,"Hi @r-reeves,. Maybe this is indeed a separate issue. `mnnpy` is indeed working on the gene expression matrix, and not on a low dimensional embedding like `FastMNN` (which is what I assume you might have been using?). You could try [Scanorama](https://github.com/brianhie/scanorama) which is a method similar to FastMNN, using a sped up algorithm and no iterative merging of batches, but a method they call ""panoramic stitching"". It has performed quite well in our [benchmark of data integration methods](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2), and is in the scanpy ecosystem and therefore should work seamlessly in a Scanpy workflow. All of this being said, you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. @VolkerBergen has been thinking a bit about how to perform batch correction in an scvelo model, maybe he could chime in, or you could post an issue in the scvelo repo.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:1074,performance,batch,batch,1074,"Hi @r-reeves,. Maybe this is indeed a separate issue. `mnnpy` is indeed working on the gene expression matrix, and not on a low dimensional embedding like `FastMNN` (which is what I assume you might have been using?). You could try [Scanorama](https://github.com/brianhie/scanorama) which is a method similar to FastMNN, using a sped up algorithm and no iterative merging of batches, but a method they call ""panoramic stitching"". It has performed quite well in our [benchmark of data integration methods](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2), and is in the scanpy ecosystem and therefore should work seamlessly in a Scanpy workflow. All of this being said, you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. @VolkerBergen has been thinking a bit about how to perform batch correction in an scvelo model, maybe he could chime in, or you could post an issue in the scvelo repo.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:484,reliability,integr,integration,484,"Hi @r-reeves,. Maybe this is indeed a separate issue. `mnnpy` is indeed working on the gene expression matrix, and not on a low dimensional embedding like `FastMNN` (which is what I assume you might have been using?). You could try [Scanorama](https://github.com/brianhie/scanorama) which is a method similar to FastMNN, using a sped up algorithm and no iterative merging of batches, but a method they call ""panoramic stitching"". It has performed quite well in our [benchmark of data integration methods](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2), and is in the scanpy ecosystem and therefore should work seamlessly in a Scanpy workflow. All of this being said, you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. @VolkerBergen has been thinking a bit about how to perform batch correction in an scvelo model, maybe he could chime in, or you could post an issue in the scvelo repo.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:702,reliability,integr,integrated,702,"Hi @r-reeves,. Maybe this is indeed a separate issue. `mnnpy` is indeed working on the gene expression matrix, and not on a low dimensional embedding like `FastMNN` (which is what I assume you might have been using?). You could try [Scanorama](https://github.com/brianhie/scanorama) which is a method similar to FastMNN, using a sped up algorithm and no iterative merging of batches, but a method they call ""panoramic stitching"". It has performed quite well in our [benchmark of data integration methods](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2), and is in the scanpy ecosystem and therefore should work seamlessly in a Scanpy workflow. All of this being said, you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. @VolkerBergen has been thinking a bit about how to perform batch correction in an scvelo model, maybe he could chime in, or you could post an issue in the scvelo repo.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:847,reliability,doe,doesn,847,"Hi @r-reeves,. Maybe this is indeed a separate issue. `mnnpy` is indeed working on the gene expression matrix, and not on a low dimensional embedding like `FastMNN` (which is what I assume you might have been using?). You could try [Scanorama](https://github.com/brianhie/scanorama) which is a method similar to FastMNN, using a sped up algorithm and no iterative merging of batches, but a method they call ""panoramic stitching"". It has performed quite well in our [benchmark of data integration methods](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2), and is in the scanpy ecosystem and therefore should work seamlessly in a Scanpy workflow. All of this being said, you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. @VolkerBergen has been thinking a bit about how to perform batch correction in an scvelo model, maybe he could chime in, or you could post an issue in the scvelo repo.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:484,security,integr,integration,484,"Hi @r-reeves,. Maybe this is indeed a separate issue. `mnnpy` is indeed working on the gene expression matrix, and not on a low dimensional embedding like `FastMNN` (which is what I assume you might have been using?). You could try [Scanorama](https://github.com/brianhie/scanorama) which is a method similar to FastMNN, using a sped up algorithm and no iterative merging of batches, but a method they call ""panoramic stitching"". It has performed quite well in our [benchmark of data integration methods](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2), and is in the scanpy ecosystem and therefore should work seamlessly in a Scanpy workflow. All of this being said, you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. @VolkerBergen has been thinking a bit about how to perform batch correction in an scvelo model, maybe he could chime in, or you could post an issue in the scvelo repo.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:702,security,integr,integrated,702,"Hi @r-reeves,. Maybe this is indeed a separate issue. `mnnpy` is indeed working on the gene expression matrix, and not on a low dimensional embedding like `FastMNN` (which is what I assume you might have been using?). You could try [Scanorama](https://github.com/brianhie/scanorama) which is a method similar to FastMNN, using a sped up algorithm and no iterative merging of batches, but a method they call ""panoramic stitching"". It has performed quite well in our [benchmark of data integration methods](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2), and is in the scanpy ecosystem and therefore should work seamlessly in a Scanpy workflow. All of this being said, you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. @VolkerBergen has been thinking a bit about how to perform batch correction in an scvelo model, maybe he could chime in, or you could post an issue in the scvelo repo.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:999,security,model,model,999,"Hi @r-reeves,. Maybe this is indeed a separate issue. `mnnpy` is indeed working on the gene expression matrix, and not on a low dimensional embedding like `FastMNN` (which is what I assume you might have been using?). You could try [Scanorama](https://github.com/brianhie/scanorama) which is a method similar to FastMNN, using a sped up algorithm and no iterative merging of batches, but a method they call ""panoramic stitching"". It has performed quite well in our [benchmark of data integration methods](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2), and is in the scanpy ecosystem and therefore should work seamlessly in a Scanpy workflow. All of this being said, you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. @VolkerBergen has been thinking a bit about how to perform batch correction in an scvelo model, maybe he could chime in, or you could post an issue in the scvelo repo.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:1104,security,model,model,1104,"Hi @r-reeves,. Maybe this is indeed a separate issue. `mnnpy` is indeed working on the gene expression matrix, and not on a low dimensional embedding like `FastMNN` (which is what I assume you might have been using?). You could try [Scanorama](https://github.com/brianhie/scanorama) which is a method similar to FastMNN, using a sped up algorithm and no iterative merging of batches, but a method they call ""panoramic stitching"". It has performed quite well in our [benchmark of data integration methods](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2), and is in the scanpy ecosystem and therefore should work seamlessly in a Scanpy workflow. All of this being said, you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. @VolkerBergen has been thinking a bit about how to perform batch correction in an scvelo model, maybe he could chime in, or you could post an issue in the scvelo repo.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:484,testability,integr,integration,484,"Hi @r-reeves,. Maybe this is indeed a separate issue. `mnnpy` is indeed working on the gene expression matrix, and not on a low dimensional embedding like `FastMNN` (which is what I assume you might have been using?). You could try [Scanorama](https://github.com/brianhie/scanorama) which is a method similar to FastMNN, using a sped up algorithm and no iterative merging of batches, but a method they call ""panoramic stitching"". It has performed quite well in our [benchmark of data integration methods](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2), and is in the scanpy ecosystem and therefore should work seamlessly in a Scanpy workflow. All of this being said, you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. @VolkerBergen has been thinking a bit about how to perform batch correction in an scvelo model, maybe he could chime in, or you could post an issue in the scvelo repo.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:702,testability,integr,integrated,702,"Hi @r-reeves,. Maybe this is indeed a separate issue. `mnnpy` is indeed working on the gene expression matrix, and not on a low dimensional embedding like `FastMNN` (which is what I assume you might have been using?). You could try [Scanorama](https://github.com/brianhie/scanorama) which is a method similar to FastMNN, using a sped up algorithm and no iterative merging of batches, but a method they call ""panoramic stitching"". It has performed quite well in our [benchmark of data integration methods](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2), and is in the scanpy ecosystem and therefore should work seamlessly in a Scanpy workflow. All of this being said, you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. @VolkerBergen has been thinking a bit about how to perform batch correction in an scvelo model, maybe he could chime in, or you could post an issue in the scvelo repo.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:437,usability,perform,performed,437,"Hi @r-reeves,. Maybe this is indeed a separate issue. `mnnpy` is indeed working on the gene expression matrix, and not on a low dimensional embedding like `FastMNN` (which is what I assume you might have been using?). You could try [Scanorama](https://github.com/brianhie/scanorama) which is a method similar to FastMNN, using a sped up algorithm and no iterative merging of batches, but a method they call ""panoramic stitching"". It has performed quite well in our [benchmark of data integration methods](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2), and is in the scanpy ecosystem and therefore should work seamlessly in a Scanpy workflow. All of this being said, you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. @VolkerBergen has been thinking a bit about how to perform batch correction in an scvelo model, maybe he could chime in, or you could post an issue in the scvelo repo.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:647,usability,workflow,workflow,647,"Hi @r-reeves,. Maybe this is indeed a separate issue. `mnnpy` is indeed working on the gene expression matrix, and not on a low dimensional embedding like `FastMNN` (which is what I assume you might have been using?). You could try [Scanorama](https://github.com/brianhie/scanorama) which is a method similar to FastMNN, using a sped up algorithm and no iterative merging of batches, but a method they call ""panoramic stitching"". It has performed quite well in our [benchmark of data integration methods](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2), and is in the scanpy ecosystem and therefore should work seamlessly in a Scanpy workflow. All of this being said, you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. @VolkerBergen has been thinking a bit about how to perform batch correction in an scvelo model, maybe he could chime in, or you could post an issue in the scvelo repo.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:761,usability,help,help,761,"Hi @r-reeves,. Maybe this is indeed a separate issue. `mnnpy` is indeed working on the gene expression matrix, and not on a low dimensional embedding like `FastMNN` (which is what I assume you might have been using?). You could try [Scanorama](https://github.com/brianhie/scanorama) which is a method similar to FastMNN, using a sped up algorithm and no iterative merging of batches, but a method they call ""panoramic stitching"". It has performed quite well in our [benchmark of data integration methods](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2), and is in the scanpy ecosystem and therefore should work seamlessly in a Scanpy workflow. All of this being said, you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. @VolkerBergen has been thinking a bit about how to perform batch correction in an scvelo model, maybe he could chime in, or you could post an issue in the scvelo repo.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:1066,usability,perform,perform,1066,"Hi @r-reeves,. Maybe this is indeed a separate issue. `mnnpy` is indeed working on the gene expression matrix, and not on a low dimensional embedding like `FastMNN` (which is what I assume you might have been using?). You could try [Scanorama](https://github.com/brianhie/scanorama) which is a method similar to FastMNN, using a sped up algorithm and no iterative merging of batches, but a method they call ""panoramic stitching"". It has performed quite well in our [benchmark of data integration methods](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2), and is in the scanpy ecosystem and therefore should work seamlessly in a Scanpy workflow. All of this being said, you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. @VolkerBergen has been thinking a bit about how to perform batch correction in an scvelo model, maybe he could chime in, or you could post an issue in the scvelo repo.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:308,deployability,integr,integration,308,"Hi @LuckyMD . Thank you for the fast reply. Yes to FastMNN, as I understand from using align_cds  when you specify discretely what you want to remove e.g. sample-sample variation it calls FastMNN from batchelor. Thanks for the recommendation  I will check out Scanorama, been meaning to read the review on integration techniques. . > you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. Ahh okay, I misunderstood the process then  my understanding was that some of the mnn correction would be carried over when performing velocity analysis. I will check out the scvelo forum for info on comparing samples. . Thank you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:357,deployability,integr,integrated,357,"Hi @LuckyMD . Thank you for the fast reply. Yes to FastMNN, as I understand from using align_cds  when you specify discretely what you want to remove e.g. sample-sample variation it calls FastMNN from batchelor. Thanks for the recommendation  I will check out Scanorama, been meaning to read the review on integration techniques. . > you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. Ahh okay, I misunderstood the process then  my understanding was that some of the mnn correction would be carried over when performing velocity analysis. I will check out the scvelo forum for info on comparing samples. . Thank you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:550,deployability,pipelin,pipeline,550,"Hi @LuckyMD . Thank you for the fast reply. Yes to FastMNN, as I understand from using align_cds  when you specify discretely what you want to remove e.g. sample-sample variation it calls FastMNN from batchelor. Thanks for the recommendation  I will check out Scanorama, been meaning to read the review on integration techniques. . > you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. Ahh okay, I misunderstood the process then  my understanding was that some of the mnn correction would be carried over when performing velocity analysis. I will check out the scvelo forum for info on comparing samples. . Thank you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:510,energy efficiency,current,currently,510,"Hi @LuckyMD . Thank you for the fast reply. Yes to FastMNN, as I understand from using align_cds  when you specify discretely what you want to remove e.g. sample-sample variation it calls FastMNN from batchelor. Thanks for the recommendation  I will check out Scanorama, been meaning to read the review on integration techniques. . > you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. Ahh okay, I misunderstood the process then  my understanding was that some of the mnn correction would be carried over when performing velocity analysis. I will check out the scvelo forum for info on comparing samples. . Thank you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:654,energy efficiency,model,model,654,"Hi @LuckyMD . Thank you for the fast reply. Yes to FastMNN, as I understand from using align_cds  when you specify discretely what you want to remove e.g. sample-sample variation it calls FastMNN from batchelor. Thanks for the recommendation  I will check out Scanorama, been meaning to read the review on integration techniques. . > you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. Ahh okay, I misunderstood the process then  my understanding was that some of the mnn correction would be carried over when performing velocity analysis. I will check out the scvelo forum for info on comparing samples. . Thank you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:202,integrability,batch,batchelor,202,"Hi @LuckyMD . Thank you for the fast reply. Yes to FastMNN, as I understand from using align_cds  when you specify discretely what you want to remove e.g. sample-sample variation it calls FastMNN from batchelor. Thanks for the recommendation  I will check out Scanorama, been meaning to read the review on integration techniques. . > you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. Ahh okay, I misunderstood the process then  my understanding was that some of the mnn correction would be carried over when performing velocity analysis. I will check out the scvelo forum for info on comparing samples. . Thank you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:308,integrability,integr,integration,308,"Hi @LuckyMD . Thank you for the fast reply. Yes to FastMNN, as I understand from using align_cds  when you specify discretely what you want to remove e.g. sample-sample variation it calls FastMNN from batchelor. Thanks for the recommendation  I will check out Scanorama, been meaning to read the review on integration techniques. . > you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. Ahh okay, I misunderstood the process then  my understanding was that some of the mnn correction would be carried over when performing velocity analysis. I will check out the scvelo forum for info on comparing samples. . Thank you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:357,integrability,integr,integrated,357,"Hi @LuckyMD . Thank you for the fast reply. Yes to FastMNN, as I understand from using align_cds  when you specify discretely what you want to remove e.g. sample-sample variation it calls FastMNN from batchelor. Thanks for the recommendation  I will check out Scanorama, been meaning to read the review on integration techniques. . > you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. Ahh okay, I misunderstood the process then  my understanding was that some of the mnn correction would be carried over when performing velocity analysis. I will check out the scvelo forum for info on comparing samples. . Thank you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:452,integrability,batch,batch,452,"Hi @LuckyMD . Thank you for the fast reply. Yes to FastMNN, as I understand from using align_cds  when you specify discretely what you want to remove e.g. sample-sample variation it calls FastMNN from batchelor. Thanks for the recommendation  I will check out Scanorama, been meaning to read the review on integration techniques. . > you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. Ahh okay, I misunderstood the process then  my understanding was that some of the mnn correction would be carried over when performing velocity analysis. I will check out the scvelo forum for info on comparing samples. . Thank you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:529,integrability,batch,batch,529,"Hi @LuckyMD . Thank you for the fast reply. Yes to FastMNN, as I understand from using align_cds  when you specify discretely what you want to remove e.g. sample-sample variation it calls FastMNN from batchelor. Thanks for the recommendation  I will check out Scanorama, been meaning to read the review on integration techniques. . > you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. Ahh okay, I misunderstood the process then  my understanding was that some of the mnn correction would be carried over when performing velocity analysis. I will check out the scvelo forum for info on comparing samples. . Thank you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:550,integrability,pipelin,pipeline,550,"Hi @LuckyMD . Thank you for the fast reply. Yes to FastMNN, as I understand from using align_cds  when you specify discretely what you want to remove e.g. sample-sample variation it calls FastMNN from batchelor. Thanks for the recommendation  I will check out Scanorama, been meaning to read the review on integration techniques. . > you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. Ahh okay, I misunderstood the process then  my understanding was that some of the mnn correction would be carried over when performing velocity analysis. I will check out the scvelo forum for info on comparing samples. . Thank you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:108,interoperability,specif,specify,108,"Hi @LuckyMD . Thank you for the fast reply. Yes to FastMNN, as I understand from using align_cds  when you specify discretely what you want to remove e.g. sample-sample variation it calls FastMNN from batchelor. Thanks for the recommendation  I will check out Scanorama, been meaning to read the review on integration techniques. . > you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. Ahh okay, I misunderstood the process then  my understanding was that some of the mnn correction would be carried over when performing velocity analysis. I will check out the scvelo forum for info on comparing samples. . Thank you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:308,interoperability,integr,integration,308,"Hi @LuckyMD . Thank you for the fast reply. Yes to FastMNN, as I understand from using align_cds  when you specify discretely what you want to remove e.g. sample-sample variation it calls FastMNN from batchelor. Thanks for the recommendation  I will check out Scanorama, been meaning to read the review on integration techniques. . > you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. Ahh okay, I misunderstood the process then  my understanding was that some of the mnn correction would be carried over when performing velocity analysis. I will check out the scvelo forum for info on comparing samples. . Thank you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:357,interoperability,integr,integrated,357,"Hi @LuckyMD . Thank you for the fast reply. Yes to FastMNN, as I understand from using align_cds  when you specify discretely what you want to remove e.g. sample-sample variation it calls FastMNN from batchelor. Thanks for the recommendation  I will check out Scanorama, been meaning to read the review on integration techniques. . > you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. Ahh okay, I misunderstood the process then  my understanding was that some of the mnn correction would be carried over when performing velocity analysis. I will check out the scvelo forum for info on comparing samples. . Thank you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:308,modifiability,integr,integration,308,"Hi @LuckyMD . Thank you for the fast reply. Yes to FastMNN, as I understand from using align_cds  when you specify discretely what you want to remove e.g. sample-sample variation it calls FastMNN from batchelor. Thanks for the recommendation  I will check out Scanorama, been meaning to read the review on integration techniques. . > you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. Ahh okay, I misunderstood the process then  my understanding was that some of the mnn correction would be carried over when performing velocity analysis. I will check out the scvelo forum for info on comparing samples. . Thank you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:357,modifiability,integr,integrated,357,"Hi @LuckyMD . Thank you for the fast reply. Yes to FastMNN, as I understand from using align_cds  when you specify discretely what you want to remove e.g. sample-sample variation it calls FastMNN from batchelor. Thanks for the recommendation  I will check out Scanorama, been meaning to read the review on integration techniques. . > you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. Ahh okay, I misunderstood the process then  my understanding was that some of the mnn correction would be carried over when performing velocity analysis. I will check out the scvelo forum for info on comparing samples. . Thank you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:202,performance,batch,batchelor,202,"Hi @LuckyMD . Thank you for the fast reply. Yes to FastMNN, as I understand from using align_cds  when you specify discretely what you want to remove e.g. sample-sample variation it calls FastMNN from batchelor. Thanks for the recommendation  I will check out Scanorama, been meaning to read the review on integration techniques. . > you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. Ahh okay, I misunderstood the process then  my understanding was that some of the mnn correction would be carried over when performing velocity analysis. I will check out the scvelo forum for info on comparing samples. . Thank you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:452,performance,batch,batch,452,"Hi @LuckyMD . Thank you for the fast reply. Yes to FastMNN, as I understand from using align_cds  when you specify discretely what you want to remove e.g. sample-sample variation it calls FastMNN from batchelor. Thanks for the recommendation  I will check out Scanorama, been meaning to read the review on integration techniques. . > you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. Ahh okay, I misunderstood the process then  my understanding was that some of the mnn correction would be carried over when performing velocity analysis. I will check out the scvelo forum for info on comparing samples. . Thank you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:529,performance,batch,batch,529,"Hi @LuckyMD . Thank you for the fast reply. Yes to FastMNN, as I understand from using align_cds  when you specify discretely what you want to remove e.g. sample-sample variation it calls FastMNN from batchelor. Thanks for the recommendation  I will check out Scanorama, been meaning to read the review on integration techniques. . > you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. Ahh okay, I misunderstood the process then  my understanding was that some of the mnn correction would be carried over when performing velocity analysis. I will check out the scvelo forum for info on comparing samples. . Thank you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:795,performance,perform,performing,795,"Hi @LuckyMD . Thank you for the fast reply. Yes to FastMNN, as I understand from using align_cds  when you specify discretely what you want to remove e.g. sample-sample variation it calls FastMNN from batchelor. Thanks for the recommendation  I will check out Scanorama, been meaning to read the review on integration techniques. . > you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. Ahh okay, I misunderstood the process then  my understanding was that some of the mnn correction would be carried over when performing velocity analysis. I will check out the scvelo forum for info on comparing samples. . Thank you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:308,reliability,integr,integration,308,"Hi @LuckyMD . Thank you for the fast reply. Yes to FastMNN, as I understand from using align_cds  when you specify discretely what you want to remove e.g. sample-sample variation it calls FastMNN from batchelor. Thanks for the recommendation  I will check out Scanorama, been meaning to read the review on integration techniques. . > you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. Ahh okay, I misunderstood the process then  my understanding was that some of the mnn correction would be carried over when performing velocity analysis. I will check out the scvelo forum for info on comparing samples. . Thank you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:357,reliability,integr,integrated,357,"Hi @LuckyMD . Thank you for the fast reply. Yes to FastMNN, as I understand from using align_cds  when you specify discretely what you want to remove e.g. sample-sample variation it calls FastMNN from batchelor. Thanks for the recommendation  I will check out Scanorama, been meaning to read the review on integration techniques. . > you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. Ahh okay, I misunderstood the process then  my understanding was that some of the mnn correction would be carried over when performing velocity analysis. I will check out the scvelo forum for info on comparing samples. . Thank you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:502,reliability,doe,doesn,502,"Hi @LuckyMD . Thank you for the fast reply. Yes to FastMNN, as I understand from using align_cds  when you specify discretely what you want to remove e.g. sample-sample variation it calls FastMNN from batchelor. Thanks for the recommendation  I will check out Scanorama, been meaning to read the review on integration techniques. . > you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. Ahh okay, I misunderstood the process then  my understanding was that some of the mnn correction would be carried over when performing velocity analysis. I will check out the scvelo forum for info on comparing samples. . Thank you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:298,safety,review,review,298,"Hi @LuckyMD . Thank you for the fast reply. Yes to FastMNN, as I understand from using align_cds  when you specify discretely what you want to remove e.g. sample-sample variation it calls FastMNN from batchelor. Thanks for the recommendation  I will check out Scanorama, been meaning to read the review on integration techniques. . > you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. Ahh okay, I misunderstood the process then  my understanding was that some of the mnn correction would be carried over when performing velocity analysis. I will check out the scvelo forum for info on comparing samples. . Thank you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:308,security,integr,integration,308,"Hi @LuckyMD . Thank you for the fast reply. Yes to FastMNN, as I understand from using align_cds  when you specify discretely what you want to remove e.g. sample-sample variation it calls FastMNN from batchelor. Thanks for the recommendation  I will check out Scanorama, been meaning to read the review on integration techniques. . > you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. Ahh okay, I misunderstood the process then  my understanding was that some of the mnn correction would be carried over when performing velocity analysis. I will check out the scvelo forum for info on comparing samples. . Thank you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:357,security,integr,integrated,357,"Hi @LuckyMD . Thank you for the fast reply. Yes to FastMNN, as I understand from using align_cds  when you specify discretely what you want to remove e.g. sample-sample variation it calls FastMNN from batchelor. Thanks for the recommendation  I will check out Scanorama, been meaning to read the review on integration techniques. . > you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. Ahh okay, I misunderstood the process then  my understanding was that some of the mnn correction would be carried over when performing velocity analysis. I will check out the scvelo forum for info on comparing samples. . Thank you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:654,security,model,model,654,"Hi @LuckyMD . Thank you for the fast reply. Yes to FastMNN, as I understand from using align_cds  when you specify discretely what you want to remove e.g. sample-sample variation it calls FastMNN from batchelor. Thanks for the recommendation  I will check out Scanorama, been meaning to read the review on integration techniques. . > you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. Ahh okay, I misunderstood the process then  my understanding was that some of the mnn correction would be carried over when performing velocity analysis. I will check out the scvelo forum for info on comparing samples. . Thank you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:65,testability,understand,understand,65,"Hi @LuckyMD . Thank you for the fast reply. Yes to FastMNN, as I understand from using align_cds  when you specify discretely what you want to remove e.g. sample-sample variation it calls FastMNN from batchelor. Thanks for the recommendation  I will check out Scanorama, been meaning to read the review on integration techniques. . > you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. Ahh okay, I misunderstood the process then  my understanding was that some of the mnn correction would be carried over when performing velocity analysis. I will check out the scvelo forum for info on comparing samples. . Thank you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:298,testability,review,review,298,"Hi @LuckyMD . Thank you for the fast reply. Yes to FastMNN, as I understand from using align_cds  when you specify discretely what you want to remove e.g. sample-sample variation it calls FastMNN from batchelor. Thanks for the recommendation  I will check out Scanorama, been meaning to read the review on integration techniques. . > you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. Ahh okay, I misunderstood the process then  my understanding was that some of the mnn correction would be carried over when performing velocity analysis. I will check out the scvelo forum for info on comparing samples. . Thank you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:308,testability,integr,integration,308,"Hi @LuckyMD . Thank you for the fast reply. Yes to FastMNN, as I understand from using align_cds  when you specify discretely what you want to remove e.g. sample-sample variation it calls FastMNN from batchelor. Thanks for the recommendation  I will check out Scanorama, been meaning to read the review on integration techniques. . > you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. Ahh okay, I misunderstood the process then  my understanding was that some of the mnn correction would be carried over when performing velocity analysis. I will check out the scvelo forum for info on comparing samples. . Thank you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:357,testability,integr,integrated,357,"Hi @LuckyMD . Thank you for the fast reply. Yes to FastMNN, as I understand from using align_cds  when you specify discretely what you want to remove e.g. sample-sample variation it calls FastMNN from batchelor. Thanks for the recommendation  I will check out Scanorama, been meaning to read the review on integration techniques. . > you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. Ahh okay, I misunderstood the process then  my understanding was that some of the mnn correction would be carried over when performing velocity analysis. I will check out the scvelo forum for info on comparing samples. . Thank you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:718,testability,understand,understanding,718,"Hi @LuckyMD . Thank you for the fast reply. Yes to FastMNN, as I understand from using align_cds  when you specify discretely what you want to remove e.g. sample-sample variation it calls FastMNN from batchelor. Thanks for the recommendation  I will check out Scanorama, been meaning to read the review on integration techniques. . > you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. Ahh okay, I misunderstood the process then  my understanding was that some of the mnn correction would be carried over when performing velocity analysis. I will check out the scvelo forum for info on comparing samples. . Thank you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:416,usability,help,help,416,"Hi @LuckyMD . Thank you for the fast reply. Yes to FastMNN, as I understand from using align_cds  when you specify discretely what you want to remove e.g. sample-sample variation it calls FastMNN from batchelor. Thanks for the recommendation  I will check out Scanorama, been meaning to read the review on integration techniques. . > you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. Ahh okay, I misunderstood the process then  my understanding was that some of the mnn correction would be carried over when performing velocity analysis. I will check out the scvelo forum for info on comparing samples. . Thank you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:795,usability,perform,performing,795,"Hi @LuckyMD . Thank you for the fast reply. Yes to FastMNN, as I understand from using align_cds  when you specify discretely what you want to remove e.g. sample-sample variation it calls FastMNN from batchelor. Thanks for the recommendation  I will check out Scanorama, been meaning to read the review on integration techniques. . > you will only get an integrated graph structure with this for scvelo, which may help a little, but won't remove the batch effect for RNA velocity calculation. scvelo doesn't currently have any batch removal in its pipeline as it is quite difficult to add as it works directly from the normalized count data and fits a model to these. Ahh okay, I misunderstood the process then  my understanding was that some of the mnn correction would be carried over when performing velocity analysis. I will check out the scvelo forum for info on comparing samples. . Thank you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1292:328,interoperability,specif,specific,328,"I am not sure I need a reproducible example to explain this... if you click on the link above that leads you to the documentation for the pl.rank_genes_groups function, you'll there is no description of the 'key' argument for that function. This should be added, so that users know how and when to make use of it. Do you have a specific further question?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1292
https://github.com/scverse/scanpy/issues/1292:116,usability,document,documentation,116,"I am not sure I need a reproducible example to explain this... if you click on the link above that leads you to the documentation for the pl.rank_genes_groups function, you'll there is no description of the 'key' argument for that function. This should be added, so that users know how and when to make use of it. Do you have a specific further question?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1292
https://github.com/scverse/scanpy/issues/1292:271,usability,user,users,271,"I am not sure I need a reproducible example to explain this... if you click on the link above that leads you to the documentation for the pl.rank_genes_groups function, you'll there is no description of the 'key' argument for that function. This should be added, so that users know how and when to make use of it. Do you have a specific further question?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1292
https://github.com/scverse/scanpy/issues/1292:44,availability,Ping,Pinging,44,good catch! Thank you for reporting this. . Pinging @Koncopd since I believe you were involved in major refactoring of this. . Thank you @rpeys,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1292
https://github.com/scverse/scanpy/issues/1292:104,modifiability,refact,refactoring,104,good catch! Thank you for reporting this. . Pinging @Koncopd since I believe you were involved in major refactoring of this. . Thank you @rpeys,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1292
https://github.com/scverse/scanpy/issues/1292:104,performance,refactor,refactoring,104,good catch! Thank you for reporting this. . Pinging @Koncopd since I believe you were involved in major refactoring of this. . Thank you @rpeys,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1292
https://github.com/scverse/scanpy/issues/1293:163,availability,ping,pinging,163,"this is not related to scanpy, but to sam (scanpy external). Please report the bug in the original repo: https://github.com/atarashansky/self-assembling-manifold. pinging @atarashansky who is possibly most helpful in this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1293
https://github.com/scverse/scanpy/issues/1293:206,usability,help,helpful,206,"this is not related to scanpy, but to sam (scanpy external). Please report the bug in the original repo: https://github.com/atarashansky/self-assembling-manifold. pinging @atarashansky who is possibly most helpful in this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1293
https://github.com/scverse/scanpy/issues/1293:122,availability,down,downgrade,122,"Hi @alkhairohr! Strange bug -- never seen it before. The latest UMAP version I've been using with SAM is `0.4.1`. Can you downgrade UMAP to that version and try again? If that fixes your issue, then I'll add `umap<=0.4.1` requirement to the `setup.py` file for SAM as a stopgap until I figure out the issue. Meanwhile, I'll try upgrading to `0.4.4` and see if I can reproduce the error. As @giovp said, because this is a SAM issue, I'll follow up on this issue with a thread on my github repo and ping you there. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1293
https://github.com/scverse/scanpy/issues/1293:380,availability,error,error,380,"Hi @alkhairohr! Strange bug -- never seen it before. The latest UMAP version I've been using with SAM is `0.4.1`. Can you downgrade UMAP to that version and try again? If that fixes your issue, then I'll add `umap<=0.4.1` requirement to the `setup.py` file for SAM as a stopgap until I figure out the issue. Meanwhile, I'll try upgrading to `0.4.4` and see if I can reproduce the error. As @giovp said, because this is a SAM issue, I'll follow up on this issue with a thread on my github repo and ping you there. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1293
https://github.com/scverse/scanpy/issues/1293:497,availability,ping,ping,497,"Hi @alkhairohr! Strange bug -- never seen it before. The latest UMAP version I've been using with SAM is `0.4.1`. Can you downgrade UMAP to that version and try again? If that fixes your issue, then I'll add `umap<=0.4.1` requirement to the `setup.py` file for SAM as a stopgap until I figure out the issue. Meanwhile, I'll try upgrading to `0.4.4` and see if I can reproduce the error. As @giovp said, because this is a SAM issue, I'll follow up on this issue with a thread on my github repo and ping you there. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1293
https://github.com/scverse/scanpy/issues/1293:69,deployability,version,version,69,"Hi @alkhairohr! Strange bug -- never seen it before. The latest UMAP version I've been using with SAM is `0.4.1`. Can you downgrade UMAP to that version and try again? If that fixes your issue, then I'll add `umap<=0.4.1` requirement to the `setup.py` file for SAM as a stopgap until I figure out the issue. Meanwhile, I'll try upgrading to `0.4.4` and see if I can reproduce the error. As @giovp said, because this is a SAM issue, I'll follow up on this issue with a thread on my github repo and ping you there. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1293
https://github.com/scverse/scanpy/issues/1293:145,deployability,version,version,145,"Hi @alkhairohr! Strange bug -- never seen it before. The latest UMAP version I've been using with SAM is `0.4.1`. Can you downgrade UMAP to that version and try again? If that fixes your issue, then I'll add `umap<=0.4.1` requirement to the `setup.py` file for SAM as a stopgap until I figure out the issue. Meanwhile, I'll try upgrading to `0.4.4` and see if I can reproduce the error. As @giovp said, because this is a SAM issue, I'll follow up on this issue with a thread on my github repo and ping you there. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1293
https://github.com/scverse/scanpy/issues/1293:328,deployability,upgrad,upgrading,328,"Hi @alkhairohr! Strange bug -- never seen it before. The latest UMAP version I've been using with SAM is `0.4.1`. Can you downgrade UMAP to that version and try again? If that fixes your issue, then I'll add `umap<=0.4.1` requirement to the `setup.py` file for SAM as a stopgap until I figure out the issue. Meanwhile, I'll try upgrading to `0.4.4` and see if I can reproduce the error. As @giovp said, because this is a SAM issue, I'll follow up on this issue with a thread on my github repo and ping you there. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1293
https://github.com/scverse/scanpy/issues/1293:69,integrability,version,version,69,"Hi @alkhairohr! Strange bug -- never seen it before. The latest UMAP version I've been using with SAM is `0.4.1`. Can you downgrade UMAP to that version and try again? If that fixes your issue, then I'll add `umap<=0.4.1` requirement to the `setup.py` file for SAM as a stopgap until I figure out the issue. Meanwhile, I'll try upgrading to `0.4.4` and see if I can reproduce the error. As @giovp said, because this is a SAM issue, I'll follow up on this issue with a thread on my github repo and ping you there. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1293
https://github.com/scverse/scanpy/issues/1293:145,integrability,version,version,145,"Hi @alkhairohr! Strange bug -- never seen it before. The latest UMAP version I've been using with SAM is `0.4.1`. Can you downgrade UMAP to that version and try again? If that fixes your issue, then I'll add `umap<=0.4.1` requirement to the `setup.py` file for SAM as a stopgap until I figure out the issue. Meanwhile, I'll try upgrading to `0.4.4` and see if I can reproduce the error. As @giovp said, because this is a SAM issue, I'll follow up on this issue with a thread on my github repo and ping you there. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1293
https://github.com/scverse/scanpy/issues/1293:69,modifiability,version,version,69,"Hi @alkhairohr! Strange bug -- never seen it before. The latest UMAP version I've been using with SAM is `0.4.1`. Can you downgrade UMAP to that version and try again? If that fixes your issue, then I'll add `umap<=0.4.1` requirement to the `setup.py` file for SAM as a stopgap until I figure out the issue. Meanwhile, I'll try upgrading to `0.4.4` and see if I can reproduce the error. As @giovp said, because this is a SAM issue, I'll follow up on this issue with a thread on my github repo and ping you there. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1293
https://github.com/scverse/scanpy/issues/1293:145,modifiability,version,version,145,"Hi @alkhairohr! Strange bug -- never seen it before. The latest UMAP version I've been using with SAM is `0.4.1`. Can you downgrade UMAP to that version and try again? If that fixes your issue, then I'll add `umap<=0.4.1` requirement to the `setup.py` file for SAM as a stopgap until I figure out the issue. Meanwhile, I'll try upgrading to `0.4.4` and see if I can reproduce the error. As @giovp said, because this is a SAM issue, I'll follow up on this issue with a thread on my github repo and ping you there. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1293
https://github.com/scverse/scanpy/issues/1293:328,modifiability,upgrad,upgrading,328,"Hi @alkhairohr! Strange bug -- never seen it before. The latest UMAP version I've been using with SAM is `0.4.1`. Can you downgrade UMAP to that version and try again? If that fixes your issue, then I'll add `umap<=0.4.1` requirement to the `setup.py` file for SAM as a stopgap until I figure out the issue. Meanwhile, I'll try upgrading to `0.4.4` and see if I can reproduce the error. As @giovp said, because this is a SAM issue, I'll follow up on this issue with a thread on my github repo and ping you there. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1293
https://github.com/scverse/scanpy/issues/1293:380,performance,error,error,380,"Hi @alkhairohr! Strange bug -- never seen it before. The latest UMAP version I've been using with SAM is `0.4.1`. Can you downgrade UMAP to that version and try again? If that fixes your issue, then I'll add `umap<=0.4.1` requirement to the `setup.py` file for SAM as a stopgap until I figure out the issue. Meanwhile, I'll try upgrading to `0.4.4` and see if I can reproduce the error. As @giovp said, because this is a SAM issue, I'll follow up on this issue with a thread on my github repo and ping you there. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1293
https://github.com/scverse/scanpy/issues/1293:380,safety,error,error,380,"Hi @alkhairohr! Strange bug -- never seen it before. The latest UMAP version I've been using with SAM is `0.4.1`. Can you downgrade UMAP to that version and try again? If that fixes your issue, then I'll add `umap<=0.4.1` requirement to the `setup.py` file for SAM as a stopgap until I figure out the issue. Meanwhile, I'll try upgrading to `0.4.4` and see if I can reproduce the error. As @giovp said, because this is a SAM issue, I'll follow up on this issue with a thread on my github repo and ping you there. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1293
https://github.com/scverse/scanpy/issues/1293:270,usability,stop,stopgap,270,"Hi @alkhairohr! Strange bug -- never seen it before. The latest UMAP version I've been using with SAM is `0.4.1`. Can you downgrade UMAP to that version and try again? If that fixes your issue, then I'll add `umap<=0.4.1` requirement to the `setup.py` file for SAM as a stopgap until I figure out the issue. Meanwhile, I'll try upgrading to `0.4.4` and see if I can reproduce the error. As @giovp said, because this is a SAM issue, I'll follow up on this issue with a thread on my github repo and ping you there. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1293
https://github.com/scverse/scanpy/issues/1293:380,usability,error,error,380,"Hi @alkhairohr! Strange bug -- never seen it before. The latest UMAP version I've been using with SAM is `0.4.1`. Can you downgrade UMAP to that version and try again? If that fixes your issue, then I'll add `umap<=0.4.1` requirement to the `setup.py` file for SAM as a stopgap until I figure out the issue. Meanwhile, I'll try upgrading to `0.4.4` and see if I can reproduce the error. As @giovp said, because this is a SAM issue, I'll follow up on this issue with a thread on my github repo and ping you there. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1293
https://github.com/scverse/scanpy/issues/1295:58,availability,error,error,58,"When using **scanpy.pl.paga_path**, I experience the same error as @plrlhb12 (TypeError: **float() argument must be a string or a number, not 'csr_matrix'**) and I can also only generate a plot after deleting adata.raw. As a consequence, I can only plot genes that are filtered for high variability during preprocessing and still present in adata.var.gene_ids. . I would be glad if there was a way to make it work without deleting adata.raw and therefore being able to plot also non-highly variable genes! Thank you! **Versions:**. > anndata==0.7.4 matplotlib==3.3.0 numpy==1.19.1 pandas==1.1.0 scanpy==1.6.0 scipy==1.5.2 sklearn==0.23.1 igraph==0.8.2 leidenalg==0.8.1 umap==0.4.6.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1295
https://github.com/scverse/scanpy/issues/1295:519,deployability,Version,Versions,519,"When using **scanpy.pl.paga_path**, I experience the same error as @plrlhb12 (TypeError: **float() argument must be a string or a number, not 'csr_matrix'**) and I can also only generate a plot after deleting adata.raw. As a consequence, I can only plot genes that are filtered for high variability during preprocessing and still present in adata.var.gene_ids. . I would be glad if there was a way to make it work without deleting adata.raw and therefore being able to plot also non-highly variable genes! Thank you! **Versions:**. > anndata==0.7.4 matplotlib==3.3.0 numpy==1.19.1 pandas==1.1.0 scanpy==1.6.0 scipy==1.5.2 sklearn==0.23.1 igraph==0.8.2 leidenalg==0.8.1 umap==0.4.6.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1295
https://github.com/scverse/scanpy/issues/1295:269,integrability,filter,filtered,269,"When using **scanpy.pl.paga_path**, I experience the same error as @plrlhb12 (TypeError: **float() argument must be a string or a number, not 'csr_matrix'**) and I can also only generate a plot after deleting adata.raw. As a consequence, I can only plot genes that are filtered for high variability during preprocessing and still present in adata.var.gene_ids. . I would be glad if there was a way to make it work without deleting adata.raw and therefore being able to plot also non-highly variable genes! Thank you! **Versions:**. > anndata==0.7.4 matplotlib==3.3.0 numpy==1.19.1 pandas==1.1.0 scanpy==1.6.0 scipy==1.5.2 sklearn==0.23.1 igraph==0.8.2 leidenalg==0.8.1 umap==0.4.6.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1295
https://github.com/scverse/scanpy/issues/1295:519,integrability,Version,Versions,519,"When using **scanpy.pl.paga_path**, I experience the same error as @plrlhb12 (TypeError: **float() argument must be a string or a number, not 'csr_matrix'**) and I can also only generate a plot after deleting adata.raw. As a consequence, I can only plot genes that are filtered for high variability during preprocessing and still present in adata.var.gene_ids. . I would be glad if there was a way to make it work without deleting adata.raw and therefore being able to plot also non-highly variable genes! Thank you! **Versions:**. > anndata==0.7.4 matplotlib==3.3.0 numpy==1.19.1 pandas==1.1.0 scanpy==1.6.0 scipy==1.5.2 sklearn==0.23.1 igraph==0.8.2 leidenalg==0.8.1 umap==0.4.6.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1295
https://github.com/scverse/scanpy/issues/1295:287,modifiability,variab,variability,287,"When using **scanpy.pl.paga_path**, I experience the same error as @plrlhb12 (TypeError: **float() argument must be a string or a number, not 'csr_matrix'**) and I can also only generate a plot after deleting adata.raw. As a consequence, I can only plot genes that are filtered for high variability during preprocessing and still present in adata.var.gene_ids. . I would be glad if there was a way to make it work without deleting adata.raw and therefore being able to plot also non-highly variable genes! Thank you! **Versions:**. > anndata==0.7.4 matplotlib==3.3.0 numpy==1.19.1 pandas==1.1.0 scanpy==1.6.0 scipy==1.5.2 sklearn==0.23.1 igraph==0.8.2 leidenalg==0.8.1 umap==0.4.6.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1295
https://github.com/scverse/scanpy/issues/1295:490,modifiability,variab,variable,490,"When using **scanpy.pl.paga_path**, I experience the same error as @plrlhb12 (TypeError: **float() argument must be a string or a number, not 'csr_matrix'**) and I can also only generate a plot after deleting adata.raw. As a consequence, I can only plot genes that are filtered for high variability during preprocessing and still present in adata.var.gene_ids. . I would be glad if there was a way to make it work without deleting adata.raw and therefore being able to plot also non-highly variable genes! Thank you! **Versions:**. > anndata==0.7.4 matplotlib==3.3.0 numpy==1.19.1 pandas==1.1.0 scanpy==1.6.0 scipy==1.5.2 sklearn==0.23.1 igraph==0.8.2 leidenalg==0.8.1 umap==0.4.6.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1295
https://github.com/scverse/scanpy/issues/1295:519,modifiability,Version,Versions,519,"When using **scanpy.pl.paga_path**, I experience the same error as @plrlhb12 (TypeError: **float() argument must be a string or a number, not 'csr_matrix'**) and I can also only generate a plot after deleting adata.raw. As a consequence, I can only plot genes that are filtered for high variability during preprocessing and still present in adata.var.gene_ids. . I would be glad if there was a way to make it work without deleting adata.raw and therefore being able to plot also non-highly variable genes! Thank you! **Versions:**. > anndata==0.7.4 matplotlib==3.3.0 numpy==1.19.1 pandas==1.1.0 scanpy==1.6.0 scipy==1.5.2 sklearn==0.23.1 igraph==0.8.2 leidenalg==0.8.1 umap==0.4.6.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1295
https://github.com/scverse/scanpy/issues/1295:58,performance,error,error,58,"When using **scanpy.pl.paga_path**, I experience the same error as @plrlhb12 (TypeError: **float() argument must be a string or a number, not 'csr_matrix'**) and I can also only generate a plot after deleting adata.raw. As a consequence, I can only plot genes that are filtered for high variability during preprocessing and still present in adata.var.gene_ids. . I would be glad if there was a way to make it work without deleting adata.raw and therefore being able to plot also non-highly variable genes! Thank you! **Versions:**. > anndata==0.7.4 matplotlib==3.3.0 numpy==1.19.1 pandas==1.1.0 scanpy==1.6.0 scipy==1.5.2 sklearn==0.23.1 igraph==0.8.2 leidenalg==0.8.1 umap==0.4.6.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1295
https://github.com/scverse/scanpy/issues/1295:58,safety,error,error,58,"When using **scanpy.pl.paga_path**, I experience the same error as @plrlhb12 (TypeError: **float() argument must be a string or a number, not 'csr_matrix'**) and I can also only generate a plot after deleting adata.raw. As a consequence, I can only plot genes that are filtered for high variability during preprocessing and still present in adata.var.gene_ids. . I would be glad if there was a way to make it work without deleting adata.raw and therefore being able to plot also non-highly variable genes! Thank you! **Versions:**. > anndata==0.7.4 matplotlib==3.3.0 numpy==1.19.1 pandas==1.1.0 scanpy==1.6.0 scipy==1.5.2 sklearn==0.23.1 igraph==0.8.2 leidenalg==0.8.1 umap==0.4.6.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1295
https://github.com/scverse/scanpy/issues/1295:38,usability,experien,experience,38,"When using **scanpy.pl.paga_path**, I experience the same error as @plrlhb12 (TypeError: **float() argument must be a string or a number, not 'csr_matrix'**) and I can also only generate a plot after deleting adata.raw. As a consequence, I can only plot genes that are filtered for high variability during preprocessing and still present in adata.var.gene_ids. . I would be glad if there was a way to make it work without deleting adata.raw and therefore being able to plot also non-highly variable genes! Thank you! **Versions:**. > anndata==0.7.4 matplotlib==3.3.0 numpy==1.19.1 pandas==1.1.0 scanpy==1.6.0 scipy==1.5.2 sklearn==0.23.1 igraph==0.8.2 leidenalg==0.8.1 umap==0.4.6.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1295
https://github.com/scverse/scanpy/issues/1295:58,usability,error,error,58,"When using **scanpy.pl.paga_path**, I experience the same error as @plrlhb12 (TypeError: **float() argument must be a string or a number, not 'csr_matrix'**) and I can also only generate a plot after deleting adata.raw. As a consequence, I can only plot genes that are filtered for high variability during preprocessing and still present in adata.var.gene_ids. . I would be glad if there was a way to make it work without deleting adata.raw and therefore being able to plot also non-highly variable genes! Thank you! **Versions:**. > anndata==0.7.4 matplotlib==3.3.0 numpy==1.19.1 pandas==1.1.0 scanpy==1.6.0 scipy==1.5.2 sklearn==0.23.1 igraph==0.8.2 leidenalg==0.8.1 umap==0.4.6.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1295
https://github.com/scverse/scanpy/issues/1295:9,availability,error,error,9,"The same error happens to me, @Blohrer . **Versions:**. > scanpy==1.6.0 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1295
https://github.com/scverse/scanpy/issues/1295:43,deployability,Version,Versions,43,"The same error happens to me, @Blohrer . **Versions:**. > scanpy==1.6.0 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1295
https://github.com/scverse/scanpy/issues/1295:43,integrability,Version,Versions,43,"The same error happens to me, @Blohrer . **Versions:**. > scanpy==1.6.0 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1295
https://github.com/scverse/scanpy/issues/1295:43,modifiability,Version,Versions,43,"The same error happens to me, @Blohrer . **Versions:**. > scanpy==1.6.0 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1295
https://github.com/scverse/scanpy/issues/1295:9,performance,error,error,9,"The same error happens to me, @Blohrer . **Versions:**. > scanpy==1.6.0 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1295
https://github.com/scverse/scanpy/issues/1295:9,safety,error,error,9,"The same error happens to me, @Blohrer . **Versions:**. > scanpy==1.6.0 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1295
https://github.com/scverse/scanpy/issues/1295:9,usability,error,error,9,"The same error happens to me, @Blohrer . **Versions:**. > scanpy==1.6.0 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1295
https://github.com/scverse/scanpy/issues/1295:147,usability,learn,learn,147,"The same error happens to me, @Blohrer . **Versions:**. > scanpy==1.6.0 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1295
https://github.com/scverse/scanpy/issues/1295:22,availability,error,error,22,"I've encountered this error as well. deleting the raw attributes did not help but what worked was changing the CSR matrix to an array. so `adata.X = adata.X.toarray()`. Hopefully, this will help others.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1295
https://github.com/scverse/scanpy/issues/1295:22,performance,error,error,22,"I've encountered this error as well. deleting the raw attributes did not help but what worked was changing the CSR matrix to an array. so `adata.X = adata.X.toarray()`. Hopefully, this will help others.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1295
https://github.com/scverse/scanpy/issues/1295:22,safety,error,error,22,"I've encountered this error as well. deleting the raw attributes did not help but what worked was changing the CSR matrix to an array. so `adata.X = adata.X.toarray()`. Hopefully, this will help others.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1295
https://github.com/scverse/scanpy/issues/1295:22,usability,error,error,22,"I've encountered this error as well. deleting the raw attributes did not help but what worked was changing the CSR matrix to an array. so `adata.X = adata.X.toarray()`. Hopefully, this will help others.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1295
https://github.com/scverse/scanpy/issues/1295:73,usability,help,help,73,"I've encountered this error as well. deleting the raw attributes did not help but what worked was changing the CSR matrix to an array. so `adata.X = adata.X.toarray()`. Hopefully, this will help others.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1295
https://github.com/scverse/scanpy/issues/1295:190,usability,help,help,190,"I've encountered this error as well. deleting the raw attributes did not help but what worked was changing the CSR matrix to an array. so `adata.X = adata.X.toarray()`. Hopefully, this will help others.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1295
https://github.com/scverse/scanpy/pull/1296:18,deployability,build,build,18,Any ideas why doc build still fails? It should be fixed on master now.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1296
https://github.com/scverse/scanpy/pull/1296:30,deployability,fail,fails,30,Any ideas why doc build still fails? It should be fixed on master now.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1296
https://github.com/scverse/scanpy/pull/1296:30,reliability,fail,fails,30,Any ideas why doc build still fails? It should be fixed on master now.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1296
https://github.com/scverse/scanpy/issues/1298:5,reliability,doe,does,5,"That does seem weird, but I think this is more of an issue with bioconda. Could you open this issue there?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:41,deployability,instal,installing,41,"@pati-ni . I have the similar issue when installing CellRank as `conda install -c bioconda cellrank`. Problem is not all dependencies are on bioconda, some of them are on `conda-forge` - I've tested it and I have the same problem with scanpy. Installing it as `conda install -c bioconda -c conda-forge scanpy` works. But @ivirshup is right, seems like conda issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:71,deployability,instal,install,71,"@pati-ni . I have the similar issue when installing CellRank as `conda install -c bioconda cellrank`. Problem is not all dependencies are on bioconda, some of them are on `conda-forge` - I've tested it and I have the same problem with scanpy. Installing it as `conda install -c bioconda -c conda-forge scanpy` works. But @ivirshup is right, seems like conda issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:121,deployability,depend,dependencies,121,"@pati-ni . I have the similar issue when installing CellRank as `conda install -c bioconda cellrank`. Problem is not all dependencies are on bioconda, some of them are on `conda-forge` - I've tested it and I have the same problem with scanpy. Installing it as `conda install -c bioconda -c conda-forge scanpy` works. But @ivirshup is right, seems like conda issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:243,deployability,Instal,Installing,243,"@pati-ni . I have the similar issue when installing CellRank as `conda install -c bioconda cellrank`. Problem is not all dependencies are on bioconda, some of them are on `conda-forge` - I've tested it and I have the same problem with scanpy. Installing it as `conda install -c bioconda -c conda-forge scanpy` works. But @ivirshup is right, seems like conda issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:267,deployability,instal,install,267,"@pati-ni . I have the similar issue when installing CellRank as `conda install -c bioconda cellrank`. Problem is not all dependencies are on bioconda, some of them are on `conda-forge` - I've tested it and I have the same problem with scanpy. Installing it as `conda install -c bioconda -c conda-forge scanpy` works. But @ivirshup is right, seems like conda issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:121,integrability,depend,dependencies,121,"@pati-ni . I have the similar issue when installing CellRank as `conda install -c bioconda cellrank`. Problem is not all dependencies are on bioconda, some of them are on `conda-forge` - I've tested it and I have the same problem with scanpy. Installing it as `conda install -c bioconda -c conda-forge scanpy` works. But @ivirshup is right, seems like conda issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:121,modifiability,depend,dependencies,121,"@pati-ni . I have the similar issue when installing CellRank as `conda install -c bioconda cellrank`. Problem is not all dependencies are on bioconda, some of them are on `conda-forge` - I've tested it and I have the same problem with scanpy. Installing it as `conda install -c bioconda -c conda-forge scanpy` works. But @ivirshup is right, seems like conda issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:121,safety,depend,dependencies,121,"@pati-ni . I have the similar issue when installing CellRank as `conda install -c bioconda cellrank`. Problem is not all dependencies are on bioconda, some of them are on `conda-forge` - I've tested it and I have the same problem with scanpy. Installing it as `conda install -c bioconda -c conda-forge scanpy` works. But @ivirshup is right, seems like conda issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:192,safety,test,tested,192,"@pati-ni . I have the similar issue when installing CellRank as `conda install -c bioconda cellrank`. Problem is not all dependencies are on bioconda, some of them are on `conda-forge` - I've tested it and I have the same problem with scanpy. Installing it as `conda install -c bioconda -c conda-forge scanpy` works. But @ivirshup is right, seems like conda issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:121,testability,depend,dependencies,121,"@pati-ni . I have the similar issue when installing CellRank as `conda install -c bioconda cellrank`. Problem is not all dependencies are on bioconda, some of them are on `conda-forge` - I've tested it and I have the same problem with scanpy. Installing it as `conda install -c bioconda -c conda-forge scanpy` works. But @ivirshup is right, seems like conda issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:192,testability,test,tested,192,"@pati-ni . I have the similar issue when installing CellRank as `conda install -c bioconda cellrank`. Problem is not all dependencies are on bioconda, some of them are on `conda-forge` - I've tested it and I have the same problem with scanpy. Installing it as `conda install -c bioconda -c conda-forge scanpy` works. But @ivirshup is right, seems like conda issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:110,deployability,instal,installing,110,"I can confirm this as a working workaround. Thank you @michalk8 . > @pati-ni. > I have the similar issue when installing CellRank as `conda install -c bioconda cellrank`. Problem is not all dependencies are on bioconda, some of them are on `conda-forge` - I've tested it and I have the same problem with scanpy. > Installing it as `conda install -c bioconda -c conda-forge scanpy` works. But @ivirshup is right, seems like conda issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:140,deployability,instal,install,140,"I can confirm this as a working workaround. Thank you @michalk8 . > @pati-ni. > I have the similar issue when installing CellRank as `conda install -c bioconda cellrank`. Problem is not all dependencies are on bioconda, some of them are on `conda-forge` - I've tested it and I have the same problem with scanpy. > Installing it as `conda install -c bioconda -c conda-forge scanpy` works. But @ivirshup is right, seems like conda issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:190,deployability,depend,dependencies,190,"I can confirm this as a working workaround. Thank you @michalk8 . > @pati-ni. > I have the similar issue when installing CellRank as `conda install -c bioconda cellrank`. Problem is not all dependencies are on bioconda, some of them are on `conda-forge` - I've tested it and I have the same problem with scanpy. > Installing it as `conda install -c bioconda -c conda-forge scanpy` works. But @ivirshup is right, seems like conda issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:314,deployability,Instal,Installing,314,"I can confirm this as a working workaround. Thank you @michalk8 . > @pati-ni. > I have the similar issue when installing CellRank as `conda install -c bioconda cellrank`. Problem is not all dependencies are on bioconda, some of them are on `conda-forge` - I've tested it and I have the same problem with scanpy. > Installing it as `conda install -c bioconda -c conda-forge scanpy` works. But @ivirshup is right, seems like conda issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:338,deployability,instal,install,338,"I can confirm this as a working workaround. Thank you @michalk8 . > @pati-ni. > I have the similar issue when installing CellRank as `conda install -c bioconda cellrank`. Problem is not all dependencies are on bioconda, some of them are on `conda-forge` - I've tested it and I have the same problem with scanpy. > Installing it as `conda install -c bioconda -c conda-forge scanpy` works. But @ivirshup is right, seems like conda issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:190,integrability,depend,dependencies,190,"I can confirm this as a working workaround. Thank you @michalk8 . > @pati-ni. > I have the similar issue when installing CellRank as `conda install -c bioconda cellrank`. Problem is not all dependencies are on bioconda, some of them are on `conda-forge` - I've tested it and I have the same problem with scanpy. > Installing it as `conda install -c bioconda -c conda-forge scanpy` works. But @ivirshup is right, seems like conda issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:190,modifiability,depend,dependencies,190,"I can confirm this as a working workaround. Thank you @michalk8 . > @pati-ni. > I have the similar issue when installing CellRank as `conda install -c bioconda cellrank`. Problem is not all dependencies are on bioconda, some of them are on `conda-forge` - I've tested it and I have the same problem with scanpy. > Installing it as `conda install -c bioconda -c conda-forge scanpy` works. But @ivirshup is right, seems like conda issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:190,safety,depend,dependencies,190,"I can confirm this as a working workaround. Thank you @michalk8 . > @pati-ni. > I have the similar issue when installing CellRank as `conda install -c bioconda cellrank`. Problem is not all dependencies are on bioconda, some of them are on `conda-forge` - I've tested it and I have the same problem with scanpy. > Installing it as `conda install -c bioconda -c conda-forge scanpy` works. But @ivirshup is right, seems like conda issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:261,safety,test,tested,261,"I can confirm this as a working workaround. Thank you @michalk8 . > @pati-ni. > I have the similar issue when installing CellRank as `conda install -c bioconda cellrank`. Problem is not all dependencies are on bioconda, some of them are on `conda-forge` - I've tested it and I have the same problem with scanpy. > Installing it as `conda install -c bioconda -c conda-forge scanpy` works. But @ivirshup is right, seems like conda issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:190,testability,depend,dependencies,190,"I can confirm this as a working workaround. Thank you @michalk8 . > @pati-ni. > I have the similar issue when installing CellRank as `conda install -c bioconda cellrank`. Problem is not all dependencies are on bioconda, some of them are on `conda-forge` - I've tested it and I have the same problem with scanpy. > Installing it as `conda install -c bioconda -c conda-forge scanpy` works. But @ivirshup is right, seems like conda issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:261,testability,test,tested,261,"I can confirm this as a working workaround. Thank you @michalk8 . > @pati-ni. > I have the similar issue when installing CellRank as `conda install -c bioconda cellrank`. Problem is not all dependencies are on bioconda, some of them are on `conda-forge` - I've tested it and I have the same problem with scanpy. > Installing it as `conda install -c bioconda -c conda-forge scanpy` works. But @ivirshup is right, seems like conda issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:6,usability,confirm,confirm,6,"I can confirm this as a working workaround. Thank you @michalk8 . > @pati-ni. > I have the similar issue when installing CellRank as `conda install -c bioconda cellrank`. Problem is not all dependencies are on bioconda, some of them are on `conda-forge` - I've tested it and I have the same problem with scanpy. > Installing it as `conda install -c bioconda -c conda-forge scanpy` works. But @ivirshup is right, seems like conda issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:192,availability,error,error,192,"Hi there! I am having a similar issue when trying to install Scanpy using conda in Ubuntu. I have uninstalled and installed Anaconda so it is the newest version and still amb getting the same error. Pip install though works well. I was wondering if you could help me with the issue as it is vry interesting for me to install it with conda. The output when installing is the following one:. > Collecting package metadata (current_repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. > Collecting package metadata (repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: - . > Found conflicts! Looking for incompatible packages. > This can take several minutes. Press CTRL-C to abort. > failed . > . > UnsatisfiableError: The following specifications were found to be incompatible with each other:. > . > Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. > . > - feature:/linux-64::__glibc==2.31=0. > - feature:|@/linux-64::__glibc==2.31=0. > . > Your installed version is: 2.31.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:1084,availability,Avail,Available,1084,"Hi there! I am having a similar issue when trying to install Scanpy using conda in Ubuntu. I have uninstalled and installed Anaconda so it is the newest version and still amb getting the same error. Pip install though works well. I was wondering if you could help me with the issue as it is vry interesting for me to install it with conda. The output when installing is the following one:. > Collecting package metadata (current_repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. > Collecting package metadata (repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: - . > Found conflicts! Looking for incompatible packages. > This can take several minutes. Press CTRL-C to abort. > failed . > . > UnsatisfiableError: The following specifications were found to be incompatible with each other:. > . > Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. > . > - feature:/linux-64::__glibc==2.31=0. > - feature:|@/linux-64::__glibc==2.31=0. > . > Your installed version is: 2.31.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:53,deployability,instal,install,53,"Hi there! I am having a similar issue when trying to install Scanpy using conda in Ubuntu. I have uninstalled and installed Anaconda so it is the newest version and still amb getting the same error. Pip install though works well. I was wondering if you could help me with the issue as it is vry interesting for me to install it with conda. The output when installing is the following one:. > Collecting package metadata (current_repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. > Collecting package metadata (repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: - . > Found conflicts! Looking for incompatible packages. > This can take several minutes. Press CTRL-C to abort. > failed . > . > UnsatisfiableError: The following specifications were found to be incompatible with each other:. > . > Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. > . > - feature:/linux-64::__glibc==2.31=0. > - feature:|@/linux-64::__glibc==2.31=0. > . > Your installed version is: 2.31.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:114,deployability,instal,installed,114,"Hi there! I am having a similar issue when trying to install Scanpy using conda in Ubuntu. I have uninstalled and installed Anaconda so it is the newest version and still amb getting the same error. Pip install though works well. I was wondering if you could help me with the issue as it is vry interesting for me to install it with conda. The output when installing is the following one:. > Collecting package metadata (current_repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. > Collecting package metadata (repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: - . > Found conflicts! Looking for incompatible packages. > This can take several minutes. Press CTRL-C to abort. > failed . > . > UnsatisfiableError: The following specifications were found to be incompatible with each other:. > . > Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. > . > - feature:/linux-64::__glibc==2.31=0. > - feature:|@/linux-64::__glibc==2.31=0. > . > Your installed version is: 2.31.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:153,deployability,version,version,153,"Hi there! I am having a similar issue when trying to install Scanpy using conda in Ubuntu. I have uninstalled and installed Anaconda so it is the newest version and still amb getting the same error. Pip install though works well. I was wondering if you could help me with the issue as it is vry interesting for me to install it with conda. The output when installing is the following one:. > Collecting package metadata (current_repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. > Collecting package metadata (repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: - . > Found conflicts! Looking for incompatible packages. > This can take several minutes. Press CTRL-C to abort. > failed . > . > UnsatisfiableError: The following specifications were found to be incompatible with each other:. > . > Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. > . > - feature:/linux-64::__glibc==2.31=0. > - feature:|@/linux-64::__glibc==2.31=0. > . > Your installed version is: 2.31.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:203,deployability,instal,install,203,"Hi there! I am having a similar issue when trying to install Scanpy using conda in Ubuntu. I have uninstalled and installed Anaconda so it is the newest version and still amb getting the same error. Pip install though works well. I was wondering if you could help me with the issue as it is vry interesting for me to install it with conda. The output when installing is the following one:. > Collecting package metadata (current_repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. > Collecting package metadata (repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: - . > Found conflicts! Looking for incompatible packages. > This can take several minutes. Press CTRL-C to abort. > failed . > . > UnsatisfiableError: The following specifications were found to be incompatible with each other:. > . > Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. > . > - feature:/linux-64::__glibc==2.31=0. > - feature:|@/linux-64::__glibc==2.31=0. > . > Your installed version is: 2.31.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:317,deployability,instal,install,317,"Hi there! I am having a similar issue when trying to install Scanpy using conda in Ubuntu. I have uninstalled and installed Anaconda so it is the newest version and still amb getting the same error. Pip install though works well. I was wondering if you could help me with the issue as it is vry interesting for me to install it with conda. The output when installing is the following one:. > Collecting package metadata (current_repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. > Collecting package metadata (repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: - . > Found conflicts! Looking for incompatible packages. > This can take several minutes. Press CTRL-C to abort. > failed . > . > UnsatisfiableError: The following specifications were found to be incompatible with each other:. > . > Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. > . > - feature:/linux-64::__glibc==2.31=0. > - feature:|@/linux-64::__glibc==2.31=0. > . > Your installed version is: 2.31.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:356,deployability,instal,installing,356,"Hi there! I am having a similar issue when trying to install Scanpy using conda in Ubuntu. I have uninstalled and installed Anaconda so it is the newest version and still amb getting the same error. Pip install though works well. I was wondering if you could help me with the issue as it is vry interesting for me to install it with conda. The output when installing is the following one:. > Collecting package metadata (current_repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. > Collecting package metadata (repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: - . > Found conflicts! Looking for incompatible packages. > This can take several minutes. Press CTRL-C to abort. > failed . > . > UnsatisfiableError: The following specifications were found to be incompatible with each other:. > . > Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. > . > - feature:/linux-64::__glibc==2.31=0. > - feature:|@/linux-64::__glibc==2.31=0. > . > Your installed version is: 2.31.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:474,deployability,fail,failed,474,"Hi there! I am having a similar issue when trying to install Scanpy using conda in Ubuntu. I have uninstalled and installed Anaconda so it is the newest version and still amb getting the same error. Pip install though works well. I was wondering if you could help me with the issue as it is vry interesting for me to install it with conda. The output when installing is the following one:. > Collecting package metadata (current_repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. > Collecting package metadata (repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: - . > Found conflicts! Looking for incompatible packages. > This can take several minutes. Press CTRL-C to abort. > failed . > . > UnsatisfiableError: The following specifications were found to be incompatible with each other:. > . > Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. > . > - feature:/linux-64::__glibc==2.31=0. > - feature:|@/linux-64::__glibc==2.31=0. > . > Your installed version is: 2.31.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:561,deployability,fail,failed,561,"Hi there! I am having a similar issue when trying to install Scanpy using conda in Ubuntu. I have uninstalled and installed Anaconda so it is the newest version and still amb getting the same error. Pip install though works well. I was wondering if you could help me with the issue as it is vry interesting for me to install it with conda. The output when installing is the following one:. > Collecting package metadata (current_repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. > Collecting package metadata (repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: - . > Found conflicts! Looking for incompatible packages. > This can take several minutes. Press CTRL-C to abort. > failed . > . > UnsatisfiableError: The following specifications were found to be incompatible with each other:. > . > Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. > . > - feature:/linux-64::__glibc==2.31=0. > - feature:|@/linux-64::__glibc==2.31=0. > . > Your installed version is: 2.31.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:724,deployability,fail,failed,724,"Hi there! I am having a similar issue when trying to install Scanpy using conda in Ubuntu. I have uninstalled and installed Anaconda so it is the newest version and still amb getting the same error. Pip install though works well. I was wondering if you could help me with the issue as it is vry interesting for me to install it with conda. The output when installing is the following one:. > Collecting package metadata (current_repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. > Collecting package metadata (repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: - . > Found conflicts! Looking for incompatible packages. > This can take several minutes. Press CTRL-C to abort. > failed . > . > UnsatisfiableError: The following specifications were found to be incompatible with each other:. > . > Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. > . > - feature:/linux-64::__glibc==2.31=0. > - feature:|@/linux-64::__glibc==2.31=0. > . > Your installed version is: 2.31.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:927,deployability,fail,failed,927,"Hi there! I am having a similar issue when trying to install Scanpy using conda in Ubuntu. I have uninstalled and installed Anaconda so it is the newest version and still amb getting the same error. Pip install though works well. I was wondering if you could help me with the issue as it is vry interesting for me to install it with conda. The output when installing is the following one:. > Collecting package metadata (current_repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. > Collecting package metadata (repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: - . > Found conflicts! Looking for incompatible packages. > This can take several minutes. Press CTRL-C to abort. > failed . > . > UnsatisfiableError: The following specifications were found to be incompatible with each other:. > . > Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. > . > - feature:/linux-64::__glibc==2.31=0. > - feature:|@/linux-64::__glibc==2.31=0. > . > Your installed version is: 2.31.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:1094,deployability,version,versionsThe,1094,"Hi there! I am having a similar issue when trying to install Scanpy using conda in Ubuntu. I have uninstalled and installed Anaconda so it is the newest version and still amb getting the same error. Pip install though works well. I was wondering if you could help me with the issue as it is vry interesting for me to install it with conda. The output when installing is the following one:. > Collecting package metadata (current_repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. > Collecting package metadata (repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: - . > Found conflicts! Looking for incompatible packages. > This can take several minutes. Press CTRL-C to abort. > failed . > . > UnsatisfiableError: The following specifications were found to be incompatible with each other:. > . > Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. > . > - feature:/linux-64::__glibc==2.31=0. > - feature:|@/linux-64::__glibc==2.31=0. > . > Your installed version is: 2.31.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:1277,deployability,instal,installed,1277,"Hi there! I am having a similar issue when trying to install Scanpy using conda in Ubuntu. I have uninstalled and installed Anaconda so it is the newest version and still amb getting the same error. Pip install though works well. I was wondering if you could help me with the issue as it is vry interesting for me to install it with conda. The output when installing is the following one:. > Collecting package metadata (current_repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. > Collecting package metadata (repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: - . > Found conflicts! Looking for incompatible packages. > This can take several minutes. Press CTRL-C to abort. > failed . > . > UnsatisfiableError: The following specifications were found to be incompatible with each other:. > . > Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. > . > - feature:/linux-64::__glibc==2.31=0. > - feature:|@/linux-64::__glibc==2.31=0. > . > Your installed version is: 2.31.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:1287,deployability,version,version,1287,"Hi there! I am having a similar issue when trying to install Scanpy using conda in Ubuntu. I have uninstalled and installed Anaconda so it is the newest version and still amb getting the same error. Pip install though works well. I was wondering if you could help me with the issue as it is vry interesting for me to install it with conda. The output when installing is the following one:. > Collecting package metadata (current_repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. > Collecting package metadata (repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: - . > Found conflicts! Looking for incompatible packages. > This can take several minutes. Press CTRL-C to abort. > failed . > . > UnsatisfiableError: The following specifications were found to be incompatible with each other:. > . > Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. > . > - feature:/linux-64::__glibc==2.31=0. > - feature:|@/linux-64::__glibc==2.31=0. > . > Your installed version is: 2.31.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:153,integrability,version,version,153,"Hi there! I am having a similar issue when trying to install Scanpy using conda in Ubuntu. I have uninstalled and installed Anaconda so it is the newest version and still amb getting the same error. Pip install though works well. I was wondering if you could help me with the issue as it is vry interesting for me to install it with conda. The output when installing is the following one:. > Collecting package metadata (current_repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. > Collecting package metadata (repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: - . > Found conflicts! Looking for incompatible packages. > This can take several minutes. Press CTRL-C to abort. > failed . > . > UnsatisfiableError: The following specifications were found to be incompatible with each other:. > . > Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. > . > - feature:/linux-64::__glibc==2.31=0. > - feature:|@/linux-64::__glibc==2.31=0. > . > Your installed version is: 2.31.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:1094,integrability,version,versionsThe,1094,"Hi there! I am having a similar issue when trying to install Scanpy using conda in Ubuntu. I have uninstalled and installed Anaconda so it is the newest version and still amb getting the same error. Pip install though works well. I was wondering if you could help me with the issue as it is vry interesting for me to install it with conda. The output when installing is the following one:. > Collecting package metadata (current_repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. > Collecting package metadata (repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: - . > Found conflicts! Looking for incompatible packages. > This can take several minutes. Press CTRL-C to abort. > failed . > . > UnsatisfiableError: The following specifications were found to be incompatible with each other:. > . > Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. > . > - feature:/linux-64::__glibc==2.31=0. > - feature:|@/linux-64::__glibc==2.31=0. > . > Your installed version is: 2.31.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:1287,integrability,version,version,1287,"Hi there! I am having a similar issue when trying to install Scanpy using conda in Ubuntu. I have uninstalled and installed Anaconda so it is the newest version and still amb getting the same error. Pip install though works well. I was wondering if you could help me with the issue as it is vry interesting for me to install it with conda. The output when installing is the following one:. > Collecting package metadata (current_repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. > Collecting package metadata (repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: - . > Found conflicts! Looking for incompatible packages. > This can take several minutes. Press CTRL-C to abort. > failed . > . > UnsatisfiableError: The following specifications were found to be incompatible with each other:. > . > Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. > . > - feature:/linux-64::__glibc==2.31=0. > - feature:|@/linux-64::__glibc==2.31=0. > . > Your installed version is: 2.31.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:823,interoperability,conflict,conflicts,823,"Hi there! I am having a similar issue when trying to install Scanpy using conda in Ubuntu. I have uninstalled and installed Anaconda so it is the newest version and still amb getting the same error. Pip install though works well. I was wondering if you could help me with the issue as it is vry interesting for me to install it with conda. The output when installing is the following one:. > Collecting package metadata (current_repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. > Collecting package metadata (repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: - . > Found conflicts! Looking for incompatible packages. > This can take several minutes. Press CTRL-C to abort. > failed . > . > UnsatisfiableError: The following specifications were found to be incompatible with each other:. > . > Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. > . > - feature:/linux-64::__glibc==2.31=0. > - feature:|@/linux-64::__glibc==2.31=0. > . > Your installed version is: 2.31.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:846,interoperability,incompatib,incompatible,846,"Hi there! I am having a similar issue when trying to install Scanpy using conda in Ubuntu. I have uninstalled and installed Anaconda so it is the newest version and still amb getting the same error. Pip install though works well. I was wondering if you could help me with the issue as it is vry interesting for me to install it with conda. The output when installing is the following one:. > Collecting package metadata (current_repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. > Collecting package metadata (repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: - . > Found conflicts! Looking for incompatible packages. > This can take several minutes. Press CTRL-C to abort. > failed . > . > UnsatisfiableError: The following specifications were found to be incompatible with each other:. > . > Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. > . > - feature:/linux-64::__glibc==2.31=0. > - feature:|@/linux-64::__glibc==2.31=0. > . > Your installed version is: 2.31.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:976,interoperability,specif,specifications,976,"Hi there! I am having a similar issue when trying to install Scanpy using conda in Ubuntu. I have uninstalled and installed Anaconda so it is the newest version and still amb getting the same error. Pip install though works well. I was wondering if you could help me with the issue as it is vry interesting for me to install it with conda. The output when installing is the following one:. > Collecting package metadata (current_repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. > Collecting package metadata (repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: - . > Found conflicts! Looking for incompatible packages. > This can take several minutes. Press CTRL-C to abort. > failed . > . > UnsatisfiableError: The following specifications were found to be incompatible with each other:. > . > Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. > . > - feature:/linux-64::__glibc==2.31=0. > - feature:|@/linux-64::__glibc==2.31=0. > . > Your installed version is: 2.31.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:1008,interoperability,incompatib,incompatible,1008,"Hi there! I am having a similar issue when trying to install Scanpy using conda in Ubuntu. I have uninstalled and installed Anaconda so it is the newest version and still amb getting the same error. Pip install though works well. I was wondering if you could help me with the issue as it is vry interesting for me to install it with conda. The output when installing is the following one:. > Collecting package metadata (current_repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. > Collecting package metadata (repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: - . > Found conflicts! Looking for incompatible packages. > This can take several minutes. Press CTRL-C to abort. > failed . > . > UnsatisfiableError: The following specifications were found to be incompatible with each other:. > . > Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. > . > - feature:/linux-64::__glibc==2.31=0. > - feature:|@/linux-64::__glibc==2.31=0. > . > Your installed version is: 2.31.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:1055,interoperability,format,format,1055,"Hi there! I am having a similar issue when trying to install Scanpy using conda in Ubuntu. I have uninstalled and installed Anaconda so it is the newest version and still amb getting the same error. Pip install though works well. I was wondering if you could help me with the issue as it is vry interesting for me to install it with conda. The output when installing is the following one:. > Collecting package metadata (current_repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. > Collecting package metadata (repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: - . > Found conflicts! Looking for incompatible packages. > This can take several minutes. Press CTRL-C to abort. > failed . > . > UnsatisfiableError: The following specifications were found to be incompatible with each other:. > . > Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. > . > - feature:/linux-64::__glibc==2.31=0. > - feature:|@/linux-64::__glibc==2.31=0. > . > Your installed version is: 2.31.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:1116,interoperability,specif,specifications,1116,"Hi there! I am having a similar issue when trying to install Scanpy using conda in Ubuntu. I have uninstalled and installed Anaconda so it is the newest version and still amb getting the same error. Pip install though works well. I was wondering if you could help me with the issue as it is vry interesting for me to install it with conda. The output when installing is the following one:. > Collecting package metadata (current_repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. > Collecting package metadata (repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: - . > Found conflicts! Looking for incompatible packages. > This can take several minutes. Press CTRL-C to abort. > failed . > . > UnsatisfiableError: The following specifications were found to be incompatible with each other:. > . > Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. > . > - feature:/linux-64::__glibc==2.31=0. > - feature:|@/linux-64::__glibc==2.31=0. > . > Your installed version is: 2.31.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:1148,interoperability,incompatib,incompatible,1148,"Hi there! I am having a similar issue when trying to install Scanpy using conda in Ubuntu. I have uninstalled and installed Anaconda so it is the newest version and still amb getting the same error. Pip install though works well. I was wondering if you could help me with the issue as it is vry interesting for me to install it with conda. The output when installing is the following one:. > Collecting package metadata (current_repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. > Collecting package metadata (repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: - . > Found conflicts! Looking for incompatible packages. > This can take several minutes. Press CTRL-C to abort. > failed . > . > UnsatisfiableError: The following specifications were found to be incompatible with each other:. > . > Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. > . > - feature:/linux-64::__glibc==2.31=0. > - feature:|@/linux-64::__glibc==2.31=0. > . > Your installed version is: 2.31.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:153,modifiability,version,version,153,"Hi there! I am having a similar issue when trying to install Scanpy using conda in Ubuntu. I have uninstalled and installed Anaconda so it is the newest version and still amb getting the same error. Pip install though works well. I was wondering if you could help me with the issue as it is vry interesting for me to install it with conda. The output when installing is the following one:. > Collecting package metadata (current_repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. > Collecting package metadata (repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: - . > Found conflicts! Looking for incompatible packages. > This can take several minutes. Press CTRL-C to abort. > failed . > . > UnsatisfiableError: The following specifications were found to be incompatible with each other:. > . > Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. > . > - feature:/linux-64::__glibc==2.31=0. > - feature:|@/linux-64::__glibc==2.31=0. > . > Your installed version is: 2.31.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:403,modifiability,pac,package,403,"Hi there! I am having a similar issue when trying to install Scanpy using conda in Ubuntu. I have uninstalled and installed Anaconda so it is the newest version and still amb getting the same error. Pip install though works well. I was wondering if you could help me with the issue as it is vry interesting for me to install it with conda. The output when installing is the following one:. > Collecting package metadata (current_repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. > Collecting package metadata (repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: - . > Found conflicts! Looking for incompatible packages. > This can take several minutes. Press CTRL-C to abort. > failed . > . > UnsatisfiableError: The following specifications were found to be incompatible with each other:. > . > Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. > . > - feature:/linux-64::__glibc==2.31=0. > - feature:|@/linux-64::__glibc==2.31=0. > . > Your installed version is: 2.31.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:661,modifiability,pac,package,661,"Hi there! I am having a similar issue when trying to install Scanpy using conda in Ubuntu. I have uninstalled and installed Anaconda so it is the newest version and still amb getting the same error. Pip install though works well. I was wondering if you could help me with the issue as it is vry interesting for me to install it with conda. The output when installing is the following one:. > Collecting package metadata (current_repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. > Collecting package metadata (repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: - . > Found conflicts! Looking for incompatible packages. > This can take several minutes. Press CTRL-C to abort. > failed . > . > UnsatisfiableError: The following specifications were found to be incompatible with each other:. > . > Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. > . > - feature:/linux-64::__glibc==2.31=0. > - feature:|@/linux-64::__glibc==2.31=0. > . > Your installed version is: 2.31.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:859,modifiability,pac,packages,859,"Hi there! I am having a similar issue when trying to install Scanpy using conda in Ubuntu. I have uninstalled and installed Anaconda so it is the newest version and still amb getting the same error. Pip install though works well. I was wondering if you could help me with the issue as it is vry interesting for me to install it with conda. The output when installing is the following one:. > Collecting package metadata (current_repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. > Collecting package metadata (repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: - . > Found conflicts! Looking for incompatible packages. > This can take several minutes. Press CTRL-C to abort. > failed . > . > UnsatisfiableError: The following specifications were found to be incompatible with each other:. > . > Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. > . > - feature:/linux-64::__glibc==2.31=0. > - feature:|@/linux-64::__glibc==2.31=0. > . > Your installed version is: 2.31.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:1073,modifiability,pac,package,1073,"Hi there! I am having a similar issue when trying to install Scanpy using conda in Ubuntu. I have uninstalled and installed Anaconda so it is the newest version and still amb getting the same error. Pip install though works well. I was wondering if you could help me with the issue as it is vry interesting for me to install it with conda. The output when installing is the following one:. > Collecting package metadata (current_repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. > Collecting package metadata (repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: - . > Found conflicts! Looking for incompatible packages. > This can take several minutes. Press CTRL-C to abort. > failed . > . > UnsatisfiableError: The following specifications were found to be incompatible with each other:. > . > Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. > . > - feature:/linux-64::__glibc==2.31=0. > - feature:|@/linux-64::__glibc==2.31=0. > . > Your installed version is: 2.31.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:1094,modifiability,version,versionsThe,1094,"Hi there! I am having a similar issue when trying to install Scanpy using conda in Ubuntu. I have uninstalled and installed Anaconda so it is the newest version and still amb getting the same error. Pip install though works well. I was wondering if you could help me with the issue as it is vry interesting for me to install it with conda. The output when installing is the following one:. > Collecting package metadata (current_repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. > Collecting package metadata (repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: - . > Found conflicts! Looking for incompatible packages. > This can take several minutes. Press CTRL-C to abort. > failed . > . > UnsatisfiableError: The following specifications were found to be incompatible with each other:. > . > Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. > . > - feature:/linux-64::__glibc==2.31=0. > - feature:|@/linux-64::__glibc==2.31=0. > . > Your installed version is: 2.31.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:1287,modifiability,version,version,1287,"Hi there! I am having a similar issue when trying to install Scanpy using conda in Ubuntu. I have uninstalled and installed Anaconda so it is the newest version and still amb getting the same error. Pip install though works well. I was wondering if you could help me with the issue as it is vry interesting for me to install it with conda. The output when installing is the following one:. > Collecting package metadata (current_repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. > Collecting package metadata (repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: - . > Found conflicts! Looking for incompatible packages. > This can take several minutes. Press CTRL-C to abort. > failed . > . > UnsatisfiableError: The following specifications were found to be incompatible with each other:. > . > Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. > . > - feature:/linux-64::__glibc==2.31=0. > - feature:|@/linux-64::__glibc==2.31=0. > . > Your installed version is: 2.31.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:192,performance,error,error,192,"Hi there! I am having a similar issue when trying to install Scanpy using conda in Ubuntu. I have uninstalled and installed Anaconda so it is the newest version and still amb getting the same error. Pip install though works well. I was wondering if you could help me with the issue as it is vry interesting for me to install it with conda. The output when installing is the following one:. > Collecting package metadata (current_repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. > Collecting package metadata (repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: - . > Found conflicts! Looking for incompatible packages. > This can take several minutes. Press CTRL-C to abort. > failed . > . > UnsatisfiableError: The following specifications were found to be incompatible with each other:. > . > Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. > . > - feature:/linux-64::__glibc==2.31=0. > - feature:|@/linux-64::__glibc==2.31=0. > . > Your installed version is: 2.31.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:474,reliability,fail,failed,474,"Hi there! I am having a similar issue when trying to install Scanpy using conda in Ubuntu. I have uninstalled and installed Anaconda so it is the newest version and still amb getting the same error. Pip install though works well. I was wondering if you could help me with the issue as it is vry interesting for me to install it with conda. The output when installing is the following one:. > Collecting package metadata (current_repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. > Collecting package metadata (repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: - . > Found conflicts! Looking for incompatible packages. > This can take several minutes. Press CTRL-C to abort. > failed . > . > UnsatisfiableError: The following specifications were found to be incompatible with each other:. > . > Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. > . > - feature:/linux-64::__glibc==2.31=0. > - feature:|@/linux-64::__glibc==2.31=0. > . > Your installed version is: 2.31.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:561,reliability,fail,failed,561,"Hi there! I am having a similar issue when trying to install Scanpy using conda in Ubuntu. I have uninstalled and installed Anaconda so it is the newest version and still amb getting the same error. Pip install though works well. I was wondering if you could help me with the issue as it is vry interesting for me to install it with conda. The output when installing is the following one:. > Collecting package metadata (current_repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. > Collecting package metadata (repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: - . > Found conflicts! Looking for incompatible packages. > This can take several minutes. Press CTRL-C to abort. > failed . > . > UnsatisfiableError: The following specifications were found to be incompatible with each other:. > . > Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. > . > - feature:/linux-64::__glibc==2.31=0. > - feature:|@/linux-64::__glibc==2.31=0. > . > Your installed version is: 2.31.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:724,reliability,fail,failed,724,"Hi there! I am having a similar issue when trying to install Scanpy using conda in Ubuntu. I have uninstalled and installed Anaconda so it is the newest version and still amb getting the same error. Pip install though works well. I was wondering if you could help me with the issue as it is vry interesting for me to install it with conda. The output when installing is the following one:. > Collecting package metadata (current_repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. > Collecting package metadata (repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: - . > Found conflicts! Looking for incompatible packages. > This can take several minutes. Press CTRL-C to abort. > failed . > . > UnsatisfiableError: The following specifications were found to be incompatible with each other:. > . > Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. > . > - feature:/linux-64::__glibc==2.31=0. > - feature:|@/linux-64::__glibc==2.31=0. > . > Your installed version is: 2.31.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:927,reliability,fail,failed,927,"Hi there! I am having a similar issue when trying to install Scanpy using conda in Ubuntu. I have uninstalled and installed Anaconda so it is the newest version and still amb getting the same error. Pip install though works well. I was wondering if you could help me with the issue as it is vry interesting for me to install it with conda. The output when installing is the following one:. > Collecting package metadata (current_repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. > Collecting package metadata (repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: - . > Found conflicts! Looking for incompatible packages. > This can take several minutes. Press CTRL-C to abort. > failed . > . > UnsatisfiableError: The following specifications were found to be incompatible with each other:. > . > Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. > . > - feature:/linux-64::__glibc==2.31=0. > - feature:|@/linux-64::__glibc==2.31=0. > . > Your installed version is: 2.31.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:1084,reliability,Availab,Available,1084,"Hi there! I am having a similar issue when trying to install Scanpy using conda in Ubuntu. I have uninstalled and installed Anaconda so it is the newest version and still amb getting the same error. Pip install though works well. I was wondering if you could help me with the issue as it is vry interesting for me to install it with conda. The output when installing is the following one:. > Collecting package metadata (current_repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. > Collecting package metadata (repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: - . > Found conflicts! Looking for incompatible packages. > This can take several minutes. Press CTRL-C to abort. > failed . > . > UnsatisfiableError: The following specifications were found to be incompatible with each other:. > . > Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. > . > - feature:/linux-64::__glibc==2.31=0. > - feature:|@/linux-64::__glibc==2.31=0. > . > Your installed version is: 2.31.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:192,safety,error,error,192,"Hi there! I am having a similar issue when trying to install Scanpy using conda in Ubuntu. I have uninstalled and installed Anaconda so it is the newest version and still amb getting the same error. Pip install though works well. I was wondering if you could help me with the issue as it is vry interesting for me to install it with conda. The output when installing is the following one:. > Collecting package metadata (current_repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. > Collecting package metadata (repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: - . > Found conflicts! Looking for incompatible packages. > This can take several minutes. Press CTRL-C to abort. > failed . > . > UnsatisfiableError: The following specifications were found to be incompatible with each other:. > . > Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. > . > - feature:/linux-64::__glibc==2.31=0. > - feature:|@/linux-64::__glibc==2.31=0. > . > Your installed version is: 2.31.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:1084,safety,Avail,Available,1084,"Hi there! I am having a similar issue when trying to install Scanpy using conda in Ubuntu. I have uninstalled and installed Anaconda so it is the newest version and still amb getting the same error. Pip install though works well. I was wondering if you could help me with the issue as it is vry interesting for me to install it with conda. The output when installing is the following one:. > Collecting package metadata (current_repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. > Collecting package metadata (repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: - . > Found conflicts! Looking for incompatible packages. > This can take several minutes. Press CTRL-C to abort. > failed . > . > UnsatisfiableError: The following specifications were found to be incompatible with each other:. > . > Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. > . > - feature:/linux-64::__glibc==2.31=0. > - feature:|@/linux-64::__glibc==2.31=0. > . > Your installed version is: 2.31.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:1084,security,Availab,Available,1084,"Hi there! I am having a similar issue when trying to install Scanpy using conda in Ubuntu. I have uninstalled and installed Anaconda so it is the newest version and still amb getting the same error. Pip install though works well. I was wondering if you could help me with the issue as it is vry interesting for me to install it with conda. The output when installing is the following one:. > Collecting package metadata (current_repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. > Collecting package metadata (repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: - . > Found conflicts! Looking for incompatible packages. > This can take several minutes. Press CTRL-C to abort. > failed . > . > UnsatisfiableError: The following specifications were found to be incompatible with each other:. > . > Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. > . > - feature:/linux-64::__glibc==2.31=0. > - feature:|@/linux-64::__glibc==2.31=0. > . > Your installed version is: 2.31.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:192,usability,error,error,192,"Hi there! I am having a similar issue when trying to install Scanpy using conda in Ubuntu. I have uninstalled and installed Anaconda so it is the newest version and still amb getting the same error. Pip install though works well. I was wondering if you could help me with the issue as it is vry interesting for me to install it with conda. The output when installing is the following one:. > Collecting package metadata (current_repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. > Collecting package metadata (repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: - . > Found conflicts! Looking for incompatible packages. > This can take several minutes. Press CTRL-C to abort. > failed . > . > UnsatisfiableError: The following specifications were found to be incompatible with each other:. > . > Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. > . > - feature:/linux-64::__glibc==2.31=0. > - feature:|@/linux-64::__glibc==2.31=0. > . > Your installed version is: 2.31.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:259,usability,help,help,259,"Hi there! I am having a similar issue when trying to install Scanpy using conda in Ubuntu. I have uninstalled and installed Anaconda so it is the newest version and still amb getting the same error. Pip install though works well. I was wondering if you could help me with the issue as it is vry interesting for me to install it with conda. The output when installing is the following one:. > Collecting package metadata (current_repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. > Collecting package metadata (repodata.json): done. > Solving environment: failed with initial frozen solve. Retrying with flexible solve. > Solving environment: - . > Found conflicts! Looking for incompatible packages. > This can take several minutes. Press CTRL-C to abort. > failed . > . > UnsatisfiableError: The following specifications were found to be incompatible with each other:. > . > Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. > . > - feature:/linux-64::__glibc==2.31=0. > - feature:|@/linux-64::__glibc==2.31=0. > . > Your installed version is: 2.31.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:146,deployability,instal,install,146,"What command are you running? You might be running into the fact that we no longer put scanpy on bioconda, but instead use conda-forge. So `conda install -c conda-forge scanpy` should work.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:5,usability,command,command,5,"What command are you running? You might be running into the fact that we no longer put scanpy on bioconda, but instead use conda-forge. So `conda install -c conda-forge scanpy` should work.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1299:21,deployability,instal,install,21,"aha, sorry, I didn't install the 'fa2' package.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1299
https://github.com/scverse/scanpy/issues/1299:39,modifiability,pac,package,39,"aha, sorry, I didn't install the 'fa2' package.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1299
https://github.com/scverse/scanpy/issues/1300:22,availability,down,downgrade,22,A temporary fix is to downgrade scipy to 1.4.1.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1300
https://github.com/scverse/scanpy/issues/1300:136,usability,learn,learn,136,"I could not reproduce this bug, I am using . `scanpy==1.5.1 anndata==0.7.4 umap==0.3.10 numpy==1.19.2 scipy==1.5.2 pandas==1.1.2 scikit-learn==0.23.2 statsmodels==0.12.0 python-igraph==0.8.2 louvain==0.6.1 leidenalg==0.7.0`. @giovp maybe be a good idea to close this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1300
https://github.com/scverse/scanpy/issues/1300:256,usability,close,close,256,"I could not reproduce this bug, I am using . `scanpy==1.5.1 anndata==0.7.4 umap==0.3.10 numpy==1.19.2 scipy==1.5.2 pandas==1.1.2 scikit-learn==0.23.2 statsmodels==0.12.0 python-igraph==0.8.2 louvain==0.6.1 leidenalg==0.7.0`. @giovp maybe be a good idea to close this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1300
https://github.com/scverse/scanpy/issues/1300:7,usability,close,close,7,"I will close this for now, @letaylor feel free to open this issue again if you have still problems or any suggestions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1300
https://github.com/scverse/scanpy/issues/1301:80,modifiability,layer,layers,80,"Hi, you can also do this directly. `adata.obsm[""mylayer_pca""] = sc.tl.pca(adata.layers[""mylayer""])`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1301
https://github.com/scverse/scanpy/issues/1301:155,deployability,observ,observation,155,"I would also like this, and will probably add it. The only issue is deciding how we name each element `pca` adds to an `anndata` object (i.e. the keys for observation loadings in `obsm`, variable loadings in `varm`, and metadata in `uns`. I'd thought of two options:. * `sc.pp.pca(adata, layer=layer, key_added=key)`. * Adds key `key` to `obsm`, `varm`, and `uns`. * Makes it very easy to know which arrays match which. * `sc.pp.pca(adata, layer=layer, key_prefix=prefix)`. * Adds `{prefix}_pca` to `obsm`, `{prefix}_PCs` to `varm`, and something like `prefix` to `uns`. * Makes it clearer how the arrays should be interpreted. Sorta fits current behaviour better.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1301
https://github.com/scverse/scanpy/issues/1301:167,energy efficiency,load,loadings,167,"I would also like this, and will probably add it. The only issue is deciding how we name each element `pca` adds to an `anndata` object (i.e. the keys for observation loadings in `obsm`, variable loadings in `varm`, and metadata in `uns`. I'd thought of two options:. * `sc.pp.pca(adata, layer=layer, key_added=key)`. * Adds key `key` to `obsm`, `varm`, and `uns`. * Makes it very easy to know which arrays match which. * `sc.pp.pca(adata, layer=layer, key_prefix=prefix)`. * Adds `{prefix}_pca` to `obsm`, `{prefix}_PCs` to `varm`, and something like `prefix` to `uns`. * Makes it clearer how the arrays should be interpreted. Sorta fits current behaviour better.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1301
https://github.com/scverse/scanpy/issues/1301:196,energy efficiency,load,loadings,196,"I would also like this, and will probably add it. The only issue is deciding how we name each element `pca` adds to an `anndata` object (i.e. the keys for observation loadings in `obsm`, variable loadings in `varm`, and metadata in `uns`. I'd thought of two options:. * `sc.pp.pca(adata, layer=layer, key_added=key)`. * Adds key `key` to `obsm`, `varm`, and `uns`. * Makes it very easy to know which arrays match which. * `sc.pp.pca(adata, layer=layer, key_prefix=prefix)`. * Adds `{prefix}_pca` to `obsm`, `{prefix}_PCs` to `varm`, and something like `prefix` to `uns`. * Makes it clearer how the arrays should be interpreted. Sorta fits current behaviour better.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1301
https://github.com/scverse/scanpy/issues/1301:639,energy efficiency,current,current,639,"I would also like this, and will probably add it. The only issue is deciding how we name each element `pca` adds to an `anndata` object (i.e. the keys for observation loadings in `obsm`, variable loadings in `varm`, and metadata in `uns`. I'd thought of two options:. * `sc.pp.pca(adata, layer=layer, key_added=key)`. * Adds key `key` to `obsm`, `varm`, and `uns`. * Makes it very easy to know which arrays match which. * `sc.pp.pca(adata, layer=layer, key_prefix=prefix)`. * Adds `{prefix}_pca` to `obsm`, `{prefix}_PCs` to `varm`, and something like `prefix` to `uns`. * Makes it clearer how the arrays should be interpreted. Sorta fits current behaviour better.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1301
https://github.com/scverse/scanpy/issues/1301:187,modifiability,variab,variable,187,"I would also like this, and will probably add it. The only issue is deciding how we name each element `pca` adds to an `anndata` object (i.e. the keys for observation loadings in `obsm`, variable loadings in `varm`, and metadata in `uns`. I'd thought of two options:. * `sc.pp.pca(adata, layer=layer, key_added=key)`. * Adds key `key` to `obsm`, `varm`, and `uns`. * Makes it very easy to know which arrays match which. * `sc.pp.pca(adata, layer=layer, key_prefix=prefix)`. * Adds `{prefix}_pca` to `obsm`, `{prefix}_PCs` to `varm`, and something like `prefix` to `uns`. * Makes it clearer how the arrays should be interpreted. Sorta fits current behaviour better.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1301
https://github.com/scverse/scanpy/issues/1301:288,modifiability,layer,layer,288,"I would also like this, and will probably add it. The only issue is deciding how we name each element `pca` adds to an `anndata` object (i.e. the keys for observation loadings in `obsm`, variable loadings in `varm`, and metadata in `uns`. I'd thought of two options:. * `sc.pp.pca(adata, layer=layer, key_added=key)`. * Adds key `key` to `obsm`, `varm`, and `uns`. * Makes it very easy to know which arrays match which. * `sc.pp.pca(adata, layer=layer, key_prefix=prefix)`. * Adds `{prefix}_pca` to `obsm`, `{prefix}_PCs` to `varm`, and something like `prefix` to `uns`. * Makes it clearer how the arrays should be interpreted. Sorta fits current behaviour better.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1301
https://github.com/scverse/scanpy/issues/1301:294,modifiability,layer,layer,294,"I would also like this, and will probably add it. The only issue is deciding how we name each element `pca` adds to an `anndata` object (i.e. the keys for observation loadings in `obsm`, variable loadings in `varm`, and metadata in `uns`. I'd thought of two options:. * `sc.pp.pca(adata, layer=layer, key_added=key)`. * Adds key `key` to `obsm`, `varm`, and `uns`. * Makes it very easy to know which arrays match which. * `sc.pp.pca(adata, layer=layer, key_prefix=prefix)`. * Adds `{prefix}_pca` to `obsm`, `{prefix}_PCs` to `varm`, and something like `prefix` to `uns`. * Makes it clearer how the arrays should be interpreted. Sorta fits current behaviour better.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1301
https://github.com/scverse/scanpy/issues/1301:440,modifiability,layer,layer,440,"I would also like this, and will probably add it. The only issue is deciding how we name each element `pca` adds to an `anndata` object (i.e. the keys for observation loadings in `obsm`, variable loadings in `varm`, and metadata in `uns`. I'd thought of two options:. * `sc.pp.pca(adata, layer=layer, key_added=key)`. * Adds key `key` to `obsm`, `varm`, and `uns`. * Makes it very easy to know which arrays match which. * `sc.pp.pca(adata, layer=layer, key_prefix=prefix)`. * Adds `{prefix}_pca` to `obsm`, `{prefix}_PCs` to `varm`, and something like `prefix` to `uns`. * Makes it clearer how the arrays should be interpreted. Sorta fits current behaviour better.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1301
https://github.com/scverse/scanpy/issues/1301:446,modifiability,layer,layer,446,"I would also like this, and will probably add it. The only issue is deciding how we name each element `pca` adds to an `anndata` object (i.e. the keys for observation loadings in `obsm`, variable loadings in `varm`, and metadata in `uns`. I'd thought of two options:. * `sc.pp.pca(adata, layer=layer, key_added=key)`. * Adds key `key` to `obsm`, `varm`, and `uns`. * Makes it very easy to know which arrays match which. * `sc.pp.pca(adata, layer=layer, key_prefix=prefix)`. * Adds `{prefix}_pca` to `obsm`, `{prefix}_PCs` to `varm`, and something like `prefix` to `uns`. * Makes it clearer how the arrays should be interpreted. Sorta fits current behaviour better.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1301
https://github.com/scverse/scanpy/issues/1301:167,performance,load,loadings,167,"I would also like this, and will probably add it. The only issue is deciding how we name each element `pca` adds to an `anndata` object (i.e. the keys for observation loadings in `obsm`, variable loadings in `varm`, and metadata in `uns`. I'd thought of two options:. * `sc.pp.pca(adata, layer=layer, key_added=key)`. * Adds key `key` to `obsm`, `varm`, and `uns`. * Makes it very easy to know which arrays match which. * `sc.pp.pca(adata, layer=layer, key_prefix=prefix)`. * Adds `{prefix}_pca` to `obsm`, `{prefix}_PCs` to `varm`, and something like `prefix` to `uns`. * Makes it clearer how the arrays should be interpreted. Sorta fits current behaviour better.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1301
https://github.com/scverse/scanpy/issues/1301:196,performance,load,loadings,196,"I would also like this, and will probably add it. The only issue is deciding how we name each element `pca` adds to an `anndata` object (i.e. the keys for observation loadings in `obsm`, variable loadings in `varm`, and metadata in `uns`. I'd thought of two options:. * `sc.pp.pca(adata, layer=layer, key_added=key)`. * Adds key `key` to `obsm`, `varm`, and `uns`. * Makes it very easy to know which arrays match which. * `sc.pp.pca(adata, layer=layer, key_prefix=prefix)`. * Adds `{prefix}_pca` to `obsm`, `{prefix}_PCs` to `varm`, and something like `prefix` to `uns`. * Makes it clearer how the arrays should be interpreted. Sorta fits current behaviour better.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1301
https://github.com/scverse/scanpy/issues/1301:155,testability,observ,observation,155,"I would also like this, and will probably add it. The only issue is deciding how we name each element `pca` adds to an `anndata` object (i.e. the keys for observation loadings in `obsm`, variable loadings in `varm`, and metadata in `uns`. I'd thought of two options:. * `sc.pp.pca(adata, layer=layer, key_added=key)`. * Adds key `key` to `obsm`, `varm`, and `uns`. * Makes it very easy to know which arrays match which. * `sc.pp.pca(adata, layer=layer, key_prefix=prefix)`. * Adds `{prefix}_pca` to `obsm`, `{prefix}_PCs` to `varm`, and something like `prefix` to `uns`. * Makes it clearer how the arrays should be interpreted. Sorta fits current behaviour better.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1301
https://github.com/scverse/scanpy/issues/1301:582,usability,clear,clearer,582,"I would also like this, and will probably add it. The only issue is deciding how we name each element `pca` adds to an `anndata` object (i.e. the keys for observation loadings in `obsm`, variable loadings in `varm`, and metadata in `uns`. I'd thought of two options:. * `sc.pp.pca(adata, layer=layer, key_added=key)`. * Adds key `key` to `obsm`, `varm`, and `uns`. * Makes it very easy to know which arrays match which. * `sc.pp.pca(adata, layer=layer, key_prefix=prefix)`. * Adds `{prefix}_pca` to `obsm`, `{prefix}_PCs` to `varm`, and something like `prefix` to `uns`. * Makes it clearer how the arrays should be interpreted. Sorta fits current behaviour better.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1301
https://github.com/scverse/scanpy/issues/1301:647,usability,behavi,behaviour,647,"I would also like this, and will probably add it. The only issue is deciding how we name each element `pca` adds to an `anndata` object (i.e. the keys for observation loadings in `obsm`, variable loadings in `varm`, and metadata in `uns`. I'd thought of two options:. * `sc.pp.pca(adata, layer=layer, key_added=key)`. * Adds key `key` to `obsm`, `varm`, and `uns`. * Makes it very easy to know which arrays match which. * `sc.pp.pca(adata, layer=layer, key_prefix=prefix)`. * Adds `{prefix}_pca` to `obsm`, `{prefix}_PCs` to `varm`, and something like `prefix` to `uns`. * Makes it clearer how the arrays should be interpreted. Sorta fits current behaviour better.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1301
https://github.com/scverse/scanpy/issues/1301:13,deployability,updat,update,13,Is there any update on the progress of this?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1301
https://github.com/scverse/scanpy/issues/1301:13,safety,updat,update,13,Is there any update on the progress of this?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1301
https://github.com/scverse/scanpy/issues/1301:13,security,updat,update,13,Is there any update on the progress of this?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1301
https://github.com/scverse/scanpy/issues/1301:27,usability,progress,progress,27,Is there any update on the progress of this?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1301
https://github.com/scverse/scanpy/issues/1301:39,modifiability,layer,layers,39,"Recently I need to run PCA on multiple layers of AnnData. If no one is working on this, I can work on a pull request for this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1301
https://github.com/scverse/scanpy/issues/1301:57,usability,close,close,57,Looks like it was added in b7e599a. We should be able to close this in 1.11 then!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1301
https://github.com/scverse/scanpy/issues/1302:125,deployability,instal,installed,125,Are you sure you haven't set wxpython as the matplotlib backend somehow? Many of us use scanpy on macOS but I never manually installed wxpython...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1302
https://github.com/scverse/scanpy/issues/1302:53,deployability,instal,install,53,"Thanks, what is the default backend on macOS? I only install matplotlib via the scanpy/anndata depenancies in a conda environment (and `MPLBACKEND` is unset). Upon installing wxpython, I can confirm the used backend. ```. >>> matplotlib.__version__. '3.2.2'. >>> matplotlib.rcParams['backend']. 'WXAgg'. >>> matplotlib.get_backend(). 'WXAgg'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1302
https://github.com/scverse/scanpy/issues/1302:164,deployability,instal,installing,164,"Thanks, what is the default backend on macOS? I only install matplotlib via the scanpy/anndata depenancies in a conda environment (and `MPLBACKEND` is unset). Upon installing wxpython, I can confirm the used backend. ```. >>> matplotlib.__version__. '3.2.2'. >>> matplotlib.rcParams['backend']. 'WXAgg'. >>> matplotlib.get_backend(). 'WXAgg'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1302
https://github.com/scverse/scanpy/issues/1302:191,usability,confirm,confirm,191,"Thanks, what is the default backend on macOS? I only install matplotlib via the scanpy/anndata depenancies in a conda environment (and `MPLBACKEND` is unset). Upon installing wxpython, I can confirm the used backend. ```. >>> matplotlib.__version__. '3.2.2'. >>> matplotlib.rcParams['backend']. 'WXAgg'. >>> matplotlib.get_backend(). 'WXAgg'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1302
https://github.com/scverse/scanpy/issues/1302:98,deployability,fail,fails,98,"`matplotlib.rcParams['backend']` gives `MacOSX` on my laptop. Sorry, no idea why mpl picks wx and fails. But I think this is not a scanpy issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1302
https://github.com/scverse/scanpy/issues/1302:98,reliability,fail,fails,98,"`matplotlib.rcParams['backend']` gives `MacOSX` on my laptop. Sorry, no idea why mpl picks wx and fails. But I think this is not a scanpy issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1302
https://github.com/scverse/scanpy/pull/1304:53,modifiability,pac,package,53,"It might be useful to have a sentence describing the package, but isn't necessary. Are you interested in adding that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1304
https://github.com/scverse/scanpy/pull/1304:284,interoperability,specif,specific,284,"Sure! @michalk8 , could you please add the below sentence:. ""CellRank is a toolkit to uncover cellular dynamics based on scRNA-seq data with RNA velocity annotation by detecting initial and terminal populations, inferring fate potentials and uncovering gene expression trends towards specific terminal populations. """,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1304
https://github.com/scverse/scanpy/pull/1304:168,safety,detect,detecting,168,"Sure! @michalk8 , could you please add the below sentence:. ""CellRank is a toolkit to uncover cellular dynamics based on scRNA-seq data with RNA velocity annotation by detecting initial and terminal populations, inferring fate potentials and uncovering gene expression trends towards specific terminal populations. """,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1304
https://github.com/scverse/scanpy/pull/1304:168,security,detect,detecting,168,"Sure! @michalk8 , could you please add the below sentence:. ""CellRank is a toolkit to uncover cellular dynamics based on scRNA-seq data with RNA velocity annotation by detecting initial and terminal populations, inferring fate potentials and uncovering gene expression trends towards specific terminal populations. """,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1304
https://github.com/scverse/scanpy/pull/1304:75,usability,tool,toolkit,75,"Sure! @michalk8 , could you please add the below sentence:. ""CellRank is a toolkit to uncover cellular dynamics based on scRNA-seq data with RNA velocity annotation by detecting initial and terminal populations, inferring fate potentials and uncovering gene expression trends towards specific terminal populations. """,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1304
https://github.com/scverse/scanpy/pull/1305:245,availability,error,error,245,"I like that CI for notebooks! Question, what should be happening here? I'm a little confused about how the path isn't a directory, but you're going to write a file inside of it? If this is the problem, I think having `exists_ok=True` will still error. In general, I believe we'd previously decided to not create parent directories for writing automatically (mentioned in https://github.com/theislab/anndata/pull/364, and I think talked about in a zoom call?). This follows other tools better, which just throw an error if your parent directory doesn't exist. I personally like this approach better because it'll throw an error for typos, instead of doing the wrong thing. The only exception here is for the `datasets` module, which should create the directory it will store data in. I would recommend you explicitly create the directory in your code if needed. @falexwolf @flying-sheep, I would like to remove the directory creation code from `_check_datafile_present_and_download`. Do you think this will be a problem? It's not documented, so I'm leaning towards just removal instead of deprecation, but could be convinced to just warn for a cycle.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1305
https://github.com/scverse/scanpy/pull/1305:513,availability,error,error,513,"I like that CI for notebooks! Question, what should be happening here? I'm a little confused about how the path isn't a directory, but you're going to write a file inside of it? If this is the problem, I think having `exists_ok=True` will still error. In general, I believe we'd previously decided to not create parent directories for writing automatically (mentioned in https://github.com/theislab/anndata/pull/364, and I think talked about in a zoom call?). This follows other tools better, which just throw an error if your parent directory doesn't exist. I personally like this approach better because it'll throw an error for typos, instead of doing the wrong thing. The only exception here is for the `datasets` module, which should create the directory it will store data in. I would recommend you explicitly create the directory in your code if needed. @falexwolf @flying-sheep, I would like to remove the directory creation code from `_check_datafile_present_and_download`. Do you think this will be a problem? It's not documented, so I'm leaning towards just removal instead of deprecation, but could be convinced to just warn for a cycle.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1305
https://github.com/scverse/scanpy/pull/1305:621,availability,error,error,621,"I like that CI for notebooks! Question, what should be happening here? I'm a little confused about how the path isn't a directory, but you're going to write a file inside of it? If this is the problem, I think having `exists_ok=True` will still error. In general, I believe we'd previously decided to not create parent directories for writing automatically (mentioned in https://github.com/theislab/anndata/pull/364, and I think talked about in a zoom call?). This follows other tools better, which just throw an error if your parent directory doesn't exist. I personally like this approach better because it'll throw an error for typos, instead of doing the wrong thing. The only exception here is for the `datasets` module, which should create the directory it will store data in. I would recommend you explicitly create the directory in your code if needed. @falexwolf @flying-sheep, I would like to remove the directory creation code from `_check_datafile_present_and_download`. Do you think this will be a problem? It's not documented, so I'm leaning towards just removal instead of deprecation, but could be convinced to just warn for a cycle.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1305
https://github.com/scverse/scanpy/pull/1305:343,deployability,automat,automatically,343,"I like that CI for notebooks! Question, what should be happening here? I'm a little confused about how the path isn't a directory, but you're going to write a file inside of it? If this is the problem, I think having `exists_ok=True` will still error. In general, I believe we'd previously decided to not create parent directories for writing automatically (mentioned in https://github.com/theislab/anndata/pull/364, and I think talked about in a zoom call?). This follows other tools better, which just throw an error if your parent directory doesn't exist. I personally like this approach better because it'll throw an error for typos, instead of doing the wrong thing. The only exception here is for the `datasets` module, which should create the directory it will store data in. I would recommend you explicitly create the directory in your code if needed. @falexwolf @flying-sheep, I would like to remove the directory creation code from `_check_datafile_present_and_download`. Do you think this will be a problem? It's not documented, so I'm leaning towards just removal instead of deprecation, but could be convinced to just warn for a cycle.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1305
https://github.com/scverse/scanpy/pull/1305:718,deployability,modul,module,718,"I like that CI for notebooks! Question, what should be happening here? I'm a little confused about how the path isn't a directory, but you're going to write a file inside of it? If this is the problem, I think having `exists_ok=True` will still error. In general, I believe we'd previously decided to not create parent directories for writing automatically (mentioned in https://github.com/theislab/anndata/pull/364, and I think talked about in a zoom call?). This follows other tools better, which just throw an error if your parent directory doesn't exist. I personally like this approach better because it'll throw an error for typos, instead of doing the wrong thing. The only exception here is for the `datasets` module, which should create the directory it will store data in. I would recommend you explicitly create the directory in your code if needed. @falexwolf @flying-sheep, I would like to remove the directory creation code from `_check_datafile_present_and_download`. Do you think this will be a problem? It's not documented, so I'm leaning towards just removal instead of deprecation, but could be convinced to just warn for a cycle.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1305
https://github.com/scverse/scanpy/pull/1305:718,modifiability,modul,module,718,"I like that CI for notebooks! Question, what should be happening here? I'm a little confused about how the path isn't a directory, but you're going to write a file inside of it? If this is the problem, I think having `exists_ok=True` will still error. In general, I believe we'd previously decided to not create parent directories for writing automatically (mentioned in https://github.com/theislab/anndata/pull/364, and I think talked about in a zoom call?). This follows other tools better, which just throw an error if your parent directory doesn't exist. I personally like this approach better because it'll throw an error for typos, instead of doing the wrong thing. The only exception here is for the `datasets` module, which should create the directory it will store data in. I would recommend you explicitly create the directory in your code if needed. @falexwolf @flying-sheep, I would like to remove the directory creation code from `_check_datafile_present_and_download`. Do you think this will be a problem? It's not documented, so I'm leaning towards just removal instead of deprecation, but could be convinced to just warn for a cycle.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1305
https://github.com/scverse/scanpy/pull/1305:245,performance,error,error,245,"I like that CI for notebooks! Question, what should be happening here? I'm a little confused about how the path isn't a directory, but you're going to write a file inside of it? If this is the problem, I think having `exists_ok=True` will still error. In general, I believe we'd previously decided to not create parent directories for writing automatically (mentioned in https://github.com/theislab/anndata/pull/364, and I think talked about in a zoom call?). This follows other tools better, which just throw an error if your parent directory doesn't exist. I personally like this approach better because it'll throw an error for typos, instead of doing the wrong thing. The only exception here is for the `datasets` module, which should create the directory it will store data in. I would recommend you explicitly create the directory in your code if needed. @falexwolf @flying-sheep, I would like to remove the directory creation code from `_check_datafile_present_and_download`. Do you think this will be a problem? It's not documented, so I'm leaning towards just removal instead of deprecation, but could be convinced to just warn for a cycle.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1305
https://github.com/scverse/scanpy/pull/1305:513,performance,error,error,513,"I like that CI for notebooks! Question, what should be happening here? I'm a little confused about how the path isn't a directory, but you're going to write a file inside of it? If this is the problem, I think having `exists_ok=True` will still error. In general, I believe we'd previously decided to not create parent directories for writing automatically (mentioned in https://github.com/theislab/anndata/pull/364, and I think talked about in a zoom call?). This follows other tools better, which just throw an error if your parent directory doesn't exist. I personally like this approach better because it'll throw an error for typos, instead of doing the wrong thing. The only exception here is for the `datasets` module, which should create the directory it will store data in. I would recommend you explicitly create the directory in your code if needed. @falexwolf @flying-sheep, I would like to remove the directory creation code from `_check_datafile_present_and_download`. Do you think this will be a problem? It's not documented, so I'm leaning towards just removal instead of deprecation, but could be convinced to just warn for a cycle.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1305
https://github.com/scverse/scanpy/pull/1305:621,performance,error,error,621,"I like that CI for notebooks! Question, what should be happening here? I'm a little confused about how the path isn't a directory, but you're going to write a file inside of it? If this is the problem, I think having `exists_ok=True` will still error. In general, I believe we'd previously decided to not create parent directories for writing automatically (mentioned in https://github.com/theislab/anndata/pull/364, and I think talked about in a zoom call?). This follows other tools better, which just throw an error if your parent directory doesn't exist. I personally like this approach better because it'll throw an error for typos, instead of doing the wrong thing. The only exception here is for the `datasets` module, which should create the directory it will store data in. I would recommend you explicitly create the directory in your code if needed. @falexwolf @flying-sheep, I would like to remove the directory creation code from `_check_datafile_present_and_download`. Do you think this will be a problem? It's not documented, so I'm leaning towards just removal instead of deprecation, but could be convinced to just warn for a cycle.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1305
https://github.com/scverse/scanpy/pull/1305:544,reliability,doe,doesn,544,"I like that CI for notebooks! Question, what should be happening here? I'm a little confused about how the path isn't a directory, but you're going to write a file inside of it? If this is the problem, I think having `exists_ok=True` will still error. In general, I believe we'd previously decided to not create parent directories for writing automatically (mentioned in https://github.com/theislab/anndata/pull/364, and I think talked about in a zoom call?). This follows other tools better, which just throw an error if your parent directory doesn't exist. I personally like this approach better because it'll throw an error for typos, instead of doing the wrong thing. The only exception here is for the `datasets` module, which should create the directory it will store data in. I would recommend you explicitly create the directory in your code if needed. @falexwolf @flying-sheep, I would like to remove the directory creation code from `_check_datafile_present_and_download`. Do you think this will be a problem? It's not documented, so I'm leaning towards just removal instead of deprecation, but could be convinced to just warn for a cycle.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1305
https://github.com/scverse/scanpy/pull/1305:245,safety,error,error,245,"I like that CI for notebooks! Question, what should be happening here? I'm a little confused about how the path isn't a directory, but you're going to write a file inside of it? If this is the problem, I think having `exists_ok=True` will still error. In general, I believe we'd previously decided to not create parent directories for writing automatically (mentioned in https://github.com/theislab/anndata/pull/364, and I think talked about in a zoom call?). This follows other tools better, which just throw an error if your parent directory doesn't exist. I personally like this approach better because it'll throw an error for typos, instead of doing the wrong thing. The only exception here is for the `datasets` module, which should create the directory it will store data in. I would recommend you explicitly create the directory in your code if needed. @falexwolf @flying-sheep, I would like to remove the directory creation code from `_check_datafile_present_and_download`. Do you think this will be a problem? It's not documented, so I'm leaning towards just removal instead of deprecation, but could be convinced to just warn for a cycle.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1305
https://github.com/scverse/scanpy/pull/1305:513,safety,error,error,513,"I like that CI for notebooks! Question, what should be happening here? I'm a little confused about how the path isn't a directory, but you're going to write a file inside of it? If this is the problem, I think having `exists_ok=True` will still error. In general, I believe we'd previously decided to not create parent directories for writing automatically (mentioned in https://github.com/theislab/anndata/pull/364, and I think talked about in a zoom call?). This follows other tools better, which just throw an error if your parent directory doesn't exist. I personally like this approach better because it'll throw an error for typos, instead of doing the wrong thing. The only exception here is for the `datasets` module, which should create the directory it will store data in. I would recommend you explicitly create the directory in your code if needed. @falexwolf @flying-sheep, I would like to remove the directory creation code from `_check_datafile_present_and_download`. Do you think this will be a problem? It's not documented, so I'm leaning towards just removal instead of deprecation, but could be convinced to just warn for a cycle.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1305
https://github.com/scverse/scanpy/pull/1305:621,safety,error,error,621,"I like that CI for notebooks! Question, what should be happening here? I'm a little confused about how the path isn't a directory, but you're going to write a file inside of it? If this is the problem, I think having `exists_ok=True` will still error. In general, I believe we'd previously decided to not create parent directories for writing automatically (mentioned in https://github.com/theislab/anndata/pull/364, and I think talked about in a zoom call?). This follows other tools better, which just throw an error if your parent directory doesn't exist. I personally like this approach better because it'll throw an error for typos, instead of doing the wrong thing. The only exception here is for the `datasets` module, which should create the directory it will store data in. I would recommend you explicitly create the directory in your code if needed. @falexwolf @flying-sheep, I would like to remove the directory creation code from `_check_datafile_present_and_download`. Do you think this will be a problem? It's not documented, so I'm leaning towards just removal instead of deprecation, but could be convinced to just warn for a cycle.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1305
https://github.com/scverse/scanpy/pull/1305:681,safety,except,exception,681,"I like that CI for notebooks! Question, what should be happening here? I'm a little confused about how the path isn't a directory, but you're going to write a file inside of it? If this is the problem, I think having `exists_ok=True` will still error. In general, I believe we'd previously decided to not create parent directories for writing automatically (mentioned in https://github.com/theislab/anndata/pull/364, and I think talked about in a zoom call?). This follows other tools better, which just throw an error if your parent directory doesn't exist. I personally like this approach better because it'll throw an error for typos, instead of doing the wrong thing. The only exception here is for the `datasets` module, which should create the directory it will store data in. I would recommend you explicitly create the directory in your code if needed. @falexwolf @flying-sheep, I would like to remove the directory creation code from `_check_datafile_present_and_download`. Do you think this will be a problem? It's not documented, so I'm leaning towards just removal instead of deprecation, but could be convinced to just warn for a cycle.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1305
https://github.com/scverse/scanpy/pull/1305:718,safety,modul,module,718,"I like that CI for notebooks! Question, what should be happening here? I'm a little confused about how the path isn't a directory, but you're going to write a file inside of it? If this is the problem, I think having `exists_ok=True` will still error. In general, I believe we'd previously decided to not create parent directories for writing automatically (mentioned in https://github.com/theislab/anndata/pull/364, and I think talked about in a zoom call?). This follows other tools better, which just throw an error if your parent directory doesn't exist. I personally like this approach better because it'll throw an error for typos, instead of doing the wrong thing. The only exception here is for the `datasets` module, which should create the directory it will store data in. I would recommend you explicitly create the directory in your code if needed. @falexwolf @flying-sheep, I would like to remove the directory creation code from `_check_datafile_present_and_download`. Do you think this will be a problem? It's not documented, so I'm leaning towards just removal instead of deprecation, but could be convinced to just warn for a cycle.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1305
https://github.com/scverse/scanpy/pull/1305:343,testability,automat,automatically,343,"I like that CI for notebooks! Question, what should be happening here? I'm a little confused about how the path isn't a directory, but you're going to write a file inside of it? If this is the problem, I think having `exists_ok=True` will still error. In general, I believe we'd previously decided to not create parent directories for writing automatically (mentioned in https://github.com/theislab/anndata/pull/364, and I think talked about in a zoom call?). This follows other tools better, which just throw an error if your parent directory doesn't exist. I personally like this approach better because it'll throw an error for typos, instead of doing the wrong thing. The only exception here is for the `datasets` module, which should create the directory it will store data in. I would recommend you explicitly create the directory in your code if needed. @falexwolf @flying-sheep, I would like to remove the directory creation code from `_check_datafile_present_and_download`. Do you think this will be a problem? It's not documented, so I'm leaning towards just removal instead of deprecation, but could be convinced to just warn for a cycle.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1305
https://github.com/scverse/scanpy/pull/1305:245,usability,error,error,245,"I like that CI for notebooks! Question, what should be happening here? I'm a little confused about how the path isn't a directory, but you're going to write a file inside of it? If this is the problem, I think having `exists_ok=True` will still error. In general, I believe we'd previously decided to not create parent directories for writing automatically (mentioned in https://github.com/theislab/anndata/pull/364, and I think talked about in a zoom call?). This follows other tools better, which just throw an error if your parent directory doesn't exist. I personally like this approach better because it'll throw an error for typos, instead of doing the wrong thing. The only exception here is for the `datasets` module, which should create the directory it will store data in. I would recommend you explicitly create the directory in your code if needed. @falexwolf @flying-sheep, I would like to remove the directory creation code from `_check_datafile_present_and_download`. Do you think this will be a problem? It's not documented, so I'm leaning towards just removal instead of deprecation, but could be convinced to just warn for a cycle.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1305
https://github.com/scverse/scanpy/pull/1305:479,usability,tool,tools,479,"I like that CI for notebooks! Question, what should be happening here? I'm a little confused about how the path isn't a directory, but you're going to write a file inside of it? If this is the problem, I think having `exists_ok=True` will still error. In general, I believe we'd previously decided to not create parent directories for writing automatically (mentioned in https://github.com/theislab/anndata/pull/364, and I think talked about in a zoom call?). This follows other tools better, which just throw an error if your parent directory doesn't exist. I personally like this approach better because it'll throw an error for typos, instead of doing the wrong thing. The only exception here is for the `datasets` module, which should create the directory it will store data in. I would recommend you explicitly create the directory in your code if needed. @falexwolf @flying-sheep, I would like to remove the directory creation code from `_check_datafile_present_and_download`. Do you think this will be a problem? It's not documented, so I'm leaning towards just removal instead of deprecation, but could be convinced to just warn for a cycle.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1305
https://github.com/scverse/scanpy/pull/1305:513,usability,error,error,513,"I like that CI for notebooks! Question, what should be happening here? I'm a little confused about how the path isn't a directory, but you're going to write a file inside of it? If this is the problem, I think having `exists_ok=True` will still error. In general, I believe we'd previously decided to not create parent directories for writing automatically (mentioned in https://github.com/theislab/anndata/pull/364, and I think talked about in a zoom call?). This follows other tools better, which just throw an error if your parent directory doesn't exist. I personally like this approach better because it'll throw an error for typos, instead of doing the wrong thing. The only exception here is for the `datasets` module, which should create the directory it will store data in. I would recommend you explicitly create the directory in your code if needed. @falexwolf @flying-sheep, I would like to remove the directory creation code from `_check_datafile_present_and_download`. Do you think this will be a problem? It's not documented, so I'm leaning towards just removal instead of deprecation, but could be convinced to just warn for a cycle.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1305
https://github.com/scverse/scanpy/pull/1305:561,usability,person,personally,561,"I like that CI for notebooks! Question, what should be happening here? I'm a little confused about how the path isn't a directory, but you're going to write a file inside of it? If this is the problem, I think having `exists_ok=True` will still error. In general, I believe we'd previously decided to not create parent directories for writing automatically (mentioned in https://github.com/theislab/anndata/pull/364, and I think talked about in a zoom call?). This follows other tools better, which just throw an error if your parent directory doesn't exist. I personally like this approach better because it'll throw an error for typos, instead of doing the wrong thing. The only exception here is for the `datasets` module, which should create the directory it will store data in. I would recommend you explicitly create the directory in your code if needed. @falexwolf @flying-sheep, I would like to remove the directory creation code from `_check_datafile_present_and_download`. Do you think this will be a problem? It's not documented, so I'm leaning towards just removal instead of deprecation, but could be convinced to just warn for a cycle.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1305
https://github.com/scverse/scanpy/pull/1305:621,usability,error,error,621,"I like that CI for notebooks! Question, what should be happening here? I'm a little confused about how the path isn't a directory, but you're going to write a file inside of it? If this is the problem, I think having `exists_ok=True` will still error. In general, I believe we'd previously decided to not create parent directories for writing automatically (mentioned in https://github.com/theislab/anndata/pull/364, and I think talked about in a zoom call?). This follows other tools better, which just throw an error if your parent directory doesn't exist. I personally like this approach better because it'll throw an error for typos, instead of doing the wrong thing. The only exception here is for the `datasets` module, which should create the directory it will store data in. I would recommend you explicitly create the directory in your code if needed. @falexwolf @flying-sheep, I would like to remove the directory creation code from `_check_datafile_present_and_download`. Do you think this will be a problem? It's not documented, so I'm leaning towards just removal instead of deprecation, but could be convinced to just warn for a cycle.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1305
https://github.com/scverse/scanpy/pull/1305:1029,usability,document,documented,1029,"I like that CI for notebooks! Question, what should be happening here? I'm a little confused about how the path isn't a directory, but you're going to write a file inside of it? If this is the problem, I think having `exists_ok=True` will still error. In general, I believe we'd previously decided to not create parent directories for writing automatically (mentioned in https://github.com/theislab/anndata/pull/364, and I think talked about in a zoom call?). This follows other tools better, which just throw an error if your parent directory doesn't exist. I personally like this approach better because it'll throw an error for typos, instead of doing the wrong thing. The only exception here is for the `datasets` module, which should create the directory it will store data in. I would recommend you explicitly create the directory in your code if needed. @falexwolf @flying-sheep, I would like to remove the directory creation code from `_check_datafile_present_and_download`. Do you think this will be a problem? It's not documented, so I'm leaning towards just removal instead of deprecation, but could be convinced to just warn for a cycle.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1305
https://github.com/scverse/scanpy/pull/1306:178,deployability,version,version,178,"Hi @esrice,. This looks great, actually I was considering adding support for the PyTorch implementation of Harmony https://github.com/lilab-bcb/harmony-pytorch. I only used this version so I don't know if it brings any speedup but results were very nice usually.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306
https://github.com/scverse/scanpy/pull/1306:178,integrability,version,version,178,"Hi @esrice,. This looks great, actually I was considering adding support for the PyTorch implementation of Harmony https://github.com/lilab-bcb/harmony-pytorch. I only used this version so I don't know if it brings any speedup but results were very nice usually.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306
https://github.com/scverse/scanpy/pull/1306:178,modifiability,version,version,178,"Hi @esrice,. This looks great, actually I was considering adding support for the PyTorch implementation of Harmony https://github.com/lilab-bcb/harmony-pytorch. I only used this version so I don't know if it brings any speedup but results were very nice usually.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306
https://github.com/scverse/scanpy/pull/1306:65,usability,support,support,65,"Hi @esrice,. This looks great, actually I was considering adding support for the PyTorch implementation of Harmony https://github.com/lilab-bcb/harmony-pytorch. I only used this version so I don't know if it brings any speedup but results were very nice usually.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306
https://github.com/scverse/scanpy/pull/1306:69,integrability,coupl,couple,69,"Thanks @gokceneraslan. This implementation takes very little time (a couple seconds per iteration on ~10k cells), so a speedup might not make much difference, but if you think using the pytorch implementation would be better, I can certainly switch to that one easily enough.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306
https://github.com/scverse/scanpy/pull/1306:69,modifiability,coupl,couple,69,"Thanks @gokceneraslan. This implementation takes very little time (a couple seconds per iteration on ~10k cells), so a speedup might not make much difference, but if you think using the pytorch implementation would be better, I can certainly switch to that one easily enough.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306
https://github.com/scverse/scanpy/pull/1306:61,performance,time,time,61,"Thanks @gokceneraslan. This implementation takes very little time (a couple seconds per iteration on ~10k cells), so a speedup might not make much difference, but if you think using the pytorch implementation would be better, I can certainly switch to that one easily enough.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306
https://github.com/scverse/scanpy/pull/1306:69,testability,coupl,couple,69,"Thanks @gokceneraslan. This implementation takes very little time (a couple seconds per iteration on ~10k cells), so a speedup might not make much difference, but if you think using the pytorch implementation would be better, I can certainly switch to that one easily enough.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306
https://github.com/scverse/scanpy/pull/1306:354,availability,error,errors,354,"Looks good then! Great that you followed https://github.com/theislab/scanpy/pull/503#issuecomment-471331400 and named it `harmony_integrate` instead of generally `harmony`. Not sure if `obsm_{in,out}_field` are good names. Maybe use something more speaking? I think we use `basis` or `rep` for something like `X_pca` elsewhere. Please also fix doc build errors and the `.travis.yml` conflict. (Kor**s**unsky19 is a typo I guess, and I think it should be `kwargs` instead of `**kwargs`).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306
https://github.com/scverse/scanpy/pull/1306:348,deployability,build,build,348,"Looks good then! Great that you followed https://github.com/theislab/scanpy/pull/503#issuecomment-471331400 and named it `harmony_integrate` instead of generally `harmony`. Not sure if `obsm_{in,out}_field` are good names. Maybe use something more speaking? I think we use `basis` or `rep` for something like `X_pca` elsewhere. Please also fix doc build errors and the `.travis.yml` conflict. (Kor**s**unsky19 is a typo I guess, and I think it should be `kwargs` instead of `**kwargs`).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306
https://github.com/scverse/scanpy/pull/1306:383,interoperability,conflict,conflict,383,"Looks good then! Great that you followed https://github.com/theislab/scanpy/pull/503#issuecomment-471331400 and named it `harmony_integrate` instead of generally `harmony`. Not sure if `obsm_{in,out}_field` are good names. Maybe use something more speaking? I think we use `basis` or `rep` for something like `X_pca` elsewhere. Please also fix doc build errors and the `.travis.yml` conflict. (Kor**s**unsky19 is a typo I guess, and I think it should be `kwargs` instead of `**kwargs`).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306
https://github.com/scverse/scanpy/pull/1306:354,performance,error,errors,354,"Looks good then! Great that you followed https://github.com/theislab/scanpy/pull/503#issuecomment-471331400 and named it `harmony_integrate` instead of generally `harmony`. Not sure if `obsm_{in,out}_field` are good names. Maybe use something more speaking? I think we use `basis` or `rep` for something like `X_pca` elsewhere. Please also fix doc build errors and the `.travis.yml` conflict. (Kor**s**unsky19 is a typo I guess, and I think it should be `kwargs` instead of `**kwargs`).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306
https://github.com/scverse/scanpy/pull/1306:354,safety,error,errors,354,"Looks good then! Great that you followed https://github.com/theislab/scanpy/pull/503#issuecomment-471331400 and named it `harmony_integrate` instead of generally `harmony`. Not sure if `obsm_{in,out}_field` are good names. Maybe use something more speaking? I think we use `basis` or `rep` for something like `X_pca` elsewhere. Please also fix doc build errors and the `.travis.yml` conflict. (Kor**s**unsky19 is a typo I guess, and I think it should be `kwargs` instead of `**kwargs`).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306
https://github.com/scverse/scanpy/pull/1306:354,usability,error,errors,354,"Looks good then! Great that you followed https://github.com/theislab/scanpy/pull/503#issuecomment-471331400 and named it `harmony_integrate` instead of generally `harmony`. Not sure if `obsm_{in,out}_field` are good names. Maybe use something more speaking? I think we use `basis` or `rep` for something like `X_pca` elsewhere. Please also fix doc build errors and the `.travis.yml` conflict. (Kor**s**unsky19 is a typo I guess, and I think it should be `kwargs` instead of `**kwargs`).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306
https://github.com/scverse/scanpy/pull/1306:106,availability,error,errors,106,"Great, thanks for the feedback. Hopefully this merge and commit fix everything. I wasn't able to see what errors were causing the readthedocs build fail as the ""Details"" link just took me to a page that said ""SORRY / This page does not exist yet."", so let me know if there are any other issues.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306
https://github.com/scverse/scanpy/pull/1306:142,deployability,build,build,142,"Great, thanks for the feedback. Hopefully this merge and commit fix everything. I wasn't able to see what errors were causing the readthedocs build fail as the ""Details"" link just took me to a page that said ""SORRY / This page does not exist yet."", so let me know if there are any other issues.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306
https://github.com/scverse/scanpy/pull/1306:148,deployability,fail,fail,148,"Great, thanks for the feedback. Hopefully this merge and commit fix everything. I wasn't able to see what errors were causing the readthedocs build fail as the ""Details"" link just took me to a page that said ""SORRY / This page does not exist yet."", so let me know if there are any other issues.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306
https://github.com/scverse/scanpy/pull/1306:106,performance,error,errors,106,"Great, thanks for the feedback. Hopefully this merge and commit fix everything. I wasn't able to see what errors were causing the readthedocs build fail as the ""Details"" link just took me to a page that said ""SORRY / This page does not exist yet."", so let me know if there are any other issues.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306
https://github.com/scverse/scanpy/pull/1306:148,reliability,fail,fail,148,"Great, thanks for the feedback. Hopefully this merge and commit fix everything. I wasn't able to see what errors were causing the readthedocs build fail as the ""Details"" link just took me to a page that said ""SORRY / This page does not exist yet."", so let me know if there are any other issues.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306
https://github.com/scverse/scanpy/pull/1306:227,reliability,doe,does,227,"Great, thanks for the feedback. Hopefully this merge and commit fix everything. I wasn't able to see what errors were causing the readthedocs build fail as the ""Details"" link just took me to a page that said ""SORRY / This page does not exist yet."", so let me know if there are any other issues.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306
https://github.com/scverse/scanpy/pull/1306:106,safety,error,errors,106,"Great, thanks for the feedback. Hopefully this merge and commit fix everything. I wasn't able to see what errors were causing the readthedocs build fail as the ""Details"" link just took me to a page that said ""SORRY / This page does not exist yet."", so let me know if there are any other issues.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306
https://github.com/scverse/scanpy/pull/1306:22,usability,feedback,feedback,22,"Great, thanks for the feedback. Hopefully this merge and commit fix everything. I wasn't able to see what errors were causing the readthedocs build fail as the ""Details"" link just took me to a page that said ""SORRY / This page does not exist yet."", so let me know if there are any other issues.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306
https://github.com/scverse/scanpy/pull/1306:106,usability,error,errors,106,"Great, thanks for the feedback. Hopefully this merge and commit fix everything. I wasn't able to see what errors were causing the readthedocs build fail as the ""Details"" link just took me to a page that said ""SORRY / This page does not exist yet."", so let me know if there are any other issues.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306
https://github.com/scverse/scanpy/pull/1306:46,deployability,build,builds,46,"Ah, yeah we need to fix the visibility of the builds. Hmm, so you cant see the build [here](https://icb-scanpy--1306.com.readthedocs.build/en/1306/external/scanpy.external.pp.harmony_integrate.html)? It still has issues:. ![grafik](https://user-images.githubusercontent.com/291575/88098047-6dc0ad00-cb99-11ea-8c30-f11ee3a820fb.png). you need to add blank lines before the `>>>` i guess. Also ![grafik](https://user-images.githubusercontent.com/291575/88098511-30a8ea80-cb9a-11ea-987b-c2fa929f36d6.png) again. You need to either give us acess to WarrenLab/scanpy@harmony or continuously merge master until you pressing the merge upstream changes button and us hitting the squash & merge button happens fast enough. forcing up-to-date branches this way is a bit annoying, but its the only way to be sure conflicts in changes dont break everything. (well, the only way without switching to [bors](https://bors.tech/))",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306
https://github.com/scverse/scanpy/pull/1306:80,deployability,build,build,80,"Ah, yeah we need to fix the visibility of the builds. Hmm, so you cant see the build [here](https://icb-scanpy--1306.com.readthedocs.build/en/1306/external/scanpy.external.pp.harmony_integrate.html)? It still has issues:. ![grafik](https://user-images.githubusercontent.com/291575/88098047-6dc0ad00-cb99-11ea-8c30-f11ee3a820fb.png). you need to add blank lines before the `>>>` i guess. Also ![grafik](https://user-images.githubusercontent.com/291575/88098511-30a8ea80-cb9a-11ea-987b-c2fa929f36d6.png) again. You need to either give us acess to WarrenLab/scanpy@harmony or continuously merge master until you pressing the merge upstream changes button and us hitting the squash & merge button happens fast enough. forcing up-to-date branches this way is a bit annoying, but its the only way to be sure conflicts in changes dont break everything. (well, the only way without switching to [bors](https://bors.tech/))",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306
https://github.com/scverse/scanpy/pull/1306:134,deployability,build,build,134,"Ah, yeah we need to fix the visibility of the builds. Hmm, so you cant see the build [here](https://icb-scanpy--1306.com.readthedocs.build/en/1306/external/scanpy.external.pp.harmony_integrate.html)? It still has issues:. ![grafik](https://user-images.githubusercontent.com/291575/88098047-6dc0ad00-cb99-11ea-8c30-f11ee3a820fb.png). you need to add blank lines before the `>>>` i guess. Also ![grafik](https://user-images.githubusercontent.com/291575/88098511-30a8ea80-cb9a-11ea-987b-c2fa929f36d6.png) again. You need to either give us acess to WarrenLab/scanpy@harmony or continuously merge master until you pressing the merge upstream changes button and us hitting the squash & merge button happens fast enough. forcing up-to-date branches this way is a bit annoying, but its the only way to be sure conflicts in changes dont break everything. (well, the only way without switching to [bors](https://bors.tech/))",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306
https://github.com/scverse/scanpy/pull/1306:574,deployability,continu,continuously,574,"Ah, yeah we need to fix the visibility of the builds. Hmm, so you cant see the build [here](https://icb-scanpy--1306.com.readthedocs.build/en/1306/external/scanpy.external.pp.harmony_integrate.html)? It still has issues:. ![grafik](https://user-images.githubusercontent.com/291575/88098047-6dc0ad00-cb99-11ea-8c30-f11ee3a820fb.png). you need to add blank lines before the `>>>` i guess. Also ![grafik](https://user-images.githubusercontent.com/291575/88098511-30a8ea80-cb9a-11ea-987b-c2fa929f36d6.png) again. You need to either give us acess to WarrenLab/scanpy@harmony or continuously merge master until you pressing the merge upstream changes button and us hitting the squash & merge button happens fast enough. forcing up-to-date branches this way is a bit annoying, but its the only way to be sure conflicts in changes dont break everything. (well, the only way without switching to [bors](https://bors.tech/))",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306
https://github.com/scverse/scanpy/pull/1306:808,interoperability,conflict,conflicts,808,"Ah, yeah we need to fix the visibility of the builds. Hmm, so you cant see the build [here](https://icb-scanpy--1306.com.readthedocs.build/en/1306/external/scanpy.external.pp.harmony_integrate.html)? It still has issues:. ![grafik](https://user-images.githubusercontent.com/291575/88098047-6dc0ad00-cb99-11ea-8c30-f11ee3a820fb.png). you need to add blank lines before the `>>>` i guess. Also ![grafik](https://user-images.githubusercontent.com/291575/88098511-30a8ea80-cb9a-11ea-987b-c2fa929f36d6.png) again. You need to either give us acess to WarrenLab/scanpy@harmony or continuously merge master until you pressing the merge upstream changes button and us hitting the squash & merge button happens fast enough. forcing up-to-date branches this way is a bit annoying, but its the only way to be sure conflicts in changes dont break everything. (well, the only way without switching to [bors](https://bors.tech/))",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306
https://github.com/scverse/scanpy/pull/1306:241,usability,user,user-images,241,"Ah, yeah we need to fix the visibility of the builds. Hmm, so you cant see the build [here](https://icb-scanpy--1306.com.readthedocs.build/en/1306/external/scanpy.external.pp.harmony_integrate.html)? It still has issues:. ![grafik](https://user-images.githubusercontent.com/291575/88098047-6dc0ad00-cb99-11ea-8c30-f11ee3a820fb.png). you need to add blank lines before the `>>>` i guess. Also ![grafik](https://user-images.githubusercontent.com/291575/88098511-30a8ea80-cb9a-11ea-987b-c2fa929f36d6.png) again. You need to either give us acess to WarrenLab/scanpy@harmony or continuously merge master until you pressing the merge upstream changes button and us hitting the squash & merge button happens fast enough. forcing up-to-date branches this way is a bit annoying, but its the only way to be sure conflicts in changes dont break everything. (well, the only way without switching to [bors](https://bors.tech/))",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306
https://github.com/scverse/scanpy/pull/1306:411,usability,user,user-images,411,"Ah, yeah we need to fix the visibility of the builds. Hmm, so you cant see the build [here](https://icb-scanpy--1306.com.readthedocs.build/en/1306/external/scanpy.external.pp.harmony_integrate.html)? It still has issues:. ![grafik](https://user-images.githubusercontent.com/291575/88098047-6dc0ad00-cb99-11ea-8c30-f11ee3a820fb.png). you need to add blank lines before the `>>>` i guess. Also ![grafik](https://user-images.githubusercontent.com/291575/88098511-30a8ea80-cb9a-11ea-987b-c2fa929f36d6.png) again. You need to either give us acess to WarrenLab/scanpy@harmony or continuously merge master until you pressing the merge upstream changes button and us hitting the squash & merge button happens fast enough. forcing up-to-date branches this way is a bit annoying, but its the only way to be sure conflicts in changes dont break everything. (well, the only way without switching to [bors](https://bors.tech/))",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306
https://github.com/scverse/scanpy/pull/1306:99,availability,error,error,99,"Nope, that link brings me to a login page, and when I log in with my github account it gives me an error. I merged master again and added newlines; hopefully this fixes the issue. I'll give you access to my fork as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306
https://github.com/scverse/scanpy/pull/1306:31,deployability,log,login,31,"Nope, that link brings me to a login page, and when I log in with my github account it gives me an error. I merged master again and added newlines; hopefully this fixes the issue. I'll give you access to my fork as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306
https://github.com/scverse/scanpy/pull/1306:54,deployability,log,log,54,"Nope, that link brings me to a login page, and when I log in with my github account it gives me an error. I merged master again and added newlines; hopefully this fixes the issue. I'll give you access to my fork as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306
https://github.com/scverse/scanpy/pull/1306:99,performance,error,error,99,"Nope, that link brings me to a login page, and when I log in with my github account it gives me an error. I merged master again and added newlines; hopefully this fixes the issue. I'll give you access to my fork as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306
https://github.com/scverse/scanpy/pull/1306:31,safety,log,login,31,"Nope, that link brings me to a login page, and when I log in with my github account it gives me an error. I merged master again and added newlines; hopefully this fixes the issue. I'll give you access to my fork as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306
https://github.com/scverse/scanpy/pull/1306:54,safety,log,log,54,"Nope, that link brings me to a login page, and when I log in with my github account it gives me an error. I merged master again and added newlines; hopefully this fixes the issue. I'll give you access to my fork as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306
https://github.com/scverse/scanpy/pull/1306:99,safety,error,error,99,"Nope, that link brings me to a login page, and when I log in with my github account it gives me an error. I merged master again and added newlines; hopefully this fixes the issue. I'll give you access to my fork as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306
https://github.com/scverse/scanpy/pull/1306:31,security,log,login,31,"Nope, that link brings me to a login page, and when I log in with my github account it gives me an error. I merged master again and added newlines; hopefully this fixes the issue. I'll give you access to my fork as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306
https://github.com/scverse/scanpy/pull/1306:54,security,log,log,54,"Nope, that link brings me to a login page, and when I log in with my github account it gives me an error. I merged master again and added newlines; hopefully this fixes the issue. I'll give you access to my fork as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306
https://github.com/scverse/scanpy/pull/1306:194,security,access,access,194,"Nope, that link brings me to a login page, and when I log in with my github account it gives me an error. I merged master again and added newlines; hopefully this fixes the issue. I'll give you access to my fork as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306
https://github.com/scverse/scanpy/pull/1306:31,testability,log,login,31,"Nope, that link brings me to a login page, and when I log in with my github account it gives me an error. I merged master again and added newlines; hopefully this fixes the issue. I'll give you access to my fork as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306
https://github.com/scverse/scanpy/pull/1306:54,testability,log,log,54,"Nope, that link brings me to a login page, and when I log in with my github account it gives me an error. I merged master again and added newlines; hopefully this fixes the issue. I'll give you access to my fork as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306
https://github.com/scverse/scanpy/pull/1306:99,usability,error,error,99,"Nope, that link brings me to a login page, and when I log in with my github account it gives me an error. I merged master again and added newlines; hopefully this fixes the issue. I'll give you access to my fork as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306
https://github.com/scverse/scanpy/issues/1307:49,deployability,build,builds,49,"Hi @ivirshup ,. Actually we can't see the PR doc builds, for https://readthedocs.com/projects/icb-scanpy/builds/361157/ for example this is what I see:. ![image](https://user-images.githubusercontent.com/1140359/86819388-93a46880-c055-11ea-8f62-458508a6f614.png). It's a bit annoying especially when it build fine locally but fails at readthedocs.com, it would be great if the person who sends the PR can also see the build log on the website.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:105,deployability,build,builds,105,"Hi @ivirshup ,. Actually we can't see the PR doc builds, for https://readthedocs.com/projects/icb-scanpy/builds/361157/ for example this is what I see:. ![image](https://user-images.githubusercontent.com/1140359/86819388-93a46880-c055-11ea-8f62-458508a6f614.png). It's a bit annoying especially when it build fine locally but fails at readthedocs.com, it would be great if the person who sends the PR can also see the build log on the website.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:303,deployability,build,build,303,"Hi @ivirshup ,. Actually we can't see the PR doc builds, for https://readthedocs.com/projects/icb-scanpy/builds/361157/ for example this is what I see:. ![image](https://user-images.githubusercontent.com/1140359/86819388-93a46880-c055-11ea-8f62-458508a6f614.png). It's a bit annoying especially when it build fine locally but fails at readthedocs.com, it would be great if the person who sends the PR can also see the build log on the website.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:326,deployability,fail,fails,326,"Hi @ivirshup ,. Actually we can't see the PR doc builds, for https://readthedocs.com/projects/icb-scanpy/builds/361157/ for example this is what I see:. ![image](https://user-images.githubusercontent.com/1140359/86819388-93a46880-c055-11ea-8f62-458508a6f614.png). It's a bit annoying especially when it build fine locally but fails at readthedocs.com, it would be great if the person who sends the PR can also see the build log on the website.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:418,deployability,build,build,418,"Hi @ivirshup ,. Actually we can't see the PR doc builds, for https://readthedocs.com/projects/icb-scanpy/builds/361157/ for example this is what I see:. ![image](https://user-images.githubusercontent.com/1140359/86819388-93a46880-c055-11ea-8f62-458508a6f614.png). It's a bit annoying especially when it build fine locally but fails at readthedocs.com, it would be great if the person who sends the PR can also see the build log on the website.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:424,deployability,log,log,424,"Hi @ivirshup ,. Actually we can't see the PR doc builds, for https://readthedocs.com/projects/icb-scanpy/builds/361157/ for example this is what I see:. ![image](https://user-images.githubusercontent.com/1140359/86819388-93a46880-c055-11ea-8f62-458508a6f614.png). It's a bit annoying especially when it build fine locally but fails at readthedocs.com, it would be great if the person who sends the PR can also see the build log on the website.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:326,reliability,fail,fails,326,"Hi @ivirshup ,. Actually we can't see the PR doc builds, for https://readthedocs.com/projects/icb-scanpy/builds/361157/ for example this is what I see:. ![image](https://user-images.githubusercontent.com/1140359/86819388-93a46880-c055-11ea-8f62-458508a6f614.png). It's a bit annoying especially when it build fine locally but fails at readthedocs.com, it would be great if the person who sends the PR can also see the build log on the website.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:424,safety,log,log,424,"Hi @ivirshup ,. Actually we can't see the PR doc builds, for https://readthedocs.com/projects/icb-scanpy/builds/361157/ for example this is what I see:. ![image](https://user-images.githubusercontent.com/1140359/86819388-93a46880-c055-11ea-8f62-458508a6f614.png). It's a bit annoying especially when it build fine locally but fails at readthedocs.com, it would be great if the person who sends the PR can also see the build log on the website.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:424,security,log,log,424,"Hi @ivirshup ,. Actually we can't see the PR doc builds, for https://readthedocs.com/projects/icb-scanpy/builds/361157/ for example this is what I see:. ![image](https://user-images.githubusercontent.com/1140359/86819388-93a46880-c055-11ea-8f62-458508a6f614.png). It's a bit annoying especially when it build fine locally but fails at readthedocs.com, it would be great if the person who sends the PR can also see the build log on the website.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:424,testability,log,log,424,"Hi @ivirshup ,. Actually we can't see the PR doc builds, for https://readthedocs.com/projects/icb-scanpy/builds/361157/ for example this is what I see:. ![image](https://user-images.githubusercontent.com/1140359/86819388-93a46880-c055-11ea-8f62-458508a6f614.png). It's a bit annoying especially when it build fine locally but fails at readthedocs.com, it would be great if the person who sends the PR can also see the build log on the website.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:170,usability,user,user-images,170,"Hi @ivirshup ,. Actually we can't see the PR doc builds, for https://readthedocs.com/projects/icb-scanpy/builds/361157/ for example this is what I see:. ![image](https://user-images.githubusercontent.com/1140359/86819388-93a46880-c055-11ea-8f62-458508a6f614.png). It's a bit annoying especially when it build fine locally but fails at readthedocs.com, it would be great if the person who sends the PR can also see the build log on the website.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:377,usability,person,person,377,"Hi @ivirshup ,. Actually we can't see the PR doc builds, for https://readthedocs.com/projects/icb-scanpy/builds/361157/ for example this is what I see:. ![image](https://user-images.githubusercontent.com/1140359/86819388-93a46880-c055-11ea-8f62-458508a6f614.png). It's a bit annoying especially when it build fine locally but fails at readthedocs.com, it would be great if the person who sends the PR can also see the build log on the website.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:85,deployability,build,builds,85,or at least the people with commit access to scanpy should be able to see the PR doc builds.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:35,security,access,access,35,or at least the people with commit access to scanpy should be able to see the PR doc builds.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:206,deployability,build,build,206,"Yeah, I had thought anyone could see that. I'll look into checking if we can make that happen. If not, I'll at least try and give everyone with commit rights to scanpy access. Can you see the docs when the build succeeds? *Updates* . * You can at least see some of the most recent build logs [here](https://readthedocs.org/projects/icb-scanpy/builds/11406014/). * It looks like you can see the PR logs for other projects, like [pip](https://readthedocs.org/projects/pip/builds/). I think the difference here is that we have a paid readthedocs account (pip is on `.org`, we are on `.com`), which may [make some things private](https://docs.readthedocs.io/en/latest/choosing-a-site.html). Hopefully we can make this not private?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:223,deployability,Updat,Updates,223,"Yeah, I had thought anyone could see that. I'll look into checking if we can make that happen. If not, I'll at least try and give everyone with commit rights to scanpy access. Can you see the docs when the build succeeds? *Updates* . * You can at least see some of the most recent build logs [here](https://readthedocs.org/projects/icb-scanpy/builds/11406014/). * It looks like you can see the PR logs for other projects, like [pip](https://readthedocs.org/projects/pip/builds/). I think the difference here is that we have a paid readthedocs account (pip is on `.org`, we are on `.com`), which may [make some things private](https://docs.readthedocs.io/en/latest/choosing-a-site.html). Hopefully we can make this not private?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:281,deployability,build,build,281,"Yeah, I had thought anyone could see that. I'll look into checking if we can make that happen. If not, I'll at least try and give everyone with commit rights to scanpy access. Can you see the docs when the build succeeds? *Updates* . * You can at least see some of the most recent build logs [here](https://readthedocs.org/projects/icb-scanpy/builds/11406014/). * It looks like you can see the PR logs for other projects, like [pip](https://readthedocs.org/projects/pip/builds/). I think the difference here is that we have a paid readthedocs account (pip is on `.org`, we are on `.com`), which may [make some things private](https://docs.readthedocs.io/en/latest/choosing-a-site.html). Hopefully we can make this not private?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:287,deployability,log,logs,287,"Yeah, I had thought anyone could see that. I'll look into checking if we can make that happen. If not, I'll at least try and give everyone with commit rights to scanpy access. Can you see the docs when the build succeeds? *Updates* . * You can at least see some of the most recent build logs [here](https://readthedocs.org/projects/icb-scanpy/builds/11406014/). * It looks like you can see the PR logs for other projects, like [pip](https://readthedocs.org/projects/pip/builds/). I think the difference here is that we have a paid readthedocs account (pip is on `.org`, we are on `.com`), which may [make some things private](https://docs.readthedocs.io/en/latest/choosing-a-site.html). Hopefully we can make this not private?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:343,deployability,build,builds,343,"Yeah, I had thought anyone could see that. I'll look into checking if we can make that happen. If not, I'll at least try and give everyone with commit rights to scanpy access. Can you see the docs when the build succeeds? *Updates* . * You can at least see some of the most recent build logs [here](https://readthedocs.org/projects/icb-scanpy/builds/11406014/). * It looks like you can see the PR logs for other projects, like [pip](https://readthedocs.org/projects/pip/builds/). I think the difference here is that we have a paid readthedocs account (pip is on `.org`, we are on `.com`), which may [make some things private](https://docs.readthedocs.io/en/latest/choosing-a-site.html). Hopefully we can make this not private?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:397,deployability,log,logs,397,"Yeah, I had thought anyone could see that. I'll look into checking if we can make that happen. If not, I'll at least try and give everyone with commit rights to scanpy access. Can you see the docs when the build succeeds? *Updates* . * You can at least see some of the most recent build logs [here](https://readthedocs.org/projects/icb-scanpy/builds/11406014/). * It looks like you can see the PR logs for other projects, like [pip](https://readthedocs.org/projects/pip/builds/). I think the difference here is that we have a paid readthedocs account (pip is on `.org`, we are on `.com`), which may [make some things private](https://docs.readthedocs.io/en/latest/choosing-a-site.html). Hopefully we can make this not private?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:470,deployability,build,builds,470,"Yeah, I had thought anyone could see that. I'll look into checking if we can make that happen. If not, I'll at least try and give everyone with commit rights to scanpy access. Can you see the docs when the build succeeds? *Updates* . * You can at least see some of the most recent build logs [here](https://readthedocs.org/projects/icb-scanpy/builds/11406014/). * It looks like you can see the PR logs for other projects, like [pip](https://readthedocs.org/projects/pip/builds/). I think the difference here is that we have a paid readthedocs account (pip is on `.org`, we are on `.com`), which may [make some things private](https://docs.readthedocs.io/en/latest/choosing-a-site.html). Hopefully we can make this not private?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:223,safety,Updat,Updates,223,"Yeah, I had thought anyone could see that. I'll look into checking if we can make that happen. If not, I'll at least try and give everyone with commit rights to scanpy access. Can you see the docs when the build succeeds? *Updates* . * You can at least see some of the most recent build logs [here](https://readthedocs.org/projects/icb-scanpy/builds/11406014/). * It looks like you can see the PR logs for other projects, like [pip](https://readthedocs.org/projects/pip/builds/). I think the difference here is that we have a paid readthedocs account (pip is on `.org`, we are on `.com`), which may [make some things private](https://docs.readthedocs.io/en/latest/choosing-a-site.html). Hopefully we can make this not private?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:287,safety,log,logs,287,"Yeah, I had thought anyone could see that. I'll look into checking if we can make that happen. If not, I'll at least try and give everyone with commit rights to scanpy access. Can you see the docs when the build succeeds? *Updates* . * You can at least see some of the most recent build logs [here](https://readthedocs.org/projects/icb-scanpy/builds/11406014/). * It looks like you can see the PR logs for other projects, like [pip](https://readthedocs.org/projects/pip/builds/). I think the difference here is that we have a paid readthedocs account (pip is on `.org`, we are on `.com`), which may [make some things private](https://docs.readthedocs.io/en/latest/choosing-a-site.html). Hopefully we can make this not private?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:397,safety,log,logs,397,"Yeah, I had thought anyone could see that. I'll look into checking if we can make that happen. If not, I'll at least try and give everyone with commit rights to scanpy access. Can you see the docs when the build succeeds? *Updates* . * You can at least see some of the most recent build logs [here](https://readthedocs.org/projects/icb-scanpy/builds/11406014/). * It looks like you can see the PR logs for other projects, like [pip](https://readthedocs.org/projects/pip/builds/). I think the difference here is that we have a paid readthedocs account (pip is on `.org`, we are on `.com`), which may [make some things private](https://docs.readthedocs.io/en/latest/choosing-a-site.html). Hopefully we can make this not private?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:168,security,access,access,168,"Yeah, I had thought anyone could see that. I'll look into checking if we can make that happen. If not, I'll at least try and give everyone with commit rights to scanpy access. Can you see the docs when the build succeeds? *Updates* . * You can at least see some of the most recent build logs [here](https://readthedocs.org/projects/icb-scanpy/builds/11406014/). * It looks like you can see the PR logs for other projects, like [pip](https://readthedocs.org/projects/pip/builds/). I think the difference here is that we have a paid readthedocs account (pip is on `.org`, we are on `.com`), which may [make some things private](https://docs.readthedocs.io/en/latest/choosing-a-site.html). Hopefully we can make this not private?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:223,security,Updat,Updates,223,"Yeah, I had thought anyone could see that. I'll look into checking if we can make that happen. If not, I'll at least try and give everyone with commit rights to scanpy access. Can you see the docs when the build succeeds? *Updates* . * You can at least see some of the most recent build logs [here](https://readthedocs.org/projects/icb-scanpy/builds/11406014/). * It looks like you can see the PR logs for other projects, like [pip](https://readthedocs.org/projects/pip/builds/). I think the difference here is that we have a paid readthedocs account (pip is on `.org`, we are on `.com`), which may [make some things private](https://docs.readthedocs.io/en/latest/choosing-a-site.html). Hopefully we can make this not private?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:287,security,log,logs,287,"Yeah, I had thought anyone could see that. I'll look into checking if we can make that happen. If not, I'll at least try and give everyone with commit rights to scanpy access. Can you see the docs when the build succeeds? *Updates* . * You can at least see some of the most recent build logs [here](https://readthedocs.org/projects/icb-scanpy/builds/11406014/). * It looks like you can see the PR logs for other projects, like [pip](https://readthedocs.org/projects/pip/builds/). I think the difference here is that we have a paid readthedocs account (pip is on `.org`, we are on `.com`), which may [make some things private](https://docs.readthedocs.io/en/latest/choosing-a-site.html). Hopefully we can make this not private?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:397,security,log,logs,397,"Yeah, I had thought anyone could see that. I'll look into checking if we can make that happen. If not, I'll at least try and give everyone with commit rights to scanpy access. Can you see the docs when the build succeeds? *Updates* . * You can at least see some of the most recent build logs [here](https://readthedocs.org/projects/icb-scanpy/builds/11406014/). * It looks like you can see the PR logs for other projects, like [pip](https://readthedocs.org/projects/pip/builds/). I think the difference here is that we have a paid readthedocs account (pip is on `.org`, we are on `.com`), which may [make some things private](https://docs.readthedocs.io/en/latest/choosing-a-site.html). Hopefully we can make this not private?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:287,testability,log,logs,287,"Yeah, I had thought anyone could see that. I'll look into checking if we can make that happen. If not, I'll at least try and give everyone with commit rights to scanpy access. Can you see the docs when the build succeeds? *Updates* . * You can at least see some of the most recent build logs [here](https://readthedocs.org/projects/icb-scanpy/builds/11406014/). * It looks like you can see the PR logs for other projects, like [pip](https://readthedocs.org/projects/pip/builds/). I think the difference here is that we have a paid readthedocs account (pip is on `.org`, we are on `.com`), which may [make some things private](https://docs.readthedocs.io/en/latest/choosing-a-site.html). Hopefully we can make this not private?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:397,testability,log,logs,397,"Yeah, I had thought anyone could see that. I'll look into checking if we can make that happen. If not, I'll at least try and give everyone with commit rights to scanpy access. Can you see the docs when the build succeeds? *Updates* . * You can at least see some of the most recent build logs [here](https://readthedocs.org/projects/icb-scanpy/builds/11406014/). * It looks like you can see the PR logs for other projects, like [pip](https://readthedocs.org/projects/pip/builds/). I think the difference here is that we have a paid readthedocs account (pip is on `.org`, we are on `.com`), which may [make some things private](https://docs.readthedocs.io/en/latest/choosing-a-site.html). Hopefully we can make this not private?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/pull/1308:207,integrability,translat,translates,207,@ivirshup . Responding to [this](https://github.com/theislab/scanpy/issues/1301#issuecomment-654772068). The problem with `{prefix}_pca` to `obsm` is that we have naming conventions for `basis='pca'` - this translates to `obsm['X_pca']` in some plotting fucntions.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1308
https://github.com/scverse/scanpy/pull/1308:207,interoperability,translat,translates,207,@ivirshup . Responding to [this](https://github.com/theislab/scanpy/issues/1301#issuecomment-654772068). The problem with `{prefix}_pca` to `obsm` is that we have naming conventions for `basis='pca'` - this translates to `obsm['X_pca']` in some plotting fucntions.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1308
https://github.com/scverse/scanpy/pull/1308:105,safety,test,tests,105,"Oh, no need to do this, I've already got this working a bit more generically (also supports `obsm`) with tests. Just wasn't sure about how to do the keys.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1308
https://github.com/scverse/scanpy/pull/1308:105,testability,test,tests,105,"Oh, no need to do this, I've already got this working a bit more generically (also supports `obsm`) with tests. Just wasn't sure about how to do the keys.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1308
https://github.com/scverse/scanpy/pull/1308:83,usability,support,supports,83,"Oh, no need to do this, I've already got this working a bit more generically (also supports `obsm`) with tests. Just wasn't sure about how to do the keys.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1308
https://github.com/scverse/scanpy/pull/1308:70,modifiability,layer,layers,70,So what is now the recommended way of calculating and plotting PCA on layers? Is it still the same as suggested in https://github.com/theislab/scanpy/issues/1301? With this I am still unable to use sc.pl.pca_variance_ratio.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1308
https://github.com/scverse/scanpy/pull/1308:4,deployability,updat,update,4,Any update on this? I can't figure out a way to run PCA on a specified layer & get the additional returns beyond the PCA plot.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1308
https://github.com/scverse/scanpy/pull/1308:61,interoperability,specif,specified,61,Any update on this? I can't figure out a way to run PCA on a specified layer & get the additional returns beyond the PCA plot.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1308
https://github.com/scverse/scanpy/pull/1308:71,modifiability,layer,layer,71,Any update on this? I can't figure out a way to run PCA on a specified layer & get the additional returns beyond the PCA plot.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1308
https://github.com/scverse/scanpy/pull/1308:4,safety,updat,update,4,Any update on this? I can't figure out a way to run PCA on a specified layer & get the additional returns beyond the PCA plot.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1308
https://github.com/scverse/scanpy/pull/1308:4,security,updat,update,4,Any update on this? I can't figure out a way to run PCA on a specified layer & get the additional returns beyond the PCA plot.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1308
https://github.com/scverse/scanpy/pull/1309:398,availability,error,errors,398,"I think the main issue with the docs building right now is that there are references to the `DotPlot` class, but there isn't any page built for those to link to. I'm not sure the `**kwargs` argument is causing an issue, since the docs for `sc.queries.enrich` have this, and seem to work fine: https://scanpy.readthedocs.io/en/stable/api/scanpy.queries.enrich.html. I have had issues with doc build errors failing to show up if you just try and build the docs again. It might be worth running `make clean` before each `make build` to see what happens.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1309
https://github.com/scverse/scanpy/pull/1309:37,deployability,build,building,37,"I think the main issue with the docs building right now is that there are references to the `DotPlot` class, but there isn't any page built for those to link to. I'm not sure the `**kwargs` argument is causing an issue, since the docs for `sc.queries.enrich` have this, and seem to work fine: https://scanpy.readthedocs.io/en/stable/api/scanpy.queries.enrich.html. I have had issues with doc build errors failing to show up if you just try and build the docs again. It might be worth running `make clean` before each `make build` to see what happens.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1309
https://github.com/scverse/scanpy/pull/1309:333,deployability,api,api,333,"I think the main issue with the docs building right now is that there are references to the `DotPlot` class, but there isn't any page built for those to link to. I'm not sure the `**kwargs` argument is causing an issue, since the docs for `sc.queries.enrich` have this, and seem to work fine: https://scanpy.readthedocs.io/en/stable/api/scanpy.queries.enrich.html. I have had issues with doc build errors failing to show up if you just try and build the docs again. It might be worth running `make clean` before each `make build` to see what happens.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1309
https://github.com/scverse/scanpy/pull/1309:392,deployability,build,build,392,"I think the main issue with the docs building right now is that there are references to the `DotPlot` class, but there isn't any page built for those to link to. I'm not sure the `**kwargs` argument is causing an issue, since the docs for `sc.queries.enrich` have this, and seem to work fine: https://scanpy.readthedocs.io/en/stable/api/scanpy.queries.enrich.html. I have had issues with doc build errors failing to show up if you just try and build the docs again. It might be worth running `make clean` before each `make build` to see what happens.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1309
https://github.com/scverse/scanpy/pull/1309:405,deployability,fail,failing,405,"I think the main issue with the docs building right now is that there are references to the `DotPlot` class, but there isn't any page built for those to link to. I'm not sure the `**kwargs` argument is causing an issue, since the docs for `sc.queries.enrich` have this, and seem to work fine: https://scanpy.readthedocs.io/en/stable/api/scanpy.queries.enrich.html. I have had issues with doc build errors failing to show up if you just try and build the docs again. It might be worth running `make clean` before each `make build` to see what happens.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1309
https://github.com/scverse/scanpy/pull/1309:444,deployability,build,build,444,"I think the main issue with the docs building right now is that there are references to the `DotPlot` class, but there isn't any page built for those to link to. I'm not sure the `**kwargs` argument is causing an issue, since the docs for `sc.queries.enrich` have this, and seem to work fine: https://scanpy.readthedocs.io/en/stable/api/scanpy.queries.enrich.html. I have had issues with doc build errors failing to show up if you just try and build the docs again. It might be worth running `make clean` before each `make build` to see what happens.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1309
https://github.com/scverse/scanpy/pull/1309:523,deployability,build,build,523,"I think the main issue with the docs building right now is that there are references to the `DotPlot` class, but there isn't any page built for those to link to. I'm not sure the `**kwargs` argument is causing an issue, since the docs for `sc.queries.enrich` have this, and seem to work fine: https://scanpy.readthedocs.io/en/stable/api/scanpy.queries.enrich.html. I have had issues with doc build errors failing to show up if you just try and build the docs again. It might be worth running `make clean` before each `make build` to see what happens.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1309
https://github.com/scverse/scanpy/pull/1309:333,integrability,api,api,333,"I think the main issue with the docs building right now is that there are references to the `DotPlot` class, but there isn't any page built for those to link to. I'm not sure the `**kwargs` argument is causing an issue, since the docs for `sc.queries.enrich` have this, and seem to work fine: https://scanpy.readthedocs.io/en/stable/api/scanpy.queries.enrich.html. I have had issues with doc build errors failing to show up if you just try and build the docs again. It might be worth running `make clean` before each `make build` to see what happens.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1309
https://github.com/scverse/scanpy/pull/1309:333,interoperability,api,api,333,"I think the main issue with the docs building right now is that there are references to the `DotPlot` class, but there isn't any page built for those to link to. I'm not sure the `**kwargs` argument is causing an issue, since the docs for `sc.queries.enrich` have this, and seem to work fine: https://scanpy.readthedocs.io/en/stable/api/scanpy.queries.enrich.html. I have had issues with doc build errors failing to show up if you just try and build the docs again. It might be worth running `make clean` before each `make build` to see what happens.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1309
https://github.com/scverse/scanpy/pull/1309:398,performance,error,errors,398,"I think the main issue with the docs building right now is that there are references to the `DotPlot` class, but there isn't any page built for those to link to. I'm not sure the `**kwargs` argument is causing an issue, since the docs for `sc.queries.enrich` have this, and seem to work fine: https://scanpy.readthedocs.io/en/stable/api/scanpy.queries.enrich.html. I have had issues with doc build errors failing to show up if you just try and build the docs again. It might be worth running `make clean` before each `make build` to see what happens.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1309
https://github.com/scverse/scanpy/pull/1309:405,reliability,fail,failing,405,"I think the main issue with the docs building right now is that there are references to the `DotPlot` class, but there isn't any page built for those to link to. I'm not sure the `**kwargs` argument is causing an issue, since the docs for `sc.queries.enrich` have this, and seem to work fine: https://scanpy.readthedocs.io/en/stable/api/scanpy.queries.enrich.html. I have had issues with doc build errors failing to show up if you just try and build the docs again. It might be worth running `make clean` before each `make build` to see what happens.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1309
https://github.com/scverse/scanpy/pull/1309:398,safety,error,errors,398,"I think the main issue with the docs building right now is that there are references to the `DotPlot` class, but there isn't any page built for those to link to. I'm not sure the `**kwargs` argument is causing an issue, since the docs for `sc.queries.enrich` have this, and seem to work fine: https://scanpy.readthedocs.io/en/stable/api/scanpy.queries.enrich.html. I have had issues with doc build errors failing to show up if you just try and build the docs again. It might be worth running `make clean` before each `make build` to see what happens.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1309
https://github.com/scverse/scanpy/pull/1309:398,usability,error,errors,398,"I think the main issue with the docs building right now is that there are references to the `DotPlot` class, but there isn't any page built for those to link to. I'm not sure the `**kwargs` argument is causing an issue, since the docs for `sc.queries.enrich` have this, and seem to work fine: https://scanpy.readthedocs.io/en/stable/api/scanpy.queries.enrich.html. I have had issues with doc build errors failing to show up if you just try and build the docs again. It might be worth running `make clean` before each `make build` to see what happens.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1309
https://github.com/scverse/scanpy/pull/1309:52,availability,error,errors,52,@flying-sheep Thanks! I will take care of the other errors.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1309
https://github.com/scverse/scanpy/pull/1309:52,performance,error,errors,52,@flying-sheep Thanks! I will take care of the other errors.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1309
https://github.com/scverse/scanpy/pull/1309:52,safety,error,errors,52,@flying-sheep Thanks! I will take care of the other errors.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1309
https://github.com/scverse/scanpy/pull/1309:52,usability,error,errors,52,@flying-sheep Thanks! I will take care of the other errors.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1309
https://github.com/scverse/scanpy/pull/1309:9,safety,test,tests,9,Now that tests are passing I will replace the outdated doc images.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1309
https://github.com/scverse/scanpy/pull/1309:9,testability,test,tests,9,Now that tests are passing I will replace the outdated doc images.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1309
https://github.com/scverse/scanpy/pull/1310:70,reliability,doe,does,70,Fantastic! Two questions:. * Was the issue from the indexing? . * How does this compare to other implementations? Is it equivalent?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1310
https://github.com/scverse/scanpy/pull/1310:135,reliability,doe,doesn,135,"Yes, the problem was in the indexing. Do you mean equivalent to `scipy.stats.mannwhitneyu`? No it isn't, as `scipy.stats.mannwhitneyu` doesn't support matrix inputs. Also `rank_genes_groups` doesn't support tie correction yet, but i'm going to add it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1310
https://github.com/scverse/scanpy/pull/1310:191,reliability,doe,doesn,191,"Yes, the problem was in the indexing. Do you mean equivalent to `scipy.stats.mannwhitneyu`? No it isn't, as `scipy.stats.mannwhitneyu` doesn't support matrix inputs. Also `rank_genes_groups` doesn't support tie correction yet, but i'm going to add it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1310
https://github.com/scverse/scanpy/pull/1310:158,safety,input,inputs,158,"Yes, the problem was in the indexing. Do you mean equivalent to `scipy.stats.mannwhitneyu`? No it isn't, as `scipy.stats.mannwhitneyu` doesn't support matrix inputs. Also `rank_genes_groups` doesn't support tie correction yet, but i'm going to add it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1310
https://github.com/scverse/scanpy/pull/1310:143,usability,support,support,143,"Yes, the problem was in the indexing. Do you mean equivalent to `scipy.stats.mannwhitneyu`? No it isn't, as `scipy.stats.mannwhitneyu` doesn't support matrix inputs. Also `rank_genes_groups` doesn't support tie correction yet, but i'm going to add it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1310
https://github.com/scverse/scanpy/pull/1310:158,usability,input,inputs,158,"Yes, the problem was in the indexing. Do you mean equivalent to `scipy.stats.mannwhitneyu`? No it isn't, as `scipy.stats.mannwhitneyu` doesn't support matrix inputs. Also `rank_genes_groups` doesn't support tie correction yet, but i'm going to add it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1310
https://github.com/scverse/scanpy/pull/1310:199,usability,support,support,199,"Yes, the problem was in the indexing. Do you mean equivalent to `scipy.stats.mannwhitneyu`? No it isn't, as `scipy.stats.mannwhitneyu` doesn't support matrix inputs. Also `rank_genes_groups` doesn't support tie correction yet, but i'm going to add it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1310
https://github.com/scverse/scanpy/pull/1310:156,interoperability,standard,standard,156,"Yeah, I was thinking `scipy.stats.mannwhitneyu` though I'm not sure if that does an approximate or exact test. It would be good if we could match some gold standard implementation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1310
https://github.com/scverse/scanpy/pull/1310:76,reliability,doe,does,76,"Yeah, I was thinking `scipy.stats.mannwhitneyu` though I'm not sure if that does an approximate or exact test. It would be good if we could match some gold standard implementation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1310
https://github.com/scverse/scanpy/pull/1310:105,safety,test,test,105,"Yeah, I was thinking `scipy.stats.mannwhitneyu` though I'm not sure if that does an approximate or exact test. It would be good if we could match some gold standard implementation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1310
https://github.com/scverse/scanpy/pull/1310:105,testability,test,test,105,"Yeah, I was thinking `scipy.stats.mannwhitneyu` though I'm not sure if that does an approximate or exact test. It would be good if we could match some gold standard implementation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1310
https://github.com/scverse/scanpy/pull/1310:50,safety,valid,valid,50,"It is also approximate, so the comparison will be valid after i add the tie correction.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1310
https://github.com/scverse/scanpy/issues/1312:57,modifiability,paramet,parameter,57,"Hi @YubinXie ,. You can fix this by setting the `wspace` parameter in the plot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1312
https://github.com/scverse/scanpy/issues/1312:148,deployability,automat,automatic,148,"> Hi @YubinXie ,. > . > You can fix this by setting the `wspace` parameter in the plot. Thank you for your quick response! Is there a way to do any automatic adjustments? something like tight_layout? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1312
https://github.com/scverse/scanpy/issues/1312:65,modifiability,paramet,parameter,65,"> Hi @YubinXie ,. > . > You can fix this by setting the `wspace` parameter in the plot. Thank you for your quick response! Is there a way to do any automatic adjustments? something like tight_layout? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1312
https://github.com/scverse/scanpy/issues/1312:148,testability,automat,automatic,148,"> Hi @YubinXie ,. > . > You can fix this by setting the `wspace` parameter in the plot. Thank you for your quick response! Is there a way to do any automatic adjustments? something like tight_layout? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1312
https://github.com/scverse/scanpy/issues/1312:29,energy efficiency,current,currently,29,"As far as I'm aware, this is currently not implemented. But @fidelram can say more here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1312
https://github.com/scverse/scanpy/issues/1312:54,deployability,Depend,Depending,54,"It is difficult to find a one-size-fits-all solution. Depending on the number of legends, the length of the labels and the DPI used the space required will vary. Thus, I think is is better for the user to adjust the plots.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1312
https://github.com/scverse/scanpy/issues/1312:54,integrability,Depend,Depending,54,"It is difficult to find a one-size-fits-all solution. Depending on the number of legends, the length of the labels and the DPI used the space required will vary. Thus, I think is is better for the user to adjust the plots.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1312
https://github.com/scverse/scanpy/issues/1312:54,modifiability,Depend,Depending,54,"It is difficult to find a one-size-fits-all solution. Depending on the number of legends, the length of the labels and the DPI used the space required will vary. Thus, I think is is better for the user to adjust the plots.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1312
https://github.com/scverse/scanpy/issues/1312:54,safety,Depend,Depending,54,"It is difficult to find a one-size-fits-all solution. Depending on the number of legends, the length of the labels and the DPI used the space required will vary. Thus, I think is is better for the user to adjust the plots.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1312
https://github.com/scverse/scanpy/issues/1312:54,testability,Depend,Depending,54,"It is difficult to find a one-size-fits-all solution. Depending on the number of legends, the length of the labels and the DPI used the space required will vary. Thus, I think is is better for the user to adjust the plots.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1312
https://github.com/scverse/scanpy/issues/1312:197,usability,user,user,197,"It is difficult to find a one-size-fits-all solution. Depending on the number of legends, the length of the labels and the DPI used the space required will vary. Thus, I think is is better for the user to adjust the plots.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1312
https://github.com/scverse/scanpy/issues/1312:169,deployability,manag,manager,169,"Has anyone explored the new constrained layout https://matplotlib.org/3.1.1/tutorials/intermediate/constrainedlayout_guide.html ? it looks like there is a better layout manager this time, I wonder if we can take advantage of it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1312
https://github.com/scverse/scanpy/issues/1312:169,energy efficiency,manag,manager,169,"Has anyone explored the new constrained layout https://matplotlib.org/3.1.1/tutorials/intermediate/constrainedlayout_guide.html ? it looks like there is a better layout manager this time, I wonder if we can take advantage of it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1312
https://github.com/scverse/scanpy/issues/1312:86,modifiability,interm,intermediate,86,"Has anyone explored the new constrained layout https://matplotlib.org/3.1.1/tutorials/intermediate/constrainedlayout_guide.html ? it looks like there is a better layout manager this time, I wonder if we can take advantage of it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1312
https://github.com/scverse/scanpy/issues/1312:182,performance,time,time,182,"Has anyone explored the new constrained layout https://matplotlib.org/3.1.1/tutorials/intermediate/constrainedlayout_guide.html ? it looks like there is a better layout manager this time, I wonder if we can take advantage of it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1312
https://github.com/scverse/scanpy/issues/1312:169,safety,manag,manager,169,"Has anyone explored the new constrained layout https://matplotlib.org/3.1.1/tutorials/intermediate/constrainedlayout_guide.html ? it looks like there is a better layout manager this time, I wonder if we can take advantage of it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1312
https://github.com/scverse/scanpy/issues/1312:84,reliability,doe,doesn,84,"This is different than tight layout and relatively new though, are you sure that it doesn't really help us at all?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1312
https://github.com/scverse/scanpy/issues/1312:99,usability,help,help,99,"This is different than tight layout and relatively new though, are you sure that it doesn't really help us at all?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1312
https://github.com/scverse/scanpy/issues/1313:49,availability,down,downgrade,49,"Hi, this is fixed on master. You can temporarily downgrade scipy to avoid this error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:79,availability,error,error,79,"Hi, this is fixed on master. You can temporarily downgrade scipy to avoid this error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:79,performance,error,error,79,"Hi, this is fixed on master. You can temporarily downgrade scipy to avoid this error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:68,safety,avoid,avoid,68,"Hi, this is fixed on master. You can temporarily downgrade scipy to avoid this error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:79,safety,error,error,79,"Hi, this is fixed on master. You can temporarily downgrade scipy to avoid this error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:79,usability,error,error,79,"Hi, this is fixed on master. You can temporarily downgrade scipy to avoid this error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:64,availability,down,downgrade,64,"Hi, was it just fixed? If I clone right now, will I not have to downgrade scipy?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:28,availability,down,downgrading,28,"Yes, it should work without downgrading.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1315:155,usability,behavi,behavior,155,"In python `('HES4')` parses as a string, not as a tuple. You'd have to put `('HES4',)` to get a tuple, while you could write `['HES4']` to get a list. The behavior here could be more straight-forward, but you should be able to get what you want by passing an iterable of strings.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1315
https://github.com/scverse/scanpy/pull/1317:8,usability,help,help,8,Glad to help! Keep up the good work ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1317
https://github.com/scverse/scanpy/issues/1318:68,performance,perform,performance,68,"@Koncopd . hi, sc.pp.neighbors doesn't have hsnw which has superior performance from what I've seen in my data and literature https://arxiv.org/abs/1603.09320.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1318
https://github.com/scverse/scanpy/issues/1318:31,reliability,doe,doesn,31,"@Koncopd . hi, sc.pp.neighbors doesn't have hsnw which has superior performance from what I've seen in my data and literature https://arxiv.org/abs/1603.09320.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1318
https://github.com/scverse/scanpy/issues/1318:68,usability,perform,performance,68,"@Koncopd . hi, sc.pp.neighbors doesn't have hsnw which has superior performance from what I've seen in my data and literature https://arxiv.org/abs/1603.09320.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1318
https://github.com/scverse/scanpy/issues/1318:58,availability,slo,slot,58,"just for reference, if the anndata object has an empty .X slot and i create another .obsm with the features like this . ```. dummy = anndata.AnnData(obs=[x for x in adata.obs.index]). dummy.obs = adata.obs. dummy.obsm[""X_feat""] = adata.X. ``` . this seems to trick the umap at the right stage to use the representation i had chosen when calling the neighbors function. Also, would it be easier to allow Umap to have an explicit ""use_rep"" param? thanks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1318
https://github.com/scverse/scanpy/issues/1318:287,deployability,stage,stage,287,"just for reference, if the anndata object has an empty .X slot and i create another .obsm with the features like this . ```. dummy = anndata.AnnData(obs=[x for x in adata.obs.index]). dummy.obs = adata.obs. dummy.obsm[""X_feat""] = adata.X. ``` . this seems to trick the umap at the right stage to use the representation i had chosen when calling the neighbors function. Also, would it be easier to allow Umap to have an explicit ""use_rep"" param? thanks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1318
https://github.com/scverse/scanpy/issues/1318:58,reliability,slo,slot,58,"just for reference, if the anndata object has an empty .X slot and i create another .obsm with the features like this . ```. dummy = anndata.AnnData(obs=[x for x in adata.obs.index]). dummy.obs = adata.obs. dummy.obsm[""X_feat""] = adata.X. ``` . this seems to trick the umap at the right stage to use the representation i had chosen when calling the neighbors function. Also, would it be easier to allow Umap to have an explicit ""use_rep"" param? thanks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1318
https://github.com/scverse/scanpy/pull/1320:74,deployability,depend,dependencies,74,"Not completely sure if this is doing what I intended. I added the `-U` so dependencies would be upgraded, but numpy still isn't being upgraded as shown by these warnings:. ```. umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.15.4 which is incompatible. scvi 0.6.6 has requirement numpy>=1.16.2, but you'll have numpy 1.15.4 which is incompatible. ```. Not sure why this is happening. I'd prefer if we didn't have to manually specify the dependencies of our dependencies. Any ideas @flying-sheep? ------------------. Updating pip doesn't seem to do anything (maybe it has to do with ""editable mode""?). --------------------. An easy fix is just to add a version requirement on `numpy`, but I really feel like dependency resolution should be dealing with that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:96,deployability,upgrad,upgraded,96,"Not completely sure if this is doing what I intended. I added the `-U` so dependencies would be upgraded, but numpy still isn't being upgraded as shown by these warnings:. ```. umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.15.4 which is incompatible. scvi 0.6.6 has requirement numpy>=1.16.2, but you'll have numpy 1.15.4 which is incompatible. ```. Not sure why this is happening. I'd prefer if we didn't have to manually specify the dependencies of our dependencies. Any ideas @flying-sheep? ------------------. Updating pip doesn't seem to do anything (maybe it has to do with ""editable mode""?). --------------------. An easy fix is just to add a version requirement on `numpy`, but I really feel like dependency resolution should be dealing with that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:134,deployability,upgrad,upgraded,134,"Not completely sure if this is doing what I intended. I added the `-U` so dependencies would be upgraded, but numpy still isn't being upgraded as shown by these warnings:. ```. umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.15.4 which is incompatible. scvi 0.6.6 has requirement numpy>=1.16.2, but you'll have numpy 1.15.4 which is incompatible. ```. Not sure why this is happening. I'd prefer if we didn't have to manually specify the dependencies of our dependencies. Any ideas @flying-sheep? ------------------. Updating pip doesn't seem to do anything (maybe it has to do with ""editable mode""?). --------------------. An easy fix is just to add a version requirement on `numpy`, but I really feel like dependency resolution should be dealing with that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:459,deployability,depend,dependencies,459,"Not completely sure if this is doing what I intended. I added the `-U` so dependencies would be upgraded, but numpy still isn't being upgraded as shown by these warnings:. ```. umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.15.4 which is incompatible. scvi 0.6.6 has requirement numpy>=1.16.2, but you'll have numpy 1.15.4 which is incompatible. ```. Not sure why this is happening. I'd prefer if we didn't have to manually specify the dependencies of our dependencies. Any ideas @flying-sheep? ------------------. Updating pip doesn't seem to do anything (maybe it has to do with ""editable mode""?). --------------------. An easy fix is just to add a version requirement on `numpy`, but I really feel like dependency resolution should be dealing with that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:479,deployability,depend,dependencies,479,"Not completely sure if this is doing what I intended. I added the `-U` so dependencies would be upgraded, but numpy still isn't being upgraded as shown by these warnings:. ```. umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.15.4 which is incompatible. scvi 0.6.6 has requirement numpy>=1.16.2, but you'll have numpy 1.15.4 which is incompatible. ```. Not sure why this is happening. I'd prefer if we didn't have to manually specify the dependencies of our dependencies. Any ideas @flying-sheep? ------------------. Updating pip doesn't seem to do anything (maybe it has to do with ""editable mode""?). --------------------. An easy fix is just to add a version requirement on `numpy`, but I really feel like dependency resolution should be dealing with that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:538,deployability,Updat,Updating,538,"Not completely sure if this is doing what I intended. I added the `-U` so dependencies would be upgraded, but numpy still isn't being upgraded as shown by these warnings:. ```. umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.15.4 which is incompatible. scvi 0.6.6 has requirement numpy>=1.16.2, but you'll have numpy 1.15.4 which is incompatible. ```. Not sure why this is happening. I'd prefer if we didn't have to manually specify the dependencies of our dependencies. Any ideas @flying-sheep? ------------------. Updating pip doesn't seem to do anything (maybe it has to do with ""editable mode""?). --------------------. An easy fix is just to add a version requirement on `numpy`, but I really feel like dependency resolution should be dealing with that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:674,deployability,version,version,674,"Not completely sure if this is doing what I intended. I added the `-U` so dependencies would be upgraded, but numpy still isn't being upgraded as shown by these warnings:. ```. umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.15.4 which is incompatible. scvi 0.6.6 has requirement numpy>=1.16.2, but you'll have numpy 1.15.4 which is incompatible. ```. Not sure why this is happening. I'd prefer if we didn't have to manually specify the dependencies of our dependencies. Any ideas @flying-sheep? ------------------. Updating pip doesn't seem to do anything (maybe it has to do with ""editable mode""?). --------------------. An easy fix is just to add a version requirement on `numpy`, but I really feel like dependency resolution should be dealing with that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:729,deployability,depend,dependency,729,"Not completely sure if this is doing what I intended. I added the `-U` so dependencies would be upgraded, but numpy still isn't being upgraded as shown by these warnings:. ```. umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.15.4 which is incompatible. scvi 0.6.6 has requirement numpy>=1.16.2, but you'll have numpy 1.15.4 which is incompatible. ```. Not sure why this is happening. I'd prefer if we didn't have to manually specify the dependencies of our dependencies. Any ideas @flying-sheep? ------------------. Updating pip doesn't seem to do anything (maybe it has to do with ""editable mode""?). --------------------. An easy fix is just to add a version requirement on `numpy`, but I really feel like dependency resolution should be dealing with that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:74,integrability,depend,dependencies,74,"Not completely sure if this is doing what I intended. I added the `-U` so dependencies would be upgraded, but numpy still isn't being upgraded as shown by these warnings:. ```. umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.15.4 which is incompatible. scvi 0.6.6 has requirement numpy>=1.16.2, but you'll have numpy 1.15.4 which is incompatible. ```. Not sure why this is happening. I'd prefer if we didn't have to manually specify the dependencies of our dependencies. Any ideas @flying-sheep? ------------------. Updating pip doesn't seem to do anything (maybe it has to do with ""editable mode""?). --------------------. An easy fix is just to add a version requirement on `numpy`, but I really feel like dependency resolution should be dealing with that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:459,integrability,depend,dependencies,459,"Not completely sure if this is doing what I intended. I added the `-U` so dependencies would be upgraded, but numpy still isn't being upgraded as shown by these warnings:. ```. umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.15.4 which is incompatible. scvi 0.6.6 has requirement numpy>=1.16.2, but you'll have numpy 1.15.4 which is incompatible. ```. Not sure why this is happening. I'd prefer if we didn't have to manually specify the dependencies of our dependencies. Any ideas @flying-sheep? ------------------. Updating pip doesn't seem to do anything (maybe it has to do with ""editable mode""?). --------------------. An easy fix is just to add a version requirement on `numpy`, but I really feel like dependency resolution should be dealing with that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:479,integrability,depend,dependencies,479,"Not completely sure if this is doing what I intended. I added the `-U` so dependencies would be upgraded, but numpy still isn't being upgraded as shown by these warnings:. ```. umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.15.4 which is incompatible. scvi 0.6.6 has requirement numpy>=1.16.2, but you'll have numpy 1.15.4 which is incompatible. ```. Not sure why this is happening. I'd prefer if we didn't have to manually specify the dependencies of our dependencies. Any ideas @flying-sheep? ------------------. Updating pip doesn't seem to do anything (maybe it has to do with ""editable mode""?). --------------------. An easy fix is just to add a version requirement on `numpy`, but I really feel like dependency resolution should be dealing with that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:674,integrability,version,version,674,"Not completely sure if this is doing what I intended. I added the `-U` so dependencies would be upgraded, but numpy still isn't being upgraded as shown by these warnings:. ```. umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.15.4 which is incompatible. scvi 0.6.6 has requirement numpy>=1.16.2, but you'll have numpy 1.15.4 which is incompatible. ```. Not sure why this is happening. I'd prefer if we didn't have to manually specify the dependencies of our dependencies. Any ideas @flying-sheep? ------------------. Updating pip doesn't seem to do anything (maybe it has to do with ""editable mode""?). --------------------. An easy fix is just to add a version requirement on `numpy`, but I really feel like dependency resolution should be dealing with that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:729,integrability,depend,dependency,729,"Not completely sure if this is doing what I intended. I added the `-U` so dependencies would be upgraded, but numpy still isn't being upgraded as shown by these warnings:. ```. umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.15.4 which is incompatible. scvi 0.6.6 has requirement numpy>=1.16.2, but you'll have numpy 1.15.4 which is incompatible. ```. Not sure why this is happening. I'd prefer if we didn't have to manually specify the dependencies of our dependencies. Any ideas @flying-sheep? ------------------. Updating pip doesn't seem to do anything (maybe it has to do with ""editable mode""?). --------------------. An easy fix is just to add a version requirement on `numpy`, but I really feel like dependency resolution should be dealing with that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:261,interoperability,incompatib,incompatible,261,"Not completely sure if this is doing what I intended. I added the `-U` so dependencies would be upgraded, but numpy still isn't being upgraded as shown by these warnings:. ```. umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.15.4 which is incompatible. scvi 0.6.6 has requirement numpy>=1.16.2, but you'll have numpy 1.15.4 which is incompatible. ```. Not sure why this is happening. I'd prefer if we didn't have to manually specify the dependencies of our dependencies. Any ideas @flying-sheep? ------------------. Updating pip doesn't seem to do anything (maybe it has to do with ""editable mode""?). --------------------. An easy fix is just to add a version requirement on `numpy`, but I really feel like dependency resolution should be dealing with that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:355,interoperability,incompatib,incompatible,355,"Not completely sure if this is doing what I intended. I added the `-U` so dependencies would be upgraded, but numpy still isn't being upgraded as shown by these warnings:. ```. umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.15.4 which is incompatible. scvi 0.6.6 has requirement numpy>=1.16.2, but you'll have numpy 1.15.4 which is incompatible. ```. Not sure why this is happening. I'd prefer if we didn't have to manually specify the dependencies of our dependencies. Any ideas @flying-sheep? ------------------. Updating pip doesn't seem to do anything (maybe it has to do with ""editable mode""?). --------------------. An easy fix is just to add a version requirement on `numpy`, but I really feel like dependency resolution should be dealing with that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:447,interoperability,specif,specify,447,"Not completely sure if this is doing what I intended. I added the `-U` so dependencies would be upgraded, but numpy still isn't being upgraded as shown by these warnings:. ```. umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.15.4 which is incompatible. scvi 0.6.6 has requirement numpy>=1.16.2, but you'll have numpy 1.15.4 which is incompatible. ```. Not sure why this is happening. I'd prefer if we didn't have to manually specify the dependencies of our dependencies. Any ideas @flying-sheep? ------------------. Updating pip doesn't seem to do anything (maybe it has to do with ""editable mode""?). --------------------. An easy fix is just to add a version requirement on `numpy`, but I really feel like dependency resolution should be dealing with that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:74,modifiability,depend,dependencies,74,"Not completely sure if this is doing what I intended. I added the `-U` so dependencies would be upgraded, but numpy still isn't being upgraded as shown by these warnings:. ```. umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.15.4 which is incompatible. scvi 0.6.6 has requirement numpy>=1.16.2, but you'll have numpy 1.15.4 which is incompatible. ```. Not sure why this is happening. I'd prefer if we didn't have to manually specify the dependencies of our dependencies. Any ideas @flying-sheep? ------------------. Updating pip doesn't seem to do anything (maybe it has to do with ""editable mode""?). --------------------. An easy fix is just to add a version requirement on `numpy`, but I really feel like dependency resolution should be dealing with that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:96,modifiability,upgrad,upgraded,96,"Not completely sure if this is doing what I intended. I added the `-U` so dependencies would be upgraded, but numpy still isn't being upgraded as shown by these warnings:. ```. umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.15.4 which is incompatible. scvi 0.6.6 has requirement numpy>=1.16.2, but you'll have numpy 1.15.4 which is incompatible. ```. Not sure why this is happening. I'd prefer if we didn't have to manually specify the dependencies of our dependencies. Any ideas @flying-sheep? ------------------. Updating pip doesn't seem to do anything (maybe it has to do with ""editable mode""?). --------------------. An easy fix is just to add a version requirement on `numpy`, but I really feel like dependency resolution should be dealing with that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:134,modifiability,upgrad,upgraded,134,"Not completely sure if this is doing what I intended. I added the `-U` so dependencies would be upgraded, but numpy still isn't being upgraded as shown by these warnings:. ```. umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.15.4 which is incompatible. scvi 0.6.6 has requirement numpy>=1.16.2, but you'll have numpy 1.15.4 which is incompatible. ```. Not sure why this is happening. I'd prefer if we didn't have to manually specify the dependencies of our dependencies. Any ideas @flying-sheep? ------------------. Updating pip doesn't seem to do anything (maybe it has to do with ""editable mode""?). --------------------. An easy fix is just to add a version requirement on `numpy`, but I really feel like dependency resolution should be dealing with that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:459,modifiability,depend,dependencies,459,"Not completely sure if this is doing what I intended. I added the `-U` so dependencies would be upgraded, but numpy still isn't being upgraded as shown by these warnings:. ```. umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.15.4 which is incompatible. scvi 0.6.6 has requirement numpy>=1.16.2, but you'll have numpy 1.15.4 which is incompatible. ```. Not sure why this is happening. I'd prefer if we didn't have to manually specify the dependencies of our dependencies. Any ideas @flying-sheep? ------------------. Updating pip doesn't seem to do anything (maybe it has to do with ""editable mode""?). --------------------. An easy fix is just to add a version requirement on `numpy`, but I really feel like dependency resolution should be dealing with that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:479,modifiability,depend,dependencies,479,"Not completely sure if this is doing what I intended. I added the `-U` so dependencies would be upgraded, but numpy still isn't being upgraded as shown by these warnings:. ```. umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.15.4 which is incompatible. scvi 0.6.6 has requirement numpy>=1.16.2, but you'll have numpy 1.15.4 which is incompatible. ```. Not sure why this is happening. I'd prefer if we didn't have to manually specify the dependencies of our dependencies. Any ideas @flying-sheep? ------------------. Updating pip doesn't seem to do anything (maybe it has to do with ""editable mode""?). --------------------. An easy fix is just to add a version requirement on `numpy`, but I really feel like dependency resolution should be dealing with that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:674,modifiability,version,version,674,"Not completely sure if this is doing what I intended. I added the `-U` so dependencies would be upgraded, but numpy still isn't being upgraded as shown by these warnings:. ```. umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.15.4 which is incompatible. scvi 0.6.6 has requirement numpy>=1.16.2, but you'll have numpy 1.15.4 which is incompatible. ```. Not sure why this is happening. I'd prefer if we didn't have to manually specify the dependencies of our dependencies. Any ideas @flying-sheep? ------------------. Updating pip doesn't seem to do anything (maybe it has to do with ""editable mode""?). --------------------. An easy fix is just to add a version requirement on `numpy`, but I really feel like dependency resolution should be dealing with that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:729,modifiability,depend,dependency,729,"Not completely sure if this is doing what I intended. I added the `-U` so dependencies would be upgraded, but numpy still isn't being upgraded as shown by these warnings:. ```. umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.15.4 which is incompatible. scvi 0.6.6 has requirement numpy>=1.16.2, but you'll have numpy 1.15.4 which is incompatible. ```. Not sure why this is happening. I'd prefer if we didn't have to manually specify the dependencies of our dependencies. Any ideas @flying-sheep? ------------------. Updating pip doesn't seem to do anything (maybe it has to do with ""editable mode""?). --------------------. An easy fix is just to add a version requirement on `numpy`, but I really feel like dependency resolution should be dealing with that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:551,reliability,doe,doesn,551,"Not completely sure if this is doing what I intended. I added the `-U` so dependencies would be upgraded, but numpy still isn't being upgraded as shown by these warnings:. ```. umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.15.4 which is incompatible. scvi 0.6.6 has requirement numpy>=1.16.2, but you'll have numpy 1.15.4 which is incompatible. ```. Not sure why this is happening. I'd prefer if we didn't have to manually specify the dependencies of our dependencies. Any ideas @flying-sheep? ------------------. Updating pip doesn't seem to do anything (maybe it has to do with ""editable mode""?). --------------------. An easy fix is just to add a version requirement on `numpy`, but I really feel like dependency resolution should be dealing with that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:4,safety,compl,completely,4,"Not completely sure if this is doing what I intended. I added the `-U` so dependencies would be upgraded, but numpy still isn't being upgraded as shown by these warnings:. ```. umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.15.4 which is incompatible. scvi 0.6.6 has requirement numpy>=1.16.2, but you'll have numpy 1.15.4 which is incompatible. ```. Not sure why this is happening. I'd prefer if we didn't have to manually specify the dependencies of our dependencies. Any ideas @flying-sheep? ------------------. Updating pip doesn't seem to do anything (maybe it has to do with ""editable mode""?). --------------------. An easy fix is just to add a version requirement on `numpy`, but I really feel like dependency resolution should be dealing with that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:74,safety,depend,dependencies,74,"Not completely sure if this is doing what I intended. I added the `-U` so dependencies would be upgraded, but numpy still isn't being upgraded as shown by these warnings:. ```. umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.15.4 which is incompatible. scvi 0.6.6 has requirement numpy>=1.16.2, but you'll have numpy 1.15.4 which is incompatible. ```. Not sure why this is happening. I'd prefer if we didn't have to manually specify the dependencies of our dependencies. Any ideas @flying-sheep? ------------------. Updating pip doesn't seem to do anything (maybe it has to do with ""editable mode""?). --------------------. An easy fix is just to add a version requirement on `numpy`, but I really feel like dependency resolution should be dealing with that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:459,safety,depend,dependencies,459,"Not completely sure if this is doing what I intended. I added the `-U` so dependencies would be upgraded, but numpy still isn't being upgraded as shown by these warnings:. ```. umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.15.4 which is incompatible. scvi 0.6.6 has requirement numpy>=1.16.2, but you'll have numpy 1.15.4 which is incompatible. ```. Not sure why this is happening. I'd prefer if we didn't have to manually specify the dependencies of our dependencies. Any ideas @flying-sheep? ------------------. Updating pip doesn't seem to do anything (maybe it has to do with ""editable mode""?). --------------------. An easy fix is just to add a version requirement on `numpy`, but I really feel like dependency resolution should be dealing with that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:479,safety,depend,dependencies,479,"Not completely sure if this is doing what I intended. I added the `-U` so dependencies would be upgraded, but numpy still isn't being upgraded as shown by these warnings:. ```. umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.15.4 which is incompatible. scvi 0.6.6 has requirement numpy>=1.16.2, but you'll have numpy 1.15.4 which is incompatible. ```. Not sure why this is happening. I'd prefer if we didn't have to manually specify the dependencies of our dependencies. Any ideas @flying-sheep? ------------------. Updating pip doesn't seem to do anything (maybe it has to do with ""editable mode""?). --------------------. An easy fix is just to add a version requirement on `numpy`, but I really feel like dependency resolution should be dealing with that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:538,safety,Updat,Updating,538,"Not completely sure if this is doing what I intended. I added the `-U` so dependencies would be upgraded, but numpy still isn't being upgraded as shown by these warnings:. ```. umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.15.4 which is incompatible. scvi 0.6.6 has requirement numpy>=1.16.2, but you'll have numpy 1.15.4 which is incompatible. ```. Not sure why this is happening. I'd prefer if we didn't have to manually specify the dependencies of our dependencies. Any ideas @flying-sheep? ------------------. Updating pip doesn't seem to do anything (maybe it has to do with ""editable mode""?). --------------------. An easy fix is just to add a version requirement on `numpy`, but I really feel like dependency resolution should be dealing with that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:729,safety,depend,dependency,729,"Not completely sure if this is doing what I intended. I added the `-U` so dependencies would be upgraded, but numpy still isn't being upgraded as shown by these warnings:. ```. umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.15.4 which is incompatible. scvi 0.6.6 has requirement numpy>=1.16.2, but you'll have numpy 1.15.4 which is incompatible. ```. Not sure why this is happening. I'd prefer if we didn't have to manually specify the dependencies of our dependencies. Any ideas @flying-sheep? ------------------. Updating pip doesn't seem to do anything (maybe it has to do with ""editable mode""?). --------------------. An easy fix is just to add a version requirement on `numpy`, but I really feel like dependency resolution should be dealing with that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:4,security,compl,completely,4,"Not completely sure if this is doing what I intended. I added the `-U` so dependencies would be upgraded, but numpy still isn't being upgraded as shown by these warnings:. ```. umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.15.4 which is incompatible. scvi 0.6.6 has requirement numpy>=1.16.2, but you'll have numpy 1.15.4 which is incompatible. ```. Not sure why this is happening. I'd prefer if we didn't have to manually specify the dependencies of our dependencies. Any ideas @flying-sheep? ------------------. Updating pip doesn't seem to do anything (maybe it has to do with ""editable mode""?). --------------------. An easy fix is just to add a version requirement on `numpy`, but I really feel like dependency resolution should be dealing with that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:538,security,Updat,Updating,538,"Not completely sure if this is doing what I intended. I added the `-U` so dependencies would be upgraded, but numpy still isn't being upgraded as shown by these warnings:. ```. umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.15.4 which is incompatible. scvi 0.6.6 has requirement numpy>=1.16.2, but you'll have numpy 1.15.4 which is incompatible. ```. Not sure why this is happening. I'd prefer if we didn't have to manually specify the dependencies of our dependencies. Any ideas @flying-sheep? ------------------. Updating pip doesn't seem to do anything (maybe it has to do with ""editable mode""?). --------------------. An easy fix is just to add a version requirement on `numpy`, but I really feel like dependency resolution should be dealing with that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:74,testability,depend,dependencies,74,"Not completely sure if this is doing what I intended. I added the `-U` so dependencies would be upgraded, but numpy still isn't being upgraded as shown by these warnings:. ```. umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.15.4 which is incompatible. scvi 0.6.6 has requirement numpy>=1.16.2, but you'll have numpy 1.15.4 which is incompatible. ```. Not sure why this is happening. I'd prefer if we didn't have to manually specify the dependencies of our dependencies. Any ideas @flying-sheep? ------------------. Updating pip doesn't seem to do anything (maybe it has to do with ""editable mode""?). --------------------. An easy fix is just to add a version requirement on `numpy`, but I really feel like dependency resolution should be dealing with that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:459,testability,depend,dependencies,459,"Not completely sure if this is doing what I intended. I added the `-U` so dependencies would be upgraded, but numpy still isn't being upgraded as shown by these warnings:. ```. umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.15.4 which is incompatible. scvi 0.6.6 has requirement numpy>=1.16.2, but you'll have numpy 1.15.4 which is incompatible. ```. Not sure why this is happening. I'd prefer if we didn't have to manually specify the dependencies of our dependencies. Any ideas @flying-sheep? ------------------. Updating pip doesn't seem to do anything (maybe it has to do with ""editable mode""?). --------------------. An easy fix is just to add a version requirement on `numpy`, but I really feel like dependency resolution should be dealing with that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:479,testability,depend,dependencies,479,"Not completely sure if this is doing what I intended. I added the `-U` so dependencies would be upgraded, but numpy still isn't being upgraded as shown by these warnings:. ```. umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.15.4 which is incompatible. scvi 0.6.6 has requirement numpy>=1.16.2, but you'll have numpy 1.15.4 which is incompatible. ```. Not sure why this is happening. I'd prefer if we didn't have to manually specify the dependencies of our dependencies. Any ideas @flying-sheep? ------------------. Updating pip doesn't seem to do anything (maybe it has to do with ""editable mode""?). --------------------. An easy fix is just to add a version requirement on `numpy`, but I really feel like dependency resolution should be dealing with that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:729,testability,depend,dependency,729,"Not completely sure if this is doing what I intended. I added the `-U` so dependencies would be upgraded, but numpy still isn't being upgraded as shown by these warnings:. ```. umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.15.4 which is incompatible. scvi 0.6.6 has requirement numpy>=1.16.2, but you'll have numpy 1.15.4 which is incompatible. ```. Not sure why this is happening. I'd prefer if we didn't have to manually specify the dependencies of our dependencies. Any ideas @flying-sheep? ------------------. Updating pip doesn't seem to do anything (maybe it has to do with ""editable mode""?). --------------------. An easy fix is just to add a version requirement on `numpy`, but I really feel like dependency resolution should be dealing with that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:182,usability,learn,learn,182,"Not completely sure if this is doing what I intended. I added the `-U` so dependencies would be upgraded, but numpy still isn't being upgraded as shown by these warnings:. ```. umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.15.4 which is incompatible. scvi 0.6.6 has requirement numpy>=1.16.2, but you'll have numpy 1.15.4 which is incompatible. ```. Not sure why this is happening. I'd prefer if we didn't have to manually specify the dependencies of our dependencies. Any ideas @flying-sheep? ------------------. Updating pip doesn't seem to do anything (maybe it has to do with ""editable mode""?). --------------------. An easy fix is just to add a version requirement on `numpy`, but I really feel like dependency resolution should be dealing with that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:410,usability,prefer,prefer,410,"Not completely sure if this is doing what I intended. I added the `-U` so dependencies would be upgraded, but numpy still isn't being upgraded as shown by these warnings:. ```. umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.15.4 which is incompatible. scvi 0.6.6 has requirement numpy>=1.16.2, but you'll have numpy 1.15.4 which is incompatible. ```. Not sure why this is happening. I'd prefer if we didn't have to manually specify the dependencies of our dependencies. Any ideas @flying-sheep? ------------------. Updating pip doesn't seem to do anything (maybe it has to do with ""editable mode""?). --------------------. An easy fix is just to add a version requirement on `numpy`, but I really feel like dependency resolution should be dealing with that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:101,deployability,depend,depend,101,"Okay, this is weird. My current theory is that it's a bug in pip. It looks like if multiple packages depend on a single dependency, pip doesn't necessarily check if all requirements are satisfied. It just checks if one packages version requirements are. It seems non-deterministic which package is used to check. --------------------------------------. I was working on an example, but then I just found this: https://github.com/pypa/pip/issues/8218. There's an unstable feature for this (`--unstable-feature=resolver`), which does work, but I think adding a requirement for numpy is a bit more justifiable.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:120,deployability,depend,dependency,120,"Okay, this is weird. My current theory is that it's a bug in pip. It looks like if multiple packages depend on a single dependency, pip doesn't necessarily check if all requirements are satisfied. It just checks if one packages version requirements are. It seems non-deterministic which package is used to check. --------------------------------------. I was working on an example, but then I just found this: https://github.com/pypa/pip/issues/8218. There's an unstable feature for this (`--unstable-feature=resolver`), which does work, but I think adding a requirement for numpy is a bit more justifiable.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:228,deployability,version,version,228,"Okay, this is weird. My current theory is that it's a bug in pip. It looks like if multiple packages depend on a single dependency, pip doesn't necessarily check if all requirements are satisfied. It just checks if one packages version requirements are. It seems non-deterministic which package is used to check. --------------------------------------. I was working on an example, but then I just found this: https://github.com/pypa/pip/issues/8218. There's an unstable feature for this (`--unstable-feature=resolver`), which does work, but I think adding a requirement for numpy is a bit more justifiable.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:24,energy efficiency,current,current,24,"Okay, this is weird. My current theory is that it's a bug in pip. It looks like if multiple packages depend on a single dependency, pip doesn't necessarily check if all requirements are satisfied. It just checks if one packages version requirements are. It seems non-deterministic which package is used to check. --------------------------------------. I was working on an example, but then I just found this: https://github.com/pypa/pip/issues/8218. There's an unstable feature for this (`--unstable-feature=resolver`), which does work, but I think adding a requirement for numpy is a bit more justifiable.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:101,integrability,depend,depend,101,"Okay, this is weird. My current theory is that it's a bug in pip. It looks like if multiple packages depend on a single dependency, pip doesn't necessarily check if all requirements are satisfied. It just checks if one packages version requirements are. It seems non-deterministic which package is used to check. --------------------------------------. I was working on an example, but then I just found this: https://github.com/pypa/pip/issues/8218. There's an unstable feature for this (`--unstable-feature=resolver`), which does work, but I think adding a requirement for numpy is a bit more justifiable.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:120,integrability,depend,dependency,120,"Okay, this is weird. My current theory is that it's a bug in pip. It looks like if multiple packages depend on a single dependency, pip doesn't necessarily check if all requirements are satisfied. It just checks if one packages version requirements are. It seems non-deterministic which package is used to check. --------------------------------------. I was working on an example, but then I just found this: https://github.com/pypa/pip/issues/8218. There's an unstable feature for this (`--unstable-feature=resolver`), which does work, but I think adding a requirement for numpy is a bit more justifiable.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:228,integrability,version,version,228,"Okay, this is weird. My current theory is that it's a bug in pip. It looks like if multiple packages depend on a single dependency, pip doesn't necessarily check if all requirements are satisfied. It just checks if one packages version requirements are. It seems non-deterministic which package is used to check. --------------------------------------. I was working on an example, but then I just found this: https://github.com/pypa/pip/issues/8218. There's an unstable feature for this (`--unstable-feature=resolver`), which does work, but I think adding a requirement for numpy is a bit more justifiable.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:92,modifiability,pac,packages,92,"Okay, this is weird. My current theory is that it's a bug in pip. It looks like if multiple packages depend on a single dependency, pip doesn't necessarily check if all requirements are satisfied. It just checks if one packages version requirements are. It seems non-deterministic which package is used to check. --------------------------------------. I was working on an example, but then I just found this: https://github.com/pypa/pip/issues/8218. There's an unstable feature for this (`--unstable-feature=resolver`), which does work, but I think adding a requirement for numpy is a bit more justifiable.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:101,modifiability,depend,depend,101,"Okay, this is weird. My current theory is that it's a bug in pip. It looks like if multiple packages depend on a single dependency, pip doesn't necessarily check if all requirements are satisfied. It just checks if one packages version requirements are. It seems non-deterministic which package is used to check. --------------------------------------. I was working on an example, but then I just found this: https://github.com/pypa/pip/issues/8218. There's an unstable feature for this (`--unstable-feature=resolver`), which does work, but I think adding a requirement for numpy is a bit more justifiable.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:120,modifiability,depend,dependency,120,"Okay, this is weird. My current theory is that it's a bug in pip. It looks like if multiple packages depend on a single dependency, pip doesn't necessarily check if all requirements are satisfied. It just checks if one packages version requirements are. It seems non-deterministic which package is used to check. --------------------------------------. I was working on an example, but then I just found this: https://github.com/pypa/pip/issues/8218. There's an unstable feature for this (`--unstable-feature=resolver`), which does work, but I think adding a requirement for numpy is a bit more justifiable.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:219,modifiability,pac,packages,219,"Okay, this is weird. My current theory is that it's a bug in pip. It looks like if multiple packages depend on a single dependency, pip doesn't necessarily check if all requirements are satisfied. It just checks if one packages version requirements are. It seems non-deterministic which package is used to check. --------------------------------------. I was working on an example, but then I just found this: https://github.com/pypa/pip/issues/8218. There's an unstable feature for this (`--unstable-feature=resolver`), which does work, but I think adding a requirement for numpy is a bit more justifiable.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:228,modifiability,version,version,228,"Okay, this is weird. My current theory is that it's a bug in pip. It looks like if multiple packages depend on a single dependency, pip doesn't necessarily check if all requirements are satisfied. It just checks if one packages version requirements are. It seems non-deterministic which package is used to check. --------------------------------------. I was working on an example, but then I just found this: https://github.com/pypa/pip/issues/8218. There's an unstable feature for this (`--unstable-feature=resolver`), which does work, but I think adding a requirement for numpy is a bit more justifiable.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:287,modifiability,pac,package,287,"Okay, this is weird. My current theory is that it's a bug in pip. It looks like if multiple packages depend on a single dependency, pip doesn't necessarily check if all requirements are satisfied. It just checks if one packages version requirements are. It seems non-deterministic which package is used to check. --------------------------------------. I was working on an example, but then I just found this: https://github.com/pypa/pip/issues/8218. There's an unstable feature for this (`--unstable-feature=resolver`), which does work, but I think adding a requirement for numpy is a bit more justifiable.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:136,reliability,doe,doesn,136,"Okay, this is weird. My current theory is that it's a bug in pip. It looks like if multiple packages depend on a single dependency, pip doesn't necessarily check if all requirements are satisfied. It just checks if one packages version requirements are. It seems non-deterministic which package is used to check. --------------------------------------. I was working on an example, but then I just found this: https://github.com/pypa/pip/issues/8218. There's an unstable feature for this (`--unstable-feature=resolver`), which does work, but I think adding a requirement for numpy is a bit more justifiable.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:527,reliability,doe,does,527,"Okay, this is weird. My current theory is that it's a bug in pip. It looks like if multiple packages depend on a single dependency, pip doesn't necessarily check if all requirements are satisfied. It just checks if one packages version requirements are. It seems non-deterministic which package is used to check. --------------------------------------. I was working on an example, but then I just found this: https://github.com/pypa/pip/issues/8218. There's an unstable feature for this (`--unstable-feature=resolver`), which does work, but I think adding a requirement for numpy is a bit more justifiable.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:101,safety,depend,depend,101,"Okay, this is weird. My current theory is that it's a bug in pip. It looks like if multiple packages depend on a single dependency, pip doesn't necessarily check if all requirements are satisfied. It just checks if one packages version requirements are. It seems non-deterministic which package is used to check. --------------------------------------. I was working on an example, but then I just found this: https://github.com/pypa/pip/issues/8218. There's an unstable feature for this (`--unstable-feature=resolver`), which does work, but I think adding a requirement for numpy is a bit more justifiable.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:120,safety,depend,dependency,120,"Okay, this is weird. My current theory is that it's a bug in pip. It looks like if multiple packages depend on a single dependency, pip doesn't necessarily check if all requirements are satisfied. It just checks if one packages version requirements are. It seems non-deterministic which package is used to check. --------------------------------------. I was working on an example, but then I just found this: https://github.com/pypa/pip/issues/8218. There's an unstable feature for this (`--unstable-feature=resolver`), which does work, but I think adding a requirement for numpy is a bit more justifiable.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:101,testability,depend,depend,101,"Okay, this is weird. My current theory is that it's a bug in pip. It looks like if multiple packages depend on a single dependency, pip doesn't necessarily check if all requirements are satisfied. It just checks if one packages version requirements are. It seems non-deterministic which package is used to check. --------------------------------------. I was working on an example, but then I just found this: https://github.com/pypa/pip/issues/8218. There's an unstable feature for this (`--unstable-feature=resolver`), which does work, but I think adding a requirement for numpy is a bit more justifiable.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:120,testability,depend,dependency,120,"Okay, this is weird. My current theory is that it's a bug in pip. It looks like if multiple packages depend on a single dependency, pip doesn't necessarily check if all requirements are satisfied. It just checks if one packages version requirements are. It seems non-deterministic which package is used to check. --------------------------------------. I was working on an example, but then I just found this: https://github.com/pypa/pip/issues/8218. There's an unstable feature for this (`--unstable-feature=resolver`), which does work, but I think adding a requirement for numpy is a bit more justifiable.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:151,deployability,instal,installed,151,"Im really happy that theyre finally adding a resolver. Without officially having a resolver, it technically wasnt a bug that incompatible stuff got installed, but instead just a missing (if very vital) feature.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:128,interoperability,incompatib,incompatible,128,"Im really happy that theyre finally adding a resolver. Without officially having a resolver, it technically wasnt a bug that incompatible stuff got installed, but instead just a missing (if very vital) feature.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/issues/1321:503,deployability,api,api,503,"Should be possible to turn the y ticks legends on. But I just tested it and didn't work. I will try to fix it. The syntax is:. ```PYTHON. sc.pl.stacked_violin(adata,marker_genes,groupby='louvain', return_fig=True).style(yticklabels=True,row_palette='muted').show(). ```. `style` needs to be used to tune the graphical parameters to avoid overcrowding the parameters list. But I am open to have a discussion on what the users think is best. Documentation is here: https://scanpy.readthedocs.io/en/latest/api/scanpy.pl.DotPlot.style.html#scanpy.pl.DotPlot.style",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1321:503,integrability,api,api,503,"Should be possible to turn the y ticks legends on. But I just tested it and didn't work. I will try to fix it. The syntax is:. ```PYTHON. sc.pl.stacked_violin(adata,marker_genes,groupby='louvain', return_fig=True).style(yticklabels=True,row_palette='muted').show(). ```. `style` needs to be used to tune the graphical parameters to avoid overcrowding the parameters list. But I am open to have a discussion on what the users think is best. Documentation is here: https://scanpy.readthedocs.io/en/latest/api/scanpy.pl.DotPlot.style.html#scanpy.pl.DotPlot.style",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1321:503,interoperability,api,api,503,"Should be possible to turn the y ticks legends on. But I just tested it and didn't work. I will try to fix it. The syntax is:. ```PYTHON. sc.pl.stacked_violin(adata,marker_genes,groupby='louvain', return_fig=True).style(yticklabels=True,row_palette='muted').show(). ```. `style` needs to be used to tune the graphical parameters to avoid overcrowding the parameters list. But I am open to have a discussion on what the users think is best. Documentation is here: https://scanpy.readthedocs.io/en/latest/api/scanpy.pl.DotPlot.style.html#scanpy.pl.DotPlot.style",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1321:318,modifiability,paramet,parameters,318,"Should be possible to turn the y ticks legends on. But I just tested it and didn't work. I will try to fix it. The syntax is:. ```PYTHON. sc.pl.stacked_violin(adata,marker_genes,groupby='louvain', return_fig=True).style(yticklabels=True,row_palette='muted').show(). ```. `style` needs to be used to tune the graphical parameters to avoid overcrowding the parameters list. But I am open to have a discussion on what the users think is best. Documentation is here: https://scanpy.readthedocs.io/en/latest/api/scanpy.pl.DotPlot.style.html#scanpy.pl.DotPlot.style",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1321:355,modifiability,paramet,parameters,355,"Should be possible to turn the y ticks legends on. But I just tested it and didn't work. I will try to fix it. The syntax is:. ```PYTHON. sc.pl.stacked_violin(adata,marker_genes,groupby='louvain', return_fig=True).style(yticklabels=True,row_palette='muted').show(). ```. `style` needs to be used to tune the graphical parameters to avoid overcrowding the parameters list. But I am open to have a discussion on what the users think is best. Documentation is here: https://scanpy.readthedocs.io/en/latest/api/scanpy.pl.DotPlot.style.html#scanpy.pl.DotPlot.style",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1321:299,performance,tune,tune,299,"Should be possible to turn the y ticks legends on. But I just tested it and didn't work. I will try to fix it. The syntax is:. ```PYTHON. sc.pl.stacked_violin(adata,marker_genes,groupby='louvain', return_fig=True).style(yticklabels=True,row_palette='muted').show(). ```. `style` needs to be used to tune the graphical parameters to avoid overcrowding the parameters list. But I am open to have a discussion on what the users think is best. Documentation is here: https://scanpy.readthedocs.io/en/latest/api/scanpy.pl.DotPlot.style.html#scanpy.pl.DotPlot.style",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1321:62,safety,test,tested,62,"Should be possible to turn the y ticks legends on. But I just tested it and didn't work. I will try to fix it. The syntax is:. ```PYTHON. sc.pl.stacked_violin(adata,marker_genes,groupby='louvain', return_fig=True).style(yticklabels=True,row_palette='muted').show(). ```. `style` needs to be used to tune the graphical parameters to avoid overcrowding the parameters list. But I am open to have a discussion on what the users think is best. Documentation is here: https://scanpy.readthedocs.io/en/latest/api/scanpy.pl.DotPlot.style.html#scanpy.pl.DotPlot.style",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1321:332,safety,avoid,avoid,332,"Should be possible to turn the y ticks legends on. But I just tested it and didn't work. I will try to fix it. The syntax is:. ```PYTHON. sc.pl.stacked_violin(adata,marker_genes,groupby='louvain', return_fig=True).style(yticklabels=True,row_palette='muted').show(). ```. `style` needs to be used to tune the graphical parameters to avoid overcrowding the parameters list. But I am open to have a discussion on what the users think is best. Documentation is here: https://scanpy.readthedocs.io/en/latest/api/scanpy.pl.DotPlot.style.html#scanpy.pl.DotPlot.style",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1321:62,testability,test,tested,62,"Should be possible to turn the y ticks legends on. But I just tested it and didn't work. I will try to fix it. The syntax is:. ```PYTHON. sc.pl.stacked_violin(adata,marker_genes,groupby='louvain', return_fig=True).style(yticklabels=True,row_palette='muted').show(). ```. `style` needs to be used to tune the graphical parameters to avoid overcrowding the parameters list. But I am open to have a discussion on what the users think is best. Documentation is here: https://scanpy.readthedocs.io/en/latest/api/scanpy.pl.DotPlot.style.html#scanpy.pl.DotPlot.style",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1321:419,usability,user,users,419,"Should be possible to turn the y ticks legends on. But I just tested it and didn't work. I will try to fix it. The syntax is:. ```PYTHON. sc.pl.stacked_violin(adata,marker_genes,groupby='louvain', return_fig=True).style(yticklabels=True,row_palette='muted').show(). ```. `style` needs to be used to tune the graphical parameters to avoid overcrowding the parameters list. But I am open to have a discussion on what the users think is best. Documentation is here: https://scanpy.readthedocs.io/en/latest/api/scanpy.pl.DotPlot.style.html#scanpy.pl.DotPlot.style",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1321:440,usability,Document,Documentation,440,"Should be possible to turn the y ticks legends on. But I just tested it and didn't work. I will try to fix it. The syntax is:. ```PYTHON. sc.pl.stacked_violin(adata,marker_genes,groupby='louvain', return_fig=True).style(yticklabels=True,row_palette='muted').show(). ```. `style` needs to be used to tune the graphical parameters to avoid overcrowding the parameters list. But I am open to have a discussion on what the users think is best. Documentation is here: https://scanpy.readthedocs.io/en/latest/api/scanpy.pl.DotPlot.style.html#scanpy.pl.DotPlot.style",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1324:195,integrability,filter,filtering,195,"I just realized that it is the `rank_genes_groups` function that returns only one group when the `reference` is set and `groups` is a list with one element. So, the `filter_rank_genes_groups` is filtering correctly but it can only filter the only returned group.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1324
https://github.com/scverse/scanpy/issues/1324:231,integrability,filter,filter,231,"I just realized that it is the `rank_genes_groups` function that returns only one group when the `reference` is set and `groups` is a list with one element. So, the `filter_rank_genes_groups` is filtering correctly but it can only filter the only returned group.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1324
https://github.com/scverse/scanpy/issues/1325:47,deployability,version,version,47,I noticed this still isn't fixed in the latest version of scanpy. Is there a reason why not? Does my solution # 2 sound reasonable? I can attempt to create a pull request if so,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1325
https://github.com/scverse/scanpy/issues/1325:47,integrability,version,version,47,I noticed this still isn't fixed in the latest version of scanpy. Is there a reason why not? Does my solution # 2 sound reasonable? I can attempt to create a pull request if so,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1325
https://github.com/scverse/scanpy/issues/1325:47,modifiability,version,version,47,I noticed this still isn't fixed in the latest version of scanpy. Is there a reason why not? Does my solution # 2 sound reasonable? I can attempt to create a pull request if so,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1325
https://github.com/scverse/scanpy/issues/1325:93,reliability,Doe,Does,93,I noticed this still isn't fixed in the latest version of scanpy. Is there a reason why not? Does my solution # 2 sound reasonable? I can attempt to create a pull request if so,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1325
https://github.com/scverse/scanpy/issues/1325:27,availability,slo,slow,27,"Hi @rpeys, sorry for being slow on this. What are you trying to do exactly? Are you looking to use scanpy plotting features afterwards, or just get tables of genes? If it's the latter, I would suggest using `sc.get.rank_genes_groups_df`, where you can do something like:. ```python. de_df = sc.get.rank_genes_groups_df(adata, group=""CD8""). de_df.query(""abs(logfoldchanges) > 1""). ```. You should then be able to use these genes to plot by passing the genes names to `var_names` parameter of the `rank_genes_groups` plotting functions. To be honest, a lot of us on the team are not really happy with the differential expression API  but also haven't had the time to completely redo it. Progress on this area has generally been slow. @fidelram has commented on `filter_rank_genes_groups` in particular here: https://github.com/theislab/scanpy/pull/1529#issuecomment-738733928.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1325
https://github.com/scverse/scanpy/issues/1325:727,availability,slo,slow,727,"Hi @rpeys, sorry for being slow on this. What are you trying to do exactly? Are you looking to use scanpy plotting features afterwards, or just get tables of genes? If it's the latter, I would suggest using `sc.get.rank_genes_groups_df`, where you can do something like:. ```python. de_df = sc.get.rank_genes_groups_df(adata, group=""CD8""). de_df.query(""abs(logfoldchanges) > 1""). ```. You should then be able to use these genes to plot by passing the genes names to `var_names` parameter of the `rank_genes_groups` plotting functions. To be honest, a lot of us on the team are not really happy with the differential expression API  but also haven't had the time to completely redo it. Progress on this area has generally been slow. @fidelram has commented on `filter_rank_genes_groups` in particular here: https://github.com/theislab/scanpy/pull/1529#issuecomment-738733928.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1325
https://github.com/scverse/scanpy/issues/1325:357,deployability,log,logfoldchanges,357,"Hi @rpeys, sorry for being slow on this. What are you trying to do exactly? Are you looking to use scanpy plotting features afterwards, or just get tables of genes? If it's the latter, I would suggest using `sc.get.rank_genes_groups_df`, where you can do something like:. ```python. de_df = sc.get.rank_genes_groups_df(adata, group=""CD8""). de_df.query(""abs(logfoldchanges) > 1""). ```. You should then be able to use these genes to plot by passing the genes names to `var_names` parameter of the `rank_genes_groups` plotting functions. To be honest, a lot of us on the team are not really happy with the differential expression API  but also haven't had the time to completely redo it. Progress on this area has generally been slow. @fidelram has commented on `filter_rank_genes_groups` in particular here: https://github.com/theislab/scanpy/pull/1529#issuecomment-738733928.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1325
https://github.com/scverse/scanpy/issues/1325:627,deployability,API,API,627,"Hi @rpeys, sorry for being slow on this. What are you trying to do exactly? Are you looking to use scanpy plotting features afterwards, or just get tables of genes? If it's the latter, I would suggest using `sc.get.rank_genes_groups_df`, where you can do something like:. ```python. de_df = sc.get.rank_genes_groups_df(adata, group=""CD8""). de_df.query(""abs(logfoldchanges) > 1""). ```. You should then be able to use these genes to plot by passing the genes names to `var_names` parameter of the `rank_genes_groups` plotting functions. To be honest, a lot of us on the team are not really happy with the differential expression API  but also haven't had the time to completely redo it. Progress on this area has generally been slow. @fidelram has commented on `filter_rank_genes_groups` in particular here: https://github.com/theislab/scanpy/pull/1529#issuecomment-738733928.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1325
https://github.com/scverse/scanpy/issues/1325:627,integrability,API,API,627,"Hi @rpeys, sorry for being slow on this. What are you trying to do exactly? Are you looking to use scanpy plotting features afterwards, or just get tables of genes? If it's the latter, I would suggest using `sc.get.rank_genes_groups_df`, where you can do something like:. ```python. de_df = sc.get.rank_genes_groups_df(adata, group=""CD8""). de_df.query(""abs(logfoldchanges) > 1""). ```. You should then be able to use these genes to plot by passing the genes names to `var_names` parameter of the `rank_genes_groups` plotting functions. To be honest, a lot of us on the team are not really happy with the differential expression API  but also haven't had the time to completely redo it. Progress on this area has generally been slow. @fidelram has commented on `filter_rank_genes_groups` in particular here: https://github.com/theislab/scanpy/pull/1529#issuecomment-738733928.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1325
https://github.com/scverse/scanpy/issues/1325:627,interoperability,API,API,627,"Hi @rpeys, sorry for being slow on this. What are you trying to do exactly? Are you looking to use scanpy plotting features afterwards, or just get tables of genes? If it's the latter, I would suggest using `sc.get.rank_genes_groups_df`, where you can do something like:. ```python. de_df = sc.get.rank_genes_groups_df(adata, group=""CD8""). de_df.query(""abs(logfoldchanges) > 1""). ```. You should then be able to use these genes to plot by passing the genes names to `var_names` parameter of the `rank_genes_groups` plotting functions. To be honest, a lot of us on the team are not really happy with the differential expression API  but also haven't had the time to completely redo it. Progress on this area has generally been slow. @fidelram has commented on `filter_rank_genes_groups` in particular here: https://github.com/theislab/scanpy/pull/1529#issuecomment-738733928.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1325
https://github.com/scverse/scanpy/issues/1325:478,modifiability,paramet,parameter,478,"Hi @rpeys, sorry for being slow on this. What are you trying to do exactly? Are you looking to use scanpy plotting features afterwards, or just get tables of genes? If it's the latter, I would suggest using `sc.get.rank_genes_groups_df`, where you can do something like:. ```python. de_df = sc.get.rank_genes_groups_df(adata, group=""CD8""). de_df.query(""abs(logfoldchanges) > 1""). ```. You should then be able to use these genes to plot by passing the genes names to `var_names` parameter of the `rank_genes_groups` plotting functions. To be honest, a lot of us on the team are not really happy with the differential expression API  but also haven't had the time to completely redo it. Progress on this area has generally been slow. @fidelram has commented on `filter_rank_genes_groups` in particular here: https://github.com/theislab/scanpy/pull/1529#issuecomment-738733928.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1325
https://github.com/scverse/scanpy/issues/1325:658,performance,time,time,658,"Hi @rpeys, sorry for being slow on this. What are you trying to do exactly? Are you looking to use scanpy plotting features afterwards, or just get tables of genes? If it's the latter, I would suggest using `sc.get.rank_genes_groups_df`, where you can do something like:. ```python. de_df = sc.get.rank_genes_groups_df(adata, group=""CD8""). de_df.query(""abs(logfoldchanges) > 1""). ```. You should then be able to use these genes to plot by passing the genes names to `var_names` parameter of the `rank_genes_groups` plotting functions. To be honest, a lot of us on the team are not really happy with the differential expression API  but also haven't had the time to completely redo it. Progress on this area has generally been slow. @fidelram has commented on `filter_rank_genes_groups` in particular here: https://github.com/theislab/scanpy/pull/1529#issuecomment-738733928.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1325
https://github.com/scverse/scanpy/issues/1325:27,reliability,slo,slow,27,"Hi @rpeys, sorry for being slow on this. What are you trying to do exactly? Are you looking to use scanpy plotting features afterwards, or just get tables of genes? If it's the latter, I would suggest using `sc.get.rank_genes_groups_df`, where you can do something like:. ```python. de_df = sc.get.rank_genes_groups_df(adata, group=""CD8""). de_df.query(""abs(logfoldchanges) > 1""). ```. You should then be able to use these genes to plot by passing the genes names to `var_names` parameter of the `rank_genes_groups` plotting functions. To be honest, a lot of us on the team are not really happy with the differential expression API  but also haven't had the time to completely redo it. Progress on this area has generally been slow. @fidelram has commented on `filter_rank_genes_groups` in particular here: https://github.com/theislab/scanpy/pull/1529#issuecomment-738733928.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1325
https://github.com/scverse/scanpy/issues/1325:727,reliability,slo,slow,727,"Hi @rpeys, sorry for being slow on this. What are you trying to do exactly? Are you looking to use scanpy plotting features afterwards, or just get tables of genes? If it's the latter, I would suggest using `sc.get.rank_genes_groups_df`, where you can do something like:. ```python. de_df = sc.get.rank_genes_groups_df(adata, group=""CD8""). de_df.query(""abs(logfoldchanges) > 1""). ```. You should then be able to use these genes to plot by passing the genes names to `var_names` parameter of the `rank_genes_groups` plotting functions. To be honest, a lot of us on the team are not really happy with the differential expression API  but also haven't had the time to completely redo it. Progress on this area has generally been slow. @fidelram has commented on `filter_rank_genes_groups` in particular here: https://github.com/theislab/scanpy/pull/1529#issuecomment-738733928.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1325
https://github.com/scverse/scanpy/issues/1325:357,safety,log,logfoldchanges,357,"Hi @rpeys, sorry for being slow on this. What are you trying to do exactly? Are you looking to use scanpy plotting features afterwards, or just get tables of genes? If it's the latter, I would suggest using `sc.get.rank_genes_groups_df`, where you can do something like:. ```python. de_df = sc.get.rank_genes_groups_df(adata, group=""CD8""). de_df.query(""abs(logfoldchanges) > 1""). ```. You should then be able to use these genes to plot by passing the genes names to `var_names` parameter of the `rank_genes_groups` plotting functions. To be honest, a lot of us on the team are not really happy with the differential expression API  but also haven't had the time to completely redo it. Progress on this area has generally been slow. @fidelram has commented on `filter_rank_genes_groups` in particular here: https://github.com/theislab/scanpy/pull/1529#issuecomment-738733928.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1325
https://github.com/scverse/scanpy/issues/1325:666,safety,compl,completely,666,"Hi @rpeys, sorry for being slow on this. What are you trying to do exactly? Are you looking to use scanpy plotting features afterwards, or just get tables of genes? If it's the latter, I would suggest using `sc.get.rank_genes_groups_df`, where you can do something like:. ```python. de_df = sc.get.rank_genes_groups_df(adata, group=""CD8""). de_df.query(""abs(logfoldchanges) > 1""). ```. You should then be able to use these genes to plot by passing the genes names to `var_names` parameter of the `rank_genes_groups` plotting functions. To be honest, a lot of us on the team are not really happy with the differential expression API  but also haven't had the time to completely redo it. Progress on this area has generally been slow. @fidelram has commented on `filter_rank_genes_groups` in particular here: https://github.com/theislab/scanpy/pull/1529#issuecomment-738733928.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1325
https://github.com/scverse/scanpy/issues/1325:357,security,log,logfoldchanges,357,"Hi @rpeys, sorry for being slow on this. What are you trying to do exactly? Are you looking to use scanpy plotting features afterwards, or just get tables of genes? If it's the latter, I would suggest using `sc.get.rank_genes_groups_df`, where you can do something like:. ```python. de_df = sc.get.rank_genes_groups_df(adata, group=""CD8""). de_df.query(""abs(logfoldchanges) > 1""). ```. You should then be able to use these genes to plot by passing the genes names to `var_names` parameter of the `rank_genes_groups` plotting functions. To be honest, a lot of us on the team are not really happy with the differential expression API  but also haven't had the time to completely redo it. Progress on this area has generally been slow. @fidelram has commented on `filter_rank_genes_groups` in particular here: https://github.com/theislab/scanpy/pull/1529#issuecomment-738733928.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1325
https://github.com/scverse/scanpy/issues/1325:568,security,team,team,568,"Hi @rpeys, sorry for being slow on this. What are you trying to do exactly? Are you looking to use scanpy plotting features afterwards, or just get tables of genes? If it's the latter, I would suggest using `sc.get.rank_genes_groups_df`, where you can do something like:. ```python. de_df = sc.get.rank_genes_groups_df(adata, group=""CD8""). de_df.query(""abs(logfoldchanges) > 1""). ```. You should then be able to use these genes to plot by passing the genes names to `var_names` parameter of the `rank_genes_groups` plotting functions. To be honest, a lot of us on the team are not really happy with the differential expression API  but also haven't had the time to completely redo it. Progress on this area has generally been slow. @fidelram has commented on `filter_rank_genes_groups` in particular here: https://github.com/theislab/scanpy/pull/1529#issuecomment-738733928.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1325
https://github.com/scverse/scanpy/issues/1325:666,security,compl,completely,666,"Hi @rpeys, sorry for being slow on this. What are you trying to do exactly? Are you looking to use scanpy plotting features afterwards, or just get tables of genes? If it's the latter, I would suggest using `sc.get.rank_genes_groups_df`, where you can do something like:. ```python. de_df = sc.get.rank_genes_groups_df(adata, group=""CD8""). de_df.query(""abs(logfoldchanges) > 1""). ```. You should then be able to use these genes to plot by passing the genes names to `var_names` parameter of the `rank_genes_groups` plotting functions. To be honest, a lot of us on the team are not really happy with the differential expression API  but also haven't had the time to completely redo it. Progress on this area has generally been slow. @fidelram has commented on `filter_rank_genes_groups` in particular here: https://github.com/theislab/scanpy/pull/1529#issuecomment-738733928.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1325
https://github.com/scverse/scanpy/issues/1325:357,testability,log,logfoldchanges,357,"Hi @rpeys, sorry for being slow on this. What are you trying to do exactly? Are you looking to use scanpy plotting features afterwards, or just get tables of genes? If it's the latter, I would suggest using `sc.get.rank_genes_groups_df`, where you can do something like:. ```python. de_df = sc.get.rank_genes_groups_df(adata, group=""CD8""). de_df.query(""abs(logfoldchanges) > 1""). ```. You should then be able to use these genes to plot by passing the genes names to `var_names` parameter of the `rank_genes_groups` plotting functions. To be honest, a lot of us on the team are not really happy with the differential expression API  but also haven't had the time to completely redo it. Progress on this area has generally been slow. @fidelram has commented on `filter_rank_genes_groups` in particular here: https://github.com/theislab/scanpy/pull/1529#issuecomment-738733928.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1325
https://github.com/scverse/scanpy/issues/1325:686,usability,Progress,Progress,686,"Hi @rpeys, sorry for being slow on this. What are you trying to do exactly? Are you looking to use scanpy plotting features afterwards, or just get tables of genes? If it's the latter, I would suggest using `sc.get.rank_genes_groups_df`, where you can do something like:. ```python. de_df = sc.get.rank_genes_groups_df(adata, group=""CD8""). de_df.query(""abs(logfoldchanges) > 1""). ```. You should then be able to use these genes to plot by passing the genes names to `var_names` parameter of the `rank_genes_groups` plotting functions. To be honest, a lot of us on the team are not really happy with the differential expression API  but also haven't had the time to completely redo it. Progress on this area has generally been slow. @fidelram has commented on `filter_rank_genes_groups` in particular here: https://github.com/theislab/scanpy/pull/1529#issuecomment-738733928.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1325
https://github.com/scverse/scanpy/issues/1325:333,integrability,filter,filter,333,"Hi @ivirshup. Thanks for suggesting this workaround - I think that can work for my use case and I will go ahead using your suggestion. . In the meantime while this is not fixed, I think it might be worthwhile to include a note in the description of the `rankby_abs` argument in `rank_genes_groups` warning users that if they use the filter function afterwards, only upregulated genes will be retained.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1325
https://github.com/scverse/scanpy/issues/1325:306,usability,user,users,306,"Hi @ivirshup. Thanks for suggesting this workaround - I think that can work for my use case and I will go ahead using your suggestion. . In the meantime while this is not fixed, I think it might be worthwhile to include a note in the description of the `rankby_abs` argument in `rank_genes_groups` warning users that if they use the filter function afterwards, only upregulated genes will be retained.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1325
https://github.com/scverse/scanpy/issues/1325:39,deployability,releas,release,39,Looks like this fix was made in a 2021 release - thanks! Will close the issue,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1325
https://github.com/scverse/scanpy/issues/1325:62,usability,close,close,62,Looks like this fix was made in a 2021 release - thanks! Will close the issue,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1325
https://github.com/scverse/scanpy/issues/1326:149,interoperability,share,share,149,Hi! Thank you for the quick response. I tried running the tutorial just now and got the same `AttributeError`. . Any information you could afford to share would be greatly appreciated.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:30,deployability,version,version,30,Is this using the development version? The fix hasn't been in a release yet.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:64,deployability,releas,release,64,Is this using the development version? The fix hasn't been in a release yet.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:30,integrability,version,version,30,Is this using the development version? The fix hasn't been in a release yet.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:30,modifiability,version,version,30,Is this using the development version? The fix hasn't been in a release yet.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:34,deployability,version,version,34,This is not using the development version.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:34,integrability,version,version,34,This is not using the development version.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:34,modifiability,version,version,34,This is not using the development version.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:15,deployability,releas,release,15,"The last minor release of Scanpy was version 1.5.1 in the end of May, so it hasn't been released yet. You would need to update scanpy to the development version on master. This can be done via `pip install git+https://www.github.com/theislab/scanpy@master` or by having a local copy of the scanpy repo, updating this and installing from source via `pip install .` :).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:37,deployability,version,version,37,"The last minor release of Scanpy was version 1.5.1 in the end of May, so it hasn't been released yet. You would need to update scanpy to the development version on master. This can be done via `pip install git+https://www.github.com/theislab/scanpy@master` or by having a local copy of the scanpy repo, updating this and installing from source via `pip install .` :).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:88,deployability,releas,released,88,"The last minor release of Scanpy was version 1.5.1 in the end of May, so it hasn't been released yet. You would need to update scanpy to the development version on master. This can be done via `pip install git+https://www.github.com/theislab/scanpy@master` or by having a local copy of the scanpy repo, updating this and installing from source via `pip install .` :).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:120,deployability,updat,update,120,"The last minor release of Scanpy was version 1.5.1 in the end of May, so it hasn't been released yet. You would need to update scanpy to the development version on master. This can be done via `pip install git+https://www.github.com/theislab/scanpy@master` or by having a local copy of the scanpy repo, updating this and installing from source via `pip install .` :).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:153,deployability,version,version,153,"The last minor release of Scanpy was version 1.5.1 in the end of May, so it hasn't been released yet. You would need to update scanpy to the development version on master. This can be done via `pip install git+https://www.github.com/theislab/scanpy@master` or by having a local copy of the scanpy repo, updating this and installing from source via `pip install .` :).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:198,deployability,instal,install,198,"The last minor release of Scanpy was version 1.5.1 in the end of May, so it hasn't been released yet. You would need to update scanpy to the development version on master. This can be done via `pip install git+https://www.github.com/theislab/scanpy@master` or by having a local copy of the scanpy repo, updating this and installing from source via `pip install .` :).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:303,deployability,updat,updating,303,"The last minor release of Scanpy was version 1.5.1 in the end of May, so it hasn't been released yet. You would need to update scanpy to the development version on master. This can be done via `pip install git+https://www.github.com/theislab/scanpy@master` or by having a local copy of the scanpy repo, updating this and installing from source via `pip install .` :).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:321,deployability,instal,installing,321,"The last minor release of Scanpy was version 1.5.1 in the end of May, so it hasn't been released yet. You would need to update scanpy to the development version on master. This can be done via `pip install git+https://www.github.com/theislab/scanpy@master` or by having a local copy of the scanpy repo, updating this and installing from source via `pip install .` :).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:353,deployability,instal,install,353,"The last minor release of Scanpy was version 1.5.1 in the end of May, so it hasn't been released yet. You would need to update scanpy to the development version on master. This can be done via `pip install git+https://www.github.com/theislab/scanpy@master` or by having a local copy of the scanpy repo, updating this and installing from source via `pip install .` :).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:37,integrability,version,version,37,"The last minor release of Scanpy was version 1.5.1 in the end of May, so it hasn't been released yet. You would need to update scanpy to the development version on master. This can be done via `pip install git+https://www.github.com/theislab/scanpy@master` or by having a local copy of the scanpy repo, updating this and installing from source via `pip install .` :).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:153,integrability,version,version,153,"The last minor release of Scanpy was version 1.5.1 in the end of May, so it hasn't been released yet. You would need to update scanpy to the development version on master. This can be done via `pip install git+https://www.github.com/theislab/scanpy@master` or by having a local copy of the scanpy repo, updating this and installing from source via `pip install .` :).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:37,modifiability,version,version,37,"The last minor release of Scanpy was version 1.5.1 in the end of May, so it hasn't been released yet. You would need to update scanpy to the development version on master. This can be done via `pip install git+https://www.github.com/theislab/scanpy@master` or by having a local copy of the scanpy repo, updating this and installing from source via `pip install .` :).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:153,modifiability,version,version,153,"The last minor release of Scanpy was version 1.5.1 in the end of May, so it hasn't been released yet. You would need to update scanpy to the development version on master. This can be done via `pip install git+https://www.github.com/theislab/scanpy@master` or by having a local copy of the scanpy repo, updating this and installing from source via `pip install .` :).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:120,safety,updat,update,120,"The last minor release of Scanpy was version 1.5.1 in the end of May, so it hasn't been released yet. You would need to update scanpy to the development version on master. This can be done via `pip install git+https://www.github.com/theislab/scanpy@master` or by having a local copy of the scanpy repo, updating this and installing from source via `pip install .` :).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:303,safety,updat,updating,303,"The last minor release of Scanpy was version 1.5.1 in the end of May, so it hasn't been released yet. You would need to update scanpy to the development version on master. This can be done via `pip install git+https://www.github.com/theislab/scanpy@master` or by having a local copy of the scanpy repo, updating this and installing from source via `pip install .` :).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:120,security,updat,update,120,"The last minor release of Scanpy was version 1.5.1 in the end of May, so it hasn't been released yet. You would need to update scanpy to the development version on master. This can be done via `pip install git+https://www.github.com/theislab/scanpy@master` or by having a local copy of the scanpy repo, updating this and installing from source via `pip install .` :).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:303,security,updat,updating,303,"The last minor release of Scanpy was version 1.5.1 in the end of May, so it hasn't been released yet. You would need to update scanpy to the development version on master. This can be done via `pip install git+https://www.github.com/theislab/scanpy@master` or by having a local copy of the scanpy repo, updating this and installing from source via `pip install .` :).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/pull/1329:22,deployability,stack,stacked,22,"@ivirshup Default for stacked violin and dotplot now looks like this (changes: colormap=Blues for violins and border for both violins and dotplot, title of each plot shows which average measure is used):. ![image](https://user-images.githubusercontent.com/4964309/88658953-97676000-d0d4-11ea-80cf-b08f02119cae.png). Alternatively, the default for stacked_violins could be (not my preference as this takes more effort to interpret but similar to the stable branch output):. ![image](https://user-images.githubusercontent.com/4964309/88659263-1197e480-d0d5-11ea-9b9e-acff6bae2443.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1329
https://github.com/scverse/scanpy/pull/1329:186,energy efficiency,measur,measure,186,"@ivirshup Default for stacked violin and dotplot now looks like this (changes: colormap=Blues for violins and border for both violins and dotplot, title of each plot shows which average measure is used):. ![image](https://user-images.githubusercontent.com/4964309/88658953-97676000-d0d4-11ea-80cf-b08f02119cae.png). Alternatively, the default for stacked_violins could be (not my preference as this takes more effort to interpret but similar to the stable branch output):. ![image](https://user-images.githubusercontent.com/4964309/88659263-1197e480-d0d5-11ea-9b9e-acff6bae2443.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1329
https://github.com/scverse/scanpy/pull/1329:222,usability,user,user-images,222,"@ivirshup Default for stacked violin and dotplot now looks like this (changes: colormap=Blues for violins and border for both violins and dotplot, title of each plot shows which average measure is used):. ![image](https://user-images.githubusercontent.com/4964309/88658953-97676000-d0d4-11ea-80cf-b08f02119cae.png). Alternatively, the default for stacked_violins could be (not my preference as this takes more effort to interpret but similar to the stable branch output):. ![image](https://user-images.githubusercontent.com/4964309/88659263-1197e480-d0d5-11ea-9b9e-acff6bae2443.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1329
https://github.com/scverse/scanpy/pull/1329:380,usability,prefer,preference,380,"@ivirshup Default for stacked violin and dotplot now looks like this (changes: colormap=Blues for violins and border for both violins and dotplot, title of each plot shows which average measure is used):. ![image](https://user-images.githubusercontent.com/4964309/88658953-97676000-d0d4-11ea-80cf-b08f02119cae.png). Alternatively, the default for stacked_violins could be (not my preference as this takes more effort to interpret but similar to the stable branch output):. ![image](https://user-images.githubusercontent.com/4964309/88659263-1197e480-d0d5-11ea-9b9e-acff6bae2443.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1329
https://github.com/scverse/scanpy/pull/1329:490,usability,user,user-images,490,"@ivirshup Default for stacked violin and dotplot now looks like this (changes: colormap=Blues for violins and border for both violins and dotplot, title of each plot shows which average measure is used):. ![image](https://user-images.githubusercontent.com/4964309/88658953-97676000-d0d4-11ea-80cf-b08f02119cae.png). Alternatively, the default for stacked_violins could be (not my preference as this takes more effort to interpret but similar to the stable branch output):. ![image](https://user-images.githubusercontent.com/4964309/88659263-1197e480-d0d5-11ea-9b9e-acff6bae2443.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1329
https://github.com/scverse/scanpy/pull/1329:214,availability,cluster,clustermap,214,"That looks great! Thanks! I also prefer the shaded violin plot, since I don't think the categorical colors are adding a ton of information. If I wanted category colors I think I'd prefer a ""barcode"" like what `sns.clustermap` does, but that isn't necessary right now. One very minor quibble. For the dot plot, would it be easy to make the outline of the dots to be the same color/ width in the legend and figure?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1329
https://github.com/scverse/scanpy/pull/1329:214,deployability,cluster,clustermap,214,"That looks great! Thanks! I also prefer the shaded violin plot, since I don't think the categorical colors are adding a ton of information. If I wanted category colors I think I'd prefer a ""barcode"" like what `sns.clustermap` does, but that isn't necessary right now. One very minor quibble. For the dot plot, would it be easy to make the outline of the dots to be the same color/ width in the legend and figure?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1329
https://github.com/scverse/scanpy/pull/1329:226,reliability,doe,does,226,"That looks great! Thanks! I also prefer the shaded violin plot, since I don't think the categorical colors are adding a ton of information. If I wanted category colors I think I'd prefer a ""barcode"" like what `sns.clustermap` does, but that isn't necessary right now. One very minor quibble. For the dot plot, would it be easy to make the outline of the dots to be the same color/ width in the legend and figure?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1329
https://github.com/scverse/scanpy/pull/1329:33,usability,prefer,prefer,33,"That looks great! Thanks! I also prefer the shaded violin plot, since I don't think the categorical colors are adding a ton of information. If I wanted category colors I think I'd prefer a ""barcode"" like what `sns.clustermap` does, but that isn't necessary right now. One very minor quibble. For the dot plot, would it be easy to make the outline of the dots to be the same color/ width in the legend and figure?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1329
https://github.com/scverse/scanpy/pull/1329:180,usability,prefer,prefer,180,"That looks great! Thanks! I also prefer the shaded violin plot, since I don't think the categorical colors are adding a ton of information. If I wanted category colors I think I'd prefer a ""barcode"" like what `sns.clustermap` does, but that isn't necessary right now. One very minor quibble. For the dot plot, would it be easy to make the outline of the dots to be the same color/ width in the legend and figure?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1329
https://github.com/scverse/scanpy/pull/1332:197,deployability,integr,integration,197,"Hi @brianhie,. It's great that you're contributing to Scanpy to make the interoperability even easier (I guess it was already quite good given you built on `AnnData`). We have been evaluating data integration methods and in which Scanorama performed quite well (you may have seen the [preprint](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2)). One aspect that would make it even easier to use the tool that we were missing in the comparison is a small tutorial. The example in the function docstring is already very helpful, but do you think it would be possible to add a quite jupyter notebook in this direction? This is obviously a request outside of this PR. On the topic of the PR, I wonder if `adata.obsm['X_pca_scanorama']` is a good default name for the generated embedding, and not just `adata.obsm['X_scanorama']` as the standard user may not have delved into the methodology as much.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:197,integrability,integr,integration,197,"Hi @brianhie,. It's great that you're contributing to Scanpy to make the interoperability even easier (I guess it was already quite good given you built on `AnnData`). We have been evaluating data integration methods and in which Scanorama performed quite well (you may have seen the [preprint](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2)). One aspect that would make it even easier to use the tool that we were missing in the comparison is a small tutorial. The example in the function docstring is already very helpful, but do you think it would be possible to add a quite jupyter notebook in this direction? This is obviously a request outside of this PR. On the topic of the PR, I wonder if `adata.obsm['X_pca_scanorama']` is a good default name for the generated embedding, and not just `adata.obsm['X_scanorama']` as the standard user may not have delved into the methodology as much.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:683,integrability,topic,topic,683,"Hi @brianhie,. It's great that you're contributing to Scanpy to make the interoperability even easier (I guess it was already quite good given you built on `AnnData`). We have been evaluating data integration methods and in which Scanorama performed quite well (you may have seen the [preprint](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2)). One aspect that would make it even easier to use the tool that we were missing in the comparison is a small tutorial. The example in the function docstring is already very helpful, but do you think it would be possible to add a quite jupyter notebook in this direction? This is obviously a request outside of this PR. On the topic of the PR, I wonder if `adata.obsm['X_pca_scanorama']` is a good default name for the generated embedding, and not just `adata.obsm['X_scanorama']` as the standard user may not have delved into the methodology as much.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:73,interoperability,interoperab,interoperability,73,"Hi @brianhie,. It's great that you're contributing to Scanpy to make the interoperability even easier (I guess it was already quite good given you built on `AnnData`). We have been evaluating data integration methods and in which Scanorama performed quite well (you may have seen the [preprint](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2)). One aspect that would make it even easier to use the tool that we were missing in the comparison is a small tutorial. The example in the function docstring is already very helpful, but do you think it would be possible to add a quite jupyter notebook in this direction? This is obviously a request outside of this PR. On the topic of the PR, I wonder if `adata.obsm['X_pca_scanorama']` is a good default name for the generated embedding, and not just `adata.obsm['X_scanorama']` as the standard user may not have delved into the methodology as much.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:197,interoperability,integr,integration,197,"Hi @brianhie,. It's great that you're contributing to Scanpy to make the interoperability even easier (I guess it was already quite good given you built on `AnnData`). We have been evaluating data integration methods and in which Scanorama performed quite well (you may have seen the [preprint](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2)). One aspect that would make it even easier to use the tool that we were missing in the comparison is a small tutorial. The example in the function docstring is already very helpful, but do you think it would be possible to add a quite jupyter notebook in this direction? This is obviously a request outside of this PR. On the topic of the PR, I wonder if `adata.obsm['X_pca_scanorama']` is a good default name for the generated embedding, and not just `adata.obsm['X_scanorama']` as the standard user may not have delved into the methodology as much.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:844,interoperability,standard,standard,844,"Hi @brianhie,. It's great that you're contributing to Scanpy to make the interoperability even easier (I guess it was already quite good given you built on `AnnData`). We have been evaluating data integration methods and in which Scanorama performed quite well (you may have seen the [preprint](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2)). One aspect that would make it even easier to use the tool that we were missing in the comparison is a small tutorial. The example in the function docstring is already very helpful, but do you think it would be possible to add a quite jupyter notebook in this direction? This is obviously a request outside of this PR. On the topic of the PR, I wonder if `adata.obsm['X_pca_scanorama']` is a good default name for the generated embedding, and not just `adata.obsm['X_scanorama']` as the standard user may not have delved into the methodology as much.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:73,modifiability,interop,interoperability,73,"Hi @brianhie,. It's great that you're contributing to Scanpy to make the interoperability even easier (I guess it was already quite good given you built on `AnnData`). We have been evaluating data integration methods and in which Scanorama performed quite well (you may have seen the [preprint](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2)). One aspect that would make it even easier to use the tool that we were missing in the comparison is a small tutorial. The example in the function docstring is already very helpful, but do you think it would be possible to add a quite jupyter notebook in this direction? This is obviously a request outside of this PR. On the topic of the PR, I wonder if `adata.obsm['X_pca_scanorama']` is a good default name for the generated embedding, and not just `adata.obsm['X_scanorama']` as the standard user may not have delved into the methodology as much.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:197,modifiability,integr,integration,197,"Hi @brianhie,. It's great that you're contributing to Scanpy to make the interoperability even easier (I guess it was already quite good given you built on `AnnData`). We have been evaluating data integration methods and in which Scanorama performed quite well (you may have seen the [preprint](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2)). One aspect that would make it even easier to use the tool that we were missing in the comparison is a small tutorial. The example in the function docstring is already very helpful, but do you think it would be possible to add a quite jupyter notebook in this direction? This is obviously a request outside of this PR. On the topic of the PR, I wonder if `adata.obsm['X_pca_scanorama']` is a good default name for the generated embedding, and not just `adata.obsm['X_scanorama']` as the standard user may not have delved into the methodology as much.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:240,performance,perform,performed,240,"Hi @brianhie,. It's great that you're contributing to Scanpy to make the interoperability even easier (I guess it was already quite good given you built on `AnnData`). We have been evaluating data integration methods and in which Scanorama performed quite well (you may have seen the [preprint](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2)). One aspect that would make it even easier to use the tool that we were missing in the comparison is a small tutorial. The example in the function docstring is already very helpful, but do you think it would be possible to add a quite jupyter notebook in this direction? This is obviously a request outside of this PR. On the topic of the PR, I wonder if `adata.obsm['X_pca_scanorama']` is a good default name for the generated embedding, and not just `adata.obsm['X_scanorama']` as the standard user may not have delved into the methodology as much.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:319,performance,content,content,319,"Hi @brianhie,. It's great that you're contributing to Scanpy to make the interoperability even easier (I guess it was already quite good given you built on `AnnData`). We have been evaluating data integration methods and in which Scanorama performed quite well (you may have seen the [preprint](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2)). One aspect that would make it even easier to use the tool that we were missing in the comparison is a small tutorial. The example in the function docstring is already very helpful, but do you think it would be possible to add a quite jupyter notebook in this direction? This is obviously a request outside of this PR. On the topic of the PR, I wonder if `adata.obsm['X_pca_scanorama']` is a good default name for the generated embedding, and not just `adata.obsm['X_scanorama']` as the standard user may not have delved into the methodology as much.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:197,reliability,integr,integration,197,"Hi @brianhie,. It's great that you're contributing to Scanpy to make the interoperability even easier (I guess it was already quite good given you built on `AnnData`). We have been evaluating data integration methods and in which Scanorama performed quite well (you may have seen the [preprint](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2)). One aspect that would make it even easier to use the tool that we were missing in the comparison is a small tutorial. The example in the function docstring is already very helpful, but do you think it would be possible to add a quite jupyter notebook in this direction? This is obviously a request outside of this PR. On the topic of the PR, I wonder if `adata.obsm['X_pca_scanorama']` is a good default name for the generated embedding, and not just `adata.obsm['X_scanorama']` as the standard user may not have delved into the methodology as much.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:197,security,integr,integration,197,"Hi @brianhie,. It's great that you're contributing to Scanpy to make the interoperability even easier (I guess it was already quite good given you built on `AnnData`). We have been evaluating data integration methods and in which Scanorama performed quite well (you may have seen the [preprint](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2)). One aspect that would make it even easier to use the tool that we were missing in the comparison is a small tutorial. The example in the function docstring is already very helpful, but do you think it would be possible to add a quite jupyter notebook in this direction? This is obviously a request outside of this PR. On the topic of the PR, I wonder if `adata.obsm['X_pca_scanorama']` is a good default name for the generated embedding, and not just `adata.obsm['X_scanorama']` as the standard user may not have delved into the methodology as much.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:197,testability,integr,integration,197,"Hi @brianhie,. It's great that you're contributing to Scanpy to make the interoperability even easier (I guess it was already quite good given you built on `AnnData`). We have been evaluating data integration methods and in which Scanorama performed quite well (you may have seen the [preprint](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2)). One aspect that would make it even easier to use the tool that we were missing in the comparison is a small tutorial. The example in the function docstring is already very helpful, but do you think it would be possible to add a quite jupyter notebook in this direction? This is obviously a request outside of this PR. On the topic of the PR, I wonder if `adata.obsm['X_pca_scanorama']` is a good default name for the generated embedding, and not just `adata.obsm['X_scanorama']` as the standard user may not have delved into the methodology as much.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:240,usability,perform,performed,240,"Hi @brianhie,. It's great that you're contributing to Scanpy to make the interoperability even easier (I guess it was already quite good given you built on `AnnData`). We have been evaluating data integration methods and in which Scanorama performed quite well (you may have seen the [preprint](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2)). One aspect that would make it even easier to use the tool that we were missing in the comparison is a small tutorial. The example in the function docstring is already very helpful, but do you think it would be possible to add a quite jupyter notebook in this direction? This is obviously a request outside of this PR. On the topic of the PR, I wonder if `adata.obsm['X_pca_scanorama']` is a good default name for the generated embedding, and not just `adata.obsm['X_scanorama']` as the standard user may not have delved into the methodology as much.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:411,usability,tool,tool,411,"Hi @brianhie,. It's great that you're contributing to Scanpy to make the interoperability even easier (I guess it was already quite good given you built on `AnnData`). We have been evaluating data integration methods and in which Scanorama performed quite well (you may have seen the [preprint](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2)). One aspect that would make it even easier to use the tool that we were missing in the comparison is a small tutorial. The example in the function docstring is already very helpful, but do you think it would be possible to add a quite jupyter notebook in this direction? This is obviously a request outside of this PR. On the topic of the PR, I wonder if `adata.obsm['X_pca_scanorama']` is a good default name for the generated embedding, and not just `adata.obsm['X_scanorama']` as the standard user may not have delved into the methodology as much.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:530,usability,help,helpful,530,"Hi @brianhie,. It's great that you're contributing to Scanpy to make the interoperability even easier (I guess it was already quite good given you built on `AnnData`). We have been evaluating data integration methods and in which Scanorama performed quite well (you may have seen the [preprint](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2)). One aspect that would make it even easier to use the tool that we were missing in the comparison is a small tutorial. The example in the function docstring is already very helpful, but do you think it would be possible to add a quite jupyter notebook in this direction? This is obviously a request outside of this PR. On the topic of the PR, I wonder if `adata.obsm['X_pca_scanorama']` is a good default name for the generated embedding, and not just `adata.obsm['X_scanorama']` as the standard user may not have delved into the methodology as much.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:853,usability,user,user,853,"Hi @brianhie,. It's great that you're contributing to Scanpy to make the interoperability even easier (I guess it was already quite good given you built on `AnnData`). We have been evaluating data integration methods and in which Scanorama performed quite well (you may have seen the [preprint](https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2)). One aspect that would make it even easier to use the tool that we were missing in the comparison is a small tutorial. The example in the function docstring is already very helpful, but do you think it would be possible to add a quite jupyter notebook in this direction? This is obviously a request outside of this PR. On the topic of the PR, I wonder if `adata.obsm['X_pca_scanorama']` is a good default name for the generated embedding, and not just `adata.obsm['X_scanorama']` as the standard user may not have delved into the methodology as much.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:61,deployability,releas,release,61,"Awesome, thanks everyone. @ivirshup I added something to the release notes in the latest commit. I hope the formatting is okay -- let me know if there's some better way to do it. @LuckyMD I've seen your benchmarking preprint and admire the work! For the current API, I'm currently mooching off of tutorials made by others: one which is simpler and one (included in the scanpy tutorials) that is a little more advanced: https://github.com/brianhie/scanorama#full-tutorial. Should this get merged and included in the scanpy API, I promise I'll make a new notebook-based tutorial (probably in Google Colab) that shows off the new API and include a link to it from the Scanorama GitHub README.md. I also agree with shortening the default embedding to `'X_scanorama'` and have done that in the latest commit. @falexwolf Happy to make any changes to the tests if you think that will boost performance, if you'd like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:262,deployability,API,API,262,"Awesome, thanks everyone. @ivirshup I added something to the release notes in the latest commit. I hope the formatting is okay -- let me know if there's some better way to do it. @LuckyMD I've seen your benchmarking preprint and admire the work! For the current API, I'm currently mooching off of tutorials made by others: one which is simpler and one (included in the scanpy tutorials) that is a little more advanced: https://github.com/brianhie/scanorama#full-tutorial. Should this get merged and included in the scanpy API, I promise I'll make a new notebook-based tutorial (probably in Google Colab) that shows off the new API and include a link to it from the Scanorama GitHub README.md. I also agree with shortening the default embedding to `'X_scanorama'` and have done that in the latest commit. @falexwolf Happy to make any changes to the tests if you think that will boost performance, if you'd like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:522,deployability,API,API,522,"Awesome, thanks everyone. @ivirshup I added something to the release notes in the latest commit. I hope the formatting is okay -- let me know if there's some better way to do it. @LuckyMD I've seen your benchmarking preprint and admire the work! For the current API, I'm currently mooching off of tutorials made by others: one which is simpler and one (included in the scanpy tutorials) that is a little more advanced: https://github.com/brianhie/scanorama#full-tutorial. Should this get merged and included in the scanpy API, I promise I'll make a new notebook-based tutorial (probably in Google Colab) that shows off the new API and include a link to it from the Scanorama GitHub README.md. I also agree with shortening the default embedding to `'X_scanorama'` and have done that in the latest commit. @falexwolf Happy to make any changes to the tests if you think that will boost performance, if you'd like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:627,deployability,API,API,627,"Awesome, thanks everyone. @ivirshup I added something to the release notes in the latest commit. I hope the formatting is okay -- let me know if there's some better way to do it. @LuckyMD I've seen your benchmarking preprint and admire the work! For the current API, I'm currently mooching off of tutorials made by others: one which is simpler and one (included in the scanpy tutorials) that is a little more advanced: https://github.com/brianhie/scanorama#full-tutorial. Should this get merged and included in the scanpy API, I promise I'll make a new notebook-based tutorial (probably in Google Colab) that shows off the new API and include a link to it from the Scanorama GitHub README.md. I also agree with shortening the default embedding to `'X_scanorama'` and have done that in the latest commit. @falexwolf Happy to make any changes to the tests if you think that will boost performance, if you'd like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:254,energy efficiency,current,current,254,"Awesome, thanks everyone. @ivirshup I added something to the release notes in the latest commit. I hope the formatting is okay -- let me know if there's some better way to do it. @LuckyMD I've seen your benchmarking preprint and admire the work! For the current API, I'm currently mooching off of tutorials made by others: one which is simpler and one (included in the scanpy tutorials) that is a little more advanced: https://github.com/brianhie/scanorama#full-tutorial. Should this get merged and included in the scanpy API, I promise I'll make a new notebook-based tutorial (probably in Google Colab) that shows off the new API and include a link to it from the Scanorama GitHub README.md. I also agree with shortening the default embedding to `'X_scanorama'` and have done that in the latest commit. @falexwolf Happy to make any changes to the tests if you think that will boost performance, if you'd like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:271,energy efficiency,current,currently,271,"Awesome, thanks everyone. @ivirshup I added something to the release notes in the latest commit. I hope the formatting is okay -- let me know if there's some better way to do it. @LuckyMD I've seen your benchmarking preprint and admire the work! For the current API, I'm currently mooching off of tutorials made by others: one which is simpler and one (included in the scanpy tutorials) that is a little more advanced: https://github.com/brianhie/scanorama#full-tutorial. Should this get merged and included in the scanpy API, I promise I'll make a new notebook-based tutorial (probably in Google Colab) that shows off the new API and include a link to it from the Scanorama GitHub README.md. I also agree with shortening the default embedding to `'X_scanorama'` and have done that in the latest commit. @falexwolf Happy to make any changes to the tests if you think that will boost performance, if you'd like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:262,integrability,API,API,262,"Awesome, thanks everyone. @ivirshup I added something to the release notes in the latest commit. I hope the formatting is okay -- let me know if there's some better way to do it. @LuckyMD I've seen your benchmarking preprint and admire the work! For the current API, I'm currently mooching off of tutorials made by others: one which is simpler and one (included in the scanpy tutorials) that is a little more advanced: https://github.com/brianhie/scanorama#full-tutorial. Should this get merged and included in the scanpy API, I promise I'll make a new notebook-based tutorial (probably in Google Colab) that shows off the new API and include a link to it from the Scanorama GitHub README.md. I also agree with shortening the default embedding to `'X_scanorama'` and have done that in the latest commit. @falexwolf Happy to make any changes to the tests if you think that will boost performance, if you'd like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:522,integrability,API,API,522,"Awesome, thanks everyone. @ivirshup I added something to the release notes in the latest commit. I hope the formatting is okay -- let me know if there's some better way to do it. @LuckyMD I've seen your benchmarking preprint and admire the work! For the current API, I'm currently mooching off of tutorials made by others: one which is simpler and one (included in the scanpy tutorials) that is a little more advanced: https://github.com/brianhie/scanorama#full-tutorial. Should this get merged and included in the scanpy API, I promise I'll make a new notebook-based tutorial (probably in Google Colab) that shows off the new API and include a link to it from the Scanorama GitHub README.md. I also agree with shortening the default embedding to `'X_scanorama'` and have done that in the latest commit. @falexwolf Happy to make any changes to the tests if you think that will boost performance, if you'd like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:627,integrability,API,API,627,"Awesome, thanks everyone. @ivirshup I added something to the release notes in the latest commit. I hope the formatting is okay -- let me know if there's some better way to do it. @LuckyMD I've seen your benchmarking preprint and admire the work! For the current API, I'm currently mooching off of tutorials made by others: one which is simpler and one (included in the scanpy tutorials) that is a little more advanced: https://github.com/brianhie/scanorama#full-tutorial. Should this get merged and included in the scanpy API, I promise I'll make a new notebook-based tutorial (probably in Google Colab) that shows off the new API and include a link to it from the Scanorama GitHub README.md. I also agree with shortening the default embedding to `'X_scanorama'` and have done that in the latest commit. @falexwolf Happy to make any changes to the tests if you think that will boost performance, if you'd like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:108,interoperability,format,formatting,108,"Awesome, thanks everyone. @ivirshup I added something to the release notes in the latest commit. I hope the formatting is okay -- let me know if there's some better way to do it. @LuckyMD I've seen your benchmarking preprint and admire the work! For the current API, I'm currently mooching off of tutorials made by others: one which is simpler and one (included in the scanpy tutorials) that is a little more advanced: https://github.com/brianhie/scanorama#full-tutorial. Should this get merged and included in the scanpy API, I promise I'll make a new notebook-based tutorial (probably in Google Colab) that shows off the new API and include a link to it from the Scanorama GitHub README.md. I also agree with shortening the default embedding to `'X_scanorama'` and have done that in the latest commit. @falexwolf Happy to make any changes to the tests if you think that will boost performance, if you'd like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:262,interoperability,API,API,262,"Awesome, thanks everyone. @ivirshup I added something to the release notes in the latest commit. I hope the formatting is okay -- let me know if there's some better way to do it. @LuckyMD I've seen your benchmarking preprint and admire the work! For the current API, I'm currently mooching off of tutorials made by others: one which is simpler and one (included in the scanpy tutorials) that is a little more advanced: https://github.com/brianhie/scanorama#full-tutorial. Should this get merged and included in the scanpy API, I promise I'll make a new notebook-based tutorial (probably in Google Colab) that shows off the new API and include a link to it from the Scanorama GitHub README.md. I also agree with shortening the default embedding to `'X_scanorama'` and have done that in the latest commit. @falexwolf Happy to make any changes to the tests if you think that will boost performance, if you'd like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:522,interoperability,API,API,522,"Awesome, thanks everyone. @ivirshup I added something to the release notes in the latest commit. I hope the formatting is okay -- let me know if there's some better way to do it. @LuckyMD I've seen your benchmarking preprint and admire the work! For the current API, I'm currently mooching off of tutorials made by others: one which is simpler and one (included in the scanpy tutorials) that is a little more advanced: https://github.com/brianhie/scanorama#full-tutorial. Should this get merged and included in the scanpy API, I promise I'll make a new notebook-based tutorial (probably in Google Colab) that shows off the new API and include a link to it from the Scanorama GitHub README.md. I also agree with shortening the default embedding to `'X_scanorama'` and have done that in the latest commit. @falexwolf Happy to make any changes to the tests if you think that will boost performance, if you'd like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:627,interoperability,API,API,627,"Awesome, thanks everyone. @ivirshup I added something to the release notes in the latest commit. I hope the formatting is okay -- let me know if there's some better way to do it. @LuckyMD I've seen your benchmarking preprint and admire the work! For the current API, I'm currently mooching off of tutorials made by others: one which is simpler and one (included in the scanpy tutorials) that is a little more advanced: https://github.com/brianhie/scanorama#full-tutorial. Should this get merged and included in the scanpy API, I promise I'll make a new notebook-based tutorial (probably in Google Colab) that shows off the new API and include a link to it from the Scanorama GitHub README.md. I also agree with shortening the default embedding to `'X_scanorama'` and have done that in the latest commit. @falexwolf Happy to make any changes to the tests if you think that will boost performance, if you'd like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:883,performance,perform,performance,883,"Awesome, thanks everyone. @ivirshup I added something to the release notes in the latest commit. I hope the formatting is okay -- let me know if there's some better way to do it. @LuckyMD I've seen your benchmarking preprint and admire the work! For the current API, I'm currently mooching off of tutorials made by others: one which is simpler and one (included in the scanpy tutorials) that is a little more advanced: https://github.com/brianhie/scanorama#full-tutorial. Should this get merged and included in the scanpy API, I promise I'll make a new notebook-based tutorial (probably in Google Colab) that shows off the new API and include a link to it from the Scanorama GitHub README.md. I also agree with shortening the default embedding to `'X_scanorama'` and have done that in the latest commit. @falexwolf Happy to make any changes to the tests if you think that will boost performance, if you'd like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:848,safety,test,tests,848,"Awesome, thanks everyone. @ivirshup I added something to the release notes in the latest commit. I hope the formatting is okay -- let me know if there's some better way to do it. @LuckyMD I've seen your benchmarking preprint and admire the work! For the current API, I'm currently mooching off of tutorials made by others: one which is simpler and one (included in the scanpy tutorials) that is a little more advanced: https://github.com/brianhie/scanorama#full-tutorial. Should this get merged and included in the scanpy API, I promise I'll make a new notebook-based tutorial (probably in Google Colab) that shows off the new API and include a link to it from the Scanorama GitHub README.md. I also agree with shortening the default embedding to `'X_scanorama'` and have done that in the latest commit. @falexwolf Happy to make any changes to the tests if you think that will boost performance, if you'd like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:336,testability,simpl,simpler,336,"Awesome, thanks everyone. @ivirshup I added something to the release notes in the latest commit. I hope the formatting is okay -- let me know if there's some better way to do it. @LuckyMD I've seen your benchmarking preprint and admire the work! For the current API, I'm currently mooching off of tutorials made by others: one which is simpler and one (included in the scanpy tutorials) that is a little more advanced: https://github.com/brianhie/scanorama#full-tutorial. Should this get merged and included in the scanpy API, I promise I'll make a new notebook-based tutorial (probably in Google Colab) that shows off the new API and include a link to it from the Scanorama GitHub README.md. I also agree with shortening the default embedding to `'X_scanorama'` and have done that in the latest commit. @falexwolf Happy to make any changes to the tests if you think that will boost performance, if you'd like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:848,testability,test,tests,848,"Awesome, thanks everyone. @ivirshup I added something to the release notes in the latest commit. I hope the formatting is okay -- let me know if there's some better way to do it. @LuckyMD I've seen your benchmarking preprint and admire the work! For the current API, I'm currently mooching off of tutorials made by others: one which is simpler and one (included in the scanpy tutorials) that is a little more advanced: https://github.com/brianhie/scanorama#full-tutorial. Should this get merged and included in the scanpy API, I promise I'll make a new notebook-based tutorial (probably in Google Colab) that shows off the new API and include a link to it from the Scanorama GitHub README.md. I also agree with shortening the default embedding to `'X_scanorama'` and have done that in the latest commit. @falexwolf Happy to make any changes to the tests if you think that will boost performance, if you'd like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:336,usability,simpl,simpler,336,"Awesome, thanks everyone. @ivirshup I added something to the release notes in the latest commit. I hope the formatting is okay -- let me know if there's some better way to do it. @LuckyMD I've seen your benchmarking preprint and admire the work! For the current API, I'm currently mooching off of tutorials made by others: one which is simpler and one (included in the scanpy tutorials) that is a little more advanced: https://github.com/brianhie/scanorama#full-tutorial. Should this get merged and included in the scanpy API, I promise I'll make a new notebook-based tutorial (probably in Google Colab) that shows off the new API and include a link to it from the Scanorama GitHub README.md. I also agree with shortening the default embedding to `'X_scanorama'` and have done that in the latest commit. @falexwolf Happy to make any changes to the tests if you think that will boost performance, if you'd like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:883,usability,perform,performance,883,"Awesome, thanks everyone. @ivirshup I added something to the release notes in the latest commit. I hope the formatting is okay -- let me know if there's some better way to do it. @LuckyMD I've seen your benchmarking preprint and admire the work! For the current API, I'm currently mooching off of tutorials made by others: one which is simpler and one (included in the scanpy tutorials) that is a little more advanced: https://github.com/brianhie/scanorama#full-tutorial. Should this get merged and included in the scanpy API, I promise I'll make a new notebook-based tutorial (probably in Google Colab) that shows off the new API and include a link to it from the Scanorama GitHub README.md. I also agree with shortening the default embedding to `'X_scanorama'` and have done that in the latest commit. @falexwolf Happy to make any changes to the tests if you think that will boost performance, if you'd like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:53,deployability,releas,releasing,53,Thanks for the contribution! Sorry about the wait on releasing this!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:36,testability,plan,plan,36,"Hi @ivirshup , I'm wondering if you plan to implement the `scanorama_correct` method as well in addition to the `scanorama_integrate` method. #2002 . Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/issues/1333:145,reliability,doe,does,145,Happens here:. https://github.com/theislab/scanpy/blob/3558a42e747856cbf55c4d118566a155c6717178/scanpy/preprocessing/_simple.py#L286-L287. Where does `.uns['log1p']` get set other than there?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:121,deployability,log,log,121,"Hi @gheimberg,. In your example you are not using a deepcopy to assign `adata.X` to `adata.layers['other']`. So when you log transform the data in the layer, it automatically log transforms the data in `adata.X` as well, as you just passed the reference. That being said, this is still a bug as even with a `adata.X.copy()` the warning is given.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:161,deployability,automat,automatically,161,"Hi @gheimberg,. In your example you are not using a deepcopy to assign `adata.X` to `adata.layers['other']`. So when you log transform the data in the layer, it automatically log transforms the data in `adata.X` as well, as you just passed the reference. That being said, this is still a bug as even with a `adata.X.copy()` the warning is given.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:175,deployability,log,log,175,"Hi @gheimberg,. In your example you are not using a deepcopy to assign `adata.X` to `adata.layers['other']`. So when you log transform the data in the layer, it automatically log transforms the data in `adata.X` as well, as you just passed the reference. That being said, this is still a bug as even with a `adata.X.copy()` the warning is given.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:125,integrability,transform,transform,125,"Hi @gheimberg,. In your example you are not using a deepcopy to assign `adata.X` to `adata.layers['other']`. So when you log transform the data in the layer, it automatically log transforms the data in `adata.X` as well, as you just passed the reference. That being said, this is still a bug as even with a `adata.X.copy()` the warning is given.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:179,integrability,transform,transforms,179,"Hi @gheimberg,. In your example you are not using a deepcopy to assign `adata.X` to `adata.layers['other']`. So when you log transform the data in the layer, it automatically log transforms the data in `adata.X` as well, as you just passed the reference. That being said, this is still a bug as even with a `adata.X.copy()` the warning is given.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:125,interoperability,transform,transform,125,"Hi @gheimberg,. In your example you are not using a deepcopy to assign `adata.X` to `adata.layers['other']`. So when you log transform the data in the layer, it automatically log transforms the data in `adata.X` as well, as you just passed the reference. That being said, this is still a bug as even with a `adata.X.copy()` the warning is given.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:179,interoperability,transform,transforms,179,"Hi @gheimberg,. In your example you are not using a deepcopy to assign `adata.X` to `adata.layers['other']`. So when you log transform the data in the layer, it automatically log transforms the data in `adata.X` as well, as you just passed the reference. That being said, this is still a bug as even with a `adata.X.copy()` the warning is given.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:91,modifiability,layer,layers,91,"Hi @gheimberg,. In your example you are not using a deepcopy to assign `adata.X` to `adata.layers['other']`. So when you log transform the data in the layer, it automatically log transforms the data in `adata.X` as well, as you just passed the reference. That being said, this is still a bug as even with a `adata.X.copy()` the warning is given.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:151,modifiability,layer,layer,151,"Hi @gheimberg,. In your example you are not using a deepcopy to assign `adata.X` to `adata.layers['other']`. So when you log transform the data in the layer, it automatically log transforms the data in `adata.X` as well, as you just passed the reference. That being said, this is still a bug as even with a `adata.X.copy()` the warning is given.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:121,safety,log,log,121,"Hi @gheimberg,. In your example you are not using a deepcopy to assign `adata.X` to `adata.layers['other']`. So when you log transform the data in the layer, it automatically log transforms the data in `adata.X` as well, as you just passed the reference. That being said, this is still a bug as even with a `adata.X.copy()` the warning is given.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:175,safety,log,log,175,"Hi @gheimberg,. In your example you are not using a deepcopy to assign `adata.X` to `adata.layers['other']`. So when you log transform the data in the layer, it automatically log transforms the data in `adata.X` as well, as you just passed the reference. That being said, this is still a bug as even with a `adata.X.copy()` the warning is given.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:121,security,log,log,121,"Hi @gheimberg,. In your example you are not using a deepcopy to assign `adata.X` to `adata.layers['other']`. So when you log transform the data in the layer, it automatically log transforms the data in `adata.X` as well, as you just passed the reference. That being said, this is still a bug as even with a `adata.X.copy()` the warning is given.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:175,security,log,log,175,"Hi @gheimberg,. In your example you are not using a deepcopy to assign `adata.X` to `adata.layers['other']`. So when you log transform the data in the layer, it automatically log transforms the data in `adata.X` as well, as you just passed the reference. That being said, this is still a bug as even with a `adata.X.copy()` the warning is given.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:121,testability,log,log,121,"Hi @gheimberg,. In your example you are not using a deepcopy to assign `adata.X` to `adata.layers['other']`. So when you log transform the data in the layer, it automatically log transforms the data in `adata.X` as well, as you just passed the reference. That being said, this is still a bug as even with a `adata.X.copy()` the warning is given.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:161,testability,automat,automatically,161,"Hi @gheimberg,. In your example you are not using a deepcopy to assign `adata.X` to `adata.layers['other']`. So when you log transform the data in the layer, it automatically log transforms the data in `adata.X` as well, as you just passed the reference. That being said, this is still a bug as even with a `adata.X.copy()` the warning is given.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:175,testability,log,log,175,"Hi @gheimberg,. In your example you are not using a deepcopy to assign `adata.X` to `adata.layers['other']`. So when you log transform the data in the layer, it automatically log transforms the data in `adata.X` as well, as you just passed the reference. That being said, this is still a bug as even with a `adata.X.copy()` the warning is given.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:29,modifiability,layer,layer,29,Guys we should just keep the layer info here in log1p:. data.uns['log1p'] = {'base': base}. like . data.uns['log1p'][layer] = {'base': base}.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:117,modifiability,layer,layer,117,Guys we should just keep the layer info here in log1p:. data.uns['log1p'] = {'base': base}. like . data.uns['log1p'][layer] = {'base': base}.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:61,deployability,Depend,Depending,61,"I've come across a strange behavior related with this issue. Depending on whether or not I save the object I get the same warning as OP. This works as it should:. ```. import scanpy as sc. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 1, no saving, works as it should. adata=adata.raw.to_adata(). sc.pp.log1p(adata). ##>>> no warning. ```. Saving mid-way does not allow to avoid the warning, even restarting the kernel before reading the data:. ```. import scanpy as sc. ## same as above. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 2, saving and re-assigning from raw. ### saving object, reading, testing again. ### Doesnt work. adata.write_h5ad(tmp+'scanpy_test.h5ad'). adata=sc.read_h5ad(tmp+'scanpy_test.h5ad'). adata=adata.raw.to_adata(). sc.pp.log1p(adata). ###>>>WARNING: adata.X seems to be already log-transformed. ```. I'm on scanpy 1.9.1 if it matters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:304,deployability,log,logaritmize,304,"I've come across a strange behavior related with this issue. Depending on whether or not I save the object I get the same warning as OP. This works as it should:. ```. import scanpy as sc. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 1, no saving, works as it should. adata=adata.raw.to_adata(). sc.pp.log1p(adata). ##>>> no warning. ```. Saving mid-way does not allow to avoid the warning, even restarting the kernel before reading the data:. ```. import scanpy as sc. ## same as above. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 2, saving and re-assigning from raw. ### saving object, reading, testing again. ### Doesnt work. adata.write_h5ad(tmp+'scanpy_test.h5ad'). adata=sc.read_h5ad(tmp+'scanpy_test.h5ad'). adata=adata.raw.to_adata(). sc.pp.log1p(adata). ###>>>WARNING: adata.X seems to be already log-transformed. ```. I'm on scanpy 1.9.1 if it matters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:695,deployability,log,logaritmize,695,"I've come across a strange behavior related with this issue. Depending on whether or not I save the object I get the same warning as OP. This works as it should:. ```. import scanpy as sc. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 1, no saving, works as it should. adata=adata.raw.to_adata(). sc.pp.log1p(adata). ##>>> no warning. ```. Saving mid-way does not allow to avoid the warning, even restarting the kernel before reading the data:. ```. import scanpy as sc. ## same as above. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 2, saving and re-assigning from raw. ### saving object, reading, testing again. ### Doesnt work. adata.write_h5ad(tmp+'scanpy_test.h5ad'). adata=sc.read_h5ad(tmp+'scanpy_test.h5ad'). adata=adata.raw.to_adata(). sc.pp.log1p(adata). ###>>>WARNING: adata.X seems to be already log-transformed. ```. I'm on scanpy 1.9.1 if it matters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:991,deployability,log,log-transformed,991,"I've come across a strange behavior related with this issue. Depending on whether or not I save the object I get the same warning as OP. This works as it should:. ```. import scanpy as sc. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 1, no saving, works as it should. adata=adata.raw.to_adata(). sc.pp.log1p(adata). ##>>> no warning. ```. Saving mid-way does not allow to avoid the warning, even restarting the kernel before reading the data:. ```. import scanpy as sc. ## same as above. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 2, saving and re-assigning from raw. ### saving object, reading, testing again. ### Doesnt work. adata.write_h5ad(tmp+'scanpy_test.h5ad'). adata=sc.read_h5ad(tmp+'scanpy_test.h5ad'). adata=adata.raw.to_adata(). sc.pp.log1p(adata). ###>>>WARNING: adata.X seems to be already log-transformed. ```. I'm on scanpy 1.9.1 if it matters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:61,integrability,Depend,Depending,61,"I've come across a strange behavior related with this issue. Depending on whether or not I save the object I get the same warning as OP. This works as it should:. ```. import scanpy as sc. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 1, no saving, works as it should. adata=adata.raw.to_adata(). sc.pp.log1p(adata). ##>>> no warning. ```. Saving mid-way does not allow to avoid the warning, even restarting the kernel before reading the data:. ```. import scanpy as sc. ## same as above. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 2, saving and re-assigning from raw. ### saving object, reading, testing again. ### Doesnt work. adata.write_h5ad(tmp+'scanpy_test.h5ad'). adata=sc.read_h5ad(tmp+'scanpy_test.h5ad'). adata=adata.raw.to_adata(). sc.pp.log1p(adata). ###>>>WARNING: adata.X seems to be already log-transformed. ```. I'm on scanpy 1.9.1 if it matters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:995,integrability,transform,transformed,995,"I've come across a strange behavior related with this issue. Depending on whether or not I save the object I get the same warning as OP. This works as it should:. ```. import scanpy as sc. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 1, no saving, works as it should. adata=adata.raw.to_adata(). sc.pp.log1p(adata). ##>>> no warning. ```. Saving mid-way does not allow to avoid the warning, even restarting the kernel before reading the data:. ```. import scanpy as sc. ## same as above. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 2, saving and re-assigning from raw. ### saving object, reading, testing again. ### Doesnt work. adata.write_h5ad(tmp+'scanpy_test.h5ad'). adata=sc.read_h5ad(tmp+'scanpy_test.h5ad'). adata=adata.raw.to_adata(). sc.pp.log1p(adata). ###>>>WARNING: adata.X seems to be already log-transformed. ```. I'm on scanpy 1.9.1 if it matters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:995,interoperability,transform,transformed,995,"I've come across a strange behavior related with this issue. Depending on whether or not I save the object I get the same warning as OP. This works as it should:. ```. import scanpy as sc. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 1, no saving, works as it should. adata=adata.raw.to_adata(). sc.pp.log1p(adata). ##>>> no warning. ```. Saving mid-way does not allow to avoid the warning, even restarting the kernel before reading the data:. ```. import scanpy as sc. ## same as above. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 2, saving and re-assigning from raw. ### saving object, reading, testing again. ### Doesnt work. adata.write_h5ad(tmp+'scanpy_test.h5ad'). adata=sc.read_h5ad(tmp+'scanpy_test.h5ad'). adata=adata.raw.to_adata(). sc.pp.log1p(adata). ###>>>WARNING: adata.X seems to be already log-transformed. ```. I'm on scanpy 1.9.1 if it matters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:61,modifiability,Depend,Depending,61,"I've come across a strange behavior related with this issue. Depending on whether or not I save the object I get the same warning as OP. This works as it should:. ```. import scanpy as sc. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 1, no saving, works as it should. adata=adata.raw.to_adata(). sc.pp.log1p(adata). ##>>> no warning. ```. Saving mid-way does not allow to avoid the warning, even restarting the kernel before reading the data:. ```. import scanpy as sc. ## same as above. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 2, saving and re-assigning from raw. ### saving object, reading, testing again. ### Doesnt work. adata.write_h5ad(tmp+'scanpy_test.h5ad'). adata=sc.read_h5ad(tmp+'scanpy_test.h5ad'). adata=adata.raw.to_adata(). sc.pp.log1p(adata). ###>>>WARNING: adata.X seems to be already log-transformed. ```. I'm on scanpy 1.9.1 if it matters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:446,reliability,doe,does,446,"I've come across a strange behavior related with this issue. Depending on whether or not I save the object I get the same warning as OP. This works as it should:. ```. import scanpy as sc. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 1, no saving, works as it should. adata=adata.raw.to_adata(). sc.pp.log1p(adata). ##>>> no warning. ```. Saving mid-way does not allow to avoid the warning, even restarting the kernel before reading the data:. ```. import scanpy as sc. ## same as above. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 2, saving and re-assigning from raw. ### saving object, reading, testing again. ### Doesnt work. adata.write_h5ad(tmp+'scanpy_test.h5ad'). adata=sc.read_h5ad(tmp+'scanpy_test.h5ad'). adata=adata.raw.to_adata(). sc.pp.log1p(adata). ###>>>WARNING: adata.X seems to be already log-transformed. ```. I'm on scanpy 1.9.1 if it matters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:801,reliability,Doe,Doesnt,801,"I've come across a strange behavior related with this issue. Depending on whether or not I save the object I get the same warning as OP. This works as it should:. ```. import scanpy as sc. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 1, no saving, works as it should. adata=adata.raw.to_adata(). sc.pp.log1p(adata). ##>>> no warning. ```. Saving mid-way does not allow to avoid the warning, even restarting the kernel before reading the data:. ```. import scanpy as sc. ## same as above. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 2, saving and re-assigning from raw. ### saving object, reading, testing again. ### Doesnt work. adata.write_h5ad(tmp+'scanpy_test.h5ad'). adata=sc.read_h5ad(tmp+'scanpy_test.h5ad'). adata=adata.raw.to_adata(). sc.pp.log1p(adata). ###>>>WARNING: adata.X seems to be already log-transformed. ```. I'm on scanpy 1.9.1 if it matters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:61,safety,Depend,Depending,61,"I've come across a strange behavior related with this issue. Depending on whether or not I save the object I get the same warning as OP. This works as it should:. ```. import scanpy as sc. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 1, no saving, works as it should. adata=adata.raw.to_adata(). sc.pp.log1p(adata). ##>>> no warning. ```. Saving mid-way does not allow to avoid the warning, even restarting the kernel before reading the data:. ```. import scanpy as sc. ## same as above. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 2, saving and re-assigning from raw. ### saving object, reading, testing again. ### Doesnt work. adata.write_h5ad(tmp+'scanpy_test.h5ad'). adata=sc.read_h5ad(tmp+'scanpy_test.h5ad'). adata=adata.raw.to_adata(). sc.pp.log1p(adata). ###>>>WARNING: adata.X seems to be already log-transformed. ```. I'm on scanpy 1.9.1 if it matters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:304,safety,log,logaritmize,304,"I've come across a strange behavior related with this issue. Depending on whether or not I save the object I get the same warning as OP. This works as it should:. ```. import scanpy as sc. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 1, no saving, works as it should. adata=adata.raw.to_adata(). sc.pp.log1p(adata). ##>>> no warning. ```. Saving mid-way does not allow to avoid the warning, even restarting the kernel before reading the data:. ```. import scanpy as sc. ## same as above. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 2, saving and re-assigning from raw. ### saving object, reading, testing again. ### Doesnt work. adata.write_h5ad(tmp+'scanpy_test.h5ad'). adata=sc.read_h5ad(tmp+'scanpy_test.h5ad'). adata=adata.raw.to_adata(). sc.pp.log1p(adata). ###>>>WARNING: adata.X seems to be already log-transformed. ```. I'm on scanpy 1.9.1 if it matters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:321,safety,Test,Test,321,"I've come across a strange behavior related with this issue. Depending on whether or not I save the object I get the same warning as OP. This works as it should:. ```. import scanpy as sc. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 1, no saving, works as it should. adata=adata.raw.to_adata(). sc.pp.log1p(adata). ##>>> no warning. ```. Saving mid-way does not allow to avoid the warning, even restarting the kernel before reading the data:. ```. import scanpy as sc. ## same as above. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 2, saving and re-assigning from raw. ### saving object, reading, testing again. ### Doesnt work. adata.write_h5ad(tmp+'scanpy_test.h5ad'). adata=sc.read_h5ad(tmp+'scanpy_test.h5ad'). adata=adata.raw.to_adata(). sc.pp.log1p(adata). ###>>>WARNING: adata.X seems to be already log-transformed. ```. I'm on scanpy 1.9.1 if it matters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:464,safety,avoid,avoid,464,"I've come across a strange behavior related with this issue. Depending on whether or not I save the object I get the same warning as OP. This works as it should:. ```. import scanpy as sc. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 1, no saving, works as it should. adata=adata.raw.to_adata(). sc.pp.log1p(adata). ##>>> no warning. ```. Saving mid-way does not allow to avoid the warning, even restarting the kernel before reading the data:. ```. import scanpy as sc. ## same as above. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 2, saving and re-assigning from raw. ### saving object, reading, testing again. ### Doesnt work. adata.write_h5ad(tmp+'scanpy_test.h5ad'). adata=sc.read_h5ad(tmp+'scanpy_test.h5ad'). adata=adata.raw.to_adata(). sc.pp.log1p(adata). ###>>>WARNING: adata.X seems to be already log-transformed. ```. I'm on scanpy 1.9.1 if it matters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:695,safety,log,logaritmize,695,"I've come across a strange behavior related with this issue. Depending on whether or not I save the object I get the same warning as OP. This works as it should:. ```. import scanpy as sc. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 1, no saving, works as it should. adata=adata.raw.to_adata(). sc.pp.log1p(adata). ##>>> no warning. ```. Saving mid-way does not allow to avoid the warning, even restarting the kernel before reading the data:. ```. import scanpy as sc. ## same as above. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 2, saving and re-assigning from raw. ### saving object, reading, testing again. ### Doesnt work. adata.write_h5ad(tmp+'scanpy_test.h5ad'). adata=sc.read_h5ad(tmp+'scanpy_test.h5ad'). adata=adata.raw.to_adata(). sc.pp.log1p(adata). ###>>>WARNING: adata.X seems to be already log-transformed. ```. I'm on scanpy 1.9.1 if it matters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:712,safety,Test,Test,712,"I've come across a strange behavior related with this issue. Depending on whether or not I save the object I get the same warning as OP. This works as it should:. ```. import scanpy as sc. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 1, no saving, works as it should. adata=adata.raw.to_adata(). sc.pp.log1p(adata). ##>>> no warning. ```. Saving mid-way does not allow to avoid the warning, even restarting the kernel before reading the data:. ```. import scanpy as sc. ## same as above. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 2, saving and re-assigning from raw. ### saving object, reading, testing again. ### Doesnt work. adata.write_h5ad(tmp+'scanpy_test.h5ad'). adata=sc.read_h5ad(tmp+'scanpy_test.h5ad'). adata=adata.raw.to_adata(). sc.pp.log1p(adata). ###>>>WARNING: adata.X seems to be already log-transformed. ```. I'm on scanpy 1.9.1 if it matters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:782,safety,test,testing,782,"I've come across a strange behavior related with this issue. Depending on whether or not I save the object I get the same warning as OP. This works as it should:. ```. import scanpy as sc. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 1, no saving, works as it should. adata=adata.raw.to_adata(). sc.pp.log1p(adata). ##>>> no warning. ```. Saving mid-way does not allow to avoid the warning, even restarting the kernel before reading the data:. ```. import scanpy as sc. ## same as above. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 2, saving and re-assigning from raw. ### saving object, reading, testing again. ### Doesnt work. adata.write_h5ad(tmp+'scanpy_test.h5ad'). adata=sc.read_h5ad(tmp+'scanpy_test.h5ad'). adata=adata.raw.to_adata(). sc.pp.log1p(adata). ###>>>WARNING: adata.X seems to be already log-transformed. ```. I'm on scanpy 1.9.1 if it matters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:991,safety,log,log-transformed,991,"I've come across a strange behavior related with this issue. Depending on whether or not I save the object I get the same warning as OP. This works as it should:. ```. import scanpy as sc. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 1, no saving, works as it should. adata=adata.raw.to_adata(). sc.pp.log1p(adata). ##>>> no warning. ```. Saving mid-way does not allow to avoid the warning, even restarting the kernel before reading the data:. ```. import scanpy as sc. ## same as above. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 2, saving and re-assigning from raw. ### saving object, reading, testing again. ### Doesnt work. adata.write_h5ad(tmp+'scanpy_test.h5ad'). adata=sc.read_h5ad(tmp+'scanpy_test.h5ad'). adata=adata.raw.to_adata(). sc.pp.log1p(adata). ###>>>WARNING: adata.X seems to be already log-transformed. ```. I'm on scanpy 1.9.1 if it matters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:304,security,log,logaritmize,304,"I've come across a strange behavior related with this issue. Depending on whether or not I save the object I get the same warning as OP. This works as it should:. ```. import scanpy as sc. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 1, no saving, works as it should. adata=adata.raw.to_adata(). sc.pp.log1p(adata). ##>>> no warning. ```. Saving mid-way does not allow to avoid the warning, even restarting the kernel before reading the data:. ```. import scanpy as sc. ## same as above. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 2, saving and re-assigning from raw. ### saving object, reading, testing again. ### Doesnt work. adata.write_h5ad(tmp+'scanpy_test.h5ad'). adata=sc.read_h5ad(tmp+'scanpy_test.h5ad'). adata=adata.raw.to_adata(). sc.pp.log1p(adata). ###>>>WARNING: adata.X seems to be already log-transformed. ```. I'm on scanpy 1.9.1 if it matters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:695,security,log,logaritmize,695,"I've come across a strange behavior related with this issue. Depending on whether or not I save the object I get the same warning as OP. This works as it should:. ```. import scanpy as sc. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 1, no saving, works as it should. adata=adata.raw.to_adata(). sc.pp.log1p(adata). ##>>> no warning. ```. Saving mid-way does not allow to avoid the warning, even restarting the kernel before reading the data:. ```. import scanpy as sc. ## same as above. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 2, saving and re-assigning from raw. ### saving object, reading, testing again. ### Doesnt work. adata.write_h5ad(tmp+'scanpy_test.h5ad'). adata=sc.read_h5ad(tmp+'scanpy_test.h5ad'). adata=adata.raw.to_adata(). sc.pp.log1p(adata). ###>>>WARNING: adata.X seems to be already log-transformed. ```. I'm on scanpy 1.9.1 if it matters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:991,security,log,log-transformed,991,"I've come across a strange behavior related with this issue. Depending on whether or not I save the object I get the same warning as OP. This works as it should:. ```. import scanpy as sc. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 1, no saving, works as it should. adata=adata.raw.to_adata(). sc.pp.log1p(adata). ##>>> no warning. ```. Saving mid-way does not allow to avoid the warning, even restarting the kernel before reading the data:. ```. import scanpy as sc. ## same as above. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 2, saving and re-assigning from raw. ### saving object, reading, testing again. ### Doesnt work. adata.write_h5ad(tmp+'scanpy_test.h5ad'). adata=sc.read_h5ad(tmp+'scanpy_test.h5ad'). adata=adata.raw.to_adata(). sc.pp.log1p(adata). ###>>>WARNING: adata.X seems to be already log-transformed. ```. I'm on scanpy 1.9.1 if it matters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:61,testability,Depend,Depending,61,"I've come across a strange behavior related with this issue. Depending on whether or not I save the object I get the same warning as OP. This works as it should:. ```. import scanpy as sc. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 1, no saving, works as it should. adata=adata.raw.to_adata(). sc.pp.log1p(adata). ##>>> no warning. ```. Saving mid-way does not allow to avoid the warning, even restarting the kernel before reading the data:. ```. import scanpy as sc. ## same as above. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 2, saving and re-assigning from raw. ### saving object, reading, testing again. ### Doesnt work. adata.write_h5ad(tmp+'scanpy_test.h5ad'). adata=sc.read_h5ad(tmp+'scanpy_test.h5ad'). adata=adata.raw.to_adata(). sc.pp.log1p(adata). ###>>>WARNING: adata.X seems to be already log-transformed. ```. I'm on scanpy 1.9.1 if it matters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:304,testability,log,logaritmize,304,"I've come across a strange behavior related with this issue. Depending on whether or not I save the object I get the same warning as OP. This works as it should:. ```. import scanpy as sc. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 1, no saving, works as it should. adata=adata.raw.to_adata(). sc.pp.log1p(adata). ##>>> no warning. ```. Saving mid-way does not allow to avoid the warning, even restarting the kernel before reading the data:. ```. import scanpy as sc. ## same as above. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 2, saving and re-assigning from raw. ### saving object, reading, testing again. ### Doesnt work. adata.write_h5ad(tmp+'scanpy_test.h5ad'). adata=sc.read_h5ad(tmp+'scanpy_test.h5ad'). adata=adata.raw.to_adata(). sc.pp.log1p(adata). ###>>>WARNING: adata.X seems to be already log-transformed. ```. I'm on scanpy 1.9.1 if it matters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:321,testability,Test,Test,321,"I've come across a strange behavior related with this issue. Depending on whether or not I save the object I get the same warning as OP. This works as it should:. ```. import scanpy as sc. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 1, no saving, works as it should. adata=adata.raw.to_adata(). sc.pp.log1p(adata). ##>>> no warning. ```. Saving mid-way does not allow to avoid the warning, even restarting the kernel before reading the data:. ```. import scanpy as sc. ## same as above. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 2, saving and re-assigning from raw. ### saving object, reading, testing again. ### Doesnt work. adata.write_h5ad(tmp+'scanpy_test.h5ad'). adata=sc.read_h5ad(tmp+'scanpy_test.h5ad'). adata=adata.raw.to_adata(). sc.pp.log1p(adata). ###>>>WARNING: adata.X seems to be already log-transformed. ```. I'm on scanpy 1.9.1 if it matters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:695,testability,log,logaritmize,695,"I've come across a strange behavior related with this issue. Depending on whether or not I save the object I get the same warning as OP. This works as it should:. ```. import scanpy as sc. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 1, no saving, works as it should. adata=adata.raw.to_adata(). sc.pp.log1p(adata). ##>>> no warning. ```. Saving mid-way does not allow to avoid the warning, even restarting the kernel before reading the data:. ```. import scanpy as sc. ## same as above. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 2, saving and re-assigning from raw. ### saving object, reading, testing again. ### Doesnt work. adata.write_h5ad(tmp+'scanpy_test.h5ad'). adata=sc.read_h5ad(tmp+'scanpy_test.h5ad'). adata=adata.raw.to_adata(). sc.pp.log1p(adata). ###>>>WARNING: adata.X seems to be already log-transformed. ```. I'm on scanpy 1.9.1 if it matters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:712,testability,Test,Test,712,"I've come across a strange behavior related with this issue. Depending on whether or not I save the object I get the same warning as OP. This works as it should:. ```. import scanpy as sc. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 1, no saving, works as it should. adata=adata.raw.to_adata(). sc.pp.log1p(adata). ##>>> no warning. ```. Saving mid-way does not allow to avoid the warning, even restarting the kernel before reading the data:. ```. import scanpy as sc. ## same as above. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 2, saving and re-assigning from raw. ### saving object, reading, testing again. ### Doesnt work. adata.write_h5ad(tmp+'scanpy_test.h5ad'). adata=sc.read_h5ad(tmp+'scanpy_test.h5ad'). adata=adata.raw.to_adata(). sc.pp.log1p(adata). ###>>>WARNING: adata.X seems to be already log-transformed. ```. I'm on scanpy 1.9.1 if it matters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:782,testability,test,testing,782,"I've come across a strange behavior related with this issue. Depending on whether or not I save the object I get the same warning as OP. This works as it should:. ```. import scanpy as sc. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 1, no saving, works as it should. adata=adata.raw.to_adata(). sc.pp.log1p(adata). ##>>> no warning. ```. Saving mid-way does not allow to avoid the warning, even restarting the kernel before reading the data:. ```. import scanpy as sc. ## same as above. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 2, saving and re-assigning from raw. ### saving object, reading, testing again. ### Doesnt work. adata.write_h5ad(tmp+'scanpy_test.h5ad'). adata=sc.read_h5ad(tmp+'scanpy_test.h5ad'). adata=adata.raw.to_adata(). sc.pp.log1p(adata). ###>>>WARNING: adata.X seems to be already log-transformed. ```. I'm on scanpy 1.9.1 if it matters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:991,testability,log,log-transformed,991,"I've come across a strange behavior related with this issue. Depending on whether or not I save the object I get the same warning as OP. This works as it should:. ```. import scanpy as sc. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 1, no saving, works as it should. adata=adata.raw.to_adata(). sc.pp.log1p(adata). ##>>> no warning. ```. Saving mid-way does not allow to avoid the warning, even restarting the kernel before reading the data:. ```. import scanpy as sc. ## same as above. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 2, saving and re-assigning from raw. ### saving object, reading, testing again. ### Doesnt work. adata.write_h5ad(tmp+'scanpy_test.h5ad'). adata=sc.read_h5ad(tmp+'scanpy_test.h5ad'). adata=adata.raw.to_adata(). sc.pp.log1p(adata). ###>>>WARNING: adata.X seems to be already log-transformed. ```. I'm on scanpy 1.9.1 if it matters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:27,usability,behavi,behavior,27,"I've come across a strange behavior related with this issue. Depending on whether or not I save the object I get the same warning as OP. This works as it should:. ```. import scanpy as sc. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 1, no saving, works as it should. adata=adata.raw.to_adata(). sc.pp.log1p(adata). ##>>> no warning. ```. Saving mid-way does not allow to avoid the warning, even restarting the kernel before reading the data:. ```. import scanpy as sc. ## same as above. adata=sc.read_h5ad(data_dir+'scanpy_QC_sexchrom.h5ad'). adata.raw=adata.copy() #data to save. sc.pp.log1p(adata) # logaritmize. ### Test 2, saving and re-assigning from raw. ### saving object, reading, testing again. ### Doesnt work. adata.write_h5ad(tmp+'scanpy_test.h5ad'). adata=sc.read_h5ad(tmp+'scanpy_test.h5ad'). adata=adata.raw.to_adata(). sc.pp.log1p(adata). ###>>>WARNING: adata.X seems to be already log-transformed. ```. I'm on scanpy 1.9.1 if it matters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:294,deployability,log,log-transformed,294,"I must also mention that upon reading in the data:. - running `adata.uns['log1p']` returns `{}`;. - setting `adata.uns['log1p'][""base""] = None` after reading doesn't help. - running `del adata.uns['log1p']` solves the problem. Visual inspection of expression values in `adata.X` seem to not be log-transformed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:298,integrability,transform,transformed,298,"I must also mention that upon reading in the data:. - running `adata.uns['log1p']` returns `{}`;. - setting `adata.uns['log1p'][""base""] = None` after reading doesn't help. - running `del adata.uns['log1p']` solves the problem. Visual inspection of expression values in `adata.X` seem to not be log-transformed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:298,interoperability,transform,transformed,298,"I must also mention that upon reading in the data:. - running `adata.uns['log1p']` returns `{}`;. - setting `adata.uns['log1p'][""base""] = None` after reading doesn't help. - running `del adata.uns['log1p']` solves the problem. Visual inspection of expression values in `adata.X` seem to not be log-transformed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:158,reliability,doe,doesn,158,"I must also mention that upon reading in the data:. - running `adata.uns['log1p']` returns `{}`;. - setting `adata.uns['log1p'][""base""] = None` after reading doesn't help. - running `del adata.uns['log1p']` solves the problem. Visual inspection of expression values in `adata.X` seem to not be log-transformed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:294,safety,log,log-transformed,294,"I must also mention that upon reading in the data:. - running `adata.uns['log1p']` returns `{}`;. - setting `adata.uns['log1p'][""base""] = None` after reading doesn't help. - running `del adata.uns['log1p']` solves the problem. Visual inspection of expression values in `adata.X` seem to not be log-transformed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:294,security,log,log-transformed,294,"I must also mention that upon reading in the data:. - running `adata.uns['log1p']` returns `{}`;. - setting `adata.uns['log1p'][""base""] = None` after reading doesn't help. - running `del adata.uns['log1p']` solves the problem. Visual inspection of expression values in `adata.X` seem to not be log-transformed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:294,testability,log,log-transformed,294,"I must also mention that upon reading in the data:. - running `adata.uns['log1p']` returns `{}`;. - setting `adata.uns['log1p'][""base""] = None` after reading doesn't help. - running `del adata.uns['log1p']` solves the problem. Visual inspection of expression values in `adata.X` seem to not be log-transformed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:166,usability,help,help,166,"I must also mention that upon reading in the data:. - running `adata.uns['log1p']` returns `{}`;. - setting `adata.uns['log1p'][""base""] = None` after reading doesn't help. - running `del adata.uns['log1p']` solves the problem. Visual inspection of expression values in `adata.X` seem to not be log-transformed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:227,usability,Visual,Visual,227,"I must also mention that upon reading in the data:. - running `adata.uns['log1p']` returns `{}`;. - setting `adata.uns['log1p'][""base""] = None` after reading doesn't help. - running `del adata.uns['log1p']` solves the problem. Visual inspection of expression values in `adata.X` seem to not be log-transformed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/pull/1334:4,reliability,doe,does,4,"Hi, does it solve the problem?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/pull/1334:93,availability,state,state,93,"@Koncopd, this seems to work for me. But also it looks like `install_opener` modifies global state and we shouldn't do that. In theory it shouldn't be too difficult to both start a download with a header, and write the result to a file, but it's not obvious `urllib` has anything to help do that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/pull/1334:181,availability,down,download,181,"@Koncopd, this seems to work for me. But also it looks like `install_opener` modifies global state and we shouldn't do that. In theory it shouldn't be too difficult to both start a download with a header, and write the result to a file, but it's not obvious `urllib` has anything to help do that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/pull/1334:93,integrability,state,state,93,"@Koncopd, this seems to work for me. But also it looks like `install_opener` modifies global state and we shouldn't do that. In theory it shouldn't be too difficult to both start a download with a header, and write the result to a file, but it's not obvious `urllib` has anything to help do that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/pull/1334:77,security,modif,modifies,77,"@Koncopd, this seems to work for me. But also it looks like `install_opener` modifies global state and we shouldn't do that. In theory it shouldn't be too difficult to both start a download with a header, and write the result to a file, but it's not obvious `urllib` has anything to help do that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/pull/1334:283,usability,help,help,283,"@Koncopd, this seems to work for me. But also it looks like `install_opener` modifies global state and we shouldn't do that. In theory it shouldn't be too difficult to both start a download with a header, and write the result to a file, but it's not obvious `urllib` has anything to help do that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/pull/1334:30,availability,down,downloading,30,"@ivirshup The idea is that if downloading with a browser or wget works but python requests fail, then the problem should be somewhere in the header. Changing user agent (to avoid blacklist \ whitelist on the server) is the most obvious thing to try.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/pull/1334:91,deployability,fail,fail,91,"@ivirshup The idea is that if downloading with a browser or wget works but python requests fail, then the problem should be somewhere in the header. Changing user agent (to avoid blacklist \ whitelist on the server) is the most obvious thing to try.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/pull/1334:91,reliability,fail,fail,91,"@ivirshup The idea is that if downloading with a browser or wget works but python requests fail, then the problem should be somewhere in the header. Changing user agent (to avoid blacklist \ whitelist on the server) is the most obvious thing to try.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/pull/1334:173,safety,avoid,avoid,173,"@ivirshup The idea is that if downloading with a browser or wget works but python requests fail, then the problem should be somewhere in the header. Changing user agent (to avoid blacklist \ whitelist on the server) is the most obvious thing to try.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/pull/1334:158,usability,user,user,158,"@ivirshup The idea is that if downloading with a browser or wget works but python requests fail, then the problem should be somewhere in the header. Changing user agent (to avoid blacklist \ whitelist on the server) is the most obvious thing to try.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/pull/1334:23,availability,Error,Error,23,How to avoid the 'HTTP Error 403: Forbidden' exactly? I reinstalled scanpy and still have this issue.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/pull/1334:23,performance,Error,Error,23,How to avoid the 'HTTP Error 403: Forbidden' exactly? I reinstalled scanpy and still have this issue.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/pull/1334:7,safety,avoid,avoid,7,How to avoid the 'HTTP Error 403: Forbidden' exactly? I reinstalled scanpy and still have this issue.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/pull/1334:23,safety,Error,Error,23,How to avoid the 'HTTP Error 403: Forbidden' exactly? I reinstalled scanpy and still have this issue.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/pull/1334:23,usability,Error,Error,23,How to avoid the 'HTTP Error 403: Forbidden' exactly? I reinstalled scanpy and still have this issue.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/pull/1334:52,availability,Error,Error,52,I installed it now but still have the issue of HTTP Error 403.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/pull/1334:2,deployability,instal,installed,2,I installed it now but still have the issue of HTTP Error 403.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/pull/1334:52,performance,Error,Error,52,I installed it now but still have the issue of HTTP Error 403.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/pull/1334:52,safety,Error,Error,52,I installed it now but still have the issue of HTTP Error 403.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/pull/1334:52,usability,Error,Error,52,I installed it now but still have the issue of HTTP Error 403.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/pull/1334:190,availability,down,downloading,190,"Hi @ivirshup ,. It just fixed when I installed the library directly from pip. Since I was following the documentation for library installation, the command mentioned in the documentation is downloading an outdated version. . Thanks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/pull/1334:37,deployability,instal,installed,37,"Hi @ivirshup ,. It just fixed when I installed the library directly from pip. Since I was following the documentation for library installation, the command mentioned in the documentation is downloading an outdated version. . Thanks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/pull/1334:130,deployability,instal,installation,130,"Hi @ivirshup ,. It just fixed when I installed the library directly from pip. Since I was following the documentation for library installation, the command mentioned in the documentation is downloading an outdated version. . Thanks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/pull/1334:214,deployability,version,version,214,"Hi @ivirshup ,. It just fixed when I installed the library directly from pip. Since I was following the documentation for library installation, the command mentioned in the documentation is downloading an outdated version. . Thanks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/pull/1334:214,integrability,version,version,214,"Hi @ivirshup ,. It just fixed when I installed the library directly from pip. Since I was following the documentation for library installation, the command mentioned in the documentation is downloading an outdated version. . Thanks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/pull/1334:214,modifiability,version,version,214,"Hi @ivirshup ,. It just fixed when I installed the library directly from pip. Since I was following the documentation for library installation, the command mentioned in the documentation is downloading an outdated version. . Thanks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/pull/1334:104,usability,document,documentation,104,"Hi @ivirshup ,. It just fixed when I installed the library directly from pip. Since I was following the documentation for library installation, the command mentioned in the documentation is downloading an outdated version. . Thanks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/pull/1334:148,usability,command,command,148,"Hi @ivirshup ,. It just fixed when I installed the library directly from pip. Since I was following the documentation for library installation, the command mentioned in the documentation is downloading an outdated version. . Thanks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/pull/1334:173,usability,document,documentation,173,"Hi @ivirshup ,. It just fixed when I installed the library directly from pip. Since I was following the documentation for library installation, the command mentioned in the documentation is downloading an outdated version. . Thanks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/issues/1335:61,usability,user,user-images,61,Output of the same code with scanpy 1.5.1:. ![image](https://user-images.githubusercontent.com/1140359/88754404-8fd3a580-d12c-11ea-9ae6-866ab1da1255.png).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1335
https://github.com/scverse/scanpy/issues/1335:59,performance,time,time,59,"It'd be great have a test for this to catch such bugs next time, like checking the range of the scores.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1335
https://github.com/scverse/scanpy/issues/1335:21,safety,test,test,21,"It'd be great have a test for this to catch such bugs next time, like checking the range of the scores.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1335
https://github.com/scverse/scanpy/issues/1335:21,testability,test,test,21,"It'd be great have a test for this to catch such bugs next time, like checking the range of the scores.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1335
https://github.com/scverse/scanpy/issues/1335:677,availability,ping,ping,677,"My suspicion is that this is more likely to do with the plotting functions, than the calculation. I think the issue is that previously the axis limits weren't being set (though they were calculated). Now they are set, but it turns out they were calculated on the full range of scores  not just the plotted ones. Here's what a potential fix looks like:. <details>. <summary> Big images </summary>. Without fix:. ![tmp](https://user-images.githubusercontent.com/8238804/88772041-7cbfe480-d1c3-11ea-80e9-9ea26c3d4cea.png). With fix:. ![tmp_new](https://user-images.githubusercontent.com/8238804/88772070-88aba680-d1c3-11ea-8872-16a26103b892.png). </details>. What do you think? (ping @fidelram)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1335
https://github.com/scverse/scanpy/issues/1335:427,usability,user,user-images,427,"My suspicion is that this is more likely to do with the plotting functions, than the calculation. I think the issue is that previously the axis limits weren't being set (though they were calculated). Now they are set, but it turns out they were calculated on the full range of scores  not just the plotted ones. Here's what a potential fix looks like:. <details>. <summary> Big images </summary>. Without fix:. ![tmp](https://user-images.githubusercontent.com/8238804/88772041-7cbfe480-d1c3-11ea-80e9-9ea26c3d4cea.png). With fix:. ![tmp_new](https://user-images.githubusercontent.com/8238804/88772070-88aba680-d1c3-11ea-8872-16a26103b892.png). </details>. What do you think? (ping @fidelram)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1335
https://github.com/scverse/scanpy/issues/1335:551,usability,user,user-images,551,"My suspicion is that this is more likely to do with the plotting functions, than the calculation. I think the issue is that previously the axis limits weren't being set (though they were calculated). Now they are set, but it turns out they were calculated on the full range of scores  not just the plotted ones. Here's what a potential fix looks like:. <details>. <summary> Big images </summary>. Without fix:. ![tmp](https://user-images.githubusercontent.com/8238804/88772041-7cbfe480-d1c3-11ea-80e9-9ea26c3d4cea.png). With fix:. ![tmp_new](https://user-images.githubusercontent.com/8238804/88772070-88aba680-d1c3-11ea-8872-16a26103b892.png). </details>. What do you think? (ping @fidelram)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1335
https://github.com/scverse/scanpy/issues/1335:74,integrability,filter,filtering,74,@ivirshup I think the problem happens because i removed the default top n filtering of genes in `rank_genes_groups`.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1335
https://github.com/scverse/scanpy/issues/1335:129,safety,test,tests,129,"Ah, that makes sense. Either way, I don't think the intent of the function was to have the axis bounds determined by how many DE tests were saved.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1335
https://github.com/scverse/scanpy/issues/1335:129,testability,test,tests,129,"Ah, that makes sense. Either way, I don't think the intent of the function was to have the axis bounds determined by how many DE tests were saved.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1335
https://github.com/scverse/scanpy/pull/1337:0,deployability,Updat,Updated,0,Updated plots. <details>. <summary> ranked_genes </summary>. Orig:. ![master_ranked_genes](https://user-images.githubusercontent.com/8238804/88785867-1b087600-d1d5-11ea-85dc-e8ea31303ae7.png). Current:. ![master_ranked_genes](https://user-images.githubusercontent.com/8238804/88785705-e0064280-d1d4-11ea-966e-f856ee2468f6.png). </details>. <details>. <summary> ranked_genes_sharey </summary>. Orig:. ![master_ranked_genes_sharey](https://user-images.githubusercontent.com/8238804/88785853-13e16800-d1d5-11ea-997a-d72955c5b3ce.png). Current:. ![master_ranked_genes_sharey](https://user-images.githubusercontent.com/8238804/88785819-06c47900-d1d5-11ea-8a74-22ef2b4803d0.png). </details>.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1337
https://github.com/scverse/scanpy/pull/1337:193,energy efficiency,Current,Current,193,Updated plots. <details>. <summary> ranked_genes </summary>. Orig:. ![master_ranked_genes](https://user-images.githubusercontent.com/8238804/88785867-1b087600-d1d5-11ea-85dc-e8ea31303ae7.png). Current:. ![master_ranked_genes](https://user-images.githubusercontent.com/8238804/88785705-e0064280-d1d4-11ea-966e-f856ee2468f6.png). </details>. <details>. <summary> ranked_genes_sharey </summary>. Orig:. ![master_ranked_genes_sharey](https://user-images.githubusercontent.com/8238804/88785853-13e16800-d1d5-11ea-997a-d72955c5b3ce.png). Current:. ![master_ranked_genes_sharey](https://user-images.githubusercontent.com/8238804/88785819-06c47900-d1d5-11ea-8a74-22ef2b4803d0.png). </details>.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1337
https://github.com/scverse/scanpy/pull/1337:532,energy efficiency,Current,Current,532,Updated plots. <details>. <summary> ranked_genes </summary>. Orig:. ![master_ranked_genes](https://user-images.githubusercontent.com/8238804/88785867-1b087600-d1d5-11ea-85dc-e8ea31303ae7.png). Current:. ![master_ranked_genes](https://user-images.githubusercontent.com/8238804/88785705-e0064280-d1d4-11ea-966e-f856ee2468f6.png). </details>. <details>. <summary> ranked_genes_sharey </summary>. Orig:. ![master_ranked_genes_sharey](https://user-images.githubusercontent.com/8238804/88785853-13e16800-d1d5-11ea-997a-d72955c5b3ce.png). Current:. ![master_ranked_genes_sharey](https://user-images.githubusercontent.com/8238804/88785819-06c47900-d1d5-11ea-8a74-22ef2b4803d0.png). </details>.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1337
https://github.com/scverse/scanpy/pull/1337:0,safety,Updat,Updated,0,Updated plots. <details>. <summary> ranked_genes </summary>. Orig:. ![master_ranked_genes](https://user-images.githubusercontent.com/8238804/88785867-1b087600-d1d5-11ea-85dc-e8ea31303ae7.png). Current:. ![master_ranked_genes](https://user-images.githubusercontent.com/8238804/88785705-e0064280-d1d4-11ea-966e-f856ee2468f6.png). </details>. <details>. <summary> ranked_genes_sharey </summary>. Orig:. ![master_ranked_genes_sharey](https://user-images.githubusercontent.com/8238804/88785853-13e16800-d1d5-11ea-997a-d72955c5b3ce.png). Current:. ![master_ranked_genes_sharey](https://user-images.githubusercontent.com/8238804/88785819-06c47900-d1d5-11ea-8a74-22ef2b4803d0.png). </details>.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1337
https://github.com/scverse/scanpy/pull/1337:0,security,Updat,Updated,0,Updated plots. <details>. <summary> ranked_genes </summary>. Orig:. ![master_ranked_genes](https://user-images.githubusercontent.com/8238804/88785867-1b087600-d1d5-11ea-85dc-e8ea31303ae7.png). Current:. ![master_ranked_genes](https://user-images.githubusercontent.com/8238804/88785705-e0064280-d1d4-11ea-966e-f856ee2468f6.png). </details>. <details>. <summary> ranked_genes_sharey </summary>. Orig:. ![master_ranked_genes_sharey](https://user-images.githubusercontent.com/8238804/88785853-13e16800-d1d5-11ea-997a-d72955c5b3ce.png). Current:. ![master_ranked_genes_sharey](https://user-images.githubusercontent.com/8238804/88785819-06c47900-d1d5-11ea-8a74-22ef2b4803d0.png). </details>.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1337
https://github.com/scverse/scanpy/pull/1337:99,usability,user,user-images,99,Updated plots. <details>. <summary> ranked_genes </summary>. Orig:. ![master_ranked_genes](https://user-images.githubusercontent.com/8238804/88785867-1b087600-d1d5-11ea-85dc-e8ea31303ae7.png). Current:. ![master_ranked_genes](https://user-images.githubusercontent.com/8238804/88785705-e0064280-d1d4-11ea-966e-f856ee2468f6.png). </details>. <details>. <summary> ranked_genes_sharey </summary>. Orig:. ![master_ranked_genes_sharey](https://user-images.githubusercontent.com/8238804/88785853-13e16800-d1d5-11ea-997a-d72955c5b3ce.png). Current:. ![master_ranked_genes_sharey](https://user-images.githubusercontent.com/8238804/88785819-06c47900-d1d5-11ea-8a74-22ef2b4803d0.png). </details>.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1337
https://github.com/scverse/scanpy/pull/1337:234,usability,user,user-images,234,Updated plots. <details>. <summary> ranked_genes </summary>. Orig:. ![master_ranked_genes](https://user-images.githubusercontent.com/8238804/88785867-1b087600-d1d5-11ea-85dc-e8ea31303ae7.png). Current:. ![master_ranked_genes](https://user-images.githubusercontent.com/8238804/88785705-e0064280-d1d4-11ea-966e-f856ee2468f6.png). </details>. <details>. <summary> ranked_genes_sharey </summary>. Orig:. ![master_ranked_genes_sharey](https://user-images.githubusercontent.com/8238804/88785853-13e16800-d1d5-11ea-997a-d72955c5b3ce.png). Current:. ![master_ranked_genes_sharey](https://user-images.githubusercontent.com/8238804/88785819-06c47900-d1d5-11ea-8a74-22ef2b4803d0.png). </details>.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1337
https://github.com/scverse/scanpy/pull/1337:438,usability,user,user-images,438,Updated plots. <details>. <summary> ranked_genes </summary>. Orig:. ![master_ranked_genes](https://user-images.githubusercontent.com/8238804/88785867-1b087600-d1d5-11ea-85dc-e8ea31303ae7.png). Current:. ![master_ranked_genes](https://user-images.githubusercontent.com/8238804/88785705-e0064280-d1d4-11ea-966e-f856ee2468f6.png). </details>. <details>. <summary> ranked_genes_sharey </summary>. Orig:. ![master_ranked_genes_sharey](https://user-images.githubusercontent.com/8238804/88785853-13e16800-d1d5-11ea-997a-d72955c5b3ce.png). Current:. ![master_ranked_genes_sharey](https://user-images.githubusercontent.com/8238804/88785819-06c47900-d1d5-11ea-8a74-22ef2b4803d0.png). </details>.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1337
https://github.com/scverse/scanpy/pull/1337:580,usability,user,user-images,580,Updated plots. <details>. <summary> ranked_genes </summary>. Orig:. ![master_ranked_genes](https://user-images.githubusercontent.com/8238804/88785867-1b087600-d1d5-11ea-85dc-e8ea31303ae7.png). Current:. ![master_ranked_genes](https://user-images.githubusercontent.com/8238804/88785705-e0064280-d1d4-11ea-966e-f856ee2468f6.png). </details>. <details>. <summary> ranked_genes_sharey </summary>. Orig:. ![master_ranked_genes_sharey](https://user-images.githubusercontent.com/8238804/88785853-13e16800-d1d5-11ea-997a-d72955c5b3ce.png). Current:. ![master_ranked_genes_sharey](https://user-images.githubusercontent.com/8238804/88785819-06c47900-d1d5-11ea-8a74-22ef2b4803d0.png). </details>.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1337
https://github.com/scverse/scanpy/pull/1337:184,usability,user,user-images,184,@ivirshup @fidelram Do you guys think that last genes are not super visible due to the lack of some margin between the x axis and the first letter of the last genes:. ![image](https://user-images.githubusercontent.com/1140359/89191526-0e877300-d571-11ea-9885-ec4676722f22.png). Was it always like that or is it pscyhological?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1337
https://github.com/scverse/scanpy/issues/1338:252,availability,down,downloaded,252,"Hi @marcellp,. The point of the tutorial is to easily become familiarized with Scanpy-based analysis of scRNA-seq data rather than to allow the exploration of a comprehensive dataset. Thus, the pbmc3k object is a reduced version of the one that can be downloaded from the 10X website to make everything run much faster. If you want to take a look at the full object, you would have to download the object from 10X and run the tutorial with that dataset (I believe it's called 2.7k PBMCs there). I'm not 100% sure how this object was generated, but I assume the number of genes were reduced to leave only the most highly variable genes in the dataset with sufficient levels of expression. This is often done in scRNA-seq analysis to reduce the number of features to calculate e.g., PCA-based embeddings for downstream analysis. Thus, it is not uncommon for some genes to not be taken into account when generating an embedding. If you want more background on scRNA-seq analysis in general, I would recommend [this introductory paper](http://msb.embopress.org/lookup/doi/10.15252/msb.20188746).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:385,availability,down,download,385,"Hi @marcellp,. The point of the tutorial is to easily become familiarized with Scanpy-based analysis of scRNA-seq data rather than to allow the exploration of a comprehensive dataset. Thus, the pbmc3k object is a reduced version of the one that can be downloaded from the 10X website to make everything run much faster. If you want to take a look at the full object, you would have to download the object from 10X and run the tutorial with that dataset (I believe it's called 2.7k PBMCs there). I'm not 100% sure how this object was generated, but I assume the number of genes were reduced to leave only the most highly variable genes in the dataset with sufficient levels of expression. This is often done in scRNA-seq analysis to reduce the number of features to calculate e.g., PCA-based embeddings for downstream analysis. Thus, it is not uncommon for some genes to not be taken into account when generating an embedding. If you want more background on scRNA-seq analysis in general, I would recommend [this introductory paper](http://msb.embopress.org/lookup/doi/10.15252/msb.20188746).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:806,availability,down,downstream,806,"Hi @marcellp,. The point of the tutorial is to easily become familiarized with Scanpy-based analysis of scRNA-seq data rather than to allow the exploration of a comprehensive dataset. Thus, the pbmc3k object is a reduced version of the one that can be downloaded from the 10X website to make everything run much faster. If you want to take a look at the full object, you would have to download the object from 10X and run the tutorial with that dataset (I believe it's called 2.7k PBMCs there). I'm not 100% sure how this object was generated, but I assume the number of genes were reduced to leave only the most highly variable genes in the dataset with sufficient levels of expression. This is often done in scRNA-seq analysis to reduce the number of features to calculate e.g., PCA-based embeddings for downstream analysis. Thus, it is not uncommon for some genes to not be taken into account when generating an embedding. If you want more background on scRNA-seq analysis in general, I would recommend [this introductory paper](http://msb.embopress.org/lookup/doi/10.15252/msb.20188746).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:221,deployability,version,version,221,"Hi @marcellp,. The point of the tutorial is to easily become familiarized with Scanpy-based analysis of scRNA-seq data rather than to allow the exploration of a comprehensive dataset. Thus, the pbmc3k object is a reduced version of the one that can be downloaded from the 10X website to make everything run much faster. If you want to take a look at the full object, you would have to download the object from 10X and run the tutorial with that dataset (I believe it's called 2.7k PBMCs there). I'm not 100% sure how this object was generated, but I assume the number of genes were reduced to leave only the most highly variable genes in the dataset with sufficient levels of expression. This is often done in scRNA-seq analysis to reduce the number of features to calculate e.g., PCA-based embeddings for downstream analysis. Thus, it is not uncommon for some genes to not be taken into account when generating an embedding. If you want more background on scRNA-seq analysis in general, I would recommend [this introductory paper](http://msb.embopress.org/lookup/doi/10.15252/msb.20188746).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:213,energy efficiency,reduc,reduced,213,"Hi @marcellp,. The point of the tutorial is to easily become familiarized with Scanpy-based analysis of scRNA-seq data rather than to allow the exploration of a comprehensive dataset. Thus, the pbmc3k object is a reduced version of the one that can be downloaded from the 10X website to make everything run much faster. If you want to take a look at the full object, you would have to download the object from 10X and run the tutorial with that dataset (I believe it's called 2.7k PBMCs there). I'm not 100% sure how this object was generated, but I assume the number of genes were reduced to leave only the most highly variable genes in the dataset with sufficient levels of expression. This is often done in scRNA-seq analysis to reduce the number of features to calculate e.g., PCA-based embeddings for downstream analysis. Thus, it is not uncommon for some genes to not be taken into account when generating an embedding. If you want more background on scRNA-seq analysis in general, I would recommend [this introductory paper](http://msb.embopress.org/lookup/doi/10.15252/msb.20188746).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:582,energy efficiency,reduc,reduced,582,"Hi @marcellp,. The point of the tutorial is to easily become familiarized with Scanpy-based analysis of scRNA-seq data rather than to allow the exploration of a comprehensive dataset. Thus, the pbmc3k object is a reduced version of the one that can be downloaded from the 10X website to make everything run much faster. If you want to take a look at the full object, you would have to download the object from 10X and run the tutorial with that dataset (I believe it's called 2.7k PBMCs there). I'm not 100% sure how this object was generated, but I assume the number of genes were reduced to leave only the most highly variable genes in the dataset with sufficient levels of expression. This is often done in scRNA-seq analysis to reduce the number of features to calculate e.g., PCA-based embeddings for downstream analysis. Thus, it is not uncommon for some genes to not be taken into account when generating an embedding. If you want more background on scRNA-seq analysis in general, I would recommend [this introductory paper](http://msb.embopress.org/lookup/doi/10.15252/msb.20188746).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:732,energy efficiency,reduc,reduce,732,"Hi @marcellp,. The point of the tutorial is to easily become familiarized with Scanpy-based analysis of scRNA-seq data rather than to allow the exploration of a comprehensive dataset. Thus, the pbmc3k object is a reduced version of the one that can be downloaded from the 10X website to make everything run much faster. If you want to take a look at the full object, you would have to download the object from 10X and run the tutorial with that dataset (I believe it's called 2.7k PBMCs there). I'm not 100% sure how this object was generated, but I assume the number of genes were reduced to leave only the most highly variable genes in the dataset with sufficient levels of expression. This is often done in scRNA-seq analysis to reduce the number of features to calculate e.g., PCA-based embeddings for downstream analysis. Thus, it is not uncommon for some genes to not be taken into account when generating an embedding. If you want more background on scRNA-seq analysis in general, I would recommend [this introductory paper](http://msb.embopress.org/lookup/doi/10.15252/msb.20188746).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:221,integrability,version,version,221,"Hi @marcellp,. The point of the tutorial is to easily become familiarized with Scanpy-based analysis of scRNA-seq data rather than to allow the exploration of a comprehensive dataset. Thus, the pbmc3k object is a reduced version of the one that can be downloaded from the 10X website to make everything run much faster. If you want to take a look at the full object, you would have to download the object from 10X and run the tutorial with that dataset (I believe it's called 2.7k PBMCs there). I'm not 100% sure how this object was generated, but I assume the number of genes were reduced to leave only the most highly variable genes in the dataset with sufficient levels of expression. This is often done in scRNA-seq analysis to reduce the number of features to calculate e.g., PCA-based embeddings for downstream analysis. Thus, it is not uncommon for some genes to not be taken into account when generating an embedding. If you want more background on scRNA-seq analysis in general, I would recommend [this introductory paper](http://msb.embopress.org/lookup/doi/10.15252/msb.20188746).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:221,modifiability,version,version,221,"Hi @marcellp,. The point of the tutorial is to easily become familiarized with Scanpy-based analysis of scRNA-seq data rather than to allow the exploration of a comprehensive dataset. Thus, the pbmc3k object is a reduced version of the one that can be downloaded from the 10X website to make everything run much faster. If you want to take a look at the full object, you would have to download the object from 10X and run the tutorial with that dataset (I believe it's called 2.7k PBMCs there). I'm not 100% sure how this object was generated, but I assume the number of genes were reduced to leave only the most highly variable genes in the dataset with sufficient levels of expression. This is often done in scRNA-seq analysis to reduce the number of features to calculate e.g., PCA-based embeddings for downstream analysis. Thus, it is not uncommon for some genes to not be taken into account when generating an embedding. If you want more background on scRNA-seq analysis in general, I would recommend [this introductory paper](http://msb.embopress.org/lookup/doi/10.15252/msb.20188746).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:620,modifiability,variab,variable,620,"Hi @marcellp,. The point of the tutorial is to easily become familiarized with Scanpy-based analysis of scRNA-seq data rather than to allow the exploration of a comprehensive dataset. Thus, the pbmc3k object is a reduced version of the one that can be downloaded from the 10X website to make everything run much faster. If you want to take a look at the full object, you would have to download the object from 10X and run the tutorial with that dataset (I believe it's called 2.7k PBMCs there). I'm not 100% sure how this object was generated, but I assume the number of genes were reduced to leave only the most highly variable genes in the dataset with sufficient levels of expression. This is often done in scRNA-seq analysis to reduce the number of features to calculate e.g., PCA-based embeddings for downstream analysis. Thus, it is not uncommon for some genes to not be taken into account when generating an embedding. If you want more background on scRNA-seq analysis in general, I would recommend [this introductory paper](http://msb.embopress.org/lookup/doi/10.15252/msb.20188746).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:244,availability,consist,consist,244,"Hi @LuckyMD ,. Thanks so much for getting back to me this quickly. I just want to clarify that I am not running this analysis with the built-in 10x data set, I have followed the tutorial as seen on the link in the report, which says: ""The data consist in 3k PBMCs from a Healthy Donor and are freely available from 10x Genomics"". I have downloaded the file from the following URL, as seen in the tutorial:. http://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz. This is also the same URL found on this link, directly from 10x:. https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.1.0/pbmc3k. The 10x summary [here](https://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_web_summary.html) mentions LYZ as one of the most differentially expressed genes, yet it is missed by the sample analysis as performed in the Scanpy tutorial. As both use the exact same count matrix as a source, there are two possibilities here as far as I can see: either the thresholds and filtering parameters in the tutorial are inaccurate and miss important marker genes, or there is a bug that drops these genes. My question is which of the following is true. From your answer I would assume it's the former, in which case maybe a disclaimer pointing this out would be helpful in the tutorial page? I think, as it stands, the average user would assume important marker genes such as LYZ would not be missed by even a rough analysis of a PBMC data set. For reference, the [tutorial](https://satijalab.org/seurat/v3.2/pbmc3k_tutorial.html) which the Scanpy one is apparently based on finds LYZ as a very important contributor to the first principal component.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:271,availability,Heal,Healthy,271,"Hi @LuckyMD ,. Thanks so much for getting back to me this quickly. I just want to clarify that I am not running this analysis with the built-in 10x data set, I have followed the tutorial as seen on the link in the report, which says: ""The data consist in 3k PBMCs from a Healthy Donor and are freely available from 10x Genomics"". I have downloaded the file from the following URL, as seen in the tutorial:. http://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz. This is also the same URL found on this link, directly from 10x:. https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.1.0/pbmc3k. The 10x summary [here](https://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_web_summary.html) mentions LYZ as one of the most differentially expressed genes, yet it is missed by the sample analysis as performed in the Scanpy tutorial. As both use the exact same count matrix as a source, there are two possibilities here as far as I can see: either the thresholds and filtering parameters in the tutorial are inaccurate and miss important marker genes, or there is a bug that drops these genes. My question is which of the following is true. From your answer I would assume it's the former, in which case maybe a disclaimer pointing this out would be helpful in the tutorial page? I think, as it stands, the average user would assume important marker genes such as LYZ would not be missed by even a rough analysis of a PBMC data set. For reference, the [tutorial](https://satijalab.org/seurat/v3.2/pbmc3k_tutorial.html) which the Scanpy one is apparently based on finds LYZ as a very important contributor to the first principal component.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:300,availability,avail,available,300,"Hi @LuckyMD ,. Thanks so much for getting back to me this quickly. I just want to clarify that I am not running this analysis with the built-in 10x data set, I have followed the tutorial as seen on the link in the report, which says: ""The data consist in 3k PBMCs from a Healthy Donor and are freely available from 10x Genomics"". I have downloaded the file from the following URL, as seen in the tutorial:. http://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz. This is also the same URL found on this link, directly from 10x:. https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.1.0/pbmc3k. The 10x summary [here](https://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_web_summary.html) mentions LYZ as one of the most differentially expressed genes, yet it is missed by the sample analysis as performed in the Scanpy tutorial. As both use the exact same count matrix as a source, there are two possibilities here as far as I can see: either the thresholds and filtering parameters in the tutorial are inaccurate and miss important marker genes, or there is a bug that drops these genes. My question is which of the following is true. From your answer I would assume it's the former, in which case maybe a disclaimer pointing this out would be helpful in the tutorial page? I think, as it stands, the average user would assume important marker genes such as LYZ would not be missed by even a rough analysis of a PBMC data set. For reference, the [tutorial](https://satijalab.org/seurat/v3.2/pbmc3k_tutorial.html) which the Scanpy one is apparently based on finds LYZ as a very important contributor to the first principal component.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:337,availability,down,downloaded,337,"Hi @LuckyMD ,. Thanks so much for getting back to me this quickly. I just want to clarify that I am not running this analysis with the built-in 10x data set, I have followed the tutorial as seen on the link in the report, which says: ""The data consist in 3k PBMCs from a Healthy Donor and are freely available from 10x Genomics"". I have downloaded the file from the following URL, as seen in the tutorial:. http://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz. This is also the same URL found on this link, directly from 10x:. https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.1.0/pbmc3k. The 10x summary [here](https://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_web_summary.html) mentions LYZ as one of the most differentially expressed genes, yet it is missed by the sample analysis as performed in the Scanpy tutorial. As both use the exact same count matrix as a source, there are two possibilities here as far as I can see: either the thresholds and filtering parameters in the tutorial are inaccurate and miss important marker genes, or there is a bug that drops these genes. My question is which of the following is true. From your answer I would assume it's the former, in which case maybe a disclaimer pointing this out would be helpful in the tutorial page? I think, as it stands, the average user would assume important marker genes such as LYZ would not be missed by even a rough analysis of a PBMC data set. For reference, the [tutorial](https://satijalab.org/seurat/v3.2/pbmc3k_tutorial.html) which the Scanpy one is apparently based on finds LYZ as a very important contributor to the first principal component.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:1032,integrability,filter,filtering,1032,"Hi @LuckyMD ,. Thanks so much for getting back to me this quickly. I just want to clarify that I am not running this analysis with the built-in 10x data set, I have followed the tutorial as seen on the link in the report, which says: ""The data consist in 3k PBMCs from a Healthy Donor and are freely available from 10x Genomics"". I have downloaded the file from the following URL, as seen in the tutorial:. http://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz. This is also the same URL found on this link, directly from 10x:. https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.1.0/pbmc3k. The 10x summary [here](https://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_web_summary.html) mentions LYZ as one of the most differentially expressed genes, yet it is missed by the sample analysis as performed in the Scanpy tutorial. As both use the exact same count matrix as a source, there are two possibilities here as far as I can see: either the thresholds and filtering parameters in the tutorial are inaccurate and miss important marker genes, or there is a bug that drops these genes. My question is which of the following is true. From your answer I would assume it's the former, in which case maybe a disclaimer pointing this out would be helpful in the tutorial page? I think, as it stands, the average user would assume important marker genes such as LYZ would not be missed by even a rough analysis of a PBMC data set. For reference, the [tutorial](https://satijalab.org/seurat/v3.2/pbmc3k_tutorial.html) which the Scanpy one is apparently based on finds LYZ as a very important contributor to the first principal component.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:1693,integrability,compon,component,1693,"Hi @LuckyMD ,. Thanks so much for getting back to me this quickly. I just want to clarify that I am not running this analysis with the built-in 10x data set, I have followed the tutorial as seen on the link in the report, which says: ""The data consist in 3k PBMCs from a Healthy Donor and are freely available from 10x Genomics"". I have downloaded the file from the following URL, as seen in the tutorial:. http://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz. This is also the same URL found on this link, directly from 10x:. https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.1.0/pbmc3k. The 10x summary [here](https://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_web_summary.html) mentions LYZ as one of the most differentially expressed genes, yet it is missed by the sample analysis as performed in the Scanpy tutorial. As both use the exact same count matrix as a source, there are two possibilities here as far as I can see: either the thresholds and filtering parameters in the tutorial are inaccurate and miss important marker genes, or there is a bug that drops these genes. My question is which of the following is true. From your answer I would assume it's the former, in which case maybe a disclaimer pointing this out would be helpful in the tutorial page? I think, as it stands, the average user would assume important marker genes such as LYZ would not be missed by even a rough analysis of a PBMC data set. For reference, the [tutorial](https://satijalab.org/seurat/v3.2/pbmc3k_tutorial.html) which the Scanpy one is apparently based on finds LYZ as a very important contributor to the first principal component.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:1693,interoperability,compon,component,1693,"Hi @LuckyMD ,. Thanks so much for getting back to me this quickly. I just want to clarify that I am not running this analysis with the built-in 10x data set, I have followed the tutorial as seen on the link in the report, which says: ""The data consist in 3k PBMCs from a Healthy Donor and are freely available from 10x Genomics"". I have downloaded the file from the following URL, as seen in the tutorial:. http://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz. This is also the same URL found on this link, directly from 10x:. https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.1.0/pbmc3k. The 10x summary [here](https://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_web_summary.html) mentions LYZ as one of the most differentially expressed genes, yet it is missed by the sample analysis as performed in the Scanpy tutorial. As both use the exact same count matrix as a source, there are two possibilities here as far as I can see: either the thresholds and filtering parameters in the tutorial are inaccurate and miss important marker genes, or there is a bug that drops these genes. My question is which of the following is true. From your answer I would assume it's the former, in which case maybe a disclaimer pointing this out would be helpful in the tutorial page? I think, as it stands, the average user would assume important marker genes such as LYZ would not be missed by even a rough analysis of a PBMC data set. For reference, the [tutorial](https://satijalab.org/seurat/v3.2/pbmc3k_tutorial.html) which the Scanpy one is apparently based on finds LYZ as a very important contributor to the first principal component.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:1042,modifiability,paramet,parameters,1042,"Hi @LuckyMD ,. Thanks so much for getting back to me this quickly. I just want to clarify that I am not running this analysis with the built-in 10x data set, I have followed the tutorial as seen on the link in the report, which says: ""The data consist in 3k PBMCs from a Healthy Donor and are freely available from 10x Genomics"". I have downloaded the file from the following URL, as seen in the tutorial:. http://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz. This is also the same URL found on this link, directly from 10x:. https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.1.0/pbmc3k. The 10x summary [here](https://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_web_summary.html) mentions LYZ as one of the most differentially expressed genes, yet it is missed by the sample analysis as performed in the Scanpy tutorial. As both use the exact same count matrix as a source, there are two possibilities here as far as I can see: either the thresholds and filtering parameters in the tutorial are inaccurate and miss important marker genes, or there is a bug that drops these genes. My question is which of the following is true. From your answer I would assume it's the former, in which case maybe a disclaimer pointing this out would be helpful in the tutorial page? I think, as it stands, the average user would assume important marker genes such as LYZ would not be missed by even a rough analysis of a PBMC data set. For reference, the [tutorial](https://satijalab.org/seurat/v3.2/pbmc3k_tutorial.html) which the Scanpy one is apparently based on finds LYZ as a very important contributor to the first principal component.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:1693,modifiability,compon,component,1693,"Hi @LuckyMD ,. Thanks so much for getting back to me this quickly. I just want to clarify that I am not running this analysis with the built-in 10x data set, I have followed the tutorial as seen on the link in the report, which says: ""The data consist in 3k PBMCs from a Healthy Donor and are freely available from 10x Genomics"". I have downloaded the file from the following URL, as seen in the tutorial:. http://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz. This is also the same URL found on this link, directly from 10x:. https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.1.0/pbmc3k. The 10x summary [here](https://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_web_summary.html) mentions LYZ as one of the most differentially expressed genes, yet it is missed by the sample analysis as performed in the Scanpy tutorial. As both use the exact same count matrix as a source, there are two possibilities here as far as I can see: either the thresholds and filtering parameters in the tutorial are inaccurate and miss important marker genes, or there is a bug that drops these genes. My question is which of the following is true. From your answer I would assume it's the former, in which case maybe a disclaimer pointing this out would be helpful in the tutorial page? I think, as it stands, the average user would assume important marker genes such as LYZ would not be missed by even a rough analysis of a PBMC data set. For reference, the [tutorial](https://satijalab.org/seurat/v3.2/pbmc3k_tutorial.html) which the Scanpy one is apparently based on finds LYZ as a very important contributor to the first principal component.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:865,performance,perform,performed,865,"Hi @LuckyMD ,. Thanks so much for getting back to me this quickly. I just want to clarify that I am not running this analysis with the built-in 10x data set, I have followed the tutorial as seen on the link in the report, which says: ""The data consist in 3k PBMCs from a Healthy Donor and are freely available from 10x Genomics"". I have downloaded the file from the following URL, as seen in the tutorial:. http://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz. This is also the same URL found on this link, directly from 10x:. https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.1.0/pbmc3k. The 10x summary [here](https://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_web_summary.html) mentions LYZ as one of the most differentially expressed genes, yet it is missed by the sample analysis as performed in the Scanpy tutorial. As both use the exact same count matrix as a source, there are two possibilities here as far as I can see: either the thresholds and filtering parameters in the tutorial are inaccurate and miss important marker genes, or there is a bug that drops these genes. My question is which of the following is true. From your answer I would assume it's the former, in which case maybe a disclaimer pointing this out would be helpful in the tutorial page? I think, as it stands, the average user would assume important marker genes such as LYZ would not be missed by even a rough analysis of a PBMC data set. For reference, the [tutorial](https://satijalab.org/seurat/v3.2/pbmc3k_tutorial.html) which the Scanpy one is apparently based on finds LYZ as a very important contributor to the first principal component.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:300,reliability,availab,available,300,"Hi @LuckyMD ,. Thanks so much for getting back to me this quickly. I just want to clarify that I am not running this analysis with the built-in 10x data set, I have followed the tutorial as seen on the link in the report, which says: ""The data consist in 3k PBMCs from a Healthy Donor and are freely available from 10x Genomics"". I have downloaded the file from the following URL, as seen in the tutorial:. http://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz. This is also the same URL found on this link, directly from 10x:. https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.1.0/pbmc3k. The 10x summary [here](https://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_web_summary.html) mentions LYZ as one of the most differentially expressed genes, yet it is missed by the sample analysis as performed in the Scanpy tutorial. As both use the exact same count matrix as a source, there are two possibilities here as far as I can see: either the thresholds and filtering parameters in the tutorial are inaccurate and miss important marker genes, or there is a bug that drops these genes. My question is which of the following is true. From your answer I would assume it's the former, in which case maybe a disclaimer pointing this out would be helpful in the tutorial page? I think, as it stands, the average user would assume important marker genes such as LYZ would not be missed by even a rough analysis of a PBMC data set. For reference, the [tutorial](https://satijalab.org/seurat/v3.2/pbmc3k_tutorial.html) which the Scanpy one is apparently based on finds LYZ as a very important contributor to the first principal component.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:300,safety,avail,available,300,"Hi @LuckyMD ,. Thanks so much for getting back to me this quickly. I just want to clarify that I am not running this analysis with the built-in 10x data set, I have followed the tutorial as seen on the link in the report, which says: ""The data consist in 3k PBMCs from a Healthy Donor and are freely available from 10x Genomics"". I have downloaded the file from the following URL, as seen in the tutorial:. http://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz. This is also the same URL found on this link, directly from 10x:. https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.1.0/pbmc3k. The 10x summary [here](https://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_web_summary.html) mentions LYZ as one of the most differentially expressed genes, yet it is missed by the sample analysis as performed in the Scanpy tutorial. As both use the exact same count matrix as a source, there are two possibilities here as far as I can see: either the thresholds and filtering parameters in the tutorial are inaccurate and miss important marker genes, or there is a bug that drops these genes. My question is which of the following is true. From your answer I would assume it's the former, in which case maybe a disclaimer pointing this out would be helpful in the tutorial page? I think, as it stands, the average user would assume important marker genes such as LYZ would not be missed by even a rough analysis of a PBMC data set. For reference, the [tutorial](https://satijalab.org/seurat/v3.2/pbmc3k_tutorial.html) which the Scanpy one is apparently based on finds LYZ as a very important contributor to the first principal component.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:300,security,availab,available,300,"Hi @LuckyMD ,. Thanks so much for getting back to me this quickly. I just want to clarify that I am not running this analysis with the built-in 10x data set, I have followed the tutorial as seen on the link in the report, which says: ""The data consist in 3k PBMCs from a Healthy Donor and are freely available from 10x Genomics"". I have downloaded the file from the following URL, as seen in the tutorial:. http://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz. This is also the same URL found on this link, directly from 10x:. https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.1.0/pbmc3k. The 10x summary [here](https://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_web_summary.html) mentions LYZ as one of the most differentially expressed genes, yet it is missed by the sample analysis as performed in the Scanpy tutorial. As both use the exact same count matrix as a source, there are two possibilities here as far as I can see: either the thresholds and filtering parameters in the tutorial are inaccurate and miss important marker genes, or there is a bug that drops these genes. My question is which of the following is true. From your answer I would assume it's the former, in which case maybe a disclaimer pointing this out would be helpful in the tutorial page? I think, as it stands, the average user would assume important marker genes such as LYZ would not be missed by even a rough analysis of a PBMC data set. For reference, the [tutorial](https://satijalab.org/seurat/v3.2/pbmc3k_tutorial.html) which the Scanpy one is apparently based on finds LYZ as a very important contributor to the first principal component.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:244,usability,consist,consist,244,"Hi @LuckyMD ,. Thanks so much for getting back to me this quickly. I just want to clarify that I am not running this analysis with the built-in 10x data set, I have followed the tutorial as seen on the link in the report, which says: ""The data consist in 3k PBMCs from a Healthy Donor and are freely available from 10x Genomics"". I have downloaded the file from the following URL, as seen in the tutorial:. http://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz. This is also the same URL found on this link, directly from 10x:. https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.1.0/pbmc3k. The 10x summary [here](https://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_web_summary.html) mentions LYZ as one of the most differentially expressed genes, yet it is missed by the sample analysis as performed in the Scanpy tutorial. As both use the exact same count matrix as a source, there are two possibilities here as far as I can see: either the thresholds and filtering parameters in the tutorial are inaccurate and miss important marker genes, or there is a bug that drops these genes. My question is which of the following is true. From your answer I would assume it's the former, in which case maybe a disclaimer pointing this out would be helpful in the tutorial page? I think, as it stands, the average user would assume important marker genes such as LYZ would not be missed by even a rough analysis of a PBMC data set. For reference, the [tutorial](https://satijalab.org/seurat/v3.2/pbmc3k_tutorial.html) which the Scanpy one is apparently based on finds LYZ as a very important contributor to the first principal component.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:578,usability,support,support,578,"Hi @LuckyMD ,. Thanks so much for getting back to me this quickly. I just want to clarify that I am not running this analysis with the built-in 10x data set, I have followed the tutorial as seen on the link in the report, which says: ""The data consist in 3k PBMCs from a Healthy Donor and are freely available from 10x Genomics"". I have downloaded the file from the following URL, as seen in the tutorial:. http://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz. This is also the same URL found on this link, directly from 10x:. https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.1.0/pbmc3k. The 10x summary [here](https://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_web_summary.html) mentions LYZ as one of the most differentially expressed genes, yet it is missed by the sample analysis as performed in the Scanpy tutorial. As both use the exact same count matrix as a source, there are two possibilities here as far as I can see: either the thresholds and filtering parameters in the tutorial are inaccurate and miss important marker genes, or there is a bug that drops these genes. My question is which of the following is true. From your answer I would assume it's the former, in which case maybe a disclaimer pointing this out would be helpful in the tutorial page? I think, as it stands, the average user would assume important marker genes such as LYZ would not be missed by even a rough analysis of a PBMC data set. For reference, the [tutorial](https://satijalab.org/seurat/v3.2/pbmc3k_tutorial.html) which the Scanpy one is apparently based on finds LYZ as a very important contributor to the first principal component.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:865,usability,perform,performed,865,"Hi @LuckyMD ,. Thanks so much for getting back to me this quickly. I just want to clarify that I am not running this analysis with the built-in 10x data set, I have followed the tutorial as seen on the link in the report, which says: ""The data consist in 3k PBMCs from a Healthy Donor and are freely available from 10x Genomics"". I have downloaded the file from the following URL, as seen in the tutorial:. http://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz. This is also the same URL found on this link, directly from 10x:. https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.1.0/pbmc3k. The 10x summary [here](https://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_web_summary.html) mentions LYZ as one of the most differentially expressed genes, yet it is missed by the sample analysis as performed in the Scanpy tutorial. As both use the exact same count matrix as a source, there are two possibilities here as far as I can see: either the thresholds and filtering parameters in the tutorial are inaccurate and miss important marker genes, or there is a bug that drops these genes. My question is which of the following is true. From your answer I would assume it's the former, in which case maybe a disclaimer pointing this out would be helpful in the tutorial page? I think, as it stands, the average user would assume important marker genes such as LYZ would not be missed by even a rough analysis of a PBMC data set. For reference, the [tutorial](https://satijalab.org/seurat/v3.2/pbmc3k_tutorial.html) which the Scanpy one is apparently based on finds LYZ as a very important contributor to the first principal component.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:1315,usability,help,helpful,1315,"Hi @LuckyMD ,. Thanks so much for getting back to me this quickly. I just want to clarify that I am not running this analysis with the built-in 10x data set, I have followed the tutorial as seen on the link in the report, which says: ""The data consist in 3k PBMCs from a Healthy Donor and are freely available from 10x Genomics"". I have downloaded the file from the following URL, as seen in the tutorial:. http://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz. This is also the same URL found on this link, directly from 10x:. https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.1.0/pbmc3k. The 10x summary [here](https://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_web_summary.html) mentions LYZ as one of the most differentially expressed genes, yet it is missed by the sample analysis as performed in the Scanpy tutorial. As both use the exact same count matrix as a source, there are two possibilities here as far as I can see: either the thresholds and filtering parameters in the tutorial are inaccurate and miss important marker genes, or there is a bug that drops these genes. My question is which of the following is true. From your answer I would assume it's the former, in which case maybe a disclaimer pointing this out would be helpful in the tutorial page? I think, as it stands, the average user would assume important marker genes such as LYZ would not be missed by even a rough analysis of a PBMC data set. For reference, the [tutorial](https://satijalab.org/seurat/v3.2/pbmc3k_tutorial.html) which the Scanpy one is apparently based on finds LYZ as a very important contributor to the first principal component.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:1380,usability,user,user,1380,"Hi @LuckyMD ,. Thanks so much for getting back to me this quickly. I just want to clarify that I am not running this analysis with the built-in 10x data set, I have followed the tutorial as seen on the link in the report, which says: ""The data consist in 3k PBMCs from a Healthy Donor and are freely available from 10x Genomics"". I have downloaded the file from the following URL, as seen in the tutorial:. http://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz. This is also the same URL found on this link, directly from 10x:. https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.1.0/pbmc3k. The 10x summary [here](https://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_web_summary.html) mentions LYZ as one of the most differentially expressed genes, yet it is missed by the sample analysis as performed in the Scanpy tutorial. As both use the exact same count matrix as a source, there are two possibilities here as far as I can see: either the thresholds and filtering parameters in the tutorial are inaccurate and miss important marker genes, or there is a bug that drops these genes. My question is which of the following is true. From your answer I would assume it's the former, in which case maybe a disclaimer pointing this out would be helpful in the tutorial page? I think, as it stands, the average user would assume important marker genes such as LYZ would not be missed by even a rough analysis of a PBMC data set. For reference, the [tutorial](https://satijalab.org/seurat/v3.2/pbmc3k_tutorial.html) which the Scanpy one is apparently based on finds LYZ as a very important contributor to the first principal component.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:385,availability,consist,consistent,385,"The tutorial was built quite a while ago to mirror the old Seurat tutorial in that direction. If you remove the line `adata = adata[:, adata.var.highly_variable]` you should have all the genes still there. . @ivirshup Maybe this line should generally be removed from the tutorial, given that we now no longer need to filter genes anyway? Is there a test to ensure tutorial results are consistent?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:317,integrability,filter,filter,317,"The tutorial was built quite a while ago to mirror the old Seurat tutorial in that direction. If you remove the line `adata = adata[:, adata.var.highly_variable]` you should have all the genes still there. . @ivirshup Maybe this line should generally be removed from the tutorial, given that we now no longer need to filter genes anyway? Is there a test to ensure tutorial results are consistent?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:349,safety,test,test,349,"The tutorial was built quite a while ago to mirror the old Seurat tutorial in that direction. If you remove the line `adata = adata[:, adata.var.highly_variable]` you should have all the genes still there. . @ivirshup Maybe this line should generally be removed from the tutorial, given that we now no longer need to filter genes anyway? Is there a test to ensure tutorial results are consistent?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:349,testability,test,test,349,"The tutorial was built quite a while ago to mirror the old Seurat tutorial in that direction. If you remove the line `adata = adata[:, adata.var.highly_variable]` you should have all the genes still there. . @ivirshup Maybe this line should generally be removed from the tutorial, given that we now no longer need to filter genes anyway? Is there a test to ensure tutorial results are consistent?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:385,usability,consist,consistent,385,"The tutorial was built quite a while ago to mirror the old Seurat tutorial in that direction. If you remove the line `adata = adata[:, adata.var.highly_variable]` you should have all the genes still there. . @ivirshup Maybe this line should generally be removed from the tutorial, given that we now no longer need to filter genes anyway? Is there a test to ensure tutorial results are consistent?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:71,integrability,filter,filtering,71,"Thank you for this. I took a dive into the data set to figure out what filtering step is causing this problem, and it seems to be the conditions set for `sc.pp.highly_variable_genes`. To carry on with `LYZ`, it does not show up because its `mean_counts` is too high, above the *maximum* of 3 set in the analysis:. ```. >>> adata.raw.to_adata().var.loc['LYZ']. gene_ids ENSG00000090382. n_cells 1631. mt False. n_cells_by_counts 1631. mean_counts 10.2467. pct_dropout_by_counts 39.5926. total_counts 27666. highly_variable False. means 3.68714. dispersions 5.12101. dispersions_norm 3.65908. Name: LYZ, dtype: object. ```. Is this filtering on `max_mean` as described in the tutorial a reasonable thing to do? That said, even if I were to not filter the matrix to restrict it to genes detected as highly variable, by default `scanpy.tl.pca` would not even use `LYZ` as a potential contributor to a principal component, because it is not highly variable. Again, the equivalent Seurat tutorial does have LYZ in it, but I assume that is because they are now using a different way to classify which genes are variable. Would you say my interpretation is correct? If so, would a better implementation of `sc.pp.highly_variable_genes` solve the problem? Would be happy to contribute if that is something that would be needed and there's no good Python-based alternative around.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:630,integrability,filter,filtering,630,"Thank you for this. I took a dive into the data set to figure out what filtering step is causing this problem, and it seems to be the conditions set for `sc.pp.highly_variable_genes`. To carry on with `LYZ`, it does not show up because its `mean_counts` is too high, above the *maximum* of 3 set in the analysis:. ```. >>> adata.raw.to_adata().var.loc['LYZ']. gene_ids ENSG00000090382. n_cells 1631. mt False. n_cells_by_counts 1631. mean_counts 10.2467. pct_dropout_by_counts 39.5926. total_counts 27666. highly_variable False. means 3.68714. dispersions 5.12101. dispersions_norm 3.65908. Name: LYZ, dtype: object. ```. Is this filtering on `max_mean` as described in the tutorial a reasonable thing to do? That said, even if I were to not filter the matrix to restrict it to genes detected as highly variable, by default `scanpy.tl.pca` would not even use `LYZ` as a potential contributor to a principal component, because it is not highly variable. Again, the equivalent Seurat tutorial does have LYZ in it, but I assume that is because they are now using a different way to classify which genes are variable. Would you say my interpretation is correct? If so, would a better implementation of `sc.pp.highly_variable_genes` solve the problem? Would be happy to contribute if that is something that would be needed and there's no good Python-based alternative around.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:742,integrability,filter,filter,742,"Thank you for this. I took a dive into the data set to figure out what filtering step is causing this problem, and it seems to be the conditions set for `sc.pp.highly_variable_genes`. To carry on with `LYZ`, it does not show up because its `mean_counts` is too high, above the *maximum* of 3 set in the analysis:. ```. >>> adata.raw.to_adata().var.loc['LYZ']. gene_ids ENSG00000090382. n_cells 1631. mt False. n_cells_by_counts 1631. mean_counts 10.2467. pct_dropout_by_counts 39.5926. total_counts 27666. highly_variable False. means 3.68714. dispersions 5.12101. dispersions_norm 3.65908. Name: LYZ, dtype: object. ```. Is this filtering on `max_mean` as described in the tutorial a reasonable thing to do? That said, even if I were to not filter the matrix to restrict it to genes detected as highly variable, by default `scanpy.tl.pca` would not even use `LYZ` as a potential contributor to a principal component, because it is not highly variable. Again, the equivalent Seurat tutorial does have LYZ in it, but I assume that is because they are now using a different way to classify which genes are variable. Would you say my interpretation is correct? If so, would a better implementation of `sc.pp.highly_variable_genes` solve the problem? Would be happy to contribute if that is something that would be needed and there's no good Python-based alternative around.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:907,integrability,compon,component,907,"Thank you for this. I took a dive into the data set to figure out what filtering step is causing this problem, and it seems to be the conditions set for `sc.pp.highly_variable_genes`. To carry on with `LYZ`, it does not show up because its `mean_counts` is too high, above the *maximum* of 3 set in the analysis:. ```. >>> adata.raw.to_adata().var.loc['LYZ']. gene_ids ENSG00000090382. n_cells 1631. mt False. n_cells_by_counts 1631. mean_counts 10.2467. pct_dropout_by_counts 39.5926. total_counts 27666. highly_variable False. means 3.68714. dispersions 5.12101. dispersions_norm 3.65908. Name: LYZ, dtype: object. ```. Is this filtering on `max_mean` as described in the tutorial a reasonable thing to do? That said, even if I were to not filter the matrix to restrict it to genes detected as highly variable, by default `scanpy.tl.pca` would not even use `LYZ` as a potential contributor to a principal component, because it is not highly variable. Again, the equivalent Seurat tutorial does have LYZ in it, but I assume that is because they are now using a different way to classify which genes are variable. Would you say my interpretation is correct? If so, would a better implementation of `sc.pp.highly_variable_genes` solve the problem? Would be happy to contribute if that is something that would be needed and there's no good Python-based alternative around.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:907,interoperability,compon,component,907,"Thank you for this. I took a dive into the data set to figure out what filtering step is causing this problem, and it seems to be the conditions set for `sc.pp.highly_variable_genes`. To carry on with `LYZ`, it does not show up because its `mean_counts` is too high, above the *maximum* of 3 set in the analysis:. ```. >>> adata.raw.to_adata().var.loc['LYZ']. gene_ids ENSG00000090382. n_cells 1631. mt False. n_cells_by_counts 1631. mean_counts 10.2467. pct_dropout_by_counts 39.5926. total_counts 27666. highly_variable False. means 3.68714. dispersions 5.12101. dispersions_norm 3.65908. Name: LYZ, dtype: object. ```. Is this filtering on `max_mean` as described in the tutorial a reasonable thing to do? That said, even if I were to not filter the matrix to restrict it to genes detected as highly variable, by default `scanpy.tl.pca` would not even use `LYZ` as a potential contributor to a principal component, because it is not highly variable. Again, the equivalent Seurat tutorial does have LYZ in it, but I assume that is because they are now using a different way to classify which genes are variable. Would you say my interpretation is correct? If so, would a better implementation of `sc.pp.highly_variable_genes` solve the problem? Would be happy to contribute if that is something that would be needed and there's no good Python-based alternative around.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:803,modifiability,variab,variable,803,"Thank you for this. I took a dive into the data set to figure out what filtering step is causing this problem, and it seems to be the conditions set for `sc.pp.highly_variable_genes`. To carry on with `LYZ`, it does not show up because its `mean_counts` is too high, above the *maximum* of 3 set in the analysis:. ```. >>> adata.raw.to_adata().var.loc['LYZ']. gene_ids ENSG00000090382. n_cells 1631. mt False. n_cells_by_counts 1631. mean_counts 10.2467. pct_dropout_by_counts 39.5926. total_counts 27666. highly_variable False. means 3.68714. dispersions 5.12101. dispersions_norm 3.65908. Name: LYZ, dtype: object. ```. Is this filtering on `max_mean` as described in the tutorial a reasonable thing to do? That said, even if I were to not filter the matrix to restrict it to genes detected as highly variable, by default `scanpy.tl.pca` would not even use `LYZ` as a potential contributor to a principal component, because it is not highly variable. Again, the equivalent Seurat tutorial does have LYZ in it, but I assume that is because they are now using a different way to classify which genes are variable. Would you say my interpretation is correct? If so, would a better implementation of `sc.pp.highly_variable_genes` solve the problem? Would be happy to contribute if that is something that would be needed and there's no good Python-based alternative around.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:907,modifiability,compon,component,907,"Thank you for this. I took a dive into the data set to figure out what filtering step is causing this problem, and it seems to be the conditions set for `sc.pp.highly_variable_genes`. To carry on with `LYZ`, it does not show up because its `mean_counts` is too high, above the *maximum* of 3 set in the analysis:. ```. >>> adata.raw.to_adata().var.loc['LYZ']. gene_ids ENSG00000090382. n_cells 1631. mt False. n_cells_by_counts 1631. mean_counts 10.2467. pct_dropout_by_counts 39.5926. total_counts 27666. highly_variable False. means 3.68714. dispersions 5.12101. dispersions_norm 3.65908. Name: LYZ, dtype: object. ```. Is this filtering on `max_mean` as described in the tutorial a reasonable thing to do? That said, even if I were to not filter the matrix to restrict it to genes detected as highly variable, by default `scanpy.tl.pca` would not even use `LYZ` as a potential contributor to a principal component, because it is not highly variable. Again, the equivalent Seurat tutorial does have LYZ in it, but I assume that is because they are now using a different way to classify which genes are variable. Would you say my interpretation is correct? If so, would a better implementation of `sc.pp.highly_variable_genes` solve the problem? Would be happy to contribute if that is something that would be needed and there's no good Python-based alternative around.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:943,modifiability,variab,variable,943,"Thank you for this. I took a dive into the data set to figure out what filtering step is causing this problem, and it seems to be the conditions set for `sc.pp.highly_variable_genes`. To carry on with `LYZ`, it does not show up because its `mean_counts` is too high, above the *maximum* of 3 set in the analysis:. ```. >>> adata.raw.to_adata().var.loc['LYZ']. gene_ids ENSG00000090382. n_cells 1631. mt False. n_cells_by_counts 1631. mean_counts 10.2467. pct_dropout_by_counts 39.5926. total_counts 27666. highly_variable False. means 3.68714. dispersions 5.12101. dispersions_norm 3.65908. Name: LYZ, dtype: object. ```. Is this filtering on `max_mean` as described in the tutorial a reasonable thing to do? That said, even if I were to not filter the matrix to restrict it to genes detected as highly variable, by default `scanpy.tl.pca` would not even use `LYZ` as a potential contributor to a principal component, because it is not highly variable. Again, the equivalent Seurat tutorial does have LYZ in it, but I assume that is because they are now using a different way to classify which genes are variable. Would you say my interpretation is correct? If so, would a better implementation of `sc.pp.highly_variable_genes` solve the problem? Would be happy to contribute if that is something that would be needed and there's no good Python-based alternative around.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:1104,modifiability,variab,variable,1104,"Thank you for this. I took a dive into the data set to figure out what filtering step is causing this problem, and it seems to be the conditions set for `sc.pp.highly_variable_genes`. To carry on with `LYZ`, it does not show up because its `mean_counts` is too high, above the *maximum* of 3 set in the analysis:. ```. >>> adata.raw.to_adata().var.loc['LYZ']. gene_ids ENSG00000090382. n_cells 1631. mt False. n_cells_by_counts 1631. mean_counts 10.2467. pct_dropout_by_counts 39.5926. total_counts 27666. highly_variable False. means 3.68714. dispersions 5.12101. dispersions_norm 3.65908. Name: LYZ, dtype: object. ```. Is this filtering on `max_mean` as described in the tutorial a reasonable thing to do? That said, even if I were to not filter the matrix to restrict it to genes detected as highly variable, by default `scanpy.tl.pca` would not even use `LYZ` as a potential contributor to a principal component, because it is not highly variable. Again, the equivalent Seurat tutorial does have LYZ in it, but I assume that is because they are now using a different way to classify which genes are variable. Would you say my interpretation is correct? If so, would a better implementation of `sc.pp.highly_variable_genes` solve the problem? Would be happy to contribute if that is something that would be needed and there's no good Python-based alternative around.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:211,reliability,doe,does,211,"Thank you for this. I took a dive into the data set to figure out what filtering step is causing this problem, and it seems to be the conditions set for `sc.pp.highly_variable_genes`. To carry on with `LYZ`, it does not show up because its `mean_counts` is too high, above the *maximum* of 3 set in the analysis:. ```. >>> adata.raw.to_adata().var.loc['LYZ']. gene_ids ENSG00000090382. n_cells 1631. mt False. n_cells_by_counts 1631. mean_counts 10.2467. pct_dropout_by_counts 39.5926. total_counts 27666. highly_variable False. means 3.68714. dispersions 5.12101. dispersions_norm 3.65908. Name: LYZ, dtype: object. ```. Is this filtering on `max_mean` as described in the tutorial a reasonable thing to do? That said, even if I were to not filter the matrix to restrict it to genes detected as highly variable, by default `scanpy.tl.pca` would not even use `LYZ` as a potential contributor to a principal component, because it is not highly variable. Again, the equivalent Seurat tutorial does have LYZ in it, but I assume that is because they are now using a different way to classify which genes are variable. Would you say my interpretation is correct? If so, would a better implementation of `sc.pp.highly_variable_genes` solve the problem? Would be happy to contribute if that is something that would be needed and there's no good Python-based alternative around.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:991,reliability,doe,does,991,"Thank you for this. I took a dive into the data set to figure out what filtering step is causing this problem, and it seems to be the conditions set for `sc.pp.highly_variable_genes`. To carry on with `LYZ`, it does not show up because its `mean_counts` is too high, above the *maximum* of 3 set in the analysis:. ```. >>> adata.raw.to_adata().var.loc['LYZ']. gene_ids ENSG00000090382. n_cells 1631. mt False. n_cells_by_counts 1631. mean_counts 10.2467. pct_dropout_by_counts 39.5926. total_counts 27666. highly_variable False. means 3.68714. dispersions 5.12101. dispersions_norm 3.65908. Name: LYZ, dtype: object. ```. Is this filtering on `max_mean` as described in the tutorial a reasonable thing to do? That said, even if I were to not filter the matrix to restrict it to genes detected as highly variable, by default `scanpy.tl.pca` would not even use `LYZ` as a potential contributor to a principal component, because it is not highly variable. Again, the equivalent Seurat tutorial does have LYZ in it, but I assume that is because they are now using a different way to classify which genes are variable. Would you say my interpretation is correct? If so, would a better implementation of `sc.pp.highly_variable_genes` solve the problem? Would be happy to contribute if that is something that would be needed and there's no good Python-based alternative around.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:784,safety,detect,detected,784,"Thank you for this. I took a dive into the data set to figure out what filtering step is causing this problem, and it seems to be the conditions set for `sc.pp.highly_variable_genes`. To carry on with `LYZ`, it does not show up because its `mean_counts` is too high, above the *maximum* of 3 set in the analysis:. ```. >>> adata.raw.to_adata().var.loc['LYZ']. gene_ids ENSG00000090382. n_cells 1631. mt False. n_cells_by_counts 1631. mean_counts 10.2467. pct_dropout_by_counts 39.5926. total_counts 27666. highly_variable False. means 3.68714. dispersions 5.12101. dispersions_norm 3.65908. Name: LYZ, dtype: object. ```. Is this filtering on `max_mean` as described in the tutorial a reasonable thing to do? That said, even if I were to not filter the matrix to restrict it to genes detected as highly variable, by default `scanpy.tl.pca` would not even use `LYZ` as a potential contributor to a principal component, because it is not highly variable. Again, the equivalent Seurat tutorial does have LYZ in it, but I assume that is because they are now using a different way to classify which genes are variable. Would you say my interpretation is correct? If so, would a better implementation of `sc.pp.highly_variable_genes` solve the problem? Would be happy to contribute if that is something that would be needed and there's no good Python-based alternative around.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:784,security,detect,detected,784,"Thank you for this. I took a dive into the data set to figure out what filtering step is causing this problem, and it seems to be the conditions set for `sc.pp.highly_variable_genes`. To carry on with `LYZ`, it does not show up because its `mean_counts` is too high, above the *maximum* of 3 set in the analysis:. ```. >>> adata.raw.to_adata().var.loc['LYZ']. gene_ids ENSG00000090382. n_cells 1631. mt False. n_cells_by_counts 1631. mean_counts 10.2467. pct_dropout_by_counts 39.5926. total_counts 27666. highly_variable False. means 3.68714. dispersions 5.12101. dispersions_norm 3.65908. Name: LYZ, dtype: object. ```. Is this filtering on `max_mean` as described in the tutorial a reasonable thing to do? That said, even if I were to not filter the matrix to restrict it to genes detected as highly variable, by default `scanpy.tl.pca` would not even use `LYZ` as a potential contributor to a principal component, because it is not highly variable. Again, the equivalent Seurat tutorial does have LYZ in it, but I assume that is because they are now using a different way to classify which genes are variable. Would you say my interpretation is correct? If so, would a better implementation of `sc.pp.highly_variable_genes` solve the problem? Would be happy to contribute if that is something that would be needed and there's no good Python-based alternative around.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:397,deployability,updat,updated,397,"Thanks for diving in deeper. I would agree with you that settig the `max_mean` is not a great idea. I have never done this in any of my analyses. As mentioned, this tutorial was a copy of an early Seurat tutorial and does not represent a recommendation on what is the best way to perform a single-cell analysis. Instead it is designed to showcase the tools that exist in Scanpy. Indeed Seurat has updated its tutorials since then, but we have not. This should probably be considered, but at the moment it would be at the end of a long to-do list. . Instead, our recommendation for how a single-cell analysis workflow should be structured would be the notebook in the best-practices tutorial [here](https://github.com/theislab/single-cell-tutorial). This should probably be linked on the scanpy front page, although it doesn't only include Scanpy analysis tools.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:280,performance,perform,perform,280,"Thanks for diving in deeper. I would agree with you that settig the `max_mean` is not a great idea. I have never done this in any of my analyses. As mentioned, this tutorial was a copy of an early Seurat tutorial and does not represent a recommendation on what is the best way to perform a single-cell analysis. Instead it is designed to showcase the tools that exist in Scanpy. Indeed Seurat has updated its tutorials since then, but we have not. This should probably be considered, but at the moment it would be at the end of a long to-do list. . Instead, our recommendation for how a single-cell analysis workflow should be structured would be the notebook in the best-practices tutorial [here](https://github.com/theislab/single-cell-tutorial). This should probably be linked on the scanpy front page, although it doesn't only include Scanpy analysis tools.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:217,reliability,doe,does,217,"Thanks for diving in deeper. I would agree with you that settig the `max_mean` is not a great idea. I have never done this in any of my analyses. As mentioned, this tutorial was a copy of an early Seurat tutorial and does not represent a recommendation on what is the best way to perform a single-cell analysis. Instead it is designed to showcase the tools that exist in Scanpy. Indeed Seurat has updated its tutorials since then, but we have not. This should probably be considered, but at the moment it would be at the end of a long to-do list. . Instead, our recommendation for how a single-cell analysis workflow should be structured would be the notebook in the best-practices tutorial [here](https://github.com/theislab/single-cell-tutorial). This should probably be linked on the scanpy front page, although it doesn't only include Scanpy analysis tools.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:672,reliability,pra,practices,672,"Thanks for diving in deeper. I would agree with you that settig the `max_mean` is not a great idea. I have never done this in any of my analyses. As mentioned, this tutorial was a copy of an early Seurat tutorial and does not represent a recommendation on what is the best way to perform a single-cell analysis. Instead it is designed to showcase the tools that exist in Scanpy. Indeed Seurat has updated its tutorials since then, but we have not. This should probably be considered, but at the moment it would be at the end of a long to-do list. . Instead, our recommendation for how a single-cell analysis workflow should be structured would be the notebook in the best-practices tutorial [here](https://github.com/theislab/single-cell-tutorial). This should probably be linked on the scanpy front page, although it doesn't only include Scanpy analysis tools.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:818,reliability,doe,doesn,818,"Thanks for diving in deeper. I would agree with you that settig the `max_mean` is not a great idea. I have never done this in any of my analyses. As mentioned, this tutorial was a copy of an early Seurat tutorial and does not represent a recommendation on what is the best way to perform a single-cell analysis. Instead it is designed to showcase the tools that exist in Scanpy. Indeed Seurat has updated its tutorials since then, but we have not. This should probably be considered, but at the moment it would be at the end of a long to-do list. . Instead, our recommendation for how a single-cell analysis workflow should be structured would be the notebook in the best-practices tutorial [here](https://github.com/theislab/single-cell-tutorial). This should probably be linked on the scanpy front page, although it doesn't only include Scanpy analysis tools.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:397,safety,updat,updated,397,"Thanks for diving in deeper. I would agree with you that settig the `max_mean` is not a great idea. I have never done this in any of my analyses. As mentioned, this tutorial was a copy of an early Seurat tutorial and does not represent a recommendation on what is the best way to perform a single-cell analysis. Instead it is designed to showcase the tools that exist in Scanpy. Indeed Seurat has updated its tutorials since then, but we have not. This should probably be considered, but at the moment it would be at the end of a long to-do list. . Instead, our recommendation for how a single-cell analysis workflow should be structured would be the notebook in the best-practices tutorial [here](https://github.com/theislab/single-cell-tutorial). This should probably be linked on the scanpy front page, although it doesn't only include Scanpy analysis tools.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:397,security,updat,updated,397,"Thanks for diving in deeper. I would agree with you that settig the `max_mean` is not a great idea. I have never done this in any of my analyses. As mentioned, this tutorial was a copy of an early Seurat tutorial and does not represent a recommendation on what is the best way to perform a single-cell analysis. Instead it is designed to showcase the tools that exist in Scanpy. Indeed Seurat has updated its tutorials since then, but we have not. This should probably be considered, but at the moment it would be at the end of a long to-do list. . Instead, our recommendation for how a single-cell analysis workflow should be structured would be the notebook in the best-practices tutorial [here](https://github.com/theislab/single-cell-tutorial). This should probably be linked on the scanpy front page, although it doesn't only include Scanpy analysis tools.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:280,usability,perform,perform,280,"Thanks for diving in deeper. I would agree with you that settig the `max_mean` is not a great idea. I have never done this in any of my analyses. As mentioned, this tutorial was a copy of an early Seurat tutorial and does not represent a recommendation on what is the best way to perform a single-cell analysis. Instead it is designed to showcase the tools that exist in Scanpy. Indeed Seurat has updated its tutorials since then, but we have not. This should probably be considered, but at the moment it would be at the end of a long to-do list. . Instead, our recommendation for how a single-cell analysis workflow should be structured would be the notebook in the best-practices tutorial [here](https://github.com/theislab/single-cell-tutorial). This should probably be linked on the scanpy front page, although it doesn't only include Scanpy analysis tools.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:351,usability,tool,tools,351,"Thanks for diving in deeper. I would agree with you that settig the `max_mean` is not a great idea. I have never done this in any of my analyses. As mentioned, this tutorial was a copy of an early Seurat tutorial and does not represent a recommendation on what is the best way to perform a single-cell analysis. Instead it is designed to showcase the tools that exist in Scanpy. Indeed Seurat has updated its tutorials since then, but we have not. This should probably be considered, but at the moment it would be at the end of a long to-do list. . Instead, our recommendation for how a single-cell analysis workflow should be structured would be the notebook in the best-practices tutorial [here](https://github.com/theislab/single-cell-tutorial). This should probably be linked on the scanpy front page, although it doesn't only include Scanpy analysis tools.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:608,usability,workflow,workflow,608,"Thanks for diving in deeper. I would agree with you that settig the `max_mean` is not a great idea. I have never done this in any of my analyses. As mentioned, this tutorial was a copy of an early Seurat tutorial and does not represent a recommendation on what is the best way to perform a single-cell analysis. Instead it is designed to showcase the tools that exist in Scanpy. Indeed Seurat has updated its tutorials since then, but we have not. This should probably be considered, but at the moment it would be at the end of a long to-do list. . Instead, our recommendation for how a single-cell analysis workflow should be structured would be the notebook in the best-practices tutorial [here](https://github.com/theislab/single-cell-tutorial). This should probably be linked on the scanpy front page, although it doesn't only include Scanpy analysis tools.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:855,usability,tool,tools,855,"Thanks for diving in deeper. I would agree with you that settig the `max_mean` is not a great idea. I have never done this in any of my analyses. As mentioned, this tutorial was a copy of an early Seurat tutorial and does not represent a recommendation on what is the best way to perform a single-cell analysis. Instead it is designed to showcase the tools that exist in Scanpy. Indeed Seurat has updated its tutorials since then, but we have not. This should probably be considered, but at the moment it would be at the end of a long to-do list. . Instead, our recommendation for how a single-cell analysis workflow should be structured would be the notebook in the best-practices tutorial [here](https://github.com/theislab/single-cell-tutorial). This should probably be linked on the scanpy front page, although it doesn't only include Scanpy analysis tools.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:392,deployability,updat,updated,392,"And in terms of the `sc.pp.highly_variable_genes` function. We typically don't use the `max_mean` and `disperson` based parametrization anymore, but instead just select `n_top_genes`, which avoids this problem altogether. That being said, there is a PR with the VST-based highly-variable genes implementation from Seurat that will be added into scanpy soon. If you would like to reproduce an updated pbmc3k tutorial from Seurat using scanpy functions, that would be very welcome of course!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:120,modifiability,paramet,parametrization,120,"And in terms of the `sc.pp.highly_variable_genes` function. We typically don't use the `max_mean` and `disperson` based parametrization anymore, but instead just select `n_top_genes`, which avoids this problem altogether. That being said, there is a PR with the VST-based highly-variable genes implementation from Seurat that will be added into scanpy soon. If you would like to reproduce an updated pbmc3k tutorial from Seurat using scanpy functions, that would be very welcome of course!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:279,modifiability,variab,variable,279,"And in terms of the `sc.pp.highly_variable_genes` function. We typically don't use the `max_mean` and `disperson` based parametrization anymore, but instead just select `n_top_genes`, which avoids this problem altogether. That being said, there is a PR with the VST-based highly-variable genes implementation from Seurat that will be added into scanpy soon. If you would like to reproduce an updated pbmc3k tutorial from Seurat using scanpy functions, that would be very welcome of course!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:190,safety,avoid,avoids,190,"And in terms of the `sc.pp.highly_variable_genes` function. We typically don't use the `max_mean` and `disperson` based parametrization anymore, but instead just select `n_top_genes`, which avoids this problem altogether. That being said, there is a PR with the VST-based highly-variable genes implementation from Seurat that will be added into scanpy soon. If you would like to reproduce an updated pbmc3k tutorial from Seurat using scanpy functions, that would be very welcome of course!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:392,safety,updat,updated,392,"And in terms of the `sc.pp.highly_variable_genes` function. We typically don't use the `max_mean` and `disperson` based parametrization anymore, but instead just select `n_top_genes`, which avoids this problem altogether. That being said, there is a PR with the VST-based highly-variable genes implementation from Seurat that will be added into scanpy soon. If you would like to reproduce an updated pbmc3k tutorial from Seurat using scanpy functions, that would be very welcome of course!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:392,security,updat,updated,392,"And in terms of the `sc.pp.highly_variable_genes` function. We typically don't use the `max_mean` and `disperson` based parametrization anymore, but instead just select `n_top_genes`, which avoids this problem altogether. That being said, there is a PR with the VST-based highly-variable genes implementation from Seurat that will be added into scanpy soon. If you would like to reproduce an updated pbmc3k tutorial from Seurat using scanpy functions, that would be very welcome of course!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1340:289,security,access,access,289,"It's definitely been discussed and is something I would like to do, but it has not been implemented. I think the main blocker here is that it would be a lot of effort to go through every plotting function and make it work with that structure. A good step towards this would be normalizing access to colors through a single function. In general, I think the colors could be stored as something like:. ```. .uns[""colors""][dim][key] = {cat1: color1, ...}. ``` . though I'm open to other solutions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1340
https://github.com/scverse/scanpy/issues/1340:159,deployability,observ,observations,159,"I think we should allow for categorical colors along either axis, and right now it's becomes ambiguous. A good example of an annotation that can apply to both observations and variables is `species`. I'd like to shift to a nested model to limit the amount of reserved keys in `.uns`. It reduces that chance of unintentional naming collisions. As for the amount of things that would need to change, a lot has to change anyways. Hardly any code that works with the current setup will work with mappings (`len` is all I can think of). If we're already making a breaking change, might as well take advantage and future proof it a bit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1340
https://github.com/scverse/scanpy/issues/1340:230,energy efficiency,model,model,230,"I think we should allow for categorical colors along either axis, and right now it's becomes ambiguous. A good example of an annotation that can apply to both observations and variables is `species`. I'd like to shift to a nested model to limit the amount of reserved keys in `.uns`. It reduces that chance of unintentional naming collisions. As for the amount of things that would need to change, a lot has to change anyways. Hardly any code that works with the current setup will work with mappings (`len` is all I can think of). If we're already making a breaking change, might as well take advantage and future proof it a bit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1340
https://github.com/scverse/scanpy/issues/1340:287,energy efficiency,reduc,reduces,287,"I think we should allow for categorical colors along either axis, and right now it's becomes ambiguous. A good example of an annotation that can apply to both observations and variables is `species`. I'd like to shift to a nested model to limit the amount of reserved keys in `.uns`. It reduces that chance of unintentional naming collisions. As for the amount of things that would need to change, a lot has to change anyways. Hardly any code that works with the current setup will work with mappings (`len` is all I can think of). If we're already making a breaking change, might as well take advantage and future proof it a bit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1340
https://github.com/scverse/scanpy/issues/1340:463,energy efficiency,current,current,463,"I think we should allow for categorical colors along either axis, and right now it's becomes ambiguous. A good example of an annotation that can apply to both observations and variables is `species`. I'd like to shift to a nested model to limit the amount of reserved keys in `.uns`. It reduces that chance of unintentional naming collisions. As for the amount of things that would need to change, a lot has to change anyways. Hardly any code that works with the current setup will work with mappings (`len` is all I can think of). If we're already making a breaking change, might as well take advantage and future proof it a bit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1340
https://github.com/scverse/scanpy/issues/1340:176,modifiability,variab,variables,176,"I think we should allow for categorical colors along either axis, and right now it's becomes ambiguous. A good example of an annotation that can apply to both observations and variables is `species`. I'd like to shift to a nested model to limit the amount of reserved keys in `.uns`. It reduces that chance of unintentional naming collisions. As for the amount of things that would need to change, a lot has to change anyways. Hardly any code that works with the current setup will work with mappings (`len` is all I can think of). If we're already making a breaking change, might as well take advantage and future proof it a bit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1340
https://github.com/scverse/scanpy/issues/1340:230,security,model,model,230,"I think we should allow for categorical colors along either axis, and right now it's becomes ambiguous. A good example of an annotation that can apply to both observations and variables is `species`. I'd like to shift to a nested model to limit the amount of reserved keys in `.uns`. It reduces that chance of unintentional naming collisions. As for the amount of things that would need to change, a lot has to change anyways. Hardly any code that works with the current setup will work with mappings (`len` is all I can think of). If we're already making a breaking change, might as well take advantage and future proof it a bit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1340
https://github.com/scverse/scanpy/issues/1340:159,testability,observ,observations,159,"I think we should allow for categorical colors along either axis, and right now it's becomes ambiguous. A good example of an annotation that can apply to both observations and variables is `species`. I'd like to shift to a nested model to limit the amount of reserved keys in `.uns`. It reduces that chance of unintentional naming collisions. As for the amount of things that would need to change, a lot has to change anyways. Hardly any code that works with the current setup will work with mappings (`len` is all I can think of). If we're already making a breaking change, might as well take advantage and future proof it a bit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1340
https://github.com/scverse/scanpy/issues/1340:13,testability,plan,plan,13,"Okay, so the plan would be a breaking change. So scanpy 1.7 then?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1340
https://github.com/scverse/scanpy/issues/1340:0,deployability,Depend,Depends,0,"Depends on how we're feeling about semantic versioning. 2.0 for a complete switch, but we could internally switch over with a compatibility layer and deprecation warnings anytime before then.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1340
https://github.com/scverse/scanpy/issues/1340:44,deployability,version,versioning,44,"Depends on how we're feeling about semantic versioning. 2.0 for a complete switch, but we could internally switch over with a compatibility layer and deprecation warnings anytime before then.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1340
https://github.com/scverse/scanpy/issues/1340:0,integrability,Depend,Depends,0,"Depends on how we're feeling about semantic versioning. 2.0 for a complete switch, but we could internally switch over with a compatibility layer and deprecation warnings anytime before then.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1340
https://github.com/scverse/scanpy/issues/1340:44,integrability,version,versioning,44,"Depends on how we're feeling about semantic versioning. 2.0 for a complete switch, but we could internally switch over with a compatibility layer and deprecation warnings anytime before then.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1340
https://github.com/scverse/scanpy/issues/1340:35,interoperability,semant,semantic,35,"Depends on how we're feeling about semantic versioning. 2.0 for a complete switch, but we could internally switch over with a compatibility layer and deprecation warnings anytime before then.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1340
https://github.com/scverse/scanpy/issues/1340:126,interoperability,compatib,compatibility,126,"Depends on how we're feeling about semantic versioning. 2.0 for a complete switch, but we could internally switch over with a compatibility layer and deprecation warnings anytime before then.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1340
https://github.com/scverse/scanpy/issues/1340:0,modifiability,Depend,Depends,0,"Depends on how we're feeling about semantic versioning. 2.0 for a complete switch, but we could internally switch over with a compatibility layer and deprecation warnings anytime before then.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1340
https://github.com/scverse/scanpy/issues/1340:44,modifiability,version,versioning,44,"Depends on how we're feeling about semantic versioning. 2.0 for a complete switch, but we could internally switch over with a compatibility layer and deprecation warnings anytime before then.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1340
https://github.com/scverse/scanpy/issues/1340:140,modifiability,layer,layer,140,"Depends on how we're feeling about semantic versioning. 2.0 for a complete switch, but we could internally switch over with a compatibility layer and deprecation warnings anytime before then.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1340
https://github.com/scverse/scanpy/issues/1340:0,safety,Depend,Depends,0,"Depends on how we're feeling about semantic versioning. 2.0 for a complete switch, but we could internally switch over with a compatibility layer and deprecation warnings anytime before then.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1340
https://github.com/scverse/scanpy/issues/1340:66,safety,compl,complete,66,"Depends on how we're feeling about semantic versioning. 2.0 for a complete switch, but we could internally switch over with a compatibility layer and deprecation warnings anytime before then.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1340
https://github.com/scverse/scanpy/issues/1340:66,security,compl,complete,66,"Depends on how we're feeling about semantic versioning. 2.0 for a complete switch, but we could internally switch over with a compatibility layer and deprecation warnings anytime before then.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1340
https://github.com/scverse/scanpy/issues/1340:0,testability,Depend,Depends,0,"Depends on how we're feeling about semantic versioning. 2.0 for a complete switch, but we could internally switch over with a compatibility layer and deprecation warnings anytime before then.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1340
https://github.com/scverse/scanpy/issues/1340:35,modifiability,layer,layer,35,I like the idea of a compatability layer. @Hrovatin is this something you would like to contribute to as well?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1340
https://github.com/scverse/scanpy/issues/1340:180,security,modif,modified,180,I agree with @ivirshup that the best would be to have a single function that returns the colors. This also facilitates documentation. The actual implementation afterwards could be modified without much effort.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1340
https://github.com/scverse/scanpy/issues/1340:119,usability,document,documentation,119,I agree with @ivirshup that the best would be to have a single function that returns the colors. This also facilitates documentation. The actual implementation afterwards could be modified without much effort.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1340
https://github.com/scverse/scanpy/issues/1341:98,deployability,version,version,98,"@taopeng1100: This is a numba bug. Please report this there, but only if you use the newest numba version (otherwise install it and try to reproduce this with the newest version). Give them this link so they see the code that triggers their bug:. https://github.com/theislab/scanpy/blob/2f160ea403d124d237fc2138c0aa0d175fbad22a/scanpy/preprocessing/_qc.py#L402-L428. @team: We should include numba in the package versions list.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:117,deployability,instal,install,117,"@taopeng1100: This is a numba bug. Please report this there, but only if you use the newest numba version (otherwise install it and try to reproduce this with the newest version). Give them this link so they see the code that triggers their bug:. https://github.com/theislab/scanpy/blob/2f160ea403d124d237fc2138c0aa0d175fbad22a/scanpy/preprocessing/_qc.py#L402-L428. @team: We should include numba in the package versions list.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:170,deployability,version,version,170,"@taopeng1100: This is a numba bug. Please report this there, but only if you use the newest numba version (otherwise install it and try to reproduce this with the newest version). Give them this link so they see the code that triggers their bug:. https://github.com/theislab/scanpy/blob/2f160ea403d124d237fc2138c0aa0d175fbad22a/scanpy/preprocessing/_qc.py#L402-L428. @team: We should include numba in the package versions list.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:413,deployability,version,versions,413,"@taopeng1100: This is a numba bug. Please report this there, but only if you use the newest numba version (otherwise install it and try to reproduce this with the newest version). Give them this link so they see the code that triggers their bug:. https://github.com/theislab/scanpy/blob/2f160ea403d124d237fc2138c0aa0d175fbad22a/scanpy/preprocessing/_qc.py#L402-L428. @team: We should include numba in the package versions list.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:98,integrability,version,version,98,"@taopeng1100: This is a numba bug. Please report this there, but only if you use the newest numba version (otherwise install it and try to reproduce this with the newest version). Give them this link so they see the code that triggers their bug:. https://github.com/theislab/scanpy/blob/2f160ea403d124d237fc2138c0aa0d175fbad22a/scanpy/preprocessing/_qc.py#L402-L428. @team: We should include numba in the package versions list.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:170,integrability,version,version,170,"@taopeng1100: This is a numba bug. Please report this there, but only if you use the newest numba version (otherwise install it and try to reproduce this with the newest version). Give them this link so they see the code that triggers their bug:. https://github.com/theislab/scanpy/blob/2f160ea403d124d237fc2138c0aa0d175fbad22a/scanpy/preprocessing/_qc.py#L402-L428. @team: We should include numba in the package versions list.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:413,integrability,version,versions,413,"@taopeng1100: This is a numba bug. Please report this there, but only if you use the newest numba version (otherwise install it and try to reproduce this with the newest version). Give them this link so they see the code that triggers their bug:. https://github.com/theislab/scanpy/blob/2f160ea403d124d237fc2138c0aa0d175fbad22a/scanpy/preprocessing/_qc.py#L402-L428. @team: We should include numba in the package versions list.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:98,modifiability,version,version,98,"@taopeng1100: This is a numba bug. Please report this there, but only if you use the newest numba version (otherwise install it and try to reproduce this with the newest version). Give them this link so they see the code that triggers their bug:. https://github.com/theislab/scanpy/blob/2f160ea403d124d237fc2138c0aa0d175fbad22a/scanpy/preprocessing/_qc.py#L402-L428. @team: We should include numba in the package versions list.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:170,modifiability,version,version,170,"@taopeng1100: This is a numba bug. Please report this there, but only if you use the newest numba version (otherwise install it and try to reproduce this with the newest version). Give them this link so they see the code that triggers their bug:. https://github.com/theislab/scanpy/blob/2f160ea403d124d237fc2138c0aa0d175fbad22a/scanpy/preprocessing/_qc.py#L402-L428. @team: We should include numba in the package versions list.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:405,modifiability,pac,package,405,"@taopeng1100: This is a numba bug. Please report this there, but only if you use the newest numba version (otherwise install it and try to reproduce this with the newest version). Give them this link so they see the code that triggers their bug:. https://github.com/theislab/scanpy/blob/2f160ea403d124d237fc2138c0aa0d175fbad22a/scanpy/preprocessing/_qc.py#L402-L428. @team: We should include numba in the package versions list.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:413,modifiability,version,versions,413,"@taopeng1100: This is a numba bug. Please report this there, but only if you use the newest numba version (otherwise install it and try to reproduce this with the newest version). Give them this link so they see the code that triggers their bug:. https://github.com/theislab/scanpy/blob/2f160ea403d124d237fc2138c0aa0d175fbad22a/scanpy/preprocessing/_qc.py#L402-L428. @team: We should include numba in the package versions list.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:368,security,team,team,368,"@taopeng1100: This is a numba bug. Please report this there, but only if you use the newest numba version (otherwise install it and try to reproduce this with the newest version). Give them this link so they see the code that triggers their bug:. https://github.com/theislab/scanpy/blob/2f160ea403d124d237fc2138c0aa0d175fbad22a/scanpy/preprocessing/_qc.py#L402-L428. @team: We should include numba in the package versions list.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:24,deployability,version,version,24,"Can you let me know the version of numba that worked for you? Get Outlook for Android<https://aka.ms/ghei36>. ________________________________. From: Philipp A. <notifications@github.com>. Sent: Thursday, July 30, 2020 2:06:10 AM. To: theislab/scanpy <scanpy@noreply.github.com>. Cc: Peng, Tao <tpeng@fredhutch.org>; Mention <mention@noreply.github.com>. Subject: Re: [theislab/scanpy] scanpy sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True) (#1341). @taopeng1100<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_taopeng1100&d=DwMCaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=j6EgtEBZ-6pbDONgnwVzuTHJ6L-gWcikckOhZCwVjPc&m=j6WdQxFMfGL2BOrFUsLxuCIlMEWSPOGMoQ3sfPhU4hw&s=mZvFxBCIH_-96BcNkwcrYuLqIFdGUQVv9-NgmpF6Kyc&e=>: This is a numba bug. Please report this there, but only if you use the newest numba version. Give them this link so they see the code that triggers their bug:. https://github.com/theislab/scanpy/blob/2f160ea403d124d237fc2138c0aa0d175fbad22a/scanpy/preprocessing/_qc.py#L402-L428<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_theislab_scanpy_blob_2f160ea403d124d237fc2138c0aa0d175fbad22a_scanpy_preprocessing_-5Fqc.py-23L402-2DL428&d=DwMCaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=j6EgtEBZ-6pbDONgnwVzuTHJ6L-gWcikckOhZCwVjPc&m=j6WdQxFMfGL2BOrFUsLxuCIlMEWSPOGMoQ3sfPhU4hw&s=6bLtPWJSoSBSNQcRvwP4Pp-mHjA7d51Ees_qcvGEJYk&e=>. @team: We should include numba in the package versions list. . You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_theislab_scanpy_issues_1341-23issuecomment-2D666246043&d=DwMCaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=j6EgtEBZ-6pbDONgnwVzuTHJ6L-gWcikckOhZCwVjPc&m=j6WdQxFMfGL2BOrFUsLxuCIlMEWSPOGMoQ3sfPhU4hw&s=AQB0zBmdSewipAgOqteV0t7F27jeGZaU-I4LngYZYus&e=>, or unsubscribe<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_notifications_unsubscribe-2Dauth_ALCZ3CPX4MWCNAHOFNSYRC3R6EZYFANCNFSM4PMLDJKQ&d=DwMCaQ&c=eRAMFD45gAfqt84",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:816,deployability,version,version,816,"Can you let me know the version of numba that worked for you? Get Outlook for Android<https://aka.ms/ghei36>. ________________________________. From: Philipp A. <notifications@github.com>. Sent: Thursday, July 30, 2020 2:06:10 AM. To: theislab/scanpy <scanpy@noreply.github.com>. Cc: Peng, Tao <tpeng@fredhutch.org>; Mention <mention@noreply.github.com>. Subject: Re: [theislab/scanpy] scanpy sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True) (#1341). @taopeng1100<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_taopeng1100&d=DwMCaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=j6EgtEBZ-6pbDONgnwVzuTHJ6L-gWcikckOhZCwVjPc&m=j6WdQxFMfGL2BOrFUsLxuCIlMEWSPOGMoQ3sfPhU4hw&s=mZvFxBCIH_-96BcNkwcrYuLqIFdGUQVv9-NgmpF6Kyc&e=>: This is a numba bug. Please report this there, but only if you use the newest numba version. Give them this link so they see the code that triggers their bug:. https://github.com/theislab/scanpy/blob/2f160ea403d124d237fc2138c0aa0d175fbad22a/scanpy/preprocessing/_qc.py#L402-L428<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_theislab_scanpy_blob_2f160ea403d124d237fc2138c0aa0d175fbad22a_scanpy_preprocessing_-5Fqc.py-23L402-2DL428&d=DwMCaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=j6EgtEBZ-6pbDONgnwVzuTHJ6L-gWcikckOhZCwVjPc&m=j6WdQxFMfGL2BOrFUsLxuCIlMEWSPOGMoQ3sfPhU4hw&s=6bLtPWJSoSBSNQcRvwP4Pp-mHjA7d51Ees_qcvGEJYk&e=>. @team: We should include numba in the package versions list. . You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_theislab_scanpy_issues_1341-23issuecomment-2D666246043&d=DwMCaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=j6EgtEBZ-6pbDONgnwVzuTHJ6L-gWcikckOhZCwVjPc&m=j6WdQxFMfGL2BOrFUsLxuCIlMEWSPOGMoQ3sfPhU4hw&s=AQB0zBmdSewipAgOqteV0t7F27jeGZaU-I4LngYZYus&e=>, or unsubscribe<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_notifications_unsubscribe-2Dauth_ALCZ3CPX4MWCNAHOFNSYRC3R6EZYFANCNFSM4PMLDJKQ&d=DwMCaQ&c=eRAMFD45gAfqt84",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:1404,deployability,version,versions,1404,"Philipp A. <notifications@github.com>. Sent: Thursday, July 30, 2020 2:06:10 AM. To: theislab/scanpy <scanpy@noreply.github.com>. Cc: Peng, Tao <tpeng@fredhutch.org>; Mention <mention@noreply.github.com>. Subject: Re: [theislab/scanpy] scanpy sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True) (#1341). @taopeng1100<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_taopeng1100&d=DwMCaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=j6EgtEBZ-6pbDONgnwVzuTHJ6L-gWcikckOhZCwVjPc&m=j6WdQxFMfGL2BOrFUsLxuCIlMEWSPOGMoQ3sfPhU4hw&s=mZvFxBCIH_-96BcNkwcrYuLqIFdGUQVv9-NgmpF6Kyc&e=>: This is a numba bug. Please report this there, but only if you use the newest numba version. Give them this link so they see the code that triggers their bug:. https://github.com/theislab/scanpy/blob/2f160ea403d124d237fc2138c0aa0d175fbad22a/scanpy/preprocessing/_qc.py#L402-L428<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_theislab_scanpy_blob_2f160ea403d124d237fc2138c0aa0d175fbad22a_scanpy_preprocessing_-5Fqc.py-23L402-2DL428&d=DwMCaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=j6EgtEBZ-6pbDONgnwVzuTHJ6L-gWcikckOhZCwVjPc&m=j6WdQxFMfGL2BOrFUsLxuCIlMEWSPOGMoQ3sfPhU4hw&s=6bLtPWJSoSBSNQcRvwP4Pp-mHjA7d51Ees_qcvGEJYk&e=>. @team: We should include numba in the package versions list. . You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_theislab_scanpy_issues_1341-23issuecomment-2D666246043&d=DwMCaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=j6EgtEBZ-6pbDONgnwVzuTHJ6L-gWcikckOhZCwVjPc&m=j6WdQxFMfGL2BOrFUsLxuCIlMEWSPOGMoQ3sfPhU4hw&s=AQB0zBmdSewipAgOqteV0t7F27jeGZaU-I4LngYZYus&e=>, or unsubscribe<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_notifications_unsubscribe-2Dauth_ALCZ3CPX4MWCNAHOFNSYRC3R6EZYFANCNFSM4PMLDJKQ&d=DwMCaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=j6EgtEBZ-6pbDONgnwVzuTHJ6L-gWcikckOhZCwVjPc&m=j6WdQxFMfGL2BOrFUsLxuCIlMEWSPOGMoQ3sfPhU4hw&s=XT2LyZ_ZXTKdnWcyG0sd7w1UgmMmxTpvj_8IWLPy44I&e=>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:24,integrability,version,version,24,"Can you let me know the version of numba that worked for you? Get Outlook for Android<https://aka.ms/ghei36>. ________________________________. From: Philipp A. <notifications@github.com>. Sent: Thursday, July 30, 2020 2:06:10 AM. To: theislab/scanpy <scanpy@noreply.github.com>. Cc: Peng, Tao <tpeng@fredhutch.org>; Mention <mention@noreply.github.com>. Subject: Re: [theislab/scanpy] scanpy sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True) (#1341). @taopeng1100<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_taopeng1100&d=DwMCaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=j6EgtEBZ-6pbDONgnwVzuTHJ6L-gWcikckOhZCwVjPc&m=j6WdQxFMfGL2BOrFUsLxuCIlMEWSPOGMoQ3sfPhU4hw&s=mZvFxBCIH_-96BcNkwcrYuLqIFdGUQVv9-NgmpF6Kyc&e=>: This is a numba bug. Please report this there, but only if you use the newest numba version. Give them this link so they see the code that triggers their bug:. https://github.com/theislab/scanpy/blob/2f160ea403d124d237fc2138c0aa0d175fbad22a/scanpy/preprocessing/_qc.py#L402-L428<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_theislab_scanpy_blob_2f160ea403d124d237fc2138c0aa0d175fbad22a_scanpy_preprocessing_-5Fqc.py-23L402-2DL428&d=DwMCaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=j6EgtEBZ-6pbDONgnwVzuTHJ6L-gWcikckOhZCwVjPc&m=j6WdQxFMfGL2BOrFUsLxuCIlMEWSPOGMoQ3sfPhU4hw&s=6bLtPWJSoSBSNQcRvwP4Pp-mHjA7d51Ees_qcvGEJYk&e=>. @team: We should include numba in the package versions list. . You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_theislab_scanpy_issues_1341-23issuecomment-2D666246043&d=DwMCaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=j6EgtEBZ-6pbDONgnwVzuTHJ6L-gWcikckOhZCwVjPc&m=j6WdQxFMfGL2BOrFUsLxuCIlMEWSPOGMoQ3sfPhU4hw&s=AQB0zBmdSewipAgOqteV0t7F27jeGZaU-I4LngYZYus&e=>, or unsubscribe<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_notifications_unsubscribe-2Dauth_ALCZ3CPX4MWCNAHOFNSYRC3R6EZYFANCNFSM4PMLDJKQ&d=DwMCaQ&c=eRAMFD45gAfqt84",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:355,integrability,Sub,Subject,355,"Can you let me know the version of numba that worked for you? Get Outlook for Android<https://aka.ms/ghei36>. ________________________________. From: Philipp A. <notifications@github.com>. Sent: Thursday, July 30, 2020 2:06:10 AM. To: theislab/scanpy <scanpy@noreply.github.com>. Cc: Peng, Tao <tpeng@fredhutch.org>; Mention <mention@noreply.github.com>. Subject: Re: [theislab/scanpy] scanpy sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True) (#1341). @taopeng1100<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_taopeng1100&d=DwMCaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=j6EgtEBZ-6pbDONgnwVzuTHJ6L-gWcikckOhZCwVjPc&m=j6WdQxFMfGL2BOrFUsLxuCIlMEWSPOGMoQ3sfPhU4hw&s=mZvFxBCIH_-96BcNkwcrYuLqIFdGUQVv9-NgmpF6Kyc&e=>: This is a numba bug. Please report this there, but only if you use the newest numba version. Give them this link so they see the code that triggers their bug:. https://github.com/theislab/scanpy/blob/2f160ea403d124d237fc2138c0aa0d175fbad22a/scanpy/preprocessing/_qc.py#L402-L428<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_theislab_scanpy_blob_2f160ea403d124d237fc2138c0aa0d175fbad22a_scanpy_preprocessing_-5Fqc.py-23L402-2DL428&d=DwMCaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=j6EgtEBZ-6pbDONgnwVzuTHJ6L-gWcikckOhZCwVjPc&m=j6WdQxFMfGL2BOrFUsLxuCIlMEWSPOGMoQ3sfPhU4hw&s=6bLtPWJSoSBSNQcRvwP4Pp-mHjA7d51Ees_qcvGEJYk&e=>. @team: We should include numba in the package versions list. . You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_theislab_scanpy_issues_1341-23issuecomment-2D666246043&d=DwMCaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=j6EgtEBZ-6pbDONgnwVzuTHJ6L-gWcikckOhZCwVjPc&m=j6WdQxFMfGL2BOrFUsLxuCIlMEWSPOGMoQ3sfPhU4hw&s=AQB0zBmdSewipAgOqteV0t7F27jeGZaU-I4LngYZYus&e=>, or unsubscribe<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_notifications_unsubscribe-2Dauth_ALCZ3CPX4MWCNAHOFNSYRC3R6EZYFANCNFSM4PMLDJKQ&d=DwMCaQ&c=eRAMFD45gAfqt84",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:816,integrability,version,version,816,"Can you let me know the version of numba that worked for you? Get Outlook for Android<https://aka.ms/ghei36>. ________________________________. From: Philipp A. <notifications@github.com>. Sent: Thursday, July 30, 2020 2:06:10 AM. To: theislab/scanpy <scanpy@noreply.github.com>. Cc: Peng, Tao <tpeng@fredhutch.org>; Mention <mention@noreply.github.com>. Subject: Re: [theislab/scanpy] scanpy sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True) (#1341). @taopeng1100<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_taopeng1100&d=DwMCaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=j6EgtEBZ-6pbDONgnwVzuTHJ6L-gWcikckOhZCwVjPc&m=j6WdQxFMfGL2BOrFUsLxuCIlMEWSPOGMoQ3sfPhU4hw&s=mZvFxBCIH_-96BcNkwcrYuLqIFdGUQVv9-NgmpF6Kyc&e=>: This is a numba bug. Please report this there, but only if you use the newest numba version. Give them this link so they see the code that triggers their bug:. https://github.com/theislab/scanpy/blob/2f160ea403d124d237fc2138c0aa0d175fbad22a/scanpy/preprocessing/_qc.py#L402-L428<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_theislab_scanpy_blob_2f160ea403d124d237fc2138c0aa0d175fbad22a_scanpy_preprocessing_-5Fqc.py-23L402-2DL428&d=DwMCaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=j6EgtEBZ-6pbDONgnwVzuTHJ6L-gWcikckOhZCwVjPc&m=j6WdQxFMfGL2BOrFUsLxuCIlMEWSPOGMoQ3sfPhU4hw&s=6bLtPWJSoSBSNQcRvwP4Pp-mHjA7d51Ees_qcvGEJYk&e=>. @team: We should include numba in the package versions list. . You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_theislab_scanpy_issues_1341-23issuecomment-2D666246043&d=DwMCaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=j6EgtEBZ-6pbDONgnwVzuTHJ6L-gWcikckOhZCwVjPc&m=j6WdQxFMfGL2BOrFUsLxuCIlMEWSPOGMoQ3sfPhU4hw&s=AQB0zBmdSewipAgOqteV0t7F27jeGZaU-I4LngYZYus&e=>, or unsubscribe<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_notifications_unsubscribe-2Dauth_ALCZ3CPX4MWCNAHOFNSYRC3R6EZYFANCNFSM4PMLDJKQ&d=DwMCaQ&c=eRAMFD45gAfqt84",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:1404,integrability,version,versions,1404,"Philipp A. <notifications@github.com>. Sent: Thursday, July 30, 2020 2:06:10 AM. To: theislab/scanpy <scanpy@noreply.github.com>. Cc: Peng, Tao <tpeng@fredhutch.org>; Mention <mention@noreply.github.com>. Subject: Re: [theislab/scanpy] scanpy sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True) (#1341). @taopeng1100<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_taopeng1100&d=DwMCaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=j6EgtEBZ-6pbDONgnwVzuTHJ6L-gWcikckOhZCwVjPc&m=j6WdQxFMfGL2BOrFUsLxuCIlMEWSPOGMoQ3sfPhU4hw&s=mZvFxBCIH_-96BcNkwcrYuLqIFdGUQVv9-NgmpF6Kyc&e=>: This is a numba bug. Please report this there, but only if you use the newest numba version. Give them this link so they see the code that triggers their bug:. https://github.com/theislab/scanpy/blob/2f160ea403d124d237fc2138c0aa0d175fbad22a/scanpy/preprocessing/_qc.py#L402-L428<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_theislab_scanpy_blob_2f160ea403d124d237fc2138c0aa0d175fbad22a_scanpy_preprocessing_-5Fqc.py-23L402-2DL428&d=DwMCaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=j6EgtEBZ-6pbDONgnwVzuTHJ6L-gWcikckOhZCwVjPc&m=j6WdQxFMfGL2BOrFUsLxuCIlMEWSPOGMoQ3sfPhU4hw&s=6bLtPWJSoSBSNQcRvwP4Pp-mHjA7d51Ees_qcvGEJYk&e=>. @team: We should include numba in the package versions list. . You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_theislab_scanpy_issues_1341-23issuecomment-2D666246043&d=DwMCaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=j6EgtEBZ-6pbDONgnwVzuTHJ6L-gWcikckOhZCwVjPc&m=j6WdQxFMfGL2BOrFUsLxuCIlMEWSPOGMoQ3sfPhU4hw&s=AQB0zBmdSewipAgOqteV0t7F27jeGZaU-I4LngYZYus&e=>, or unsubscribe<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_notifications_unsubscribe-2Dauth_ALCZ3CPX4MWCNAHOFNSYRC3R6EZYFANCNFSM4PMLDJKQ&d=DwMCaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=j6EgtEBZ-6pbDONgnwVzuTHJ6L-gWcikckOhZCwVjPc&m=j6WdQxFMfGL2BOrFUsLxuCIlMEWSPOGMoQ3sfPhU4hw&s=XT2LyZ_ZXTKdnWcyG0sd7w1UgmMmxTpvj_8IWLPy44I&e=>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:24,modifiability,version,version,24,"Can you let me know the version of numba that worked for you? Get Outlook for Android<https://aka.ms/ghei36>. ________________________________. From: Philipp A. <notifications@github.com>. Sent: Thursday, July 30, 2020 2:06:10 AM. To: theislab/scanpy <scanpy@noreply.github.com>. Cc: Peng, Tao <tpeng@fredhutch.org>; Mention <mention@noreply.github.com>. Subject: Re: [theislab/scanpy] scanpy sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True) (#1341). @taopeng1100<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_taopeng1100&d=DwMCaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=j6EgtEBZ-6pbDONgnwVzuTHJ6L-gWcikckOhZCwVjPc&m=j6WdQxFMfGL2BOrFUsLxuCIlMEWSPOGMoQ3sfPhU4hw&s=mZvFxBCIH_-96BcNkwcrYuLqIFdGUQVv9-NgmpF6Kyc&e=>: This is a numba bug. Please report this there, but only if you use the newest numba version. Give them this link so they see the code that triggers their bug:. https://github.com/theislab/scanpy/blob/2f160ea403d124d237fc2138c0aa0d175fbad22a/scanpy/preprocessing/_qc.py#L402-L428<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_theislab_scanpy_blob_2f160ea403d124d237fc2138c0aa0d175fbad22a_scanpy_preprocessing_-5Fqc.py-23L402-2DL428&d=DwMCaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=j6EgtEBZ-6pbDONgnwVzuTHJ6L-gWcikckOhZCwVjPc&m=j6WdQxFMfGL2BOrFUsLxuCIlMEWSPOGMoQ3sfPhU4hw&s=6bLtPWJSoSBSNQcRvwP4Pp-mHjA7d51Ees_qcvGEJYk&e=>. @team: We should include numba in the package versions list. . You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_theislab_scanpy_issues_1341-23issuecomment-2D666246043&d=DwMCaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=j6EgtEBZ-6pbDONgnwVzuTHJ6L-gWcikckOhZCwVjPc&m=j6WdQxFMfGL2BOrFUsLxuCIlMEWSPOGMoQ3sfPhU4hw&s=AQB0zBmdSewipAgOqteV0t7F27jeGZaU-I4LngYZYus&e=>, or unsubscribe<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_notifications_unsubscribe-2Dauth_ALCZ3CPX4MWCNAHOFNSYRC3R6EZYFANCNFSM4PMLDJKQ&d=DwMCaQ&c=eRAMFD45gAfqt84",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:816,modifiability,version,version,816,"Can you let me know the version of numba that worked for you? Get Outlook for Android<https://aka.ms/ghei36>. ________________________________. From: Philipp A. <notifications@github.com>. Sent: Thursday, July 30, 2020 2:06:10 AM. To: theislab/scanpy <scanpy@noreply.github.com>. Cc: Peng, Tao <tpeng@fredhutch.org>; Mention <mention@noreply.github.com>. Subject: Re: [theislab/scanpy] scanpy sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True) (#1341). @taopeng1100<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_taopeng1100&d=DwMCaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=j6EgtEBZ-6pbDONgnwVzuTHJ6L-gWcikckOhZCwVjPc&m=j6WdQxFMfGL2BOrFUsLxuCIlMEWSPOGMoQ3sfPhU4hw&s=mZvFxBCIH_-96BcNkwcrYuLqIFdGUQVv9-NgmpF6Kyc&e=>: This is a numba bug. Please report this there, but only if you use the newest numba version. Give them this link so they see the code that triggers their bug:. https://github.com/theislab/scanpy/blob/2f160ea403d124d237fc2138c0aa0d175fbad22a/scanpy/preprocessing/_qc.py#L402-L428<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_theislab_scanpy_blob_2f160ea403d124d237fc2138c0aa0d175fbad22a_scanpy_preprocessing_-5Fqc.py-23L402-2DL428&d=DwMCaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=j6EgtEBZ-6pbDONgnwVzuTHJ6L-gWcikckOhZCwVjPc&m=j6WdQxFMfGL2BOrFUsLxuCIlMEWSPOGMoQ3sfPhU4hw&s=6bLtPWJSoSBSNQcRvwP4Pp-mHjA7d51Ees_qcvGEJYk&e=>. @team: We should include numba in the package versions list. . You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_theislab_scanpy_issues_1341-23issuecomment-2D666246043&d=DwMCaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=j6EgtEBZ-6pbDONgnwVzuTHJ6L-gWcikckOhZCwVjPc&m=j6WdQxFMfGL2BOrFUsLxuCIlMEWSPOGMoQ3sfPhU4hw&s=AQB0zBmdSewipAgOqteV0t7F27jeGZaU-I4LngYZYus&e=>, or unsubscribe<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_notifications_unsubscribe-2Dauth_ALCZ3CPX4MWCNAHOFNSYRC3R6EZYFANCNFSM4PMLDJKQ&d=DwMCaQ&c=eRAMFD45gAfqt84",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:1396,modifiability,pac,package,1396,"Philipp A. <notifications@github.com>. Sent: Thursday, July 30, 2020 2:06:10 AM. To: theislab/scanpy <scanpy@noreply.github.com>. Cc: Peng, Tao <tpeng@fredhutch.org>; Mention <mention@noreply.github.com>. Subject: Re: [theislab/scanpy] scanpy sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True) (#1341). @taopeng1100<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_taopeng1100&d=DwMCaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=j6EgtEBZ-6pbDONgnwVzuTHJ6L-gWcikckOhZCwVjPc&m=j6WdQxFMfGL2BOrFUsLxuCIlMEWSPOGMoQ3sfPhU4hw&s=mZvFxBCIH_-96BcNkwcrYuLqIFdGUQVv9-NgmpF6Kyc&e=>: This is a numba bug. Please report this there, but only if you use the newest numba version. Give them this link so they see the code that triggers their bug:. https://github.com/theislab/scanpy/blob/2f160ea403d124d237fc2138c0aa0d175fbad22a/scanpy/preprocessing/_qc.py#L402-L428<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_theislab_scanpy_blob_2f160ea403d124d237fc2138c0aa0d175fbad22a_scanpy_preprocessing_-5Fqc.py-23L402-2DL428&d=DwMCaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=j6EgtEBZ-6pbDONgnwVzuTHJ6L-gWcikckOhZCwVjPc&m=j6WdQxFMfGL2BOrFUsLxuCIlMEWSPOGMoQ3sfPhU4hw&s=6bLtPWJSoSBSNQcRvwP4Pp-mHjA7d51Ees_qcvGEJYk&e=>. @team: We should include numba in the package versions list. . You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_theislab_scanpy_issues_1341-23issuecomment-2D666246043&d=DwMCaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=j6EgtEBZ-6pbDONgnwVzuTHJ6L-gWcikckOhZCwVjPc&m=j6WdQxFMfGL2BOrFUsLxuCIlMEWSPOGMoQ3sfPhU4hw&s=AQB0zBmdSewipAgOqteV0t7F27jeGZaU-I4LngYZYus&e=>, or unsubscribe<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_notifications_unsubscribe-2Dauth_ALCZ3CPX4MWCNAHOFNSYRC3R6EZYFANCNFSM4PMLDJKQ&d=DwMCaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=j6EgtEBZ-6pbDONgnwVzuTHJ6L-gWcikckOhZCwVjPc&m=j6WdQxFMfGL2BOrFUsLxuCIlMEWSPOGMoQ3sfPhU4hw&s=XT2LyZ_ZXTKdnWcyG0sd7w1UgmMmxTpvj_8IWLPy44I&e=>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:1404,modifiability,version,versions,1404,"Philipp A. <notifications@github.com>. Sent: Thursday, July 30, 2020 2:06:10 AM. To: theislab/scanpy <scanpy@noreply.github.com>. Cc: Peng, Tao <tpeng@fredhutch.org>; Mention <mention@noreply.github.com>. Subject: Re: [theislab/scanpy] scanpy sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True) (#1341). @taopeng1100<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_taopeng1100&d=DwMCaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=j6EgtEBZ-6pbDONgnwVzuTHJ6L-gWcikckOhZCwVjPc&m=j6WdQxFMfGL2BOrFUsLxuCIlMEWSPOGMoQ3sfPhU4hw&s=mZvFxBCIH_-96BcNkwcrYuLqIFdGUQVv9-NgmpF6Kyc&e=>: This is a numba bug. Please report this there, but only if you use the newest numba version. Give them this link so they see the code that triggers their bug:. https://github.com/theislab/scanpy/blob/2f160ea403d124d237fc2138c0aa0d175fbad22a/scanpy/preprocessing/_qc.py#L402-L428<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_theislab_scanpy_blob_2f160ea403d124d237fc2138c0aa0d175fbad22a_scanpy_preprocessing_-5Fqc.py-23L402-2DL428&d=DwMCaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=j6EgtEBZ-6pbDONgnwVzuTHJ6L-gWcikckOhZCwVjPc&m=j6WdQxFMfGL2BOrFUsLxuCIlMEWSPOGMoQ3sfPhU4hw&s=6bLtPWJSoSBSNQcRvwP4Pp-mHjA7d51Ees_qcvGEJYk&e=>. @team: We should include numba in the package versions list. . You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_theislab_scanpy_issues_1341-23issuecomment-2D666246043&d=DwMCaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=j6EgtEBZ-6pbDONgnwVzuTHJ6L-gWcikckOhZCwVjPc&m=j6WdQxFMfGL2BOrFUsLxuCIlMEWSPOGMoQ3sfPhU4hw&s=AQB0zBmdSewipAgOqteV0t7F27jeGZaU-I4LngYZYus&e=>, or unsubscribe<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_notifications_unsubscribe-2Dauth_ALCZ3CPX4MWCNAHOFNSYRC3R6EZYFANCNFSM4PMLDJKQ&d=DwMCaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=j6EgtEBZ-6pbDONgnwVzuTHJ6L-gWcikckOhZCwVjPc&m=j6WdQxFMfGL2BOrFUsLxuCIlMEWSPOGMoQ3sfPhU4hw&s=XT2LyZ_ZXTKdnWcyG0sd7w1UgmMmxTpvj_8IWLPy44I&e=>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:1359,security,team,team,1359,"Philipp A. <notifications@github.com>. Sent: Thursday, July 30, 2020 2:06:10 AM. To: theislab/scanpy <scanpy@noreply.github.com>. Cc: Peng, Tao <tpeng@fredhutch.org>; Mention <mention@noreply.github.com>. Subject: Re: [theislab/scanpy] scanpy sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True) (#1341). @taopeng1100<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_taopeng1100&d=DwMCaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=j6EgtEBZ-6pbDONgnwVzuTHJ6L-gWcikckOhZCwVjPc&m=j6WdQxFMfGL2BOrFUsLxuCIlMEWSPOGMoQ3sfPhU4hw&s=mZvFxBCIH_-96BcNkwcrYuLqIFdGUQVv9-NgmpF6Kyc&e=>: This is a numba bug. Please report this there, but only if you use the newest numba version. Give them this link so they see the code that triggers their bug:. https://github.com/theislab/scanpy/blob/2f160ea403d124d237fc2138c0aa0d175fbad22a/scanpy/preprocessing/_qc.py#L402-L428<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_theislab_scanpy_blob_2f160ea403d124d237fc2138c0aa0d175fbad22a_scanpy_preprocessing_-5Fqc.py-23L402-2DL428&d=DwMCaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=j6EgtEBZ-6pbDONgnwVzuTHJ6L-gWcikckOhZCwVjPc&m=j6WdQxFMfGL2BOrFUsLxuCIlMEWSPOGMoQ3sfPhU4hw&s=6bLtPWJSoSBSNQcRvwP4Pp-mHjA7d51Ees_qcvGEJYk&e=>. @team: We should include numba in the package versions list. . You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_theislab_scanpy_issues_1341-23issuecomment-2D666246043&d=DwMCaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=j6EgtEBZ-6pbDONgnwVzuTHJ6L-gWcikckOhZCwVjPc&m=j6WdQxFMfGL2BOrFUsLxuCIlMEWSPOGMoQ3sfPhU4hw&s=AQB0zBmdSewipAgOqteV0t7F27jeGZaU-I4LngYZYus&e=>, or unsubscribe<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_notifications_unsubscribe-2Dauth_ALCZ3CPX4MWCNAHOFNSYRC3R6EZYFANCNFSM4PMLDJKQ&d=DwMCaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=j6EgtEBZ-6pbDONgnwVzuTHJ6L-gWcikckOhZCwVjPc&m=j6WdQxFMfGL2BOrFUsLxuCIlMEWSPOGMoQ3sfPhU4hw&s=XT2LyZ_ZXTKdnWcyG0sd7w1UgmMmxTpvj_8IWLPy44I&e=>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:24,deployability,version,version,24,You can find the newest version on the PyPI page: https://pypi.org/project/numba/,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:24,integrability,version,version,24,You can find the newest version on the PyPI page: https://pypi.org/project/numba/,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:24,modifiability,version,version,24,You can find the newest version on the PyPI page: https://pypi.org/project/numba/,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:44,availability,error,error,44,"Thank you @stuartarchibald, it sure is! The error happens when numba tries to JIT-compile `top_segment_proportions_sparse_csr`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:44,performance,error,error,44,"Thank you @stuartarchibald, it sure is! The error happens when numba tries to JIT-compile `top_segment_proportions_sparse_csr`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:44,safety,error,error,44,"Thank you @stuartarchibald, it sure is! The error happens when numba tries to JIT-compile `top_segment_proportions_sparse_csr`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:44,usability,error,error,44,"Thank you @stuartarchibald, it sure is! The error happens when numba tries to JIT-compile `top_segment_proportions_sparse_csr`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:26,usability,help,help,26,"Hi Philip, can you kindly help me here? How can I get sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True) to work for me?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:6,availability,down,downgrade,6,Maybe downgrade numba for the time being? IDK to which version though. @stuartarchibald has more insight here. Please follow numba/numba#5955 for updates!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:55,deployability,version,version,55,Maybe downgrade numba for the time being? IDK to which version though. @stuartarchibald has more insight here. Please follow numba/numba#5955 for updates!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:146,deployability,updat,updates,146,Maybe downgrade numba for the time being? IDK to which version though. @stuartarchibald has more insight here. Please follow numba/numba#5955 for updates!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:55,integrability,version,version,55,Maybe downgrade numba for the time being? IDK to which version though. @stuartarchibald has more insight here. Please follow numba/numba#5955 for updates!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:55,modifiability,version,version,55,Maybe downgrade numba for the time being? IDK to which version though. @stuartarchibald has more insight here. Please follow numba/numba#5955 for updates!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:30,performance,time,time,30,Maybe downgrade numba for the time being? IDK to which version though. @stuartarchibald has more insight here. Please follow numba/numba#5955 for updates!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:146,safety,updat,updates,146,Maybe downgrade numba for the time being? IDK to which version though. @stuartarchibald has more insight here. Please follow numba/numba#5955 for updates!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:146,security,updat,updates,146,Maybe downgrade numba for the time being? IDK to which version though. @stuartarchibald has more insight here. Please follow numba/numba#5955 for updates!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:52,availability,down,downgrade,52,"I am using Anaconda/Jupyter in my PC. When I try to downgrade numba, I run into issues of numba dependency packages in Anaconda so I am stuck!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:96,deployability,depend,dependency,96,"I am using Anaconda/Jupyter in my PC. When I try to downgrade numba, I run into issues of numba dependency packages in Anaconda so I am stuck!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:96,integrability,depend,dependency,96,"I am using Anaconda/Jupyter in my PC. When I try to downgrade numba, I run into issues of numba dependency packages in Anaconda so I am stuck!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:96,modifiability,depend,dependency,96,"I am using Anaconda/Jupyter in my PC. When I try to downgrade numba, I run into issues of numba dependency packages in Anaconda so I am stuck!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:107,modifiability,pac,packages,107,"I am using Anaconda/Jupyter in my PC. When I try to downgrade numba, I run into issues of numba dependency packages in Anaconda so I am stuck!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:96,safety,depend,dependency,96,"I am using Anaconda/Jupyter in my PC. When I try to downgrade numba, I run into issues of numba dependency packages in Anaconda so I am stuck!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:96,testability,depend,dependency,96,"I am using Anaconda/Jupyter in my PC. When I try to downgrade numba, I run into issues of numba dependency packages in Anaconda so I am stuck!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:110,usability,help,help,110,"@flying-sheep I might know a work around for scanpy whilst we try and fix the root cause in numba, would that help?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:91,deployability,instal,installing,91,"Sure, thank you! Care to do a quick PR? Then we can point @taopeng1100 in the direction of installing scanpys dev version and everyones happy. @taopeng1100 please reply by GitHub comment and not by email anymore, it spams up this comment section. I always have to remove some junk your email program adds.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:115,deployability,version,version,115,"Sure, thank you! Care to do a quick PR? Then we can point @taopeng1100 in the direction of installing scanpys dev version and everyones happy. @taopeng1100 please reply by GitHub comment and not by email anymore, it spams up this comment section. I always have to remove some junk your email program adds.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:115,integrability,version,version,115,"Sure, thank you! Care to do a quick PR? Then we can point @taopeng1100 in the direction of installing scanpys dev version and everyones happy. @taopeng1100 please reply by GitHub comment and not by email anymore, it spams up this comment section. I always have to remove some junk your email program adds.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:115,modifiability,version,version,115,"Sure, thank you! Care to do a quick PR? Then we can point @taopeng1100 in the direction of installing scanpys dev version and everyones happy. @taopeng1100 please reply by GitHub comment and not by email anymore, it spams up this comment section. I always have to remove some junk your email program adds.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:40,deployability,instal,install,40,"Okay, its merged! @taopeng1100, please install the dev version of scanpy like this, and retry:. ```bash. pip install git+https://github.com/theislab/scanpy.git. # or. pip install --user git+https://github.com/theislab/scanpy.git. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:56,deployability,version,version,56,"Okay, its merged! @taopeng1100, please install the dev version of scanpy like this, and retry:. ```bash. pip install git+https://github.com/theislab/scanpy.git. # or. pip install --user git+https://github.com/theislab/scanpy.git. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:110,deployability,instal,install,110,"Okay, its merged! @taopeng1100, please install the dev version of scanpy like this, and retry:. ```bash. pip install git+https://github.com/theislab/scanpy.git. # or. pip install --user git+https://github.com/theislab/scanpy.git. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:172,deployability,instal,install,172,"Okay, its merged! @taopeng1100, please install the dev version of scanpy like this, and retry:. ```bash. pip install git+https://github.com/theislab/scanpy.git. # or. pip install --user git+https://github.com/theislab/scanpy.git. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:56,integrability,version,version,56,"Okay, its merged! @taopeng1100, please install the dev version of scanpy like this, and retry:. ```bash. pip install git+https://github.com/theislab/scanpy.git. # or. pip install --user git+https://github.com/theislab/scanpy.git. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:56,modifiability,version,version,56,"Okay, its merged! @taopeng1100, please install the dev version of scanpy like this, and retry:. ```bash. pip install git+https://github.com/theislab/scanpy.git. # or. pip install --user git+https://github.com/theislab/scanpy.git. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:182,usability,user,user,182,"Okay, its merged! @taopeng1100, please install the dev version of scanpy like this, and retry:. ```bash. pip install git+https://github.com/theislab/scanpy.git. # or. pip install --user git+https://github.com/theislab/scanpy.git. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:36,usability,help,help,36,It all works NOW! I appreciate your help!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:36,usability,help,help,36,It all works NOW! I appreciate your help!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:36,usability,help,help,36,It all works NOW! I appreciate your help!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:36,usability,help,help,36,It all works NOW! I appreciate your help!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/pull/1342:187,deployability,log,log,187,"I tried to improve the ticklabel location which now looks like this. Also, I added a parameter to turn on the labels. ```PYTHON. sc.pl.stacked_violin(adata,marker_genes,groupby='louvain',log=False, yticklabels=True, row_palette='muted'). ```. ![image](https://user-images.githubusercontent.com/4964309/89010208-6a05f680-d30e-11ea-995b-bd5b1a673c51.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1342
https://github.com/scverse/scanpy/pull/1342:85,modifiability,paramet,parameter,85,"I tried to improve the ticklabel location which now looks like this. Also, I added a parameter to turn on the labels. ```PYTHON. sc.pl.stacked_violin(adata,marker_genes,groupby='louvain',log=False, yticklabels=True, row_palette='muted'). ```. ![image](https://user-images.githubusercontent.com/4964309/89010208-6a05f680-d30e-11ea-995b-bd5b1a673c51.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1342
https://github.com/scverse/scanpy/pull/1342:187,safety,log,log,187,"I tried to improve the ticklabel location which now looks like this. Also, I added a parameter to turn on the labels. ```PYTHON. sc.pl.stacked_violin(adata,marker_genes,groupby='louvain',log=False, yticklabels=True, row_palette='muted'). ```. ![image](https://user-images.githubusercontent.com/4964309/89010208-6a05f680-d30e-11ea-995b-bd5b1a673c51.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1342
https://github.com/scverse/scanpy/pull/1342:187,security,log,log,187,"I tried to improve the ticklabel location which now looks like this. Also, I added a parameter to turn on the labels. ```PYTHON. sc.pl.stacked_violin(adata,marker_genes,groupby='louvain',log=False, yticklabels=True, row_palette='muted'). ```. ![image](https://user-images.githubusercontent.com/4964309/89010208-6a05f680-d30e-11ea-995b-bd5b1a673c51.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1342
https://github.com/scverse/scanpy/pull/1342:187,testability,log,log,187,"I tried to improve the ticklabel location which now looks like this. Also, I added a parameter to turn on the labels. ```PYTHON. sc.pl.stacked_violin(adata,marker_genes,groupby='louvain',log=False, yticklabels=True, row_palette='muted'). ```. ![image](https://user-images.githubusercontent.com/4964309/89010208-6a05f680-d30e-11ea-995b-bd5b1a673c51.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1342
https://github.com/scverse/scanpy/pull/1342:260,usability,user,user-images,260,"I tried to improve the ticklabel location which now looks like this. Also, I added a parameter to turn on the labels. ```PYTHON. sc.pl.stacked_violin(adata,marker_genes,groupby='louvain',log=False, yticklabels=True, row_palette='muted'). ```. ![image](https://user-images.githubusercontent.com/4964309/89010208-6a05f680-d30e-11ea-995b-bd5b1a673c51.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1342
https://github.com/scverse/scanpy/pull/1343:68,deployability,depend,dependency,68,"I was thinking we could go a bit further. We could add `sinfo` as a dependency and make `print_versions` just call: `sinfo.sinfo(dependencies=True)` which will always be comprehensive. <details>. <summary> Example output: </summary>. ```. -----. IPython 7.16.1. scanpy 1.5.2.dev38+g6728bdab. sinfo 0.3.1. -----. IPython 7.16.1. PIL 7.2.0. anndata 0.7.5.dev0+g58886f0.d20200729. asciitree NA. backcall 0.2.0. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. dask 2.21.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.2. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.33.0. louvain 0.7.0. matplotlib 3.3.0. monotonic NA. mpl_toolkits NA. msgpack 1.0.0. natsort 7.0.1. numba 0.50.1. numcodecs 0.6.4. numexpr 2.7.1. numpy 1.19.0. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 2.4.7. pytz 2020.1. scanpy 1.5.2.dev38+g6728bdab. scipy 1.5.1. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.2. tlz 0.10.0. toolz 0.10.0. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zarr 2.4.0. -----. Python 3.8.5 (default, Jul 23 2020, 15:50:11) [Clang 11.0.3 (clang-1103.0.32.62)]. macOS-10.15.6-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2020-07-30 19:28. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1343
https://github.com/scverse/scanpy/pull/1343:129,deployability,depend,dependencies,129,"I was thinking we could go a bit further. We could add `sinfo` as a dependency and make `print_versions` just call: `sinfo.sinfo(dependencies=True)` which will always be comprehensive. <details>. <summary> Example output: </summary>. ```. -----. IPython 7.16.1. scanpy 1.5.2.dev38+g6728bdab. sinfo 0.3.1. -----. IPython 7.16.1. PIL 7.2.0. anndata 0.7.5.dev0+g58886f0.d20200729. asciitree NA. backcall 0.2.0. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. dask 2.21.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.2. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.33.0. louvain 0.7.0. matplotlib 3.3.0. monotonic NA. mpl_toolkits NA. msgpack 1.0.0. natsort 7.0.1. numba 0.50.1. numcodecs 0.6.4. numexpr 2.7.1. numpy 1.19.0. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 2.4.7. pytz 2020.1. scanpy 1.5.2.dev38+g6728bdab. scipy 1.5.1. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.2. tlz 0.10.0. toolz 0.10.0. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zarr 2.4.0. -----. Python 3.8.5 (default, Jul 23 2020, 15:50:11) [Clang 11.0.3 (clang-1103.0.32.62)]. macOS-10.15.6-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2020-07-30 19:28. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1343
https://github.com/scverse/scanpy/pull/1343:1488,deployability,log,logical,1488,"I was thinking we could go a bit further. We could add `sinfo` as a dependency and make `print_versions` just call: `sinfo.sinfo(dependencies=True)` which will always be comprehensive. <details>. <summary> Example output: </summary>. ```. -----. IPython 7.16.1. scanpy 1.5.2.dev38+g6728bdab. sinfo 0.3.1. -----. IPython 7.16.1. PIL 7.2.0. anndata 0.7.5.dev0+g58886f0.d20200729. asciitree NA. backcall 0.2.0. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. dask 2.21.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.2. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.33.0. louvain 0.7.0. matplotlib 3.3.0. monotonic NA. mpl_toolkits NA. msgpack 1.0.0. natsort 7.0.1. numba 0.50.1. numcodecs 0.6.4. numexpr 2.7.1. numpy 1.19.0. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 2.4.7. pytz 2020.1. scanpy 1.5.2.dev38+g6728bdab. scipy 1.5.1. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.2. tlz 0.10.0. toolz 0.10.0. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zarr 2.4.0. -----. Python 3.8.5 (default, Jul 23 2020, 15:50:11) [Clang 11.0.3 (clang-1103.0.32.62)]. macOS-10.15.6-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2020-07-30 19:28. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1343
https://github.com/scverse/scanpy/pull/1343:1540,deployability,updat,updated,1540,"I was thinking we could go a bit further. We could add `sinfo` as a dependency and make `print_versions` just call: `sinfo.sinfo(dependencies=True)` which will always be comprehensive. <details>. <summary> Example output: </summary>. ```. -----. IPython 7.16.1. scanpy 1.5.2.dev38+g6728bdab. sinfo 0.3.1. -----. IPython 7.16.1. PIL 7.2.0. anndata 0.7.5.dev0+g58886f0.d20200729. asciitree NA. backcall 0.2.0. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. dask 2.21.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.2. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.33.0. louvain 0.7.0. matplotlib 3.3.0. monotonic NA. mpl_toolkits NA. msgpack 1.0.0. natsort 7.0.1. numba 0.50.1. numcodecs 0.6.4. numexpr 2.7.1. numpy 1.19.0. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 2.4.7. pytz 2020.1. scanpy 1.5.2.dev38+g6728bdab. scipy 1.5.1. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.2. tlz 0.10.0. toolz 0.10.0. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zarr 2.4.0. -----. Python 3.8.5 (default, Jul 23 2020, 15:50:11) [Clang 11.0.3 (clang-1103.0.32.62)]. macOS-10.15.6-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2020-07-30 19:28. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1343
https://github.com/scverse/scanpy/pull/1343:421,energy efficiency,cloud,cloudpickle,421,"I was thinking we could go a bit further. We could add `sinfo` as a dependency and make `print_versions` just call: `sinfo.sinfo(dependencies=True)` which will always be comprehensive. <details>. <summary> Example output: </summary>. ```. -----. IPython 7.16.1. scanpy 1.5.2.dev38+g6728bdab. sinfo 0.3.1. -----. IPython 7.16.1. PIL 7.2.0. anndata 0.7.5.dev0+g58886f0.d20200729. asciitree NA. backcall 0.2.0. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. dask 2.21.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.2. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.33.0. louvain 0.7.0. matplotlib 3.3.0. monotonic NA. mpl_toolkits NA. msgpack 1.0.0. natsort 7.0.1. numba 0.50.1. numcodecs 0.6.4. numexpr 2.7.1. numpy 1.19.0. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 2.4.7. pytz 2020.1. scanpy 1.5.2.dev38+g6728bdab. scipy 1.5.1. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.2. tlz 0.10.0. toolz 0.10.0. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zarr 2.4.0. -----. Python 3.8.5 (default, Jul 23 2020, 15:50:11) [Clang 11.0.3 (clang-1103.0.32.62)]. macOS-10.15.6-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2020-07-30 19:28. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1343
https://github.com/scverse/scanpy/pull/1343:1496,energy efficiency,CPU,CPU,1496,"I was thinking we could go a bit further. We could add `sinfo` as a dependency and make `print_versions` just call: `sinfo.sinfo(dependencies=True)` which will always be comprehensive. <details>. <summary> Example output: </summary>. ```. -----. IPython 7.16.1. scanpy 1.5.2.dev38+g6728bdab. sinfo 0.3.1. -----. IPython 7.16.1. PIL 7.2.0. anndata 0.7.5.dev0+g58886f0.d20200729. asciitree NA. backcall 0.2.0. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. dask 2.21.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.2. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.33.0. louvain 0.7.0. matplotlib 3.3.0. monotonic NA. mpl_toolkits NA. msgpack 1.0.0. natsort 7.0.1. numba 0.50.1. numcodecs 0.6.4. numexpr 2.7.1. numpy 1.19.0. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 2.4.7. pytz 2020.1. scanpy 1.5.2.dev38+g6728bdab. scipy 1.5.1. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.2. tlz 0.10.0. toolz 0.10.0. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zarr 2.4.0. -----. Python 3.8.5 (default, Jul 23 2020, 15:50:11) [Clang 11.0.3 (clang-1103.0.32.62)]. macOS-10.15.6-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2020-07-30 19:28. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1343
https://github.com/scverse/scanpy/pull/1343:1500,energy efficiency,core,cores,1500,"I was thinking we could go a bit further. We could add `sinfo` as a dependency and make `print_versions` just call: `sinfo.sinfo(dependencies=True)` which will always be comprehensive. <details>. <summary> Example output: </summary>. ```. -----. IPython 7.16.1. scanpy 1.5.2.dev38+g6728bdab. sinfo 0.3.1. -----. IPython 7.16.1. PIL 7.2.0. anndata 0.7.5.dev0+g58886f0.d20200729. asciitree NA. backcall 0.2.0. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. dask 2.21.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.2. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.33.0. louvain 0.7.0. matplotlib 3.3.0. monotonic NA. mpl_toolkits NA. msgpack 1.0.0. natsort 7.0.1. numba 0.50.1. numcodecs 0.6.4. numexpr 2.7.1. numpy 1.19.0. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 2.4.7. pytz 2020.1. scanpy 1.5.2.dev38+g6728bdab. scipy 1.5.1. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.2. tlz 0.10.0. toolz 0.10.0. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zarr 2.4.0. -----. Python 3.8.5 (default, Jul 23 2020, 15:50:11) [Clang 11.0.3 (clang-1103.0.32.62)]. macOS-10.15.6-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2020-07-30 19:28. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1343
https://github.com/scverse/scanpy/pull/1343:68,integrability,depend,dependency,68,"I was thinking we could go a bit further. We could add `sinfo` as a dependency and make `print_versions` just call: `sinfo.sinfo(dependencies=True)` which will always be comprehensive. <details>. <summary> Example output: </summary>. ```. -----. IPython 7.16.1. scanpy 1.5.2.dev38+g6728bdab. sinfo 0.3.1. -----. IPython 7.16.1. PIL 7.2.0. anndata 0.7.5.dev0+g58886f0.d20200729. asciitree NA. backcall 0.2.0. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. dask 2.21.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.2. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.33.0. louvain 0.7.0. matplotlib 3.3.0. monotonic NA. mpl_toolkits NA. msgpack 1.0.0. natsort 7.0.1. numba 0.50.1. numcodecs 0.6.4. numexpr 2.7.1. numpy 1.19.0. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 2.4.7. pytz 2020.1. scanpy 1.5.2.dev38+g6728bdab. scipy 1.5.1. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.2. tlz 0.10.0. toolz 0.10.0. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zarr 2.4.0. -----. Python 3.8.5 (default, Jul 23 2020, 15:50:11) [Clang 11.0.3 (clang-1103.0.32.62)]. macOS-10.15.6-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2020-07-30 19:28. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1343
https://github.com/scverse/scanpy/pull/1343:129,integrability,depend,dependencies,129,"I was thinking we could go a bit further. We could add `sinfo` as a dependency and make `print_versions` just call: `sinfo.sinfo(dependencies=True)` which will always be comprehensive. <details>. <summary> Example output: </summary>. ```. -----. IPython 7.16.1. scanpy 1.5.2.dev38+g6728bdab. sinfo 0.3.1. -----. IPython 7.16.1. PIL 7.2.0. anndata 0.7.5.dev0+g58886f0.d20200729. asciitree NA. backcall 0.2.0. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. dask 2.21.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.2. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.33.0. louvain 0.7.0. matplotlib 3.3.0. monotonic NA. mpl_toolkits NA. msgpack 1.0.0. natsort 7.0.1. numba 0.50.1. numcodecs 0.6.4. numexpr 2.7.1. numpy 1.19.0. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 2.4.7. pytz 2020.1. scanpy 1.5.2.dev38+g6728bdab. scipy 1.5.1. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.2. tlz 0.10.0. toolz 0.10.0. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zarr 2.4.0. -----. Python 3.8.5 (default, Jul 23 2020, 15:50:11) [Clang 11.0.3 (clang-1103.0.32.62)]. macOS-10.15.6-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2020-07-30 19:28. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1343
https://github.com/scverse/scanpy/pull/1343:68,modifiability,depend,dependency,68,"I was thinking we could go a bit further. We could add `sinfo` as a dependency and make `print_versions` just call: `sinfo.sinfo(dependencies=True)` which will always be comprehensive. <details>. <summary> Example output: </summary>. ```. -----. IPython 7.16.1. scanpy 1.5.2.dev38+g6728bdab. sinfo 0.3.1. -----. IPython 7.16.1. PIL 7.2.0. anndata 0.7.5.dev0+g58886f0.d20200729. asciitree NA. backcall 0.2.0. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. dask 2.21.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.2. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.33.0. louvain 0.7.0. matplotlib 3.3.0. monotonic NA. mpl_toolkits NA. msgpack 1.0.0. natsort 7.0.1. numba 0.50.1. numcodecs 0.6.4. numexpr 2.7.1. numpy 1.19.0. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 2.4.7. pytz 2020.1. scanpy 1.5.2.dev38+g6728bdab. scipy 1.5.1. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.2. tlz 0.10.0. toolz 0.10.0. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zarr 2.4.0. -----. Python 3.8.5 (default, Jul 23 2020, 15:50:11) [Clang 11.0.3 (clang-1103.0.32.62)]. macOS-10.15.6-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2020-07-30 19:28. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1343
https://github.com/scverse/scanpy/pull/1343:129,modifiability,depend,dependencies,129,"I was thinking we could go a bit further. We could add `sinfo` as a dependency and make `print_versions` just call: `sinfo.sinfo(dependencies=True)` which will always be comprehensive. <details>. <summary> Example output: </summary>. ```. -----. IPython 7.16.1. scanpy 1.5.2.dev38+g6728bdab. sinfo 0.3.1. -----. IPython 7.16.1. PIL 7.2.0. anndata 0.7.5.dev0+g58886f0.d20200729. asciitree NA. backcall 0.2.0. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. dask 2.21.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.2. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.33.0. louvain 0.7.0. matplotlib 3.3.0. monotonic NA. mpl_toolkits NA. msgpack 1.0.0. natsort 7.0.1. numba 0.50.1. numcodecs 0.6.4. numexpr 2.7.1. numpy 1.19.0. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 2.4.7. pytz 2020.1. scanpy 1.5.2.dev38+g6728bdab. scipy 1.5.1. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.2. tlz 0.10.0. toolz 0.10.0. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zarr 2.4.0. -----. Python 3.8.5 (default, Jul 23 2020, 15:50:11) [Clang 11.0.3 (clang-1103.0.32.62)]. macOS-10.15.6-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2020-07-30 19:28. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1343
https://github.com/scverse/scanpy/pull/1343:519,modifiability,deco,decorator,519,"I was thinking we could go a bit further. We could add `sinfo` as a dependency and make `print_versions` just call: `sinfo.sinfo(dependencies=True)` which will always be comprehensive. <details>. <summary> Example output: </summary>. ```. -----. IPython 7.16.1. scanpy 1.5.2.dev38+g6728bdab. sinfo 0.3.1. -----. IPython 7.16.1. PIL 7.2.0. anndata 0.7.5.dev0+g58886f0.d20200729. asciitree NA. backcall 0.2.0. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. dask 2.21.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.2. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.33.0. louvain 0.7.0. matplotlib 3.3.0. monotonic NA. mpl_toolkits NA. msgpack 1.0.0. natsort 7.0.1. numba 0.50.1. numcodecs 0.6.4. numexpr 2.7.1. numpy 1.19.0. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 2.4.7. pytz 2020.1. scanpy 1.5.2.dev38+g6728bdab. scipy 1.5.1. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.2. tlz 0.10.0. toolz 0.10.0. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zarr 2.4.0. -----. Python 3.8.5 (default, Jul 23 2020, 15:50:11) [Clang 11.0.3 (clang-1103.0.32.62)]. macOS-10.15.6-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2020-07-30 19:28. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1343
https://github.com/scverse/scanpy/pull/1343:884,modifiability,pac,packaging,884,"I was thinking we could go a bit further. We could add `sinfo` as a dependency and make `print_versions` just call: `sinfo.sinfo(dependencies=True)` which will always be comprehensive. <details>. <summary> Example output: </summary>. ```. -----. IPython 7.16.1. scanpy 1.5.2.dev38+g6728bdab. sinfo 0.3.1. -----. IPython 7.16.1. PIL 7.2.0. anndata 0.7.5.dev0+g58886f0.d20200729. asciitree NA. backcall 0.2.0. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. dask 2.21.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.2. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.33.0. louvain 0.7.0. matplotlib 3.3.0. monotonic NA. mpl_toolkits NA. msgpack 1.0.0. natsort 7.0.1. numba 0.50.1. numcodecs 0.6.4. numexpr 2.7.1. numpy 1.19.0. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 2.4.7. pytz 2020.1. scanpy 1.5.2.dev38+g6728bdab. scipy 1.5.1. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.2. tlz 0.10.0. toolz 0.10.0. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zarr 2.4.0. -----. Python 3.8.5 (default, Jul 23 2020, 15:50:11) [Clang 11.0.3 (clang-1103.0.32.62)]. macOS-10.15.6-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2020-07-30 19:28. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1343
https://github.com/scverse/scanpy/pull/1343:1496,performance,CPU,CPU,1496,"I was thinking we could go a bit further. We could add `sinfo` as a dependency and make `print_versions` just call: `sinfo.sinfo(dependencies=True)` which will always be comprehensive. <details>. <summary> Example output: </summary>. ```. -----. IPython 7.16.1. scanpy 1.5.2.dev38+g6728bdab. sinfo 0.3.1. -----. IPython 7.16.1. PIL 7.2.0. anndata 0.7.5.dev0+g58886f0.d20200729. asciitree NA. backcall 0.2.0. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. dask 2.21.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.2. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.33.0. louvain 0.7.0. matplotlib 3.3.0. monotonic NA. mpl_toolkits NA. msgpack 1.0.0. natsort 7.0.1. numba 0.50.1. numcodecs 0.6.4. numexpr 2.7.1. numpy 1.19.0. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 2.4.7. pytz 2020.1. scanpy 1.5.2.dev38+g6728bdab. scipy 1.5.1. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.2. tlz 0.10.0. toolz 0.10.0. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zarr 2.4.0. -----. Python 3.8.5 (default, Jul 23 2020, 15:50:11) [Clang 11.0.3 (clang-1103.0.32.62)]. macOS-10.15.6-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2020-07-30 19:28. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1343
https://github.com/scverse/scanpy/pull/1343:68,safety,depend,dependency,68,"I was thinking we could go a bit further. We could add `sinfo` as a dependency and make `print_versions` just call: `sinfo.sinfo(dependencies=True)` which will always be comprehensive. <details>. <summary> Example output: </summary>. ```. -----. IPython 7.16.1. scanpy 1.5.2.dev38+g6728bdab. sinfo 0.3.1. -----. IPython 7.16.1. PIL 7.2.0. anndata 0.7.5.dev0+g58886f0.d20200729. asciitree NA. backcall 0.2.0. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. dask 2.21.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.2. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.33.0. louvain 0.7.0. matplotlib 3.3.0. monotonic NA. mpl_toolkits NA. msgpack 1.0.0. natsort 7.0.1. numba 0.50.1. numcodecs 0.6.4. numexpr 2.7.1. numpy 1.19.0. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 2.4.7. pytz 2020.1. scanpy 1.5.2.dev38+g6728bdab. scipy 1.5.1. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.2. tlz 0.10.0. toolz 0.10.0. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zarr 2.4.0. -----. Python 3.8.5 (default, Jul 23 2020, 15:50:11) [Clang 11.0.3 (clang-1103.0.32.62)]. macOS-10.15.6-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2020-07-30 19:28. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1343
https://github.com/scverse/scanpy/pull/1343:129,safety,depend,dependencies,129,"I was thinking we could go a bit further. We could add `sinfo` as a dependency and make `print_versions` just call: `sinfo.sinfo(dependencies=True)` which will always be comprehensive. <details>. <summary> Example output: </summary>. ```. -----. IPython 7.16.1. scanpy 1.5.2.dev38+g6728bdab. sinfo 0.3.1. -----. IPython 7.16.1. PIL 7.2.0. anndata 0.7.5.dev0+g58886f0.d20200729. asciitree NA. backcall 0.2.0. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. dask 2.21.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.2. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.33.0. louvain 0.7.0. matplotlib 3.3.0. monotonic NA. mpl_toolkits NA. msgpack 1.0.0. natsort 7.0.1. numba 0.50.1. numcodecs 0.6.4. numexpr 2.7.1. numpy 1.19.0. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 2.4.7. pytz 2020.1. scanpy 1.5.2.dev38+g6728bdab. scipy 1.5.1. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.2. tlz 0.10.0. toolz 0.10.0. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zarr 2.4.0. -----. Python 3.8.5 (default, Jul 23 2020, 15:50:11) [Clang 11.0.3 (clang-1103.0.32.62)]. macOS-10.15.6-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2020-07-30 19:28. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1343
https://github.com/scverse/scanpy/pull/1343:1488,safety,log,logical,1488,"I was thinking we could go a bit further. We could add `sinfo` as a dependency and make `print_versions` just call: `sinfo.sinfo(dependencies=True)` which will always be comprehensive. <details>. <summary> Example output: </summary>. ```. -----. IPython 7.16.1. scanpy 1.5.2.dev38+g6728bdab. sinfo 0.3.1. -----. IPython 7.16.1. PIL 7.2.0. anndata 0.7.5.dev0+g58886f0.d20200729. asciitree NA. backcall 0.2.0. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. dask 2.21.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.2. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.33.0. louvain 0.7.0. matplotlib 3.3.0. monotonic NA. mpl_toolkits NA. msgpack 1.0.0. natsort 7.0.1. numba 0.50.1. numcodecs 0.6.4. numexpr 2.7.1. numpy 1.19.0. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 2.4.7. pytz 2020.1. scanpy 1.5.2.dev38+g6728bdab. scipy 1.5.1. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.2. tlz 0.10.0. toolz 0.10.0. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zarr 2.4.0. -----. Python 3.8.5 (default, Jul 23 2020, 15:50:11) [Clang 11.0.3 (clang-1103.0.32.62)]. macOS-10.15.6-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2020-07-30 19:28. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1343
https://github.com/scverse/scanpy/pull/1343:1540,safety,updat,updated,1540,"I was thinking we could go a bit further. We could add `sinfo` as a dependency and make `print_versions` just call: `sinfo.sinfo(dependencies=True)` which will always be comprehensive. <details>. <summary> Example output: </summary>. ```. -----. IPython 7.16.1. scanpy 1.5.2.dev38+g6728bdab. sinfo 0.3.1. -----. IPython 7.16.1. PIL 7.2.0. anndata 0.7.5.dev0+g58886f0.d20200729. asciitree NA. backcall 0.2.0. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. dask 2.21.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.2. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.33.0. louvain 0.7.0. matplotlib 3.3.0. monotonic NA. mpl_toolkits NA. msgpack 1.0.0. natsort 7.0.1. numba 0.50.1. numcodecs 0.6.4. numexpr 2.7.1. numpy 1.19.0. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 2.4.7. pytz 2020.1. scanpy 1.5.2.dev38+g6728bdab. scipy 1.5.1. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.2. tlz 0.10.0. toolz 0.10.0. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zarr 2.4.0. -----. Python 3.8.5 (default, Jul 23 2020, 15:50:11) [Clang 11.0.3 (clang-1103.0.32.62)]. macOS-10.15.6-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2020-07-30 19:28. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1343
https://github.com/scverse/scanpy/pull/1343:1488,security,log,logical,1488,"I was thinking we could go a bit further. We could add `sinfo` as a dependency and make `print_versions` just call: `sinfo.sinfo(dependencies=True)` which will always be comprehensive. <details>. <summary> Example output: </summary>. ```. -----. IPython 7.16.1. scanpy 1.5.2.dev38+g6728bdab. sinfo 0.3.1. -----. IPython 7.16.1. PIL 7.2.0. anndata 0.7.5.dev0+g58886f0.d20200729. asciitree NA. backcall 0.2.0. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. dask 2.21.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.2. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.33.0. louvain 0.7.0. matplotlib 3.3.0. monotonic NA. mpl_toolkits NA. msgpack 1.0.0. natsort 7.0.1. numba 0.50.1. numcodecs 0.6.4. numexpr 2.7.1. numpy 1.19.0. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 2.4.7. pytz 2020.1. scanpy 1.5.2.dev38+g6728bdab. scipy 1.5.1. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.2. tlz 0.10.0. toolz 0.10.0. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zarr 2.4.0. -----. Python 3.8.5 (default, Jul 23 2020, 15:50:11) [Clang 11.0.3 (clang-1103.0.32.62)]. macOS-10.15.6-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2020-07-30 19:28. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1343
https://github.com/scverse/scanpy/pull/1343:1520,security,Session,Session,1520,"I was thinking we could go a bit further. We could add `sinfo` as a dependency and make `print_versions` just call: `sinfo.sinfo(dependencies=True)` which will always be comprehensive. <details>. <summary> Example output: </summary>. ```. -----. IPython 7.16.1. scanpy 1.5.2.dev38+g6728bdab. sinfo 0.3.1. -----. IPython 7.16.1. PIL 7.2.0. anndata 0.7.5.dev0+g58886f0.d20200729. asciitree NA. backcall 0.2.0. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. dask 2.21.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.2. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.33.0. louvain 0.7.0. matplotlib 3.3.0. monotonic NA. mpl_toolkits NA. msgpack 1.0.0. natsort 7.0.1. numba 0.50.1. numcodecs 0.6.4. numexpr 2.7.1. numpy 1.19.0. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 2.4.7. pytz 2020.1. scanpy 1.5.2.dev38+g6728bdab. scipy 1.5.1. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.2. tlz 0.10.0. toolz 0.10.0. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zarr 2.4.0. -----. Python 3.8.5 (default, Jul 23 2020, 15:50:11) [Clang 11.0.3 (clang-1103.0.32.62)]. macOS-10.15.6-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2020-07-30 19:28. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1343
https://github.com/scverse/scanpy/pull/1343:1540,security,updat,updated,1540,"I was thinking we could go a bit further. We could add `sinfo` as a dependency and make `print_versions` just call: `sinfo.sinfo(dependencies=True)` which will always be comprehensive. <details>. <summary> Example output: </summary>. ```. -----. IPython 7.16.1. scanpy 1.5.2.dev38+g6728bdab. sinfo 0.3.1. -----. IPython 7.16.1. PIL 7.2.0. anndata 0.7.5.dev0+g58886f0.d20200729. asciitree NA. backcall 0.2.0. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. dask 2.21.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.2. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.33.0. louvain 0.7.0. matplotlib 3.3.0. monotonic NA. mpl_toolkits NA. msgpack 1.0.0. natsort 7.0.1. numba 0.50.1. numcodecs 0.6.4. numexpr 2.7.1. numpy 1.19.0. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 2.4.7. pytz 2020.1. scanpy 1.5.2.dev38+g6728bdab. scipy 1.5.1. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.2. tlz 0.10.0. toolz 0.10.0. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zarr 2.4.0. -----. Python 3.8.5 (default, Jul 23 2020, 15:50:11) [Clang 11.0.3 (clang-1103.0.32.62)]. macOS-10.15.6-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2020-07-30 19:28. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1343
https://github.com/scverse/scanpy/pull/1343:68,testability,depend,dependency,68,"I was thinking we could go a bit further. We could add `sinfo` as a dependency and make `print_versions` just call: `sinfo.sinfo(dependencies=True)` which will always be comprehensive. <details>. <summary> Example output: </summary>. ```. -----. IPython 7.16.1. scanpy 1.5.2.dev38+g6728bdab. sinfo 0.3.1. -----. IPython 7.16.1. PIL 7.2.0. anndata 0.7.5.dev0+g58886f0.d20200729. asciitree NA. backcall 0.2.0. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. dask 2.21.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.2. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.33.0. louvain 0.7.0. matplotlib 3.3.0. monotonic NA. mpl_toolkits NA. msgpack 1.0.0. natsort 7.0.1. numba 0.50.1. numcodecs 0.6.4. numexpr 2.7.1. numpy 1.19.0. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 2.4.7. pytz 2020.1. scanpy 1.5.2.dev38+g6728bdab. scipy 1.5.1. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.2. tlz 0.10.0. toolz 0.10.0. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zarr 2.4.0. -----. Python 3.8.5 (default, Jul 23 2020, 15:50:11) [Clang 11.0.3 (clang-1103.0.32.62)]. macOS-10.15.6-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2020-07-30 19:28. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1343
https://github.com/scverse/scanpy/pull/1343:129,testability,depend,dependencies,129,"I was thinking we could go a bit further. We could add `sinfo` as a dependency and make `print_versions` just call: `sinfo.sinfo(dependencies=True)` which will always be comprehensive. <details>. <summary> Example output: </summary>. ```. -----. IPython 7.16.1. scanpy 1.5.2.dev38+g6728bdab. sinfo 0.3.1. -----. IPython 7.16.1. PIL 7.2.0. anndata 0.7.5.dev0+g58886f0.d20200729. asciitree NA. backcall 0.2.0. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. dask 2.21.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.2. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.33.0. louvain 0.7.0. matplotlib 3.3.0. monotonic NA. mpl_toolkits NA. msgpack 1.0.0. natsort 7.0.1. numba 0.50.1. numcodecs 0.6.4. numexpr 2.7.1. numpy 1.19.0. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 2.4.7. pytz 2020.1. scanpy 1.5.2.dev38+g6728bdab. scipy 1.5.1. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.2. tlz 0.10.0. toolz 0.10.0. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zarr 2.4.0. -----. Python 3.8.5 (default, Jul 23 2020, 15:50:11) [Clang 11.0.3 (clang-1103.0.32.62)]. macOS-10.15.6-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2020-07-30 19:28. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1343
https://github.com/scverse/scanpy/pull/1343:1488,testability,log,logical,1488,"I was thinking we could go a bit further. We could add `sinfo` as a dependency and make `print_versions` just call: `sinfo.sinfo(dependencies=True)` which will always be comprehensive. <details>. <summary> Example output: </summary>. ```. -----. IPython 7.16.1. scanpy 1.5.2.dev38+g6728bdab. sinfo 0.3.1. -----. IPython 7.16.1. PIL 7.2.0. anndata 0.7.5.dev0+g58886f0.d20200729. asciitree NA. backcall 0.2.0. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. dask 2.21.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.2. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.33.0. louvain 0.7.0. matplotlib 3.3.0. monotonic NA. mpl_toolkits NA. msgpack 1.0.0. natsort 7.0.1. numba 0.50.1. numcodecs 0.6.4. numexpr 2.7.1. numpy 1.19.0. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 2.4.7. pytz 2020.1. scanpy 1.5.2.dev38+g6728bdab. scipy 1.5.1. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.2. tlz 0.10.0. toolz 0.10.0. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zarr 2.4.0. -----. Python 3.8.5 (default, Jul 23 2020, 15:50:11) [Clang 11.0.3 (clang-1103.0.32.62)]. macOS-10.15.6-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2020-07-30 19:28. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1343
https://github.com/scverse/scanpy/pull/1343:1270,usability,tool,toolz,1270,"I was thinking we could go a bit further. We could add `sinfo` as a dependency and make `print_versions` just call: `sinfo.sinfo(dependencies=True)` which will always be comprehensive. <details>. <summary> Example output: </summary>. ```. -----. IPython 7.16.1. scanpy 1.5.2.dev38+g6728bdab. sinfo 0.3.1. -----. IPython 7.16.1. PIL 7.2.0. anndata 0.7.5.dev0+g58886f0.d20200729. asciitree NA. backcall 0.2.0. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. dask 2.21.0. dateutil 2.8.1. decorator 4.4.2. fasteners NA. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.2. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.33.0. louvain 0.7.0. matplotlib 3.3.0. monotonic NA. mpl_toolkits NA. msgpack 1.0.0. natsort 7.0.1. numba 0.50.1. numcodecs 0.6.4. numexpr 2.7.1. numpy 1.19.0. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 2.4.7. pytz 2020.1. scanpy 1.5.2.dev38+g6728bdab. scipy 1.5.1. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.2. tlz 0.10.0. toolz 0.10.0. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zarr 2.4.0. -----. Python 3.8.5 (default, Jul 23 2020, 15:50:11) [Clang 11.0.3 (clang-1103.0.32.62)]. macOS-10.15.6-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2020-07-30 19:28. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1343
https://github.com/scverse/scanpy/pull/1343:14,energy efficiency,cool,cool,14,"That would be cool. If we add a lot of text though, we need to improve the issue template too, people just dont understand where to put their text.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1343
https://github.com/scverse/scanpy/pull/1343:113,testability,understand,understand,113,"That would be cool. If we add a lot of text though, we need to improve the issue template too, people just dont understand where to put their text.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1343
https://github.com/scverse/scanpy/pull/1343:43,integrability,wrap,wrap,43,"How would you change it? I'd probably just wrap the section that says ""paste here"" with a `<details>` tag.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1343
https://github.com/scverse/scanpy/pull/1343:23,deployability,manag,manage,23,"Yeah, but people often manage to delete the ```` ``` ```` and so on. Maybe we can write it in a way even people who dont know markdown know what exactly to replace. Maybe some text like Please replace this text (and only the text) with your (traceback|code|version output)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1343
https://github.com/scverse/scanpy/pull/1343:259,deployability,version,version,259,"Yeah, but people often manage to delete the ```` ``` ```` and so on. Maybe we can write it in a way even people who dont know markdown know what exactly to replace. Maybe some text like Please replace this text (and only the text) with your (traceback|code|version output)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1343
https://github.com/scverse/scanpy/pull/1343:23,energy efficiency,manag,manage,23,"Yeah, but people often manage to delete the ```` ``` ```` and so on. Maybe we can write it in a way even people who dont know markdown know what exactly to replace. Maybe some text like Please replace this text (and only the text) with your (traceback|code|version output)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1343
https://github.com/scverse/scanpy/pull/1343:259,integrability,version,version,259,"Yeah, but people often manage to delete the ```` ``` ```` and so on. Maybe we can write it in a way even people who dont know markdown know what exactly to replace. Maybe some text like Please replace this text (and only the text) with your (traceback|code|version output)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1343
https://github.com/scverse/scanpy/pull/1343:259,modifiability,version,version,259,"Yeah, but people often manage to delete the ```` ``` ```` and so on. Maybe we can write it in a way even people who dont know markdown know what exactly to replace. Maybe some text like Please replace this text (and only the text) with your (traceback|code|version output)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1343
https://github.com/scverse/scanpy/pull/1343:23,safety,manag,manage,23,"Yeah, but people often manage to delete the ```` ``` ```` and so on. Maybe we can write it in a way even people who dont know markdown know what exactly to replace. Maybe some text like Please replace this text (and only the text) with your (traceback|code|version output)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1343
https://github.com/scverse/scanpy/pull/1343:244,testability,trace,traceback,244,"Yeah, but people often manage to delete the ```` ``` ```` and so on. Maybe we can write it in a way even people who dont know markdown know what exactly to replace. Maybe some text like Please replace this text (and only the text) with your (traceback|code|version output)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1343
https://github.com/scverse/scanpy/pull/1343:124,deployability,version,versions,124,"I guess I'm not too worried about the formatting being off, since that's easy to fix. It's so much harder to guess software versions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1343
https://github.com/scverse/scanpy/pull/1343:124,integrability,version,versions,124,"I guess I'm not too worried about the formatting being off, since that's easy to fix. It's so much harder to guess software versions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1343
https://github.com/scverse/scanpy/pull/1343:38,interoperability,format,formatting,38,"I guess I'm not too worried about the formatting being off, since that's easy to fix. It's so much harder to guess software versions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1343
https://github.com/scverse/scanpy/pull/1343:124,modifiability,version,versions,124,"I guess I'm not too worried about the formatting being off, since that's easy to fix. It's so much harder to guess software versions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1343
https://github.com/scverse/scanpy/pull/1343:6,usability,guid,guide,6,"Their guide is also applicable to us, even if it uses a lot of pandas examples.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1343
https://github.com/scverse/scanpy/pull/1344:5,availability,ping,ping,5,Also ping @flying-sheep since I believe you wrote the initial version.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:62,deployability,version,version,62,Also ping @flying-sheep since I believe you wrote the initial version.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:62,integrability,version,version,62,Also ping @flying-sheep since I believe you wrote the initial version.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:62,modifiability,version,version,62,Also ping @flying-sheep since I believe you wrote the initial version.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:18,deployability,depend,depend,18,Shouldnt we just depend on `requests` if its so complicated and we have to resort to code copying? Basically every Python user should have it installed anyway.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:144,deployability,instal,installed,144,Shouldnt we just depend on `requests` if its so complicated and we have to resort to code copying? Basically every Python user should have it installed anyway.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:18,integrability,depend,depend,18,Shouldnt we just depend on `requests` if its so complicated and we have to resort to code copying? Basically every Python user should have it installed anyway.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:18,modifiability,depend,depend,18,Shouldnt we just depend on `requests` if its so complicated and we have to resort to code copying? Basically every Python user should have it installed anyway.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:18,safety,depend,depend,18,Shouldnt we just depend on `requests` if its so complicated and we have to resort to code copying? Basically every Python user should have it installed anyway.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:50,safety,compl,complicated,50,Shouldnt we just depend on `requests` if its so complicated and we have to resort to code copying? Basically every Python user should have it installed anyway.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:50,security,compl,complicated,50,Shouldnt we just depend on `requests` if its so complicated and we have to resort to code copying? Basically every Python user should have it installed anyway.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:18,testability,depend,depend,18,Shouldnt we just depend on `requests` if its so complicated and we have to resort to code copying? Basically every Python user should have it installed anyway.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:124,usability,user,user,124,Shouldnt we just depend on `requests` if its so complicated and we have to resort to code copying? Basically every Python user should have it installed anyway.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:123,deployability,updat,update,123,"I looked into that, but I'm not sure it actually makes this any less complicated. The issue is getting the `tqdm` thing to update, and requests would need all of the same logic to do that as far as I can tell. Plus, at that point it's copying from stack overflow vs. copying from python's stdlib. You'd think this would be a convenience function somewhere. Or you'd think that `urlretrieve` could take a `Request` object.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:171,deployability,log,logic,171,"I looked into that, but I'm not sure it actually makes this any less complicated. The issue is getting the `tqdm` thing to update, and requests would need all of the same logic to do that as far as I can tell. Plus, at that point it's copying from stack overflow vs. copying from python's stdlib. You'd think this would be a convenience function somewhere. Or you'd think that `urlretrieve` could take a `Request` object.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:248,deployability,stack,stack,248,"I looked into that, but I'm not sure it actually makes this any less complicated. The issue is getting the `tqdm` thing to update, and requests would need all of the same logic to do that as far as I can tell. Plus, at that point it's copying from stack overflow vs. copying from python's stdlib. You'd think this would be a convenience function somewhere. Or you'd think that `urlretrieve` could take a `Request` object.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:69,safety,compl,complicated,69,"I looked into that, but I'm not sure it actually makes this any less complicated. The issue is getting the `tqdm` thing to update, and requests would need all of the same logic to do that as far as I can tell. Plus, at that point it's copying from stack overflow vs. copying from python's stdlib. You'd think this would be a convenience function somewhere. Or you'd think that `urlretrieve` could take a `Request` object.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:123,safety,updat,update,123,"I looked into that, but I'm not sure it actually makes this any less complicated. The issue is getting the `tqdm` thing to update, and requests would need all of the same logic to do that as far as I can tell. Plus, at that point it's copying from stack overflow vs. copying from python's stdlib. You'd think this would be a convenience function somewhere. Or you'd think that `urlretrieve` could take a `Request` object.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:171,safety,log,logic,171,"I looked into that, but I'm not sure it actually makes this any less complicated. The issue is getting the `tqdm` thing to update, and requests would need all of the same logic to do that as far as I can tell. Plus, at that point it's copying from stack overflow vs. copying from python's stdlib. You'd think this would be a convenience function somewhere. Or you'd think that `urlretrieve` could take a `Request` object.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:69,security,compl,complicated,69,"I looked into that, but I'm not sure it actually makes this any less complicated. The issue is getting the `tqdm` thing to update, and requests would need all of the same logic to do that as far as I can tell. Plus, at that point it's copying from stack overflow vs. copying from python's stdlib. You'd think this would be a convenience function somewhere. Or you'd think that `urlretrieve` could take a `Request` object.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:123,security,updat,update,123,"I looked into that, but I'm not sure it actually makes this any less complicated. The issue is getting the `tqdm` thing to update, and requests would need all of the same logic to do that as far as I can tell. Plus, at that point it's copying from stack overflow vs. copying from python's stdlib. You'd think this would be a convenience function somewhere. Or you'd think that `urlretrieve` could take a `Request` object.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:171,security,log,logic,171,"I looked into that, but I'm not sure it actually makes this any less complicated. The issue is getting the `tqdm` thing to update, and requests would need all of the same logic to do that as far as I can tell. Plus, at that point it's copying from stack overflow vs. copying from python's stdlib. You'd think this would be a convenience function somewhere. Or you'd think that `urlretrieve` could take a `Request` object.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:171,testability,log,logic,171,"I looked into that, but I'm not sure it actually makes this any less complicated. The issue is getting the `tqdm` thing to update, and requests would need all of the same logic to do that as far as I can tell. Plus, at that point it's copying from stack overflow vs. copying from python's stdlib. You'd think this would be a convenience function somewhere. Or you'd think that `urlretrieve` could take a `Request` object.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:99,deployability,stack,stackoverflow,99,"Requests makes everything rather convenient, thats its main appeal. Example for our case: https://stackoverflow.com/a/62113293/247482",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:229,deployability,version,version,229,"When we first discussed this with @Mirkazemi , we were also thinking about `requests`, but we weren't sure how would you feel guys of having to include this as a requirement. Can't contribute much but would also go on with Isaac version which wouldn't require that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:229,integrability,version,version,229,"When we first discussed this with @Mirkazemi , we were also thinking about `requests`, but we weren't sure how would you feel guys of having to include this as a requirement. Can't contribute much but would also go on with Isaac version which wouldn't require that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:229,modifiability,version,version,229,"When we first discussed this with @Mirkazemi , we were also thinking about `requests`, but we weren't sure how would you feel guys of having to include this as a requirement. Can't contribute much but would also go on with Isaac version which wouldn't require that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:79,deployability,depend,dependency,79,"Its more code we have to maintain. If I had to decide between adding a common dependency, feature regression, or complex code, Id go with the first one.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:79,integrability,depend,dependency,79,"Its more code we have to maintain. If I had to decide between adding a common dependency, feature regression, or complex code, Id go with the first one.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:26,modifiability,maintain,maintain,26,"Its more code we have to maintain. If I had to decide between adding a common dependency, feature regression, or complex code, Id go with the first one.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:79,modifiability,depend,dependency,79,"Its more code we have to maintain. If I had to decide between adding a common dependency, feature regression, or complex code, Id go with the first one.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:26,safety,maintain,maintain,26,"Its more code we have to maintain. If I had to decide between adding a common dependency, feature regression, or complex code, Id go with the first one.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:79,safety,depend,dependency,79,"Its more code we have to maintain. If I had to decide between adding a common dependency, feature regression, or complex code, Id go with the first one.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:114,safety,compl,complex,114,"Its more code we have to maintain. If I had to decide between adding a common dependency, feature regression, or complex code, Id go with the first one.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:114,security,compl,complex,114,"Its more code we have to maintain. If I had to decide between adding a common dependency, feature regression, or complex code, Id go with the first one.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:79,testability,depend,dependency,79,"Its more code we have to maintain. If I had to decide between adding a common dependency, feature regression, or complex code, Id go with the first one.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:99,testability,regress,regression,99,"Its more code we have to maintain. If I had to decide between adding a common dependency, feature regression, or complex code, Id go with the first one.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:186,usability,close,close,186,"To me, the code looks pretty equivalent. Since I've run into issues with unexpected defaults in some of the requests developers libraries, I'm more comfortable sticking with code that's close to what we've had before. . I will shorten the code a bit though",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/issues/1346:368,testability,assert,assert,368,"Thanks for the report! I believe the results should be the same for multiple runs. Could you provide an example of this? I'm having a bit of trouble reproducing. Here's what I ran:. ```python. import scanpy as sc. import numpy as np. pbmc = sc.datasets.pbmc68k_reduced(). a = pbmc.copy(). b = pbmc.copy(). sc.pp.regress_out(a, ""phase""). sc.pp.regress_out(b, ""phase""). assert np.array_equal(a.X, b.X). assert not np.array_equal(a.X, pbmc.X). ```. Is this what you meant?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1346
https://github.com/scverse/scanpy/issues/1346:401,testability,assert,assert,401,"Thanks for the report! I believe the results should be the same for multiple runs. Could you provide an example of this? I'm having a bit of trouble reproducing. Here's what I ran:. ```python. import scanpy as sc. import numpy as np. pbmc = sc.datasets.pbmc68k_reduced(). a = pbmc.copy(). b = pbmc.copy(). sc.pp.regress_out(a, ""phase""). sc.pp.regress_out(b, ""phase""). assert np.array_equal(a.X, b.X). assert not np.array_equal(a.X, pbmc.X). ```. Is this what you meant?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1346
https://github.com/scverse/scanpy/issues/1346:52,usability,close,close,52,"As we haven't heard back after the question we will close the issue for now, hopefully you obtained the expected behaviour in the end :). However, please don't hesitate to reopen this issue or create a new one if you have any more questions or run into any related problems in the future. Thanks for being a part of our community! :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1346
https://github.com/scverse/scanpy/issues/1346:113,usability,behavi,behaviour,113,"As we haven't heard back after the question we will close the issue for now, hopefully you obtained the expected behaviour in the end :). However, please don't hesitate to reopen this issue or create a new one if you have any more questions or run into any related problems in the future. Thanks for being a part of our community! :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1346
https://github.com/scverse/scanpy/issues/1347:107,availability,cluster,clustering,107,Indeed is a pun on `scampi`. I also think that the body segments of the shrimp should resemble single cell clustering. ![image](https://user-images.githubusercontent.com/4964309/89010761-7fc7eb80-d30f-11ea-9eda-616cd9661055.png).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1347
https://github.com/scverse/scanpy/issues/1347:107,deployability,cluster,clustering,107,Indeed is a pun on `scampi`. I also think that the body segments of the shrimp should resemble single cell clustering. ![image](https://user-images.githubusercontent.com/4964309/89010761-7fc7eb80-d30f-11ea-9eda-616cd9661055.png).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1347
https://github.com/scverse/scanpy/issues/1347:136,usability,user,user-images,136,Indeed is a pun on `scampi`. I also think that the body segments of the shrimp should resemble single cell clustering. ![image](https://user-images.githubusercontent.com/4964309/89010761-7fc7eb80-d30f-11ea-9eda-616cd9661055.png).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1347
https://github.com/scverse/scanpy/issues/1347:73,deployability,log,logo,73,"Yeah, Alex came up with the name and I came up with the idea to make the logo a shrimp. I think it was the logos designer [Daniela Barreto from sdakzente](http://suedakzente.de/) who came up with the body-segments-are-cells idea, but it might also have been one of us, as we were floating ideas about combining something techy with something biological in the logo. The logo page is here btw: https://scverse.org/scanpy/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1347
https://github.com/scverse/scanpy/issues/1347:107,deployability,log,logo,107,"Yeah, Alex came up with the name and I came up with the idea to make the logo a shrimp. I think it was the logos designer [Daniela Barreto from sdakzente](http://suedakzente.de/) who came up with the body-segments-are-cells idea, but it might also have been one of us, as we were floating ideas about combining something techy with something biological in the logo. The logo page is here btw: https://scverse.org/scanpy/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1347
https://github.com/scverse/scanpy/issues/1347:362,deployability,log,logo,362,"Yeah, Alex came up with the name and I came up with the idea to make the logo a shrimp. I think it was the logos designer [Daniela Barreto from sdakzente](http://suedakzente.de/) who came up with the body-segments-are-cells idea, but it might also have been one of us, as we were floating ideas about combining something techy with something biological in the logo. The logo page is here btw: https://scverse.org/scanpy/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1347
https://github.com/scverse/scanpy/issues/1347:372,deployability,log,logo,372,"Yeah, Alex came up with the name and I came up with the idea to make the logo a shrimp. I think it was the logos designer [Daniela Barreto from sdakzente](http://suedakzente.de/) who came up with the body-segments-are-cells idea, but it might also have been one of us, as we were floating ideas about combining something techy with something biological in the logo. The logo page is here btw: https://scverse.org/scanpy/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1347
https://github.com/scverse/scanpy/issues/1347:73,safety,log,logo,73,"Yeah, Alex came up with the name and I came up with the idea to make the logo a shrimp. I think it was the logos designer [Daniela Barreto from sdakzente](http://suedakzente.de/) who came up with the body-segments-are-cells idea, but it might also have been one of us, as we were floating ideas about combining something techy with something biological in the logo. The logo page is here btw: https://scverse.org/scanpy/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1347
https://github.com/scverse/scanpy/issues/1347:107,safety,log,logo,107,"Yeah, Alex came up with the name and I came up with the idea to make the logo a shrimp. I think it was the logos designer [Daniela Barreto from sdakzente](http://suedakzente.de/) who came up with the body-segments-are-cells idea, but it might also have been one of us, as we were floating ideas about combining something techy with something biological in the logo. The logo page is here btw: https://scverse.org/scanpy/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1347
https://github.com/scverse/scanpy/issues/1347:362,safety,log,logo,362,"Yeah, Alex came up with the name and I came up with the idea to make the logo a shrimp. I think it was the logos designer [Daniela Barreto from sdakzente](http://suedakzente.de/) who came up with the body-segments-are-cells idea, but it might also have been one of us, as we were floating ideas about combining something techy with something biological in the logo. The logo page is here btw: https://scverse.org/scanpy/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1347
https://github.com/scverse/scanpy/issues/1347:372,safety,log,logo,372,"Yeah, Alex came up with the name and I came up with the idea to make the logo a shrimp. I think it was the logos designer [Daniela Barreto from sdakzente](http://suedakzente.de/) who came up with the body-segments-are-cells idea, but it might also have been one of us, as we were floating ideas about combining something techy with something biological in the logo. The logo page is here btw: https://scverse.org/scanpy/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1347
https://github.com/scverse/scanpy/issues/1347:73,security,log,logo,73,"Yeah, Alex came up with the name and I came up with the idea to make the logo a shrimp. I think it was the logos designer [Daniela Barreto from sdakzente](http://suedakzente.de/) who came up with the body-segments-are-cells idea, but it might also have been one of us, as we were floating ideas about combining something techy with something biological in the logo. The logo page is here btw: https://scverse.org/scanpy/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1347
https://github.com/scverse/scanpy/issues/1347:107,security,log,logo,107,"Yeah, Alex came up with the name and I came up with the idea to make the logo a shrimp. I think it was the logos designer [Daniela Barreto from sdakzente](http://suedakzente.de/) who came up with the body-segments-are-cells idea, but it might also have been one of us, as we were floating ideas about combining something techy with something biological in the logo. The logo page is here btw: https://scverse.org/scanpy/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1347
https://github.com/scverse/scanpy/issues/1347:362,security,log,logo,362,"Yeah, Alex came up with the name and I came up with the idea to make the logo a shrimp. I think it was the logos designer [Daniela Barreto from sdakzente](http://suedakzente.de/) who came up with the body-segments-are-cells idea, but it might also have been one of us, as we were floating ideas about combining something techy with something biological in the logo. The logo page is here btw: https://scverse.org/scanpy/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1347
https://github.com/scverse/scanpy/issues/1347:372,security,log,logo,372,"Yeah, Alex came up with the name and I came up with the idea to make the logo a shrimp. I think it was the logos designer [Daniela Barreto from sdakzente](http://suedakzente.de/) who came up with the body-segments-are-cells idea, but it might also have been one of us, as we were floating ideas about combining something techy with something biological in the logo. The logo page is here btw: https://scverse.org/scanpy/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1347
https://github.com/scverse/scanpy/issues/1347:73,testability,log,logo,73,"Yeah, Alex came up with the name and I came up with the idea to make the logo a shrimp. I think it was the logos designer [Daniela Barreto from sdakzente](http://suedakzente.de/) who came up with the body-segments-are-cells idea, but it might also have been one of us, as we were floating ideas about combining something techy with something biological in the logo. The logo page is here btw: https://scverse.org/scanpy/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1347
https://github.com/scverse/scanpy/issues/1347:107,testability,log,logo,107,"Yeah, Alex came up with the name and I came up with the idea to make the logo a shrimp. I think it was the logos designer [Daniela Barreto from sdakzente](http://suedakzente.de/) who came up with the body-segments-are-cells idea, but it might also have been one of us, as we were floating ideas about combining something techy with something biological in the logo. The logo page is here btw: https://scverse.org/scanpy/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1347
https://github.com/scverse/scanpy/issues/1347:362,testability,log,logo,362,"Yeah, Alex came up with the name and I came up with the idea to make the logo a shrimp. I think it was the logos designer [Daniela Barreto from sdakzente](http://suedakzente.de/) who came up with the body-segments-are-cells idea, but it might also have been one of us, as we were floating ideas about combining something techy with something biological in the logo. The logo page is here btw: https://scverse.org/scanpy/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1347
https://github.com/scverse/scanpy/issues/1347:372,testability,log,logo,372,"Yeah, Alex came up with the name and I came up with the idea to make the logo a shrimp. I think it was the logos designer [Daniela Barreto from sdakzente](http://suedakzente.de/) who came up with the body-segments-are-cells idea, but it might also have been one of us, as we were floating ideas about combining something techy with something biological in the logo. The logo page is here btw: https://scverse.org/scanpy/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1347
https://github.com/scverse/scanpy/issues/1347:69,deployability,log,logo,69,thanks for the question and the answer. I have been interpreting the logo as an ant for 7 years.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1347
https://github.com/scverse/scanpy/issues/1347:69,safety,log,logo,69,thanks for the question and the answer. I have been interpreting the logo as an ant for 7 years.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1347
https://github.com/scverse/scanpy/issues/1347:69,security,log,logo,69,thanks for the question and the answer. I have been interpreting the logo as an ant for 7 years.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1347
https://github.com/scverse/scanpy/issues/1347:69,testability,log,logo,69,thanks for the question and the answer. I have been interpreting the logo as an ant for 7 years.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1347
https://github.com/scverse/scanpy/pull/1348:50,usability,user,users,50,Alex and I thought that it's pretty unlikely most users import anndata. I prefer how ergonomic it is to have fewer namespaces to deal with. Plus we do re-export almost everything else from anndata here already.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1348
https://github.com/scverse/scanpy/pull/1348:74,usability,prefer,prefer,74,Alex and I thought that it's pretty unlikely most users import anndata. I prefer how ergonomic it is to have fewer namespaces to deal with. Plus we do re-export almost everything else from anndata here already.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1348
https://github.com/scverse/scanpy/pull/1348:85,usability,ergonom,ergonomic,85,Alex and I thought that it's pretty unlikely most users import anndata. I prefer how ergonomic it is to have fewer namespaces to deal with. Plus we do re-export almost everything else from anndata here already.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1348
https://github.com/scverse/scanpy/pull/1348:41,deployability,API,API,41,"That is, we should have a section in the API overview that is headed ""anndata functionality"" or something similar: . ![image](https://user-images.githubusercontent.com/16916678/89020732-b0178600-d31f-11ea-9c10-dd99afe36ab4.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1348
https://github.com/scverse/scanpy/pull/1348:41,integrability,API,API,41,"That is, we should have a section in the API overview that is headed ""anndata functionality"" or something similar: . ![image](https://user-images.githubusercontent.com/16916678/89020732-b0178600-d31f-11ea-9c10-dd99afe36ab4.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1348
https://github.com/scverse/scanpy/pull/1348:41,interoperability,API,API,41,"That is, we should have a section in the API overview that is headed ""anndata functionality"" or something similar: . ![image](https://user-images.githubusercontent.com/16916678/89020732-b0178600-d31f-11ea-9c10-dd99afe36ab4.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1348
https://github.com/scverse/scanpy/pull/1348:134,usability,user,user-images,134,"That is, we should have a section in the API overview that is headed ""anndata functionality"" or something similar: . ![image](https://user-images.githubusercontent.com/16916678/89020732-b0178600-d31f-11ea-9c10-dd99afe36ab4.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1348
https://github.com/scverse/scanpy/pull/1349:11,deployability,Updat,Updating,11,"Thank you. Updating and releasing a new scanpydoc version is very simple:. First you make and check out your changes in scanpydocs own documentation, like in any sphinx project:. ```console. $ $EDITOR scanpydoc/theme/static/css/scanpy.css. [hack away]. $ cd docs. $ make html. $ $BROWSER _build/html/index.html. [check if it looks right]. ```. Then you can very quickly commit, tag, and release:. ```console. $ git add scanpydoc/theme/static/css/scanpy.css. $ git commit -m 'Made layout even wider (o________o)'. $ git tag v0.5.1 # Dont forget the v! $ flit publish. ```. Thats literally all.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1349
https://github.com/scverse/scanpy/pull/1349:24,deployability,releas,releasing,24,"Thank you. Updating and releasing a new scanpydoc version is very simple:. First you make and check out your changes in scanpydocs own documentation, like in any sphinx project:. ```console. $ $EDITOR scanpydoc/theme/static/css/scanpy.css. [hack away]. $ cd docs. $ make html. $ $BROWSER _build/html/index.html. [check if it looks right]. ```. Then you can very quickly commit, tag, and release:. ```console. $ git add scanpydoc/theme/static/css/scanpy.css. $ git commit -m 'Made layout even wider (o________o)'. $ git tag v0.5.1 # Dont forget the v! $ flit publish. ```. Thats literally all.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1349
https://github.com/scverse/scanpy/pull/1349:50,deployability,version,version,50,"Thank you. Updating and releasing a new scanpydoc version is very simple:. First you make and check out your changes in scanpydocs own documentation, like in any sphinx project:. ```console. $ $EDITOR scanpydoc/theme/static/css/scanpy.css. [hack away]. $ cd docs. $ make html. $ $BROWSER _build/html/index.html. [check if it looks right]. ```. Then you can very quickly commit, tag, and release:. ```console. $ git add scanpydoc/theme/static/css/scanpy.css. $ git commit -m 'Made layout even wider (o________o)'. $ git tag v0.5.1 # Dont forget the v! $ flit publish. ```. Thats literally all.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1349
https://github.com/scverse/scanpy/pull/1349:388,deployability,releas,release,388,"Thank you. Updating and releasing a new scanpydoc version is very simple:. First you make and check out your changes in scanpydocs own documentation, like in any sphinx project:. ```console. $ $EDITOR scanpydoc/theme/static/css/scanpy.css. [hack away]. $ cd docs. $ make html. $ $BROWSER _build/html/index.html. [check if it looks right]. ```. Then you can very quickly commit, tag, and release:. ```console. $ git add scanpydoc/theme/static/css/scanpy.css. $ git commit -m 'Made layout even wider (o________o)'. $ git tag v0.5.1 # Dont forget the v! $ flit publish. ```. Thats literally all.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1349
https://github.com/scverse/scanpy/pull/1349:50,integrability,version,version,50,"Thank you. Updating and releasing a new scanpydoc version is very simple:. First you make and check out your changes in scanpydocs own documentation, like in any sphinx project:. ```console. $ $EDITOR scanpydoc/theme/static/css/scanpy.css. [hack away]. $ cd docs. $ make html. $ $BROWSER _build/html/index.html. [check if it looks right]. ```. Then you can very quickly commit, tag, and release:. ```console. $ git add scanpydoc/theme/static/css/scanpy.css. $ git commit -m 'Made layout even wider (o________o)'. $ git tag v0.5.1 # Dont forget the v! $ flit publish. ```. Thats literally all.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1349
https://github.com/scverse/scanpy/pull/1349:562,integrability,pub,publish,562,"Thank you. Updating and releasing a new scanpydoc version is very simple:. First you make and check out your changes in scanpydocs own documentation, like in any sphinx project:. ```console. $ $EDITOR scanpydoc/theme/static/css/scanpy.css. [hack away]. $ cd docs. $ make html. $ $BROWSER _build/html/index.html. [check if it looks right]. ```. Then you can very quickly commit, tag, and release:. ```console. $ git add scanpydoc/theme/static/css/scanpy.css. $ git commit -m 'Made layout even wider (o________o)'. $ git tag v0.5.1 # Dont forget the v! $ flit publish. ```. Thats literally all.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1349
https://github.com/scverse/scanpy/pull/1349:50,modifiability,version,version,50,"Thank you. Updating and releasing a new scanpydoc version is very simple:. First you make and check out your changes in scanpydocs own documentation, like in any sphinx project:. ```console. $ $EDITOR scanpydoc/theme/static/css/scanpy.css. [hack away]. $ cd docs. $ make html. $ $BROWSER _build/html/index.html. [check if it looks right]. ```. Then you can very quickly commit, tag, and release:. ```console. $ git add scanpydoc/theme/static/css/scanpy.css. $ git commit -m 'Made layout even wider (o________o)'. $ git tag v0.5.1 # Dont forget the v! $ flit publish. ```. Thats literally all.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1349
https://github.com/scverse/scanpy/pull/1349:11,safety,Updat,Updating,11,"Thank you. Updating and releasing a new scanpydoc version is very simple:. First you make and check out your changes in scanpydocs own documentation, like in any sphinx project:. ```console. $ $EDITOR scanpydoc/theme/static/css/scanpy.css. [hack away]. $ cd docs. $ make html. $ $BROWSER _build/html/index.html. [check if it looks right]. ```. Then you can very quickly commit, tag, and release:. ```console. $ git add scanpydoc/theme/static/css/scanpy.css. $ git commit -m 'Made layout even wider (o________o)'. $ git tag v0.5.1 # Dont forget the v! $ flit publish. ```. Thats literally all.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1349
https://github.com/scverse/scanpy/pull/1349:11,security,Updat,Updating,11,"Thank you. Updating and releasing a new scanpydoc version is very simple:. First you make and check out your changes in scanpydocs own documentation, like in any sphinx project:. ```console. $ $EDITOR scanpydoc/theme/static/css/scanpy.css. [hack away]. $ cd docs. $ make html. $ $BROWSER _build/html/index.html. [check if it looks right]. ```. Then you can very quickly commit, tag, and release:. ```console. $ git add scanpydoc/theme/static/css/scanpy.css. $ git commit -m 'Made layout even wider (o________o)'. $ git tag v0.5.1 # Dont forget the v! $ flit publish. ```. Thats literally all.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1349
https://github.com/scverse/scanpy/pull/1349:242,security,hack,hack,242,"Thank you. Updating and releasing a new scanpydoc version is very simple:. First you make and check out your changes in scanpydocs own documentation, like in any sphinx project:. ```console. $ $EDITOR scanpydoc/theme/static/css/scanpy.css. [hack away]. $ cd docs. $ make html. $ $BROWSER _build/html/index.html. [check if it looks right]. ```. Then you can very quickly commit, tag, and release:. ```console. $ git add scanpydoc/theme/static/css/scanpy.css. $ git commit -m 'Made layout even wider (o________o)'. $ git tag v0.5.1 # Dont forget the v! $ flit publish. ```. Thats literally all.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1349
https://github.com/scverse/scanpy/pull/1349:66,testability,simpl,simple,66,"Thank you. Updating and releasing a new scanpydoc version is very simple:. First you make and check out your changes in scanpydocs own documentation, like in any sphinx project:. ```console. $ $EDITOR scanpydoc/theme/static/css/scanpy.css. [hack away]. $ cd docs. $ make html. $ $BROWSER _build/html/index.html. [check if it looks right]. ```. Then you can very quickly commit, tag, and release:. ```console. $ git add scanpydoc/theme/static/css/scanpy.css. $ git commit -m 'Made layout even wider (o________o)'. $ git tag v0.5.1 # Dont forget the v! $ flit publish. ```. Thats literally all.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1349
https://github.com/scverse/scanpy/pull/1349:66,usability,simpl,simple,66,"Thank you. Updating and releasing a new scanpydoc version is very simple:. First you make and check out your changes in scanpydocs own documentation, like in any sphinx project:. ```console. $ $EDITOR scanpydoc/theme/static/css/scanpy.css. [hack away]. $ cd docs. $ make html. $ $BROWSER _build/html/index.html. [check if it looks right]. ```. Then you can very quickly commit, tag, and release:. ```console. $ git add scanpydoc/theme/static/css/scanpy.css. $ git commit -m 'Made layout even wider (o________o)'. $ git tag v0.5.1 # Dont forget the v! $ flit publish. ```. Thats literally all.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1349
https://github.com/scverse/scanpy/pull/1349:136,usability,document,documentation,136,"Thank you. Updating and releasing a new scanpydoc version is very simple:. First you make and check out your changes in scanpydocs own documentation, like in any sphinx project:. ```console. $ $EDITOR scanpydoc/theme/static/css/scanpy.css. [hack away]. $ cd docs. $ make html. $ $BROWSER _build/html/index.html. [check if it looks right]. ```. Then you can very quickly commit, tag, and release:. ```console. $ git add scanpydoc/theme/static/css/scanpy.css. $ git commit -m 'Made layout even wider (o________o)'. $ git tag v0.5.1 # Dont forget the v! $ flit publish. ```. Thats literally all.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1349
https://github.com/scverse/scanpy/issues/1351:336,availability,error,error,336,"That problem occurs within h5py (we just wrap the underlying OSError) and isnt a consequence of how scanpy uses h5py. The relevant part of the traceback is:. ```pytb. OSError: Can't read data (file read failed:. time = Sat Aug 1 13:27:54 2020,. filename = '/path.../filtered_gene_bc_matrices.h5ad',. file descriptor = 47,. errno = 5,. error message = 'Input/output error',. buf = 0x55ec782e9031,. total read size = 7011,. bytes this sub-read = 7011,. bytes actually read = 18446744073709551615,. offset = 0). ```. The reported filename looks weird: `'/path.../filtered_gene_bc_matrices.h5ad'`. Is that file on some network share or colab or so? Because thatd explain wonky I/O. 18 exabytes (18 quintillion bytes!) read seems really off too! I assume `self.group[""data""][...]` tries to read all the data for `.X` and some bug or connection problem tells h5py that theres 18 exabytes. h5py then asks the OS to give them those 18 exabytes which the OS politely denies. See also:. - https://github.com/googlecolab/colabtools/issues/559. - https://forum.hdfgroup.org/t/errors-accessing-hdf5-over-cifs-and-or-nfs/6341",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:366,availability,error,error,366,"That problem occurs within h5py (we just wrap the underlying OSError) and isnt a consequence of how scanpy uses h5py. The relevant part of the traceback is:. ```pytb. OSError: Can't read data (file read failed:. time = Sat Aug 1 13:27:54 2020,. filename = '/path.../filtered_gene_bc_matrices.h5ad',. file descriptor = 47,. errno = 5,. error message = 'Input/output error',. buf = 0x55ec782e9031,. total read size = 7011,. bytes this sub-read = 7011,. bytes actually read = 18446744073709551615,. offset = 0). ```. The reported filename looks weird: `'/path.../filtered_gene_bc_matrices.h5ad'`. Is that file on some network share or colab or so? Because thatd explain wonky I/O. 18 exabytes (18 quintillion bytes!) read seems really off too! I assume `self.group[""data""][...]` tries to read all the data for `.X` and some bug or connection problem tells h5py that theres 18 exabytes. h5py then asks the OS to give them those 18 exabytes which the OS politely denies. See also:. - https://github.com/googlecolab/colabtools/issues/559. - https://forum.hdfgroup.org/t/errors-accessing-hdf5-over-cifs-and-or-nfs/6341",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:1067,availability,error,errors-accessing-,1067,"That problem occurs within h5py (we just wrap the underlying OSError) and isnt a consequence of how scanpy uses h5py. The relevant part of the traceback is:. ```pytb. OSError: Can't read data (file read failed:. time = Sat Aug 1 13:27:54 2020,. filename = '/path.../filtered_gene_bc_matrices.h5ad',. file descriptor = 47,. errno = 5,. error message = 'Input/output error',. buf = 0x55ec782e9031,. total read size = 7011,. bytes this sub-read = 7011,. bytes actually read = 18446744073709551615,. offset = 0). ```. The reported filename looks weird: `'/path.../filtered_gene_bc_matrices.h5ad'`. Is that file on some network share or colab or so? Because thatd explain wonky I/O. 18 exabytes (18 quintillion bytes!) read seems really off too! I assume `self.group[""data""][...]` tries to read all the data for `.X` and some bug or connection problem tells h5py that theres 18 exabytes. h5py then asks the OS to give them those 18 exabytes which the OS politely denies. See also:. - https://github.com/googlecolab/colabtools/issues/559. - https://forum.hdfgroup.org/t/errors-accessing-hdf5-over-cifs-and-or-nfs/6341",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:204,deployability,fail,failed,204,"That problem occurs within h5py (we just wrap the underlying OSError) and isnt a consequence of how scanpy uses h5py. The relevant part of the traceback is:. ```pytb. OSError: Can't read data (file read failed:. time = Sat Aug 1 13:27:54 2020,. filename = '/path.../filtered_gene_bc_matrices.h5ad',. file descriptor = 47,. errno = 5,. error message = 'Input/output error',. buf = 0x55ec782e9031,. total read size = 7011,. bytes this sub-read = 7011,. bytes actually read = 18446744073709551615,. offset = 0). ```. The reported filename looks weird: `'/path.../filtered_gene_bc_matrices.h5ad'`. Is that file on some network share or colab or so? Because thatd explain wonky I/O. 18 exabytes (18 quintillion bytes!) read seems really off too! I assume `self.group[""data""][...]` tries to read all the data for `.X` and some bug or connection problem tells h5py that theres 18 exabytes. h5py then asks the OS to give them those 18 exabytes which the OS politely denies. See also:. - https://github.com/googlecolab/colabtools/issues/559. - https://forum.hdfgroup.org/t/errors-accessing-hdf5-over-cifs-and-or-nfs/6341",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:41,integrability,wrap,wrap,41,"That problem occurs within h5py (we just wrap the underlying OSError) and isnt a consequence of how scanpy uses h5py. The relevant part of the traceback is:. ```pytb. OSError: Can't read data (file read failed:. time = Sat Aug 1 13:27:54 2020,. filename = '/path.../filtered_gene_bc_matrices.h5ad',. file descriptor = 47,. errno = 5,. error message = 'Input/output error',. buf = 0x55ec782e9031,. total read size = 7011,. bytes this sub-read = 7011,. bytes actually read = 18446744073709551615,. offset = 0). ```. The reported filename looks weird: `'/path.../filtered_gene_bc_matrices.h5ad'`. Is that file on some network share or colab or so? Because thatd explain wonky I/O. 18 exabytes (18 quintillion bytes!) read seems really off too! I assume `self.group[""data""][...]` tries to read all the data for `.X` and some bug or connection problem tells h5py that theres 18 exabytes. h5py then asks the OS to give them those 18 exabytes which the OS politely denies. See also:. - https://github.com/googlecolab/colabtools/issues/559. - https://forum.hdfgroup.org/t/errors-accessing-hdf5-over-cifs-and-or-nfs/6341",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:342,integrability,messag,message,342,"That problem occurs within h5py (we just wrap the underlying OSError) and isnt a consequence of how scanpy uses h5py. The relevant part of the traceback is:. ```pytb. OSError: Can't read data (file read failed:. time = Sat Aug 1 13:27:54 2020,. filename = '/path.../filtered_gene_bc_matrices.h5ad',. file descriptor = 47,. errno = 5,. error message = 'Input/output error',. buf = 0x55ec782e9031,. total read size = 7011,. bytes this sub-read = 7011,. bytes actually read = 18446744073709551615,. offset = 0). ```. The reported filename looks weird: `'/path.../filtered_gene_bc_matrices.h5ad'`. Is that file on some network share or colab or so? Because thatd explain wonky I/O. 18 exabytes (18 quintillion bytes!) read seems really off too! I assume `self.group[""data""][...]` tries to read all the data for `.X` and some bug or connection problem tells h5py that theres 18 exabytes. h5py then asks the OS to give them those 18 exabytes which the OS politely denies. See also:. - https://github.com/googlecolab/colabtools/issues/559. - https://forum.hdfgroup.org/t/errors-accessing-hdf5-over-cifs-and-or-nfs/6341",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:434,integrability,sub,sub-read,434,"That problem occurs within h5py (we just wrap the underlying OSError) and isnt a consequence of how scanpy uses h5py. The relevant part of the traceback is:. ```pytb. OSError: Can't read data (file read failed:. time = Sat Aug 1 13:27:54 2020,. filename = '/path.../filtered_gene_bc_matrices.h5ad',. file descriptor = 47,. errno = 5,. error message = 'Input/output error',. buf = 0x55ec782e9031,. total read size = 7011,. bytes this sub-read = 7011,. bytes actually read = 18446744073709551615,. offset = 0). ```. The reported filename looks weird: `'/path.../filtered_gene_bc_matrices.h5ad'`. Is that file on some network share or colab or so? Because thatd explain wonky I/O. 18 exabytes (18 quintillion bytes!) read seems really off too! I assume `self.group[""data""][...]` tries to read all the data for `.X` and some bug or connection problem tells h5py that theres 18 exabytes. h5py then asks the OS to give them those 18 exabytes which the OS politely denies. See also:. - https://github.com/googlecolab/colabtools/issues/559. - https://forum.hdfgroup.org/t/errors-accessing-hdf5-over-cifs-and-or-nfs/6341",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:342,interoperability,messag,message,342,"That problem occurs within h5py (we just wrap the underlying OSError) and isnt a consequence of how scanpy uses h5py. The relevant part of the traceback is:. ```pytb. OSError: Can't read data (file read failed:. time = Sat Aug 1 13:27:54 2020,. filename = '/path.../filtered_gene_bc_matrices.h5ad',. file descriptor = 47,. errno = 5,. error message = 'Input/output error',. buf = 0x55ec782e9031,. total read size = 7011,. bytes this sub-read = 7011,. bytes actually read = 18446744073709551615,. offset = 0). ```. The reported filename looks weird: `'/path.../filtered_gene_bc_matrices.h5ad'`. Is that file on some network share or colab or so? Because thatd explain wonky I/O. 18 exabytes (18 quintillion bytes!) read seems really off too! I assume `self.group[""data""][...]` tries to read all the data for `.X` and some bug or connection problem tells h5py that theres 18 exabytes. h5py then asks the OS to give them those 18 exabytes which the OS politely denies. See also:. - https://github.com/googlecolab/colabtools/issues/559. - https://forum.hdfgroup.org/t/errors-accessing-hdf5-over-cifs-and-or-nfs/6341",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:624,interoperability,share,share,624,"That problem occurs within h5py (we just wrap the underlying OSError) and isnt a consequence of how scanpy uses h5py. The relevant part of the traceback is:. ```pytb. OSError: Can't read data (file read failed:. time = Sat Aug 1 13:27:54 2020,. filename = '/path.../filtered_gene_bc_matrices.h5ad',. file descriptor = 47,. errno = 5,. error message = 'Input/output error',. buf = 0x55ec782e9031,. total read size = 7011,. bytes this sub-read = 7011,. bytes actually read = 18446744073709551615,. offset = 0). ```. The reported filename looks weird: `'/path.../filtered_gene_bc_matrices.h5ad'`. Is that file on some network share or colab or so? Because thatd explain wonky I/O. 18 exabytes (18 quintillion bytes!) read seems really off too! I assume `self.group[""data""][...]` tries to read all the data for `.X` and some bug or connection problem tells h5py that theres 18 exabytes. h5py then asks the OS to give them those 18 exabytes which the OS politely denies. See also:. - https://github.com/googlecolab/colabtools/issues/559. - https://forum.hdfgroup.org/t/errors-accessing-hdf5-over-cifs-and-or-nfs/6341",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:213,performance,time,time,213,"That problem occurs within h5py (we just wrap the underlying OSError) and isnt a consequence of how scanpy uses h5py. The relevant part of the traceback is:. ```pytb. OSError: Can't read data (file read failed:. time = Sat Aug 1 13:27:54 2020,. filename = '/path.../filtered_gene_bc_matrices.h5ad',. file descriptor = 47,. errno = 5,. error message = 'Input/output error',. buf = 0x55ec782e9031,. total read size = 7011,. bytes this sub-read = 7011,. bytes actually read = 18446744073709551615,. offset = 0). ```. The reported filename looks weird: `'/path.../filtered_gene_bc_matrices.h5ad'`. Is that file on some network share or colab or so? Because thatd explain wonky I/O. 18 exabytes (18 quintillion bytes!) read seems really off too! I assume `self.group[""data""][...]` tries to read all the data for `.X` and some bug or connection problem tells h5py that theres 18 exabytes. h5py then asks the OS to give them those 18 exabytes which the OS politely denies. See also:. - https://github.com/googlecolab/colabtools/issues/559. - https://forum.hdfgroup.org/t/errors-accessing-hdf5-over-cifs-and-or-nfs/6341",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:336,performance,error,error,336,"That problem occurs within h5py (we just wrap the underlying OSError) and isnt a consequence of how scanpy uses h5py. The relevant part of the traceback is:. ```pytb. OSError: Can't read data (file read failed:. time = Sat Aug 1 13:27:54 2020,. filename = '/path.../filtered_gene_bc_matrices.h5ad',. file descriptor = 47,. errno = 5,. error message = 'Input/output error',. buf = 0x55ec782e9031,. total read size = 7011,. bytes this sub-read = 7011,. bytes actually read = 18446744073709551615,. offset = 0). ```. The reported filename looks weird: `'/path.../filtered_gene_bc_matrices.h5ad'`. Is that file on some network share or colab or so? Because thatd explain wonky I/O. 18 exabytes (18 quintillion bytes!) read seems really off too! I assume `self.group[""data""][...]` tries to read all the data for `.X` and some bug or connection problem tells h5py that theres 18 exabytes. h5py then asks the OS to give them those 18 exabytes which the OS politely denies. See also:. - https://github.com/googlecolab/colabtools/issues/559. - https://forum.hdfgroup.org/t/errors-accessing-hdf5-over-cifs-and-or-nfs/6341",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:366,performance,error,error,366,"That problem occurs within h5py (we just wrap the underlying OSError) and isnt a consequence of how scanpy uses h5py. The relevant part of the traceback is:. ```pytb. OSError: Can't read data (file read failed:. time = Sat Aug 1 13:27:54 2020,. filename = '/path.../filtered_gene_bc_matrices.h5ad',. file descriptor = 47,. errno = 5,. error message = 'Input/output error',. buf = 0x55ec782e9031,. total read size = 7011,. bytes this sub-read = 7011,. bytes actually read = 18446744073709551615,. offset = 0). ```. The reported filename looks weird: `'/path.../filtered_gene_bc_matrices.h5ad'`. Is that file on some network share or colab or so? Because thatd explain wonky I/O. 18 exabytes (18 quintillion bytes!) read seems really off too! I assume `self.group[""data""][...]` tries to read all the data for `.X` and some bug or connection problem tells h5py that theres 18 exabytes. h5py then asks the OS to give them those 18 exabytes which the OS politely denies. See also:. - https://github.com/googlecolab/colabtools/issues/559. - https://forum.hdfgroup.org/t/errors-accessing-hdf5-over-cifs-and-or-nfs/6341",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:616,performance,network,network,616,"That problem occurs within h5py (we just wrap the underlying OSError) and isnt a consequence of how scanpy uses h5py. The relevant part of the traceback is:. ```pytb. OSError: Can't read data (file read failed:. time = Sat Aug 1 13:27:54 2020,. filename = '/path.../filtered_gene_bc_matrices.h5ad',. file descriptor = 47,. errno = 5,. error message = 'Input/output error',. buf = 0x55ec782e9031,. total read size = 7011,. bytes this sub-read = 7011,. bytes actually read = 18446744073709551615,. offset = 0). ```. The reported filename looks weird: `'/path.../filtered_gene_bc_matrices.h5ad'`. Is that file on some network share or colab or so? Because thatd explain wonky I/O. 18 exabytes (18 quintillion bytes!) read seems really off too! I assume `self.group[""data""][...]` tries to read all the data for `.X` and some bug or connection problem tells h5py that theres 18 exabytes. h5py then asks the OS to give them those 18 exabytes which the OS politely denies. See also:. - https://github.com/googlecolab/colabtools/issues/559. - https://forum.hdfgroup.org/t/errors-accessing-hdf5-over-cifs-and-or-nfs/6341",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:675,performance,I/O,I/O,675,"That problem occurs within h5py (we just wrap the underlying OSError) and isnt a consequence of how scanpy uses h5py. The relevant part of the traceback is:. ```pytb. OSError: Can't read data (file read failed:. time = Sat Aug 1 13:27:54 2020,. filename = '/path.../filtered_gene_bc_matrices.h5ad',. file descriptor = 47,. errno = 5,. error message = 'Input/output error',. buf = 0x55ec782e9031,. total read size = 7011,. bytes this sub-read = 7011,. bytes actually read = 18446744073709551615,. offset = 0). ```. The reported filename looks weird: `'/path.../filtered_gene_bc_matrices.h5ad'`. Is that file on some network share or colab or so? Because thatd explain wonky I/O. 18 exabytes (18 quintillion bytes!) read seems really off too! I assume `self.group[""data""][...]` tries to read all the data for `.X` and some bug or connection problem tells h5py that theres 18 exabytes. h5py then asks the OS to give them those 18 exabytes which the OS politely denies. See also:. - https://github.com/googlecolab/colabtools/issues/559. - https://forum.hdfgroup.org/t/errors-accessing-hdf5-over-cifs-and-or-nfs/6341",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:1067,performance,error,errors-accessing-,1067,"That problem occurs within h5py (we just wrap the underlying OSError) and isnt a consequence of how scanpy uses h5py. The relevant part of the traceback is:. ```pytb. OSError: Can't read data (file read failed:. time = Sat Aug 1 13:27:54 2020,. filename = '/path.../filtered_gene_bc_matrices.h5ad',. file descriptor = 47,. errno = 5,. error message = 'Input/output error',. buf = 0x55ec782e9031,. total read size = 7011,. bytes this sub-read = 7011,. bytes actually read = 18446744073709551615,. offset = 0). ```. The reported filename looks weird: `'/path.../filtered_gene_bc_matrices.h5ad'`. Is that file on some network share or colab or so? Because thatd explain wonky I/O. 18 exabytes (18 quintillion bytes!) read seems really off too! I assume `self.group[""data""][...]` tries to read all the data for `.X` and some bug or connection problem tells h5py that theres 18 exabytes. h5py then asks the OS to give them those 18 exabytes which the OS politely denies. See also:. - https://github.com/googlecolab/colabtools/issues/559. - https://forum.hdfgroup.org/t/errors-accessing-hdf5-over-cifs-and-or-nfs/6341",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:204,reliability,fail,failed,204,"That problem occurs within h5py (we just wrap the underlying OSError) and isnt a consequence of how scanpy uses h5py. The relevant part of the traceback is:. ```pytb. OSError: Can't read data (file read failed:. time = Sat Aug 1 13:27:54 2020,. filename = '/path.../filtered_gene_bc_matrices.h5ad',. file descriptor = 47,. errno = 5,. error message = 'Input/output error',. buf = 0x55ec782e9031,. total read size = 7011,. bytes this sub-read = 7011,. bytes actually read = 18446744073709551615,. offset = 0). ```. The reported filename looks weird: `'/path.../filtered_gene_bc_matrices.h5ad'`. Is that file on some network share or colab or so? Because thatd explain wonky I/O. 18 exabytes (18 quintillion bytes!) read seems really off too! I assume `self.group[""data""][...]` tries to read all the data for `.X` and some bug or connection problem tells h5py that theres 18 exabytes. h5py then asks the OS to give them those 18 exabytes which the OS politely denies. See also:. - https://github.com/googlecolab/colabtools/issues/559. - https://forum.hdfgroup.org/t/errors-accessing-hdf5-over-cifs-and-or-nfs/6341",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:336,safety,error,error,336,"That problem occurs within h5py (we just wrap the underlying OSError) and isnt a consequence of how scanpy uses h5py. The relevant part of the traceback is:. ```pytb. OSError: Can't read data (file read failed:. time = Sat Aug 1 13:27:54 2020,. filename = '/path.../filtered_gene_bc_matrices.h5ad',. file descriptor = 47,. errno = 5,. error message = 'Input/output error',. buf = 0x55ec782e9031,. total read size = 7011,. bytes this sub-read = 7011,. bytes actually read = 18446744073709551615,. offset = 0). ```. The reported filename looks weird: `'/path.../filtered_gene_bc_matrices.h5ad'`. Is that file on some network share or colab or so? Because thatd explain wonky I/O. 18 exabytes (18 quintillion bytes!) read seems really off too! I assume `self.group[""data""][...]` tries to read all the data for `.X` and some bug or connection problem tells h5py that theres 18 exabytes. h5py then asks the OS to give them those 18 exabytes which the OS politely denies. See also:. - https://github.com/googlecolab/colabtools/issues/559. - https://forum.hdfgroup.org/t/errors-accessing-hdf5-over-cifs-and-or-nfs/6341",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:353,safety,Input,Input,353,"That problem occurs within h5py (we just wrap the underlying OSError) and isnt a consequence of how scanpy uses h5py. The relevant part of the traceback is:. ```pytb. OSError: Can't read data (file read failed:. time = Sat Aug 1 13:27:54 2020,. filename = '/path.../filtered_gene_bc_matrices.h5ad',. file descriptor = 47,. errno = 5,. error message = 'Input/output error',. buf = 0x55ec782e9031,. total read size = 7011,. bytes this sub-read = 7011,. bytes actually read = 18446744073709551615,. offset = 0). ```. The reported filename looks weird: `'/path.../filtered_gene_bc_matrices.h5ad'`. Is that file on some network share or colab or so? Because thatd explain wonky I/O. 18 exabytes (18 quintillion bytes!) read seems really off too! I assume `self.group[""data""][...]` tries to read all the data for `.X` and some bug or connection problem tells h5py that theres 18 exabytes. h5py then asks the OS to give them those 18 exabytes which the OS politely denies. See also:. - https://github.com/googlecolab/colabtools/issues/559. - https://forum.hdfgroup.org/t/errors-accessing-hdf5-over-cifs-and-or-nfs/6341",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:366,safety,error,error,366,"That problem occurs within h5py (we just wrap the underlying OSError) and isnt a consequence of how scanpy uses h5py. The relevant part of the traceback is:. ```pytb. OSError: Can't read data (file read failed:. time = Sat Aug 1 13:27:54 2020,. filename = '/path.../filtered_gene_bc_matrices.h5ad',. file descriptor = 47,. errno = 5,. error message = 'Input/output error',. buf = 0x55ec782e9031,. total read size = 7011,. bytes this sub-read = 7011,. bytes actually read = 18446744073709551615,. offset = 0). ```. The reported filename looks weird: `'/path.../filtered_gene_bc_matrices.h5ad'`. Is that file on some network share or colab or so? Because thatd explain wonky I/O. 18 exabytes (18 quintillion bytes!) read seems really off too! I assume `self.group[""data""][...]` tries to read all the data for `.X` and some bug or connection problem tells h5py that theres 18 exabytes. h5py then asks the OS to give them those 18 exabytes which the OS politely denies. See also:. - https://github.com/googlecolab/colabtools/issues/559. - https://forum.hdfgroup.org/t/errors-accessing-hdf5-over-cifs-and-or-nfs/6341",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:1067,safety,error,errors-accessing-,1067,"That problem occurs within h5py (we just wrap the underlying OSError) and isnt a consequence of how scanpy uses h5py. The relevant part of the traceback is:. ```pytb. OSError: Can't read data (file read failed:. time = Sat Aug 1 13:27:54 2020,. filename = '/path.../filtered_gene_bc_matrices.h5ad',. file descriptor = 47,. errno = 5,. error message = 'Input/output error',. buf = 0x55ec782e9031,. total read size = 7011,. bytes this sub-read = 7011,. bytes actually read = 18446744073709551615,. offset = 0). ```. The reported filename looks weird: `'/path.../filtered_gene_bc_matrices.h5ad'`. Is that file on some network share or colab or so? Because thatd explain wonky I/O. 18 exabytes (18 quintillion bytes!) read seems really off too! I assume `self.group[""data""][...]` tries to read all the data for `.X` and some bug or connection problem tells h5py that theres 18 exabytes. h5py then asks the OS to give them those 18 exabytes which the OS politely denies. See also:. - https://github.com/googlecolab/colabtools/issues/559. - https://forum.hdfgroup.org/t/errors-accessing-hdf5-over-cifs-and-or-nfs/6341",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:616,security,network,network,616,"That problem occurs within h5py (we just wrap the underlying OSError) and isnt a consequence of how scanpy uses h5py. The relevant part of the traceback is:. ```pytb. OSError: Can't read data (file read failed:. time = Sat Aug 1 13:27:54 2020,. filename = '/path.../filtered_gene_bc_matrices.h5ad',. file descriptor = 47,. errno = 5,. error message = 'Input/output error',. buf = 0x55ec782e9031,. total read size = 7011,. bytes this sub-read = 7011,. bytes actually read = 18446744073709551615,. offset = 0). ```. The reported filename looks weird: `'/path.../filtered_gene_bc_matrices.h5ad'`. Is that file on some network share or colab or so? Because thatd explain wonky I/O. 18 exabytes (18 quintillion bytes!) read seems really off too! I assume `self.group[""data""][...]` tries to read all the data for `.X` and some bug or connection problem tells h5py that theres 18 exabytes. h5py then asks the OS to give them those 18 exabytes which the OS politely denies. See also:. - https://github.com/googlecolab/colabtools/issues/559. - https://forum.hdfgroup.org/t/errors-accessing-hdf5-over-cifs-and-or-nfs/6341",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:1074,security,access,accessing-,1074,"That problem occurs within h5py (we just wrap the underlying OSError) and isnt a consequence of how scanpy uses h5py. The relevant part of the traceback is:. ```pytb. OSError: Can't read data (file read failed:. time = Sat Aug 1 13:27:54 2020,. filename = '/path.../filtered_gene_bc_matrices.h5ad',. file descriptor = 47,. errno = 5,. error message = 'Input/output error',. buf = 0x55ec782e9031,. total read size = 7011,. bytes this sub-read = 7011,. bytes actually read = 18446744073709551615,. offset = 0). ```. The reported filename looks weird: `'/path.../filtered_gene_bc_matrices.h5ad'`. Is that file on some network share or colab or so? Because thatd explain wonky I/O. 18 exabytes (18 quintillion bytes!) read seems really off too! I assume `self.group[""data""][...]` tries to read all the data for `.X` and some bug or connection problem tells h5py that theres 18 exabytes. h5py then asks the OS to give them those 18 exabytes which the OS politely denies. See also:. - https://github.com/googlecolab/colabtools/issues/559. - https://forum.hdfgroup.org/t/errors-accessing-hdf5-over-cifs-and-or-nfs/6341",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:144,testability,trace,traceback,144,"That problem occurs within h5py (we just wrap the underlying OSError) and isnt a consequence of how scanpy uses h5py. The relevant part of the traceback is:. ```pytb. OSError: Can't read data (file read failed:. time = Sat Aug 1 13:27:54 2020,. filename = '/path.../filtered_gene_bc_matrices.h5ad',. file descriptor = 47,. errno = 5,. error message = 'Input/output error',. buf = 0x55ec782e9031,. total read size = 7011,. bytes this sub-read = 7011,. bytes actually read = 18446744073709551615,. offset = 0). ```. The reported filename looks weird: `'/path.../filtered_gene_bc_matrices.h5ad'`. Is that file on some network share or colab or so? Because thatd explain wonky I/O. 18 exabytes (18 quintillion bytes!) read seems really off too! I assume `self.group[""data""][...]` tries to read all the data for `.X` and some bug or connection problem tells h5py that theres 18 exabytes. h5py then asks the OS to give them those 18 exabytes which the OS politely denies. See also:. - https://github.com/googlecolab/colabtools/issues/559. - https://forum.hdfgroup.org/t/errors-accessing-hdf5-over-cifs-and-or-nfs/6341",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:336,usability,error,error,336,"That problem occurs within h5py (we just wrap the underlying OSError) and isnt a consequence of how scanpy uses h5py. The relevant part of the traceback is:. ```pytb. OSError: Can't read data (file read failed:. time = Sat Aug 1 13:27:54 2020,. filename = '/path.../filtered_gene_bc_matrices.h5ad',. file descriptor = 47,. errno = 5,. error message = 'Input/output error',. buf = 0x55ec782e9031,. total read size = 7011,. bytes this sub-read = 7011,. bytes actually read = 18446744073709551615,. offset = 0). ```. The reported filename looks weird: `'/path.../filtered_gene_bc_matrices.h5ad'`. Is that file on some network share or colab or so? Because thatd explain wonky I/O. 18 exabytes (18 quintillion bytes!) read seems really off too! I assume `self.group[""data""][...]` tries to read all the data for `.X` and some bug or connection problem tells h5py that theres 18 exabytes. h5py then asks the OS to give them those 18 exabytes which the OS politely denies. See also:. - https://github.com/googlecolab/colabtools/issues/559. - https://forum.hdfgroup.org/t/errors-accessing-hdf5-over-cifs-and-or-nfs/6341",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:353,usability,Input,Input,353,"That problem occurs within h5py (we just wrap the underlying OSError) and isnt a consequence of how scanpy uses h5py. The relevant part of the traceback is:. ```pytb. OSError: Can't read data (file read failed:. time = Sat Aug 1 13:27:54 2020,. filename = '/path.../filtered_gene_bc_matrices.h5ad',. file descriptor = 47,. errno = 5,. error message = 'Input/output error',. buf = 0x55ec782e9031,. total read size = 7011,. bytes this sub-read = 7011,. bytes actually read = 18446744073709551615,. offset = 0). ```. The reported filename looks weird: `'/path.../filtered_gene_bc_matrices.h5ad'`. Is that file on some network share or colab or so? Because thatd explain wonky I/O. 18 exabytes (18 quintillion bytes!) read seems really off too! I assume `self.group[""data""][...]` tries to read all the data for `.X` and some bug or connection problem tells h5py that theres 18 exabytes. h5py then asks the OS to give them those 18 exabytes which the OS politely denies. See also:. - https://github.com/googlecolab/colabtools/issues/559. - https://forum.hdfgroup.org/t/errors-accessing-hdf5-over-cifs-and-or-nfs/6341",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:366,usability,error,error,366,"That problem occurs within h5py (we just wrap the underlying OSError) and isnt a consequence of how scanpy uses h5py. The relevant part of the traceback is:. ```pytb. OSError: Can't read data (file read failed:. time = Sat Aug 1 13:27:54 2020,. filename = '/path.../filtered_gene_bc_matrices.h5ad',. file descriptor = 47,. errno = 5,. error message = 'Input/output error',. buf = 0x55ec782e9031,. total read size = 7011,. bytes this sub-read = 7011,. bytes actually read = 18446744073709551615,. offset = 0). ```. The reported filename looks weird: `'/path.../filtered_gene_bc_matrices.h5ad'`. Is that file on some network share or colab or so? Because thatd explain wonky I/O. 18 exabytes (18 quintillion bytes!) read seems really off too! I assume `self.group[""data""][...]` tries to read all the data for `.X` and some bug or connection problem tells h5py that theres 18 exabytes. h5py then asks the OS to give them those 18 exabytes which the OS politely denies. See also:. - https://github.com/googlecolab/colabtools/issues/559. - https://forum.hdfgroup.org/t/errors-accessing-hdf5-over-cifs-and-or-nfs/6341",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:1067,usability,error,errors-accessing-,1067,"That problem occurs within h5py (we just wrap the underlying OSError) and isnt a consequence of how scanpy uses h5py. The relevant part of the traceback is:. ```pytb. OSError: Can't read data (file read failed:. time = Sat Aug 1 13:27:54 2020,. filename = '/path.../filtered_gene_bc_matrices.h5ad',. file descriptor = 47,. errno = 5,. error message = 'Input/output error',. buf = 0x55ec782e9031,. total read size = 7011,. bytes this sub-read = 7011,. bytes actually read = 18446744073709551615,. offset = 0). ```. The reported filename looks weird: `'/path.../filtered_gene_bc_matrices.h5ad'`. Is that file on some network share or colab or so? Because thatd explain wonky I/O. 18 exabytes (18 quintillion bytes!) read seems really off too! I assume `self.group[""data""][...]` tries to read all the data for `.X` and some bug or connection problem tells h5py that theres 18 exabytes. h5py then asks the OS to give them those 18 exabytes which the OS politely denies. See also:. - https://github.com/googlecolab/colabtools/issues/559. - https://forum.hdfgroup.org/t/errors-accessing-hdf5-over-cifs-and-or-nfs/6341",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:23,availability,error,error,23,"This is quite a common error on our internal servers @Hrovatin. I have been getting around it by reading from a different server, and then it just often works. It would be great if you can figure our what the issue might be.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:23,performance,error,error,23,"This is quite a common error on our internal servers @Hrovatin. I have been getting around it by reading from a different server, and then it just often works. It would be great if you can figure our what the issue might be.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:23,safety,error,error,23,"This is quite a common error on our internal servers @Hrovatin. I have been getting around it by reading from a different server, and then it just often works. It would be great if you can figure our what the issue might be.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:23,usability,error,error,23,"This is quite a common error on our internal servers @Hrovatin. I have been getting around it by reading from a different server, and then it just often works. It would be great if you can figure our what the issue might be.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:121,availability,error,errors,121,Which server do you suggest? - I had tried a couple with no success. I am having a lot of trouble with it - I am getting errors when reading different parts of the file - even when trying to use just h5py.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:45,integrability,coupl,couple,45,Which server do you suggest? - I had tried a couple with no success. I am having a lot of trouble with it - I am getting errors when reading different parts of the file - even when trying to use just h5py.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:45,modifiability,coupl,couple,45,Which server do you suggest? - I had tried a couple with no success. I am having a lot of trouble with it - I am getting errors when reading different parts of the file - even when trying to use just h5py.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:121,performance,error,errors,121,Which server do you suggest? - I had tried a couple with no success. I am having a lot of trouble with it - I am getting errors when reading different parts of the file - even when trying to use just h5py.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:121,safety,error,errors,121,Which server do you suggest? - I had tried a couple with no success. I am having a lot of trouble with it - I am getting errors when reading different parts of the file - even when trying to use just h5py.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:45,testability,coupl,couple,45,Which server do you suggest? - I had tried a couple with no success. I am having a lot of trouble with it - I am getting errors when reading different parts of the file - even when trying to use just h5py.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:121,usability,error,errors,121,Which server do you suggest? - I had tried a couple with no success. I am having a lot of trouble with it - I am getting errors when reading different parts of the file - even when trying to use just h5py.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:58,integrability,queue,queue,58,"I have been moving between interactive servers not on the queue. `icb-lisa`, `icb-sarah`, and `icb-mona`, and if none of those work, then the older servers `hias`, `sepp`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:58,performance,queue,queue,58,"I have been moving between interactive servers not on the queue. `icb-lisa`, `icb-sarah`, and `icb-mona`, and if none of those work, then the older servers `hias`, `sepp`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:27,usability,interact,interactive,27,"I have been moving between interactive servers not on the queue. `icb-lisa`, `icb-sarah`, and `icb-mona`, and if none of those work, then the older servers `hias`, `sepp`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:8,performance,time,time,8,"From my time in @theislab I infer this means its a network mount problem. You can probably fix it by putting the file somewhere in the local file system then. Since /home/* is network-mounted, that means /localscratch/ or /tmp/ I assume",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:52,performance,network,network,52,"From my time in @theislab I infer this means its a network mount problem. You can probably fix it by putting the file somewhere in the local file system then. Since /home/* is network-mounted, that means /localscratch/ or /tmp/ I assume",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:177,performance,network,network-mounted,177,"From my time in @theislab I infer this means its a network mount problem. You can probably fix it by putting the file somewhere in the local file system then. Since /home/* is network-mounted, that means /localscratch/ or /tmp/ I assume",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:52,security,network,network,52,"From my time in @theislab I infer this means its a network mount problem. You can probably fix it by putting the file somewhere in the local file system then. Since /home/* is network-mounted, that means /localscratch/ or /tmp/ I assume",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:177,security,network,network-mounted,177,"From my time in @theislab I infer this means its a network mount problem. You can probably fix it by putting the file somewhere in the local file system then. Since /home/* is network-mounted, that means /localscratch/ or /tmp/ I assume",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:84,energy efficiency,current,currently,84,Thank you very much @flying-sheep - copying to tmp for the time of reading seems to currently work.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:59,performance,time,time,59,Thank you very much @flying-sheep - copying to tmp for the time of reading seems to currently work.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:57,availability,error,errors,57,"Great to hear! Usually when theres weird, site-specific errors, I say I cant help because I dont have SSH access and my crystal ball is currently out of order. Seems like my crystal ball worked just fine these days!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:140,energy efficiency,current,currently,140,"Great to hear! Usually when theres weird, site-specific errors, I say I cant help because I dont have SSH access and my crystal ball is currently out of order. Seems like my crystal ball worked just fine these days!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:48,interoperability,specif,specific,48,"Great to hear! Usually when theres weird, site-specific errors, I say I cant help because I dont have SSH access and my crystal ball is currently out of order. Seems like my crystal ball worked just fine these days!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:57,performance,error,errors,57,"Great to hear! Usually when theres weird, site-specific errors, I say I cant help because I dont have SSH access and my crystal ball is currently out of order. Seems like my crystal ball worked just fine these days!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:57,safety,error,errors,57,"Great to hear! Usually when theres weird, site-specific errors, I say I cant help because I dont have SSH access and my crystal ball is currently out of order. Seems like my crystal ball worked just fine these days!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:105,security,SSH,SSH,105,"Great to hear! Usually when theres weird, site-specific errors, I say I cant help because I dont have SSH access and my crystal ball is currently out of order. Seems like my crystal ball worked just fine these days!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:109,security,access,access,109,"Great to hear! Usually when theres weird, site-specific errors, I say I cant help because I dont have SSH access and my crystal ball is currently out of order. Seems like my crystal ball worked just fine these days!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:57,usability,error,errors,57,"Great to hear! Usually when theres weird, site-specific errors, I say I cant help because I dont have SSH access and my crystal ball is currently out of order. Seems like my crystal ball worked just fine these days!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:79,usability,help,help,79,"Great to hear! Usually when theres weird, site-specific errors, I say I cant help because I dont have SSH access and my crystal ball is currently out of order. Seems like my crystal ball worked just fine these days!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:63,availability,error,error,63,@flying-sheep just wait until tomorrow... when the next random error occurs ;).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:63,performance,error,error,63,@flying-sheep just wait until tomorrow... when the next random error occurs ;).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:63,safety,error,error,63,@flying-sheep just wait until tomorrow... when the next random error occurs ;).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:63,usability,error,error,63,@flying-sheep just wait until tomorrow... when the next random error occurs ;).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:15,availability,error,error,15,"Found the same error in our internal workflows. Saved the data to h5py files, but could not open them anymore for some reason. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_group(group). 531 if encoding_type:. --> 532 EncodingVersions[encoding_type].check(. 533 group.name, group.attrs[""encoding-version""]. /opt/conda/lib/python3.7/enum.py in __getitem__(cls, name). 356 def __getitem__(cls, name):. --> 357 return cls._member_map_[name]. 358 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-20-38a594ec7d06> in <module>. ----> 1 adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 424 d[k] = read_dataframe(f[k]). 425 else: # Base case. --> 426 d[k] = read_attribute(f[k]). 427 . 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:127,availability,Error,Error,127,"Found the same error in our internal workflows. Saved the data to h5py files, but could not open them anymore for some reason. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_group(group). 531 if encoding_type:. --> 532 EncodingVersions[encoding_type].check(. 533 group.name, group.attrs[""encoding-version""]. /opt/conda/lib/python3.7/enum.py in __getitem__(cls, name). 356 def __getitem__(cls, name):. --> 357 return cls._member_map_[name]. 358 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-20-38a594ec7d06> in <module>. ----> 1 adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 424 d[k] = read_dataframe(f[k]). 425 else: # Base case. --> 426 d[k] = read_attribute(f[k]). 427 . 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:1734,availability,error,error,1734,"):. --> 357 return cls._member_map_[name]. 358 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-20-38a594ec7d06> in <module>. ----> 1 adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 424 d[k] = read_dataframe(f[k]). 425 else: # Base case. --> 426 d[k] = read_attribute(f[k]). 427 . 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). ```. <details>. <summary>Versions</summary>. Package Version. ----------------------- ------------. absl-py 1.1.0. aiohttp 3.8.1. aiosignal 1.2.0. anndata 0.7.5. anndata2ri 1.0.6. annoy 1.17.0. argon2-cffi 21.3.0. argon2-cffi-bindings 21.2.0. asn1crypto 1.4.0. async-timeout 4.0.2. asynctest 0.13.0. attrs 20.3.0. backcall 0.2.0. beautifulsoup4 4.11.1. bleach 5.0.0. boto3 1.17.66. botocore 1.20.66. brotlipy 0.7.0. cached-property 1.5.2. cachetools 5.2.0. certifi 2020.12.5. cffi 1.14.5. chardet 4.0.0. charset-normalizer 2.0.12. chex 0.1.3. click 8.1.3. colormath 3.0.0. commonmark 0.9.1. conda 4.6.14. conda-package-handling 1.7.3. cryptography 3.4.7. cycler 0.10.0. Cython 0.29.30. decorator 5.0.7. defusedxml 0.7.1",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:1857,availability,error,error,1857,"n occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-20-38a594ec7d06> in <module>. ----> 1 adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 424 d[k] = read_dataframe(f[k]). 425 else: # Base case. --> 426 d[k] = read_attribute(f[k]). 427 . 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). ```. <details>. <summary>Versions</summary>. Package Version. ----------------------- ------------. absl-py 1.1.0. aiohttp 3.8.1. aiosignal 1.2.0. anndata 0.7.5. anndata2ri 1.0.6. annoy 1.17.0. argon2-cffi 21.3.0. argon2-cffi-bindings 21.2.0. asn1crypto 1.4.0. async-timeout 4.0.2. asynctest 0.13.0. attrs 20.3.0. backcall 0.2.0. beautifulsoup4 4.11.1. bleach 5.0.0. boto3 1.17.66. botocore 1.20.66. brotlipy 0.7.0. cached-property 1.5.2. cachetools 5.2.0. certifi 2020.12.5. cffi 1.14.5. chardet 4.0.0. charset-normalizer 2.0.12. chex 0.1.3. click 8.1.3. colormath 3.0.0. commonmark 0.9.1. conda 4.6.14. conda-package-handling 1.7.3. cryptography 3.4.7. cycler 0.10.0. Cython 0.29.30. decorator 5.0.7. defusedxml 0.7.1. dill 0.3.3. dm-tree 0.1.7. docrep 0.3.2. entrypoints 0.4. et-xmlfile 1.1.0. fa2 0.3.5. fastjsonschema 2.15.3. flatbuffers",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:637,deployability,version,version,637,"Found the same error in our internal workflows. Saved the data to h5py files, but could not open them anymore for some reason. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_group(group). 531 if encoding_type:. --> 532 EncodingVersions[encoding_type].check(. 533 group.name, group.attrs[""encoding-version""]. /opt/conda/lib/python3.7/enum.py in __getitem__(cls, name). 356 def __getitem__(cls, name):. --> 357 return cls._member_map_[name]. 358 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-20-38a594ec7d06> in <module>. ----> 1 adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 424 d[k] = read_dataframe(f[k]). 425 else: # Base case. --> 426 d[k] = read_attribute(f[k]). 427 . 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:961,deployability,modul,module,961,"Found the same error in our internal workflows. Saved the data to h5py files, but could not open them anymore for some reason. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_group(group). 531 if encoding_type:. --> 532 EncodingVersions[encoding_type].check(. 533 group.name, group.attrs[""encoding-version""]. /opt/conda/lib/python3.7/enum.py in __getitem__(cls, name). 356 def __getitem__(cls, name):. --> 357 return cls._member_map_[name]. 358 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-20-38a594ec7d06> in <module>. ----> 1 adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 424 d[k] = read_dataframe(f[k]). 425 else: # Base case. --> 426 d[k] = read_attribute(f[k]). 427 . 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:2043,deployability,Version,Versions,2043,"'). /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 424 d[k] = read_dataframe(f[k]). 425 else: # Base case. --> 426 d[k] = read_attribute(f[k]). 427 . 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). ```. <details>. <summary>Versions</summary>. Package Version. ----------------------- ------------. absl-py 1.1.0. aiohttp 3.8.1. aiosignal 1.2.0. anndata 0.7.5. anndata2ri 1.0.6. annoy 1.17.0. argon2-cffi 21.3.0. argon2-cffi-bindings 21.2.0. asn1crypto 1.4.0. async-timeout 4.0.2. asynctest 0.13.0. attrs 20.3.0. backcall 0.2.0. beautifulsoup4 4.11.1. bleach 5.0.0. boto3 1.17.66. botocore 1.20.66. brotlipy 0.7.0. cached-property 1.5.2. cachetools 5.2.0. certifi 2020.12.5. cffi 1.14.5. chardet 4.0.0. charset-normalizer 2.0.12. chex 0.1.3. click 8.1.3. colormath 3.0.0. commonmark 0.9.1. conda 4.6.14. conda-package-handling 1.7.3. cryptography 3.4.7. cycler 0.10.0. Cython 0.29.30. decorator 5.0.7. defusedxml 0.7.1. dill 0.3.3. dm-tree 0.1.7. docrep 0.3.2. entrypoints 0.4. et-xmlfile 1.1.0. fa2 0.3.5. fastjsonschema 2.15.3. flatbuffers 2.0. flax 0.5.0. frozenlist 1.3.0. fsspec 2022.5.0. future 0.18.2. get-version 2.2. google-auth 2.6.6. google-auth-oauthlib 0.4.6. google-pasta 0.2.0. grpcio 1.46.3. h5py 3.2.1. idna 2.1",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:2071,deployability,Version,Version,2071,"/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 424 d[k] = read_dataframe(f[k]). 425 else: # Base case. --> 426 d[k] = read_attribute(f[k]). 427 . 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). ```. <details>. <summary>Versions</summary>. Package Version. ----------------------- ------------. absl-py 1.1.0. aiohttp 3.8.1. aiosignal 1.2.0. anndata 0.7.5. anndata2ri 1.0.6. annoy 1.17.0. argon2-cffi 21.3.0. argon2-cffi-bindings 21.2.0. asn1crypto 1.4.0. async-timeout 4.0.2. asynctest 0.13.0. attrs 20.3.0. backcall 0.2.0. beautifulsoup4 4.11.1. bleach 5.0.0. boto3 1.17.66. botocore 1.20.66. brotlipy 0.7.0. cached-property 1.5.2. cachetools 5.2.0. certifi 2020.12.5. cffi 1.14.5. chardet 4.0.0. charset-normalizer 2.0.12. chex 0.1.3. click 8.1.3. colormath 3.0.0. commonmark 0.9.1. conda 4.6.14. conda-package-handling 1.7.3. cryptography 3.4.7. cycler 0.10.0. Cython 0.29.30. decorator 5.0.7. defusedxml 0.7.1. dill 0.3.3. dm-tree 0.1.7. docrep 0.3.2. entrypoints 0.4. et-xmlfile 1.1.0. fa2 0.3.5. fastjsonschema 2.15.3. flatbuffers 2.0. flax 0.5.0. frozenlist 1.3.0. fsspec 2022.5.0. future 0.18.2. get-version 2.2. google-auth 2.6.6. google-auth-oauthlib 0.4.6. google-pasta 0.2.0. grpcio 1.46.3. h5py 3.2.1. idna 2.10. imageio 2.19.3. importlib",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:2932,deployability,version,version,2932, from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). ```. <details>. <summary>Versions</summary>. Package Version. ----------------------- ------------. absl-py 1.1.0. aiohttp 3.8.1. aiosignal 1.2.0. anndata 0.7.5. anndata2ri 1.0.6. annoy 1.17.0. argon2-cffi 21.3.0. argon2-cffi-bindings 21.2.0. asn1crypto 1.4.0. async-timeout 4.0.2. asynctest 0.13.0. attrs 20.3.0. backcall 0.2.0. beautifulsoup4 4.11.1. bleach 5.0.0. boto3 1.17.66. botocore 1.20.66. brotlipy 0.7.0. cached-property 1.5.2. cachetools 5.2.0. certifi 2020.12.5. cffi 1.14.5. chardet 4.0.0. charset-normalizer 2.0.12. chex 0.1.3. click 8.1.3. colormath 3.0.0. commonmark 0.9.1. conda 4.6.14. conda-package-handling 1.7.3. cryptography 3.4.7. cycler 0.10.0. Cython 0.29.30. decorator 5.0.7. defusedxml 0.7.1. dill 0.3.3. dm-tree 0.1.7. docrep 0.3.2. entrypoints 0.4. et-xmlfile 1.1.0. fa2 0.3.5. fastjsonschema 2.15.3. flatbuffers 2.0. flax 0.5.0. frozenlist 1.3.0. fsspec 2022.5.0. future 0.18.2. get-version 2.2. google-auth 2.6.6. google-auth-oauthlib 0.4.6. google-pasta 0.2.0. grpcio 1.46.3. h5py 3.2.1. idna 2.10. imageio 2.19.3. importlib-metadata 4.11.4. importlib-resources 5.7.1. ipykernel 5.5.4. ipython 7.23.1. ipython-genutils 0.2.0. ipywidgets 7.7.0. jax 0.3.13. jaxlib 0.3.10. jedi 0.18.0. Jinja2 3.1.2. jmespath 0.10.0. joblib 1.0.1. jsonschema 4.6.0. jupyter-client 6.1.12. jupyter-core 4.7.1. jupyterlab-pygments 0.2.2. jupyterlab-widgets 1.1.0. kiwisolver 1.3.1. legacy-api-wrap 1.2. leidenalg 0.8.4. llvmlite 0.35.0. loompy 3.0.7. louvain 0.7.0. Markdown 3.3.7. MarkupSafe 2.1.1. matplotlib 3.4.1. matplotlib-inline 0.1.2. mistune 0.8.4. msgpack 1.0.4. multidict 6.0.2. multipledispatch 0.6.0. multiprocess 0.70.11.1. natsort 7.1.1. nbclient 0.6.4. nbconvert 6.5.0. nbformat 5.4.0. nest-asyncio 1.5.5. networkx 2.5. notebook 6.4.11. numba 0.52.0. numexpr 2.7.3. numpy 1.19.5. numpy-groupies 0.9.17. numpyro 0.9.2. oauthlib 3.2.0. openpyxl 3.0.10. opt-einsum 3.3.0. optax 0.1.2. packagin,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:3103,deployability,resourc,resources,3103,--------. absl-py 1.1.0. aiohttp 3.8.1. aiosignal 1.2.0. anndata 0.7.5. anndata2ri 1.0.6. annoy 1.17.0. argon2-cffi 21.3.0. argon2-cffi-bindings 21.2.0. asn1crypto 1.4.0. async-timeout 4.0.2. asynctest 0.13.0. attrs 20.3.0. backcall 0.2.0. beautifulsoup4 4.11.1. bleach 5.0.0. boto3 1.17.66. botocore 1.20.66. brotlipy 0.7.0. cached-property 1.5.2. cachetools 5.2.0. certifi 2020.12.5. cffi 1.14.5. chardet 4.0.0. charset-normalizer 2.0.12. chex 0.1.3. click 8.1.3. colormath 3.0.0. commonmark 0.9.1. conda 4.6.14. conda-package-handling 1.7.3. cryptography 3.4.7. cycler 0.10.0. Cython 0.29.30. decorator 5.0.7. defusedxml 0.7.1. dill 0.3.3. dm-tree 0.1.7. docrep 0.3.2. entrypoints 0.4. et-xmlfile 1.1.0. fa2 0.3.5. fastjsonschema 2.15.3. flatbuffers 2.0. flax 0.5.0. frozenlist 1.3.0. fsspec 2022.5.0. future 0.18.2. get-version 2.2. google-auth 2.6.6. google-auth-oauthlib 0.4.6. google-pasta 0.2.0. grpcio 1.46.3. h5py 3.2.1. idna 2.10. imageio 2.19.3. importlib-metadata 4.11.4. importlib-resources 5.7.1. ipykernel 5.5.4. ipython 7.23.1. ipython-genutils 0.2.0. ipywidgets 7.7.0. jax 0.3.13. jaxlib 0.3.10. jedi 0.18.0. Jinja2 3.1.2. jmespath 0.10.0. joblib 1.0.1. jsonschema 4.6.0. jupyter-client 6.1.12. jupyter-core 4.7.1. jupyterlab-pygments 0.2.2. jupyterlab-widgets 1.1.0. kiwisolver 1.3.1. legacy-api-wrap 1.2. leidenalg 0.8.4. llvmlite 0.35.0. loompy 3.0.7. louvain 0.7.0. Markdown 3.3.7. MarkupSafe 2.1.1. matplotlib 3.4.1. matplotlib-inline 0.1.2. mistune 0.8.4. msgpack 1.0.4. multidict 6.0.2. multipledispatch 0.6.0. multiprocess 0.70.11.1. natsort 7.1.1. nbclient 0.6.4. nbconvert 6.5.0. nbformat 5.4.0. nest-asyncio 1.5.5. networkx 2.5. notebook 6.4.11. numba 0.52.0. numexpr 2.7.3. numpy 1.19.5. numpy-groupies 0.9.17. numpyro 0.9.2. oauthlib 3.2.0. openpyxl 3.0.10. opt-einsum 3.3.0. optax 0.1.2. packaging 20.9. pandas 1.2.0. pandocfilters 1.5.0. parso 0.8.2. pathos 0.2.7. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 9.1.1. pip 21.1.1. pox 0.2.9. ppft 1.6.6.3. prom,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:3419,deployability,api,api-wrap,3419,ipy 0.7.0. cached-property 1.5.2. cachetools 5.2.0. certifi 2020.12.5. cffi 1.14.5. chardet 4.0.0. charset-normalizer 2.0.12. chex 0.1.3. click 8.1.3. colormath 3.0.0. commonmark 0.9.1. conda 4.6.14. conda-package-handling 1.7.3. cryptography 3.4.7. cycler 0.10.0. Cython 0.29.30. decorator 5.0.7. defusedxml 0.7.1. dill 0.3.3. dm-tree 0.1.7. docrep 0.3.2. entrypoints 0.4. et-xmlfile 1.1.0. fa2 0.3.5. fastjsonschema 2.15.3. flatbuffers 2.0. flax 0.5.0. frozenlist 1.3.0. fsspec 2022.5.0. future 0.18.2. get-version 2.2. google-auth 2.6.6. google-auth-oauthlib 0.4.6. google-pasta 0.2.0. grpcio 1.46.3. h5py 3.2.1. idna 2.10. imageio 2.19.3. importlib-metadata 4.11.4. importlib-resources 5.7.1. ipykernel 5.5.4. ipython 7.23.1. ipython-genutils 0.2.0. ipywidgets 7.7.0. jax 0.3.13. jaxlib 0.3.10. jedi 0.18.0. Jinja2 3.1.2. jmespath 0.10.0. joblib 1.0.1. jsonschema 4.6.0. jupyter-client 6.1.12. jupyter-core 4.7.1. jupyterlab-pygments 0.2.2. jupyterlab-widgets 1.1.0. kiwisolver 1.3.1. legacy-api-wrap 1.2. leidenalg 0.8.4. llvmlite 0.35.0. loompy 3.0.7. louvain 0.7.0. Markdown 3.3.7. MarkupSafe 2.1.1. matplotlib 3.4.1. matplotlib-inline 0.1.2. mistune 0.8.4. msgpack 1.0.4. multidict 6.0.2. multipledispatch 0.6.0. multiprocess 0.70.11.1. natsort 7.1.1. nbclient 0.6.4. nbconvert 6.5.0. nbformat 5.4.0. nest-asyncio 1.5.5. networkx 2.5. notebook 6.4.11. numba 0.52.0. numexpr 2.7.3. numpy 1.19.5. numpy-groupies 0.9.17. numpyro 0.9.2. oauthlib 3.2.0. openpyxl 3.0.10. opt-einsum 3.3.0. optax 0.1.2. packaging 20.9. pandas 1.2.0. pandocfilters 1.5.0. parso 0.8.2. pathos 0.2.7. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 9.1.1. pip 21.1.1. pox 0.2.9. ppft 1.6.6.3. prometheus-client 0.14.1. prompt-toolkit 3.0.18. protobuf 3.19.0. protobuf3-to-dict 0.1.5. ptyprocess 0.7.0. pyasn1 0.4.8. pyasn1-modules 0.2.8. pycosat 0.6.3. pycparser 2.20. pyDeprecate 0.3.1. Pygments 2.9.0. pyOpenSSL 20.0.1. pyparsing 2.4.7. pyro-api 0.1.2. pyro-ppl 1.8.1. pyrsistent 0.18.1. PySocks 1.7.1. python-,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:4234,deployability,modul,modules,4234,ja2 3.1.2. jmespath 0.10.0. joblib 1.0.1. jsonschema 4.6.0. jupyter-client 6.1.12. jupyter-core 4.7.1. jupyterlab-pygments 0.2.2. jupyterlab-widgets 1.1.0. kiwisolver 1.3.1. legacy-api-wrap 1.2. leidenalg 0.8.4. llvmlite 0.35.0. loompy 3.0.7. louvain 0.7.0. Markdown 3.3.7. MarkupSafe 2.1.1. matplotlib 3.4.1. matplotlib-inline 0.1.2. mistune 0.8.4. msgpack 1.0.4. multidict 6.0.2. multipledispatch 0.6.0. multiprocess 0.70.11.1. natsort 7.1.1. nbclient 0.6.4. nbconvert 6.5.0. nbformat 5.4.0. nest-asyncio 1.5.5. networkx 2.5. notebook 6.4.11. numba 0.52.0. numexpr 2.7.3. numpy 1.19.5. numpy-groupies 0.9.17. numpyro 0.9.2. oauthlib 3.2.0. openpyxl 3.0.10. opt-einsum 3.3.0. optax 0.1.2. packaging 20.9. pandas 1.2.0. pandocfilters 1.5.0. parso 0.8.2. pathos 0.2.7. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 9.1.1. pip 21.1.1. pox 0.2.9. ppft 1.6.6.3. prometheus-client 0.14.1. prompt-toolkit 3.0.18. protobuf 3.19.0. protobuf3-to-dict 0.1.5. ptyprocess 0.7.0. pyasn1 0.4.8. pyasn1-modules 0.2.8. pycosat 0.6.3. pycparser 2.20. pyDeprecate 0.3.1. Pygments 2.9.0. pyOpenSSL 20.0.1. pyparsing 2.4.7. pyro-api 0.1.2. pyro-ppl 1.8.1. pyrsistent 0.18.1. PySocks 1.7.1. python-dateutil 2.8.1. python-igraph 0.9.1. pytorch-lightning 1.5.10. pytz 2021.1. PyWavelets 1.3.0. PyYAML 6.0. pyzmq 22.0.3. requests 2.25.1. requests-oauthlib 1.3.1. rich 12.4.4. rpy2 3.4.2. rsa 4.8. ruamel-yaml-conda 0.15.80. ruamel.yaml 0.17.21. ruamel.yaml.clib 0.2.6. s3transfer 0.4.2. sagemaker 2.39.0.post0. scanpy 1.6.1. scikit-image 0.19.2. scikit-learn 0.24.2. scikit-misc 0.1.4. scipy 1.6.0. scrublet 0.2.3. scvi-tools 0.16.2. seaborn 0.11.1. Send2Trash 1.8.0. setuptools 59.5.0. setuptools-scm 6.0.1. sinfo 0.3.1. six 1.15.0. smdebug-rulesconfig 1.0.1. soupsieve 2.3.2.post1. spectra 0.0.11. statsmodels 0.12.2. stdlib-list 0.8.0. tables 3.6.1. tensorboard 2.9.0. tensorboard-data-server 0.6.1. tensorboard-plugin-wit 1.8.1. terminado 0.15.0. texttable 1.6.3. threadpoolctl 2.1.0. tifffile 2021.11.2. tinycss,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:4355,deployability,api,api,4355,nts 0.2.2. jupyterlab-widgets 1.1.0. kiwisolver 1.3.1. legacy-api-wrap 1.2. leidenalg 0.8.4. llvmlite 0.35.0. loompy 3.0.7. louvain 0.7.0. Markdown 3.3.7. MarkupSafe 2.1.1. matplotlib 3.4.1. matplotlib-inline 0.1.2. mistune 0.8.4. msgpack 1.0.4. multidict 6.0.2. multipledispatch 0.6.0. multiprocess 0.70.11.1. natsort 7.1.1. nbclient 0.6.4. nbconvert 6.5.0. nbformat 5.4.0. nest-asyncio 1.5.5. networkx 2.5. notebook 6.4.11. numba 0.52.0. numexpr 2.7.3. numpy 1.19.5. numpy-groupies 0.9.17. numpyro 0.9.2. oauthlib 3.2.0. openpyxl 3.0.10. opt-einsum 3.3.0. optax 0.1.2. packaging 20.9. pandas 1.2.0. pandocfilters 1.5.0. parso 0.8.2. pathos 0.2.7. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 9.1.1. pip 21.1.1. pox 0.2.9. ppft 1.6.6.3. prometheus-client 0.14.1. prompt-toolkit 3.0.18. protobuf 3.19.0. protobuf3-to-dict 0.1.5. ptyprocess 0.7.0. pyasn1 0.4.8. pyasn1-modules 0.2.8. pycosat 0.6.3. pycparser 2.20. pyDeprecate 0.3.1. Pygments 2.9.0. pyOpenSSL 20.0.1. pyparsing 2.4.7. pyro-api 0.1.2. pyro-ppl 1.8.1. pyrsistent 0.18.1. PySocks 1.7.1. python-dateutil 2.8.1. python-igraph 0.9.1. pytorch-lightning 1.5.10. pytz 2021.1. PyWavelets 1.3.0. PyYAML 6.0. pyzmq 22.0.3. requests 2.25.1. requests-oauthlib 1.3.1. rich 12.4.4. rpy2 3.4.2. rsa 4.8. ruamel-yaml-conda 0.15.80. ruamel.yaml 0.17.21. ruamel.yaml.clib 0.2.6. s3transfer 0.4.2. sagemaker 2.39.0.post0. scanpy 1.6.1. scikit-image 0.19.2. scikit-learn 0.24.2. scikit-misc 0.1.4. scipy 1.6.0. scrublet 0.2.3. scvi-tools 0.16.2. seaborn 0.11.1. Send2Trash 1.8.0. setuptools 59.5.0. setuptools-scm 6.0.1. sinfo 0.3.1. six 1.15.0. smdebug-rulesconfig 1.0.1. soupsieve 2.3.2.post1. spectra 0.0.11. statsmodels 0.12.2. stdlib-list 0.8.0. tables 3.6.1. tensorboard 2.9.0. tensorboard-data-server 0.6.1. tensorboard-plugin-wit 1.8.1. terminado 0.15.0. texttable 1.6.3. threadpoolctl 2.1.0. tifffile 2021.11.2. tinycss2 1.1.1. toolz 0.11.2. torch 1.11.0. torchmetrics 0.9.0. tornado 6.1. tqdm 4.60.0. traitlets 5.2.2.post1. typing-extens,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:5579,deployability,updat,updated,5579," natsort 7.1.1. nbclient 0.6.4. nbconvert 6.5.0. nbformat 5.4.0. nest-asyncio 1.5.5. networkx 2.5. notebook 6.4.11. numba 0.52.0. numexpr 2.7.3. numpy 1.19.5. numpy-groupies 0.9.17. numpyro 0.9.2. oauthlib 3.2.0. openpyxl 3.0.10. opt-einsum 3.3.0. optax 0.1.2. packaging 20.9. pandas 1.2.0. pandocfilters 1.5.0. parso 0.8.2. pathos 0.2.7. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 9.1.1. pip 21.1.1. pox 0.2.9. ppft 1.6.6.3. prometheus-client 0.14.1. prompt-toolkit 3.0.18. protobuf 3.19.0. protobuf3-to-dict 0.1.5. ptyprocess 0.7.0. pyasn1 0.4.8. pyasn1-modules 0.2.8. pycosat 0.6.3. pycparser 2.20. pyDeprecate 0.3.1. Pygments 2.9.0. pyOpenSSL 20.0.1. pyparsing 2.4.7. pyro-api 0.1.2. pyro-ppl 1.8.1. pyrsistent 0.18.1. PySocks 1.7.1. python-dateutil 2.8.1. python-igraph 0.9.1. pytorch-lightning 1.5.10. pytz 2021.1. PyWavelets 1.3.0. PyYAML 6.0. pyzmq 22.0.3. requests 2.25.1. requests-oauthlib 1.3.1. rich 12.4.4. rpy2 3.4.2. rsa 4.8. ruamel-yaml-conda 0.15.80. ruamel.yaml 0.17.21. ruamel.yaml.clib 0.2.6. s3transfer 0.4.2. sagemaker 2.39.0.post0. scanpy 1.6.1. scikit-image 0.19.2. scikit-learn 0.24.2. scikit-misc 0.1.4. scipy 1.6.0. scrublet 0.2.3. scvi-tools 0.16.2. seaborn 0.11.1. Send2Trash 1.8.0. setuptools 59.5.0. setuptools-scm 6.0.1. sinfo 0.3.1. six 1.15.0. smdebug-rulesconfig 1.0.1. soupsieve 2.3.2.post1. spectra 0.0.11. statsmodels 0.12.2. stdlib-list 0.8.0. tables 3.6.1. tensorboard 2.9.0. tensorboard-data-server 0.6.1. tensorboard-plugin-wit 1.8.1. terminado 0.15.0. texttable 1.6.3. threadpoolctl 2.1.0. tifffile 2021.11.2. tinycss2 1.1.1. toolz 0.11.2. torch 1.11.0. torchmetrics 0.9.0. tornado 6.1. tqdm 4.60.0. traitlets 5.2.2.post1. typing-extensions 4.2.0. tzlocal 2.1. umap-learn 0.4.6. urllib3 1.26.4. wcwidth 0.2.5. webencodings 0.5.1. Werkzeug 2.1.2. wheel 0.36.2. widgetsnbextension 3.6.0. yarl 1.7.2. zipp 3.4.1. Note: you may need to restart the kernel to use updated packages."". </details>. Has anyone found any solution to work around this issue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:3103,energy efficiency,resourc,resources,3103,--------. absl-py 1.1.0. aiohttp 3.8.1. aiosignal 1.2.0. anndata 0.7.5. anndata2ri 1.0.6. annoy 1.17.0. argon2-cffi 21.3.0. argon2-cffi-bindings 21.2.0. asn1crypto 1.4.0. async-timeout 4.0.2. asynctest 0.13.0. attrs 20.3.0. backcall 0.2.0. beautifulsoup4 4.11.1. bleach 5.0.0. boto3 1.17.66. botocore 1.20.66. brotlipy 0.7.0. cached-property 1.5.2. cachetools 5.2.0. certifi 2020.12.5. cffi 1.14.5. chardet 4.0.0. charset-normalizer 2.0.12. chex 0.1.3. click 8.1.3. colormath 3.0.0. commonmark 0.9.1. conda 4.6.14. conda-package-handling 1.7.3. cryptography 3.4.7. cycler 0.10.0. Cython 0.29.30. decorator 5.0.7. defusedxml 0.7.1. dill 0.3.3. dm-tree 0.1.7. docrep 0.3.2. entrypoints 0.4. et-xmlfile 1.1.0. fa2 0.3.5. fastjsonschema 2.15.3. flatbuffers 2.0. flax 0.5.0. frozenlist 1.3.0. fsspec 2022.5.0. future 0.18.2. get-version 2.2. google-auth 2.6.6. google-auth-oauthlib 0.4.6. google-pasta 0.2.0. grpcio 1.46.3. h5py 3.2.1. idna 2.10. imageio 2.19.3. importlib-metadata 4.11.4. importlib-resources 5.7.1. ipykernel 5.5.4. ipython 7.23.1. ipython-genutils 0.2.0. ipywidgets 7.7.0. jax 0.3.13. jaxlib 0.3.10. jedi 0.18.0. Jinja2 3.1.2. jmespath 0.10.0. joblib 1.0.1. jsonschema 4.6.0. jupyter-client 6.1.12. jupyter-core 4.7.1. jupyterlab-pygments 0.2.2. jupyterlab-widgets 1.1.0. kiwisolver 1.3.1. legacy-api-wrap 1.2. leidenalg 0.8.4. llvmlite 0.35.0. loompy 3.0.7. louvain 0.7.0. Markdown 3.3.7. MarkupSafe 2.1.1. matplotlib 3.4.1. matplotlib-inline 0.1.2. mistune 0.8.4. msgpack 1.0.4. multidict 6.0.2. multipledispatch 0.6.0. multiprocess 0.70.11.1. natsort 7.1.1. nbclient 0.6.4. nbconvert 6.5.0. nbformat 5.4.0. nest-asyncio 1.5.5. networkx 2.5. notebook 6.4.11. numba 0.52.0. numexpr 2.7.3. numpy 1.19.5. numpy-groupies 0.9.17. numpyro 0.9.2. oauthlib 3.2.0. openpyxl 3.0.10. opt-einsum 3.3.0. optax 0.1.2. packaging 20.9. pandas 1.2.0. pandocfilters 1.5.0. parso 0.8.2. pathos 0.2.7. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 9.1.1. pip 21.1.1. pox 0.2.9. ppft 1.6.6.3. prom,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:3329,energy efficiency,core,core,3329, backcall 0.2.0. beautifulsoup4 4.11.1. bleach 5.0.0. boto3 1.17.66. botocore 1.20.66. brotlipy 0.7.0. cached-property 1.5.2. cachetools 5.2.0. certifi 2020.12.5. cffi 1.14.5. chardet 4.0.0. charset-normalizer 2.0.12. chex 0.1.3. click 8.1.3. colormath 3.0.0. commonmark 0.9.1. conda 4.6.14. conda-package-handling 1.7.3. cryptography 3.4.7. cycler 0.10.0. Cython 0.29.30. decorator 5.0.7. defusedxml 0.7.1. dill 0.3.3. dm-tree 0.1.7. docrep 0.3.2. entrypoints 0.4. et-xmlfile 1.1.0. fa2 0.3.5. fastjsonschema 2.15.3. flatbuffers 2.0. flax 0.5.0. frozenlist 1.3.0. fsspec 2022.5.0. future 0.18.2. get-version 2.2. google-auth 2.6.6. google-auth-oauthlib 0.4.6. google-pasta 0.2.0. grpcio 1.46.3. h5py 3.2.1. idna 2.10. imageio 2.19.3. importlib-metadata 4.11.4. importlib-resources 5.7.1. ipykernel 5.5.4. ipython 7.23.1. ipython-genutils 0.2.0. ipywidgets 7.7.0. jax 0.3.13. jaxlib 0.3.10. jedi 0.18.0. Jinja2 3.1.2. jmespath 0.10.0. joblib 1.0.1. jsonschema 4.6.0. jupyter-client 6.1.12. jupyter-core 4.7.1. jupyterlab-pygments 0.2.2. jupyterlab-widgets 1.1.0. kiwisolver 1.3.1. legacy-api-wrap 1.2. leidenalg 0.8.4. llvmlite 0.35.0. loompy 3.0.7. louvain 0.7.0. Markdown 3.3.7. MarkupSafe 2.1.1. matplotlib 3.4.1. matplotlib-inline 0.1.2. mistune 0.8.4. msgpack 1.0.4. multidict 6.0.2. multipledispatch 0.6.0. multiprocess 0.70.11.1. natsort 7.1.1. nbclient 0.6.4. nbconvert 6.5.0. nbformat 5.4.0. nest-asyncio 1.5.5. networkx 2.5. notebook 6.4.11. numba 0.52.0. numexpr 2.7.3. numpy 1.19.5. numpy-groupies 0.9.17. numpyro 0.9.2. oauthlib 3.2.0. openpyxl 3.0.10. opt-einsum 3.3.0. optax 0.1.2. packaging 20.9. pandas 1.2.0. pandocfilters 1.5.0. parso 0.8.2. pathos 0.2.7. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 9.1.1. pip 21.1.1. pox 0.2.9. ppft 1.6.6.3. prometheus-client 0.14.1. prompt-toolkit 3.0.18. protobuf 3.19.0. protobuf3-to-dict 0.1.5. ptyprocess 0.7.0. pyasn1 0.4.8. pyasn1-modules 0.2.8. pycosat 0.6.3. pycparser 2.20. pyDeprecate 0.3.1. Pygments 2.9.0. pyOpenSSL 20.0.1,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:637,integrability,version,version,637,"Found the same error in our internal workflows. Saved the data to h5py files, but could not open them anymore for some reason. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_group(group). 531 if encoding_type:. --> 532 EncodingVersions[encoding_type].check(. 533 group.name, group.attrs[""encoding-version""]. /opt/conda/lib/python3.7/enum.py in __getitem__(cls, name). 356 def __getitem__(cls, name):. --> 357 return cls._member_map_[name]. 358 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-20-38a594ec7d06> in <module>. ----> 1 adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 424 d[k] = read_dataframe(f[k]). 425 else: # Base case. --> 426 d[k] = read_attribute(f[k]). 427 . 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:1367,integrability,wrap,wrapper,1367,"y:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_group(group). 531 if encoding_type:. --> 532 EncodingVersions[encoding_type].check(. 533 group.name, group.attrs[""encoding-version""]. /opt/conda/lib/python3.7/enum.py in __getitem__(cls, name). 356 def __getitem__(cls, name):. --> 357 return cls._member_map_[name]. 358 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-20-38a594ec7d06> in <module>. ----> 1 adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 424 d[k] = read_dataframe(f[k]). 425 else: # Base case. --> 426 d[k] = read_attribute(f[k]). 427 . 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). ```. <details>. <summary>Versions</summary>. Package Version. ----------------------- ------------. absl-py 1.1.0. aiohttp 3.8.1. aiosignal 1.2.0. anndata 0.7.5. anndata2ri 1.0.6. annoy 1.17.0. argon2-cffi 21.3.0. argon2-cffi-bindings 21.2.0. asn1crypto 1.4.0. async-timeout 4.0.2. asynctest 0.13.0. attrs 20.3.0. backcall 0.2.0. beautifulsoup4 4.11.1. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:2043,integrability,Version,Versions,2043,"'). /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 424 d[k] = read_dataframe(f[k]). 425 else: # Base case. --> 426 d[k] = read_attribute(f[k]). 427 . 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). ```. <details>. <summary>Versions</summary>. Package Version. ----------------------- ------------. absl-py 1.1.0. aiohttp 3.8.1. aiosignal 1.2.0. anndata 0.7.5. anndata2ri 1.0.6. annoy 1.17.0. argon2-cffi 21.3.0. argon2-cffi-bindings 21.2.0. asn1crypto 1.4.0. async-timeout 4.0.2. asynctest 0.13.0. attrs 20.3.0. backcall 0.2.0. beautifulsoup4 4.11.1. bleach 5.0.0. boto3 1.17.66. botocore 1.20.66. brotlipy 0.7.0. cached-property 1.5.2. cachetools 5.2.0. certifi 2020.12.5. cffi 1.14.5. chardet 4.0.0. charset-normalizer 2.0.12. chex 0.1.3. click 8.1.3. colormath 3.0.0. commonmark 0.9.1. conda 4.6.14. conda-package-handling 1.7.3. cryptography 3.4.7. cycler 0.10.0. Cython 0.29.30. decorator 5.0.7. defusedxml 0.7.1. dill 0.3.3. dm-tree 0.1.7. docrep 0.3.2. entrypoints 0.4. et-xmlfile 1.1.0. fa2 0.3.5. fastjsonschema 2.15.3. flatbuffers 2.0. flax 0.5.0. frozenlist 1.3.0. fsspec 2022.5.0. future 0.18.2. get-version 2.2. google-auth 2.6.6. google-auth-oauthlib 0.4.6. google-pasta 0.2.0. grpcio 1.46.3. h5py 3.2.1. idna 2.1",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:2071,integrability,Version,Version,2071,"/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 424 d[k] = read_dataframe(f[k]). 425 else: # Base case. --> 426 d[k] = read_attribute(f[k]). 427 . 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). ```. <details>. <summary>Versions</summary>. Package Version. ----------------------- ------------. absl-py 1.1.0. aiohttp 3.8.1. aiosignal 1.2.0. anndata 0.7.5. anndata2ri 1.0.6. annoy 1.17.0. argon2-cffi 21.3.0. argon2-cffi-bindings 21.2.0. asn1crypto 1.4.0. async-timeout 4.0.2. asynctest 0.13.0. attrs 20.3.0. backcall 0.2.0. beautifulsoup4 4.11.1. bleach 5.0.0. boto3 1.17.66. botocore 1.20.66. brotlipy 0.7.0. cached-property 1.5.2. cachetools 5.2.0. certifi 2020.12.5. cffi 1.14.5. chardet 4.0.0. charset-normalizer 2.0.12. chex 0.1.3. click 8.1.3. colormath 3.0.0. commonmark 0.9.1. conda 4.6.14. conda-package-handling 1.7.3. cryptography 3.4.7. cycler 0.10.0. Cython 0.29.30. decorator 5.0.7. defusedxml 0.7.1. dill 0.3.3. dm-tree 0.1.7. docrep 0.3.2. entrypoints 0.4. et-xmlfile 1.1.0. fa2 0.3.5. fastjsonschema 2.15.3. flatbuffers 2.0. flax 0.5.0. frozenlist 1.3.0. fsspec 2022.5.0. future 0.18.2. get-version 2.2. google-auth 2.6.6. google-auth-oauthlib 0.4.6. google-pasta 0.2.0. grpcio 1.46.3. h5py 3.2.1. idna 2.10. imageio 2.19.3. importlib",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:2932,integrability,version,version,2932, from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). ```. <details>. <summary>Versions</summary>. Package Version. ----------------------- ------------. absl-py 1.1.0. aiohttp 3.8.1. aiosignal 1.2.0. anndata 0.7.5. anndata2ri 1.0.6. annoy 1.17.0. argon2-cffi 21.3.0. argon2-cffi-bindings 21.2.0. asn1crypto 1.4.0. async-timeout 4.0.2. asynctest 0.13.0. attrs 20.3.0. backcall 0.2.0. beautifulsoup4 4.11.1. bleach 5.0.0. boto3 1.17.66. botocore 1.20.66. brotlipy 0.7.0. cached-property 1.5.2. cachetools 5.2.0. certifi 2020.12.5. cffi 1.14.5. chardet 4.0.0. charset-normalizer 2.0.12. chex 0.1.3. click 8.1.3. colormath 3.0.0. commonmark 0.9.1. conda 4.6.14. conda-package-handling 1.7.3. cryptography 3.4.7. cycler 0.10.0. Cython 0.29.30. decorator 5.0.7. defusedxml 0.7.1. dill 0.3.3. dm-tree 0.1.7. docrep 0.3.2. entrypoints 0.4. et-xmlfile 1.1.0. fa2 0.3.5. fastjsonschema 2.15.3. flatbuffers 2.0. flax 0.5.0. frozenlist 1.3.0. fsspec 2022.5.0. future 0.18.2. get-version 2.2. google-auth 2.6.6. google-auth-oauthlib 0.4.6. google-pasta 0.2.0. grpcio 1.46.3. h5py 3.2.1. idna 2.10. imageio 2.19.3. importlib-metadata 4.11.4. importlib-resources 5.7.1. ipykernel 5.5.4. ipython 7.23.1. ipython-genutils 0.2.0. ipywidgets 7.7.0. jax 0.3.13. jaxlib 0.3.10. jedi 0.18.0. Jinja2 3.1.2. jmespath 0.10.0. joblib 1.0.1. jsonschema 4.6.0. jupyter-client 6.1.12. jupyter-core 4.7.1. jupyterlab-pygments 0.2.2. jupyterlab-widgets 1.1.0. kiwisolver 1.3.1. legacy-api-wrap 1.2. leidenalg 0.8.4. llvmlite 0.35.0. loompy 3.0.7. louvain 0.7.0. Markdown 3.3.7. MarkupSafe 2.1.1. matplotlib 3.4.1. matplotlib-inline 0.1.2. mistune 0.8.4. msgpack 1.0.4. multidict 6.0.2. multipledispatch 0.6.0. multiprocess 0.70.11.1. natsort 7.1.1. nbclient 0.6.4. nbconvert 6.5.0. nbformat 5.4.0. nest-asyncio 1.5.5. networkx 2.5. notebook 6.4.11. numba 0.52.0. numexpr 2.7.3. numpy 1.19.5. numpy-groupies 0.9.17. numpyro 0.9.2. oauthlib 3.2.0. openpyxl 3.0.10. opt-einsum 3.3.0. optax 0.1.2. packagin,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:3419,integrability,api,api-wrap,3419,ipy 0.7.0. cached-property 1.5.2. cachetools 5.2.0. certifi 2020.12.5. cffi 1.14.5. chardet 4.0.0. charset-normalizer 2.0.12. chex 0.1.3. click 8.1.3. colormath 3.0.0. commonmark 0.9.1. conda 4.6.14. conda-package-handling 1.7.3. cryptography 3.4.7. cycler 0.10.0. Cython 0.29.30. decorator 5.0.7. defusedxml 0.7.1. dill 0.3.3. dm-tree 0.1.7. docrep 0.3.2. entrypoints 0.4. et-xmlfile 1.1.0. fa2 0.3.5. fastjsonschema 2.15.3. flatbuffers 2.0. flax 0.5.0. frozenlist 1.3.0. fsspec 2022.5.0. future 0.18.2. get-version 2.2. google-auth 2.6.6. google-auth-oauthlib 0.4.6. google-pasta 0.2.0. grpcio 1.46.3. h5py 3.2.1. idna 2.10. imageio 2.19.3. importlib-metadata 4.11.4. importlib-resources 5.7.1. ipykernel 5.5.4. ipython 7.23.1. ipython-genutils 0.2.0. ipywidgets 7.7.0. jax 0.3.13. jaxlib 0.3.10. jedi 0.18.0. Jinja2 3.1.2. jmespath 0.10.0. joblib 1.0.1. jsonschema 4.6.0. jupyter-client 6.1.12. jupyter-core 4.7.1. jupyterlab-pygments 0.2.2. jupyterlab-widgets 1.1.0. kiwisolver 1.3.1. legacy-api-wrap 1.2. leidenalg 0.8.4. llvmlite 0.35.0. loompy 3.0.7. louvain 0.7.0. Markdown 3.3.7. MarkupSafe 2.1.1. matplotlib 3.4.1. matplotlib-inline 0.1.2. mistune 0.8.4. msgpack 1.0.4. multidict 6.0.2. multipledispatch 0.6.0. multiprocess 0.70.11.1. natsort 7.1.1. nbclient 0.6.4. nbconvert 6.5.0. nbformat 5.4.0. nest-asyncio 1.5.5. networkx 2.5. notebook 6.4.11. numba 0.52.0. numexpr 2.7.3. numpy 1.19.5. numpy-groupies 0.9.17. numpyro 0.9.2. oauthlib 3.2.0. openpyxl 3.0.10. opt-einsum 3.3.0. optax 0.1.2. packaging 20.9. pandas 1.2.0. pandocfilters 1.5.0. parso 0.8.2. pathos 0.2.7. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 9.1.1. pip 21.1.1. pox 0.2.9. ppft 1.6.6.3. prometheus-client 0.14.1. prompt-toolkit 3.0.18. protobuf 3.19.0. protobuf3-to-dict 0.1.5. ptyprocess 0.7.0. pyasn1 0.4.8. pyasn1-modules 0.2.8. pycosat 0.6.3. pycparser 2.20. pyDeprecate 0.3.1. Pygments 2.9.0. pyOpenSSL 20.0.1. pyparsing 2.4.7. pyro-api 0.1.2. pyro-ppl 1.8.1. pyrsistent 0.18.1. PySocks 1.7.1. python-,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:4355,integrability,api,api,4355,nts 0.2.2. jupyterlab-widgets 1.1.0. kiwisolver 1.3.1. legacy-api-wrap 1.2. leidenalg 0.8.4. llvmlite 0.35.0. loompy 3.0.7. louvain 0.7.0. Markdown 3.3.7. MarkupSafe 2.1.1. matplotlib 3.4.1. matplotlib-inline 0.1.2. mistune 0.8.4. msgpack 1.0.4. multidict 6.0.2. multipledispatch 0.6.0. multiprocess 0.70.11.1. natsort 7.1.1. nbclient 0.6.4. nbconvert 6.5.0. nbformat 5.4.0. nest-asyncio 1.5.5. networkx 2.5. notebook 6.4.11. numba 0.52.0. numexpr 2.7.3. numpy 1.19.5. numpy-groupies 0.9.17. numpyro 0.9.2. oauthlib 3.2.0. openpyxl 3.0.10. opt-einsum 3.3.0. optax 0.1.2. packaging 20.9. pandas 1.2.0. pandocfilters 1.5.0. parso 0.8.2. pathos 0.2.7. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 9.1.1. pip 21.1.1. pox 0.2.9. ppft 1.6.6.3. prometheus-client 0.14.1. prompt-toolkit 3.0.18. protobuf 3.19.0. protobuf3-to-dict 0.1.5. ptyprocess 0.7.0. pyasn1 0.4.8. pyasn1-modules 0.2.8. pycosat 0.6.3. pycparser 2.20. pyDeprecate 0.3.1. Pygments 2.9.0. pyOpenSSL 20.0.1. pyparsing 2.4.7. pyro-api 0.1.2. pyro-ppl 1.8.1. pyrsistent 0.18.1. PySocks 1.7.1. python-dateutil 2.8.1. python-igraph 0.9.1. pytorch-lightning 1.5.10. pytz 2021.1. PyWavelets 1.3.0. PyYAML 6.0. pyzmq 22.0.3. requests 2.25.1. requests-oauthlib 1.3.1. rich 12.4.4. rpy2 3.4.2. rsa 4.8. ruamel-yaml-conda 0.15.80. ruamel.yaml 0.17.21. ruamel.yaml.clib 0.2.6. s3transfer 0.4.2. sagemaker 2.39.0.post0. scanpy 1.6.1. scikit-image 0.19.2. scikit-learn 0.24.2. scikit-misc 0.1.4. scipy 1.6.0. scrublet 0.2.3. scvi-tools 0.16.2. seaborn 0.11.1. Send2Trash 1.8.0. setuptools 59.5.0. setuptools-scm 6.0.1. sinfo 0.3.1. six 1.15.0. smdebug-rulesconfig 1.0.1. soupsieve 2.3.2.post1. spectra 0.0.11. statsmodels 0.12.2. stdlib-list 0.8.0. tables 3.6.1. tensorboard 2.9.0. tensorboard-data-server 0.6.1. tensorboard-plugin-wit 1.8.1. terminado 0.15.0. texttable 1.6.3. threadpoolctl 2.1.0. tifffile 2021.11.2. tinycss2 1.1.1. toolz 0.11.2. torch 1.11.0. torchmetrics 0.9.0. tornado 6.1. tqdm 4.60.0. traitlets 5.2.2.post1. typing-extens,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:1367,interoperability,wrapper,wrapper,1367,"y:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_group(group). 531 if encoding_type:. --> 532 EncodingVersions[encoding_type].check(. 533 group.name, group.attrs[""encoding-version""]. /opt/conda/lib/python3.7/enum.py in __getitem__(cls, name). 356 def __getitem__(cls, name):. --> 357 return cls._member_map_[name]. 358 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-20-38a594ec7d06> in <module>. ----> 1 adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 424 d[k] = read_dataframe(f[k]). 425 else: # Base case. --> 426 d[k] = read_attribute(f[k]). 427 . 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). ```. <details>. <summary>Versions</summary>. Package Version. ----------------------- ------------. absl-py 1.1.0. aiohttp 3.8.1. aiosignal 1.2.0. anndata 0.7.5. anndata2ri 1.0.6. annoy 1.17.0. argon2-cffi 21.3.0. argon2-cffi-bindings 21.2.0. asn1crypto 1.4.0. async-timeout 4.0.2. asynctest 0.13.0. attrs 20.3.0. backcall 0.2.0. beautifulsoup4 4.11.1. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:2244,interoperability,bind,bindings,2244," = read_attribute(f[k]). 427 . 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). ```. <details>. <summary>Versions</summary>. Package Version. ----------------------- ------------. absl-py 1.1.0. aiohttp 3.8.1. aiosignal 1.2.0. anndata 0.7.5. anndata2ri 1.0.6. annoy 1.17.0. argon2-cffi 21.3.0. argon2-cffi-bindings 21.2.0. asn1crypto 1.4.0. async-timeout 4.0.2. asynctest 0.13.0. attrs 20.3.0. backcall 0.2.0. beautifulsoup4 4.11.1. bleach 5.0.0. boto3 1.17.66. botocore 1.20.66. brotlipy 0.7.0. cached-property 1.5.2. cachetools 5.2.0. certifi 2020.12.5. cffi 1.14.5. chardet 4.0.0. charset-normalizer 2.0.12. chex 0.1.3. click 8.1.3. colormath 3.0.0. commonmark 0.9.1. conda 4.6.14. conda-package-handling 1.7.3. cryptography 3.4.7. cycler 0.10.0. Cython 0.29.30. decorator 5.0.7. defusedxml 0.7.1. dill 0.3.3. dm-tree 0.1.7. docrep 0.3.2. entrypoints 0.4. et-xmlfile 1.1.0. fa2 0.3.5. fastjsonschema 2.15.3. flatbuffers 2.0. flax 0.5.0. frozenlist 1.3.0. fsspec 2022.5.0. future 0.18.2. get-version 2.2. google-auth 2.6.6. google-auth-oauthlib 0.4.6. google-pasta 0.2.0. grpcio 1.46.3. h5py 3.2.1. idna 2.10. imageio 2.19.3. importlib-metadata 4.11.4. importlib-resources 5.7.1. ipykernel 5.5.4. ipython 7.23.1. ipython-genutils 0.2.0. ipywidgets 7.7.0. jax 0.3.13. jaxlib 0.3.10. jedi 0.18.0. Jinja2 3.1.2.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:2800,interoperability,xml,xmlfile,2800,"em)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). ```. <details>. <summary>Versions</summary>. Package Version. ----------------------- ------------. absl-py 1.1.0. aiohttp 3.8.1. aiosignal 1.2.0. anndata 0.7.5. anndata2ri 1.0.6. annoy 1.17.0. argon2-cffi 21.3.0. argon2-cffi-bindings 21.2.0. asn1crypto 1.4.0. async-timeout 4.0.2. asynctest 0.13.0. attrs 20.3.0. backcall 0.2.0. beautifulsoup4 4.11.1. bleach 5.0.0. boto3 1.17.66. botocore 1.20.66. brotlipy 0.7.0. cached-property 1.5.2. cachetools 5.2.0. certifi 2020.12.5. cffi 1.14.5. chardet 4.0.0. charset-normalizer 2.0.12. chex 0.1.3. click 8.1.3. colormath 3.0.0. commonmark 0.9.1. conda 4.6.14. conda-package-handling 1.7.3. cryptography 3.4.7. cycler 0.10.0. Cython 0.29.30. decorator 5.0.7. defusedxml 0.7.1. dill 0.3.3. dm-tree 0.1.7. docrep 0.3.2. entrypoints 0.4. et-xmlfile 1.1.0. fa2 0.3.5. fastjsonschema 2.15.3. flatbuffers 2.0. flax 0.5.0. frozenlist 1.3.0. fsspec 2022.5.0. future 0.18.2. get-version 2.2. google-auth 2.6.6. google-auth-oauthlib 0.4.6. google-pasta 0.2.0. grpcio 1.46.3. h5py 3.2.1. idna 2.10. imageio 2.19.3. importlib-metadata 4.11.4. importlib-resources 5.7.1. ipykernel 5.5.4. ipython 7.23.1. ipython-genutils 0.2.0. ipywidgets 7.7.0. jax 0.3.13. jaxlib 0.3.10. jedi 0.18.0. Jinja2 3.1.2. jmespath 0.10.0. joblib 1.0.1. jsonschema 4.6.0. jupyter-client 6.1.12. jupyter-core 4.7.1. jupyterlab-pygments 0.2.2. jupyterlab-widgets 1.1.0. kiwisolver 1.3.1. legacy-api-wrap 1.2. leidenalg 0.8.4. llvmlite 0.35.0. loompy 3.0.7. louvain 0.7.0. Markdown 3.3.7. MarkupSafe 2.1.1. matplotlib 3.4.1. matplotlib-inline 0.1.2. mistune 0.8.4. msgpack 1.0.4. multidict 6.0.2. multipledispatch 0.6.0. multiprocess 0.70.11.1. natsort 7.1.1. nbclient 0.6.4. nbconvert 6.5.0. nbformat 5.4.0. nest-asyncio 1.5.5. networkx 2.5. notebook 6.4.11. numba 0.52.0. numexpr",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:3419,interoperability,api,api-wrap,3419,ipy 0.7.0. cached-property 1.5.2. cachetools 5.2.0. certifi 2020.12.5. cffi 1.14.5. chardet 4.0.0. charset-normalizer 2.0.12. chex 0.1.3. click 8.1.3. colormath 3.0.0. commonmark 0.9.1. conda 4.6.14. conda-package-handling 1.7.3. cryptography 3.4.7. cycler 0.10.0. Cython 0.29.30. decorator 5.0.7. defusedxml 0.7.1. dill 0.3.3. dm-tree 0.1.7. docrep 0.3.2. entrypoints 0.4. et-xmlfile 1.1.0. fa2 0.3.5. fastjsonschema 2.15.3. flatbuffers 2.0. flax 0.5.0. frozenlist 1.3.0. fsspec 2022.5.0. future 0.18.2. get-version 2.2. google-auth 2.6.6. google-auth-oauthlib 0.4.6. google-pasta 0.2.0. grpcio 1.46.3. h5py 3.2.1. idna 2.10. imageio 2.19.3. importlib-metadata 4.11.4. importlib-resources 5.7.1. ipykernel 5.5.4. ipython 7.23.1. ipython-genutils 0.2.0. ipywidgets 7.7.0. jax 0.3.13. jaxlib 0.3.10. jedi 0.18.0. Jinja2 3.1.2. jmespath 0.10.0. joblib 1.0.1. jsonschema 4.6.0. jupyter-client 6.1.12. jupyter-core 4.7.1. jupyterlab-pygments 0.2.2. jupyterlab-widgets 1.1.0. kiwisolver 1.3.1. legacy-api-wrap 1.2. leidenalg 0.8.4. llvmlite 0.35.0. loompy 3.0.7. louvain 0.7.0. Markdown 3.3.7. MarkupSafe 2.1.1. matplotlib 3.4.1. matplotlib-inline 0.1.2. mistune 0.8.4. msgpack 1.0.4. multidict 6.0.2. multipledispatch 0.6.0. multiprocess 0.70.11.1. natsort 7.1.1. nbclient 0.6.4. nbconvert 6.5.0. nbformat 5.4.0. nest-asyncio 1.5.5. networkx 2.5. notebook 6.4.11. numba 0.52.0. numexpr 2.7.3. numpy 1.19.5. numpy-groupies 0.9.17. numpyro 0.9.2. oauthlib 3.2.0. openpyxl 3.0.10. opt-einsum 3.3.0. optax 0.1.2. packaging 20.9. pandas 1.2.0. pandocfilters 1.5.0. parso 0.8.2. pathos 0.2.7. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 9.1.1. pip 21.1.1. pox 0.2.9. ppft 1.6.6.3. prometheus-client 0.14.1. prompt-toolkit 3.0.18. protobuf 3.19.0. protobuf3-to-dict 0.1.5. ptyprocess 0.7.0. pyasn1 0.4.8. pyasn1-modules 0.2.8. pycosat 0.6.3. pycparser 2.20. pyDeprecate 0.3.1. Pygments 2.9.0. pyOpenSSL 20.0.1. pyparsing 2.4.7. pyro-api 0.1.2. pyro-ppl 1.8.1. pyrsistent 0.18.1. PySocks 1.7.1. python-,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:4355,interoperability,api,api,4355,nts 0.2.2. jupyterlab-widgets 1.1.0. kiwisolver 1.3.1. legacy-api-wrap 1.2. leidenalg 0.8.4. llvmlite 0.35.0. loompy 3.0.7. louvain 0.7.0. Markdown 3.3.7. MarkupSafe 2.1.1. matplotlib 3.4.1. matplotlib-inline 0.1.2. mistune 0.8.4. msgpack 1.0.4. multidict 6.0.2. multipledispatch 0.6.0. multiprocess 0.70.11.1. natsort 7.1.1. nbclient 0.6.4. nbconvert 6.5.0. nbformat 5.4.0. nest-asyncio 1.5.5. networkx 2.5. notebook 6.4.11. numba 0.52.0. numexpr 2.7.3. numpy 1.19.5. numpy-groupies 0.9.17. numpyro 0.9.2. oauthlib 3.2.0. openpyxl 3.0.10. opt-einsum 3.3.0. optax 0.1.2. packaging 20.9. pandas 1.2.0. pandocfilters 1.5.0. parso 0.8.2. pathos 0.2.7. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 9.1.1. pip 21.1.1. pox 0.2.9. ppft 1.6.6.3. prometheus-client 0.14.1. prompt-toolkit 3.0.18. protobuf 3.19.0. protobuf3-to-dict 0.1.5. ptyprocess 0.7.0. pyasn1 0.4.8. pyasn1-modules 0.2.8. pycosat 0.6.3. pycparser 2.20. pyDeprecate 0.3.1. Pygments 2.9.0. pyOpenSSL 20.0.1. pyparsing 2.4.7. pyro-api 0.1.2. pyro-ppl 1.8.1. pyrsistent 0.18.1. PySocks 1.7.1. python-dateutil 2.8.1. python-igraph 0.9.1. pytorch-lightning 1.5.10. pytz 2021.1. PyWavelets 1.3.0. PyYAML 6.0. pyzmq 22.0.3. requests 2.25.1. requests-oauthlib 1.3.1. rich 12.4.4. rpy2 3.4.2. rsa 4.8. ruamel-yaml-conda 0.15.80. ruamel.yaml 0.17.21. ruamel.yaml.clib 0.2.6. s3transfer 0.4.2. sagemaker 2.39.0.post0. scanpy 1.6.1. scikit-image 0.19.2. scikit-learn 0.24.2. scikit-misc 0.1.4. scipy 1.6.0. scrublet 0.2.3. scvi-tools 0.16.2. seaborn 0.11.1. Send2Trash 1.8.0. setuptools 59.5.0. setuptools-scm 6.0.1. sinfo 0.3.1. six 1.15.0. smdebug-rulesconfig 1.0.1. soupsieve 2.3.2.post1. spectra 0.0.11. statsmodels 0.12.2. stdlib-list 0.8.0. tables 3.6.1. tensorboard 2.9.0. tensorboard-data-server 0.6.1. tensorboard-plugin-wit 1.8.1. terminado 0.15.0. texttable 1.6.3. threadpoolctl 2.1.0. tifffile 2021.11.2. tinycss2 1.1.1. toolz 0.11.2. torch 1.11.0. torchmetrics 0.9.0. tornado 6.1. tqdm 4.60.0. traitlets 5.2.2.post1. typing-extens,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:5137,interoperability,plug,plugin-wit,5137," natsort 7.1.1. nbclient 0.6.4. nbconvert 6.5.0. nbformat 5.4.0. nest-asyncio 1.5.5. networkx 2.5. notebook 6.4.11. numba 0.52.0. numexpr 2.7.3. numpy 1.19.5. numpy-groupies 0.9.17. numpyro 0.9.2. oauthlib 3.2.0. openpyxl 3.0.10. opt-einsum 3.3.0. optax 0.1.2. packaging 20.9. pandas 1.2.0. pandocfilters 1.5.0. parso 0.8.2. pathos 0.2.7. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 9.1.1. pip 21.1.1. pox 0.2.9. ppft 1.6.6.3. prometheus-client 0.14.1. prompt-toolkit 3.0.18. protobuf 3.19.0. protobuf3-to-dict 0.1.5. ptyprocess 0.7.0. pyasn1 0.4.8. pyasn1-modules 0.2.8. pycosat 0.6.3. pycparser 2.20. pyDeprecate 0.3.1. Pygments 2.9.0. pyOpenSSL 20.0.1. pyparsing 2.4.7. pyro-api 0.1.2. pyro-ppl 1.8.1. pyrsistent 0.18.1. PySocks 1.7.1. python-dateutil 2.8.1. python-igraph 0.9.1. pytorch-lightning 1.5.10. pytz 2021.1. PyWavelets 1.3.0. PyYAML 6.0. pyzmq 22.0.3. requests 2.25.1. requests-oauthlib 1.3.1. rich 12.4.4. rpy2 3.4.2. rsa 4.8. ruamel-yaml-conda 0.15.80. ruamel.yaml 0.17.21. ruamel.yaml.clib 0.2.6. s3transfer 0.4.2. sagemaker 2.39.0.post0. scanpy 1.6.1. scikit-image 0.19.2. scikit-learn 0.24.2. scikit-misc 0.1.4. scipy 1.6.0. scrublet 0.2.3. scvi-tools 0.16.2. seaborn 0.11.1. Send2Trash 1.8.0. setuptools 59.5.0. setuptools-scm 6.0.1. sinfo 0.3.1. six 1.15.0. smdebug-rulesconfig 1.0.1. soupsieve 2.3.2.post1. spectra 0.0.11. statsmodels 0.12.2. stdlib-list 0.8.0. tables 3.6.1. tensorboard 2.9.0. tensorboard-data-server 0.6.1. tensorboard-plugin-wit 1.8.1. terminado 0.15.0. texttable 1.6.3. threadpoolctl 2.1.0. tifffile 2021.11.2. tinycss2 1.1.1. toolz 0.11.2. torch 1.11.0. torchmetrics 0.9.0. tornado 6.1. tqdm 4.60.0. traitlets 5.2.2.post1. typing-extensions 4.2.0. tzlocal 2.1. umap-learn 0.4.6. urllib3 1.26.4. wcwidth 0.2.5. webencodings 0.5.1. Werkzeug 2.1.2. wheel 0.36.2. widgetsnbextension 3.6.0. yarl 1.7.2. zipp 3.4.1. Note: you may need to restart the kernel to use updated packages."". </details>. Has anyone found any solution to work around this issue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:295,modifiability,pac,packages,295,"Found the same error in our internal workflows. Saved the data to h5py files, but could not open them anymore for some reason. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_group(group). 531 if encoding_type:. --> 532 EncodingVersions[encoding_type].check(. 533 group.name, group.attrs[""encoding-version""]. /opt/conda/lib/python3.7/enum.py in __getitem__(cls, name). 356 def __getitem__(cls, name):. --> 357 return cls._member_map_[name]. 358 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-20-38a594ec7d06> in <module>. ----> 1 adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 424 d[k] = read_dataframe(f[k]). 425 else: # Base case. --> 426 d[k] = read_attribute(f[k]). 427 . 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:477,modifiability,pac,packages,477,"Found the same error in our internal workflows. Saved the data to h5py files, but could not open them anymore for some reason. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_group(group). 531 if encoding_type:. --> 532 EncodingVersions[encoding_type].check(. 533 group.name, group.attrs[""encoding-version""]. /opt/conda/lib/python3.7/enum.py in __getitem__(cls, name). 356 def __getitem__(cls, name):. --> 357 return cls._member_map_[name]. 358 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-20-38a594ec7d06> in <module>. ----> 1 adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 424 d[k] = read_dataframe(f[k]). 425 else: # Base case. --> 426 d[k] = read_attribute(f[k]). 427 . 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:637,modifiability,version,version,637,"Found the same error in our internal workflows. Saved the data to h5py files, but could not open them anymore for some reason. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_group(group). 531 if encoding_type:. --> 532 EncodingVersions[encoding_type].check(. 533 group.name, group.attrs[""encoding-version""]. /opt/conda/lib/python3.7/enum.py in __getitem__(cls, name). 356 def __getitem__(cls, name):. --> 357 return cls._member_map_[name]. 358 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-20-38a594ec7d06> in <module>. ----> 1 adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 424 d[k] = read_dataframe(f[k]). 425 else: # Base case. --> 426 d[k] = read_attribute(f[k]). 427 . 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:961,modifiability,modul,module,961,"Found the same error in our internal workflows. Saved the data to h5py files, but could not open them anymore for some reason. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_group(group). 531 if encoding_type:. --> 532 EncodingVersions[encoding_type].check(. 533 group.name, group.attrs[""encoding-version""]. /opt/conda/lib/python3.7/enum.py in __getitem__(cls, name). 356 def __getitem__(cls, name):. --> 357 return cls._member_map_[name]. 358 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-20-38a594ec7d06> in <module>. ----> 1 adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 424 d[k] = read_dataframe(f[k]). 425 else: # Base case. --> 426 d[k] = read_attribute(f[k]). 427 . 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:1081,modifiability,pac,packages,1081,"ld not open them anymore for some reason. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_group(group). 531 if encoding_type:. --> 532 EncodingVersions[encoding_type].check(. 533 group.name, group.attrs[""encoding-version""]. /opt/conda/lib/python3.7/enum.py in __getitem__(cls, name). 356 def __getitem__(cls, name):. --> 357 return cls._member_map_[name]. 358 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-20-38a594ec7d06> in <module>. ----> 1 adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 424 d[k] = read_dataframe(f[k]). 425 else: # Base case. --> 426 d[k] = read_attribute(f[k]). 427 . 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). ```. <details>. <summary>Versions</summary>. Package Version. -----",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:1587,modifiability,pac,packages,1587,"check(. 533 group.name, group.attrs[""encoding-version""]. /opt/conda/lib/python3.7/enum.py in __getitem__(cls, name). 356 def __getitem__(cls, name):. --> 357 return cls._member_map_[name]. 358 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-20-38a594ec7d06> in <module>. ----> 1 adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 424 d[k] = read_dataframe(f[k]). 425 else: # Base case. --> 426 d[k] = read_attribute(f[k]). 427 . 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). ```. <details>. <summary>Versions</summary>. Package Version. ----------------------- ------------. absl-py 1.1.0. aiohttp 3.8.1. aiosignal 1.2.0. anndata 0.7.5. anndata2ri 1.0.6. annoy 1.17.0. argon2-cffi 21.3.0. argon2-cffi-bindings 21.2.0. asn1crypto 1.4.0. async-timeout 4.0.2. asynctest 0.13.0. attrs 20.3.0. backcall 0.2.0. beautifulsoup4 4.11.1. bleach 5.0.0. boto3 1.17.66. botocore 1.20.66. brotlipy 0.7.0. cached-property 1.5.2. cachetools 5.2.0. certifi 2020.12.5. cffi 1.14.5. chardet 4.0.0. charset-normalizer 2.0.12. chex 0.1.3. click 8.1.3. colormath 3.0.0. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:1890,modifiability,layer,layers,1890,"ceback (most recent call last). <ipython-input-20-38a594ec7d06> in <module>. ----> 1 adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 424 d[k] = read_dataframe(f[k]). 425 else: # Base case. --> 426 d[k] = read_attribute(f[k]). 427 . 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). ```. <details>. <summary>Versions</summary>. Package Version. ----------------------- ------------. absl-py 1.1.0. aiohttp 3.8.1. aiosignal 1.2.0. anndata 0.7.5. anndata2ri 1.0.6. annoy 1.17.0. argon2-cffi 21.3.0. argon2-cffi-bindings 21.2.0. asn1crypto 1.4.0. async-timeout 4.0.2. asynctest 0.13.0. attrs 20.3.0. backcall 0.2.0. beautifulsoup4 4.11.1. bleach 5.0.0. boto3 1.17.66. botocore 1.20.66. brotlipy 0.7.0. cached-property 1.5.2. cachetools 5.2.0. certifi 2020.12.5. cffi 1.14.5. chardet 4.0.0. charset-normalizer 2.0.12. chex 0.1.3. click 8.1.3. colormath 3.0.0. commonmark 0.9.1. conda 4.6.14. conda-package-handling 1.7.3. cryptography 3.4.7. cycler 0.10.0. Cython 0.29.30. decorator 5.0.7. defusedxml 0.7.1. dill 0.3.3. dm-tree 0.1.7. docrep 0.3.2. entrypoints 0.4. et-xmlfile 1.1.0. fa2 0.3.5. fastjsonschema 2.15.3. flatbuffers 2.0. flax 0.5.0. frozenlist 1.3.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:2043,modifiability,Version,Versions,2043,"'). /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 424 d[k] = read_dataframe(f[k]). 425 else: # Base case. --> 426 d[k] = read_attribute(f[k]). 427 . 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). ```. <details>. <summary>Versions</summary>. Package Version. ----------------------- ------------. absl-py 1.1.0. aiohttp 3.8.1. aiosignal 1.2.0. anndata 0.7.5. anndata2ri 1.0.6. annoy 1.17.0. argon2-cffi 21.3.0. argon2-cffi-bindings 21.2.0. asn1crypto 1.4.0. async-timeout 4.0.2. asynctest 0.13.0. attrs 20.3.0. backcall 0.2.0. beautifulsoup4 4.11.1. bleach 5.0.0. boto3 1.17.66. botocore 1.20.66. brotlipy 0.7.0. cached-property 1.5.2. cachetools 5.2.0. certifi 2020.12.5. cffi 1.14.5. chardet 4.0.0. charset-normalizer 2.0.12. chex 0.1.3. click 8.1.3. colormath 3.0.0. commonmark 0.9.1. conda 4.6.14. conda-package-handling 1.7.3. cryptography 3.4.7. cycler 0.10.0. Cython 0.29.30. decorator 5.0.7. defusedxml 0.7.1. dill 0.3.3. dm-tree 0.1.7. docrep 0.3.2. entrypoints 0.4. et-xmlfile 1.1.0. fa2 0.3.5. fastjsonschema 2.15.3. flatbuffers 2.0. flax 0.5.0. frozenlist 1.3.0. fsspec 2022.5.0. future 0.18.2. get-version 2.2. google-auth 2.6.6. google-auth-oauthlib 0.4.6. google-pasta 0.2.0. grpcio 1.46.3. h5py 3.2.1. idna 2.1",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:2063,modifiability,Pac,Package,2063,"ython3.7/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 424 d[k] = read_dataframe(f[k]). 425 else: # Base case. --> 426 d[k] = read_attribute(f[k]). 427 . 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). ```. <details>. <summary>Versions</summary>. Package Version. ----------------------- ------------. absl-py 1.1.0. aiohttp 3.8.1. aiosignal 1.2.0. anndata 0.7.5. anndata2ri 1.0.6. annoy 1.17.0. argon2-cffi 21.3.0. argon2-cffi-bindings 21.2.0. asn1crypto 1.4.0. async-timeout 4.0.2. asynctest 0.13.0. attrs 20.3.0. backcall 0.2.0. beautifulsoup4 4.11.1. bleach 5.0.0. boto3 1.17.66. botocore 1.20.66. brotlipy 0.7.0. cached-property 1.5.2. cachetools 5.2.0. certifi 2020.12.5. cffi 1.14.5. chardet 4.0.0. charset-normalizer 2.0.12. chex 0.1.3. click 8.1.3. colormath 3.0.0. commonmark 0.9.1. conda 4.6.14. conda-package-handling 1.7.3. cryptography 3.4.7. cycler 0.10.0. Cython 0.29.30. decorator 5.0.7. defusedxml 0.7.1. dill 0.3.3. dm-tree 0.1.7. docrep 0.3.2. entrypoints 0.4. et-xmlfile 1.1.0. fa2 0.3.5. fastjsonschema 2.15.3. flatbuffers 2.0. flax 0.5.0. frozenlist 1.3.0. fsspec 2022.5.0. future 0.18.2. get-version 2.2. google-auth 2.6.6. google-auth-oauthlib 0.4.6. google-pasta 0.2.0. grpcio 1.46.3. h5py 3.2.1. idna 2.10. imageio 2.19.3. i",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:2071,modifiability,Version,Version,2071,"/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 424 d[k] = read_dataframe(f[k]). 425 else: # Base case. --> 426 d[k] = read_attribute(f[k]). 427 . 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). ```. <details>. <summary>Versions</summary>. Package Version. ----------------------- ------------. absl-py 1.1.0. aiohttp 3.8.1. aiosignal 1.2.0. anndata 0.7.5. anndata2ri 1.0.6. annoy 1.17.0. argon2-cffi 21.3.0. argon2-cffi-bindings 21.2.0. asn1crypto 1.4.0. async-timeout 4.0.2. asynctest 0.13.0. attrs 20.3.0. backcall 0.2.0. beautifulsoup4 4.11.1. bleach 5.0.0. boto3 1.17.66. botocore 1.20.66. brotlipy 0.7.0. cached-property 1.5.2. cachetools 5.2.0. certifi 2020.12.5. cffi 1.14.5. chardet 4.0.0. charset-normalizer 2.0.12. chex 0.1.3. click 8.1.3. colormath 3.0.0. commonmark 0.9.1. conda 4.6.14. conda-package-handling 1.7.3. cryptography 3.4.7. cycler 0.10.0. Cython 0.29.30. decorator 5.0.7. defusedxml 0.7.1. dill 0.3.3. dm-tree 0.1.7. docrep 0.3.2. entrypoints 0.4. et-xmlfile 1.1.0. fa2 0.3.5. fastjsonschema 2.15.3. flatbuffers 2.0. flax 0.5.0. frozenlist 1.3.0. fsspec 2022.5.0. future 0.18.2. get-version 2.2. google-auth 2.6.6. google-auth-oauthlib 0.4.6. google-pasta 0.2.0. grpcio 1.46.3. h5py 3.2.1. idna 2.10. imageio 2.19.3. importlib",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:2244,modifiability,bind,bindings,2244," = read_attribute(f[k]). 427 . 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). ```. <details>. <summary>Versions</summary>. Package Version. ----------------------- ------------. absl-py 1.1.0. aiohttp 3.8.1. aiosignal 1.2.0. anndata 0.7.5. anndata2ri 1.0.6. annoy 1.17.0. argon2-cffi 21.3.0. argon2-cffi-bindings 21.2.0. asn1crypto 1.4.0. async-timeout 4.0.2. asynctest 0.13.0. attrs 20.3.0. backcall 0.2.0. beautifulsoup4 4.11.1. bleach 5.0.0. boto3 1.17.66. botocore 1.20.66. brotlipy 0.7.0. cached-property 1.5.2. cachetools 5.2.0. certifi 2020.12.5. cffi 1.14.5. chardet 4.0.0. charset-normalizer 2.0.12. chex 0.1.3. click 8.1.3. colormath 3.0.0. commonmark 0.9.1. conda 4.6.14. conda-package-handling 1.7.3. cryptography 3.4.7. cycler 0.10.0. Cython 0.29.30. decorator 5.0.7. defusedxml 0.7.1. dill 0.3.3. dm-tree 0.1.7. docrep 0.3.2. entrypoints 0.4. et-xmlfile 1.1.0. fa2 0.3.5. fastjsonschema 2.15.3. flatbuffers 2.0. flax 0.5.0. frozenlist 1.3.0. fsspec 2022.5.0. future 0.18.2. get-version 2.2. google-auth 2.6.6. google-auth-oauthlib 0.4.6. google-pasta 0.2.0. grpcio 1.46.3. h5py 3.2.1. idna 2.10. imageio 2.19.3. importlib-metadata 4.11.4. importlib-resources 5.7.1. ipykernel 5.5.4. ipython 7.23.1. ipython-genutils 0.2.0. ipywidgets 7.7.0. jax 0.3.13. jaxlib 0.3.10. jedi 0.18.0. Jinja2 3.1.2.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:2629,modifiability,pac,package-handling,2629,", *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). ```. <details>. <summary>Versions</summary>. Package Version. ----------------------- ------------. absl-py 1.1.0. aiohttp 3.8.1. aiosignal 1.2.0. anndata 0.7.5. anndata2ri 1.0.6. annoy 1.17.0. argon2-cffi 21.3.0. argon2-cffi-bindings 21.2.0. asn1crypto 1.4.0. async-timeout 4.0.2. asynctest 0.13.0. attrs 20.3.0. backcall 0.2.0. beautifulsoup4 4.11.1. bleach 5.0.0. boto3 1.17.66. botocore 1.20.66. brotlipy 0.7.0. cached-property 1.5.2. cachetools 5.2.0. certifi 2020.12.5. cffi 1.14.5. chardet 4.0.0. charset-normalizer 2.0.12. chex 0.1.3. click 8.1.3. colormath 3.0.0. commonmark 0.9.1. conda 4.6.14. conda-package-handling 1.7.3. cryptography 3.4.7. cycler 0.10.0. Cython 0.29.30. decorator 5.0.7. defusedxml 0.7.1. dill 0.3.3. dm-tree 0.1.7. docrep 0.3.2. entrypoints 0.4. et-xmlfile 1.1.0. fa2 0.3.5. fastjsonschema 2.15.3. flatbuffers 2.0. flax 0.5.0. frozenlist 1.3.0. fsspec 2022.5.0. future 0.18.2. get-version 2.2. google-auth 2.6.6. google-auth-oauthlib 0.4.6. google-pasta 0.2.0. grpcio 1.46.3. h5py 3.2.1. idna 2.10. imageio 2.19.3. importlib-metadata 4.11.4. importlib-resources 5.7.1. ipykernel 5.5.4. ipython 7.23.1. ipython-genutils 0.2.0. ipywidgets 7.7.0. jax 0.3.13. jaxlib 0.3.10. jedi 0.18.0. Jinja2 3.1.2. jmespath 0.10.0. joblib 1.0.1. jsonschema 4.6.0. jupyter-client 6.1.12. jupyter-core 4.7.1. jupyterlab-pygments 0.2.2. jupyterlab-widgets 1.1.0. kiwisolver 1.3.1. legacy-api-wrap 1.2. leidenalg 0.8.4. llvmlite 0.35.0. loompy 3.0.7. louvain 0.7.0. Markdown 3.3.7. MarkupSafe 2.1.1. matplotlib 3.4.1. matplotlib-inline 0.1.2. mistune 0.8.4. msgpack 1.0.4. multidict 6.0.2. multipledispatch ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:2704,modifiability,deco,decorator,2704,"dError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). ```. <details>. <summary>Versions</summary>. Package Version. ----------------------- ------------. absl-py 1.1.0. aiohttp 3.8.1. aiosignal 1.2.0. anndata 0.7.5. anndata2ri 1.0.6. annoy 1.17.0. argon2-cffi 21.3.0. argon2-cffi-bindings 21.2.0. asn1crypto 1.4.0. async-timeout 4.0.2. asynctest 0.13.0. attrs 20.3.0. backcall 0.2.0. beautifulsoup4 4.11.1. bleach 5.0.0. boto3 1.17.66. botocore 1.20.66. brotlipy 0.7.0. cached-property 1.5.2. cachetools 5.2.0. certifi 2020.12.5. cffi 1.14.5. chardet 4.0.0. charset-normalizer 2.0.12. chex 0.1.3. click 8.1.3. colormath 3.0.0. commonmark 0.9.1. conda 4.6.14. conda-package-handling 1.7.3. cryptography 3.4.7. cycler 0.10.0. Cython 0.29.30. decorator 5.0.7. defusedxml 0.7.1. dill 0.3.3. dm-tree 0.1.7. docrep 0.3.2. entrypoints 0.4. et-xmlfile 1.1.0. fa2 0.3.5. fastjsonschema 2.15.3. flatbuffers 2.0. flax 0.5.0. frozenlist 1.3.0. fsspec 2022.5.0. future 0.18.2. get-version 2.2. google-auth 2.6.6. google-auth-oauthlib 0.4.6. google-pasta 0.2.0. grpcio 1.46.3. h5py 3.2.1. idna 2.10. imageio 2.19.3. importlib-metadata 4.11.4. importlib-resources 5.7.1. ipykernel 5.5.4. ipython 7.23.1. ipython-genutils 0.2.0. ipywidgets 7.7.0. jax 0.3.13. jaxlib 0.3.10. jedi 0.18.0. Jinja2 3.1.2. jmespath 0.10.0. joblib 1.0.1. jsonschema 4.6.0. jupyter-client 6.1.12. jupyter-core 4.7.1. jupyterlab-pygments 0.2.2. jupyterlab-widgets 1.1.0. kiwisolver 1.3.1. legacy-api-wrap 1.2. leidenalg 0.8.4. llvmlite 0.35.0. loompy 3.0.7. louvain 0.7.0. Markdown 3.3.7. MarkupSafe 2.1.1. matplotlib 3.4.1. matplotlib-inline 0.1.2. mistune 0.8.4. msgpack 1.0.4. multidict 6.0.2. multipledispatch 0.6.0. multiprocess 0.70.11.1. natsort 7.1.1. nbclient 0.6.4. nbconvert ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:2932,modifiability,version,version,2932, from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). ```. <details>. <summary>Versions</summary>. Package Version. ----------------------- ------------. absl-py 1.1.0. aiohttp 3.8.1. aiosignal 1.2.0. anndata 0.7.5. anndata2ri 1.0.6. annoy 1.17.0. argon2-cffi 21.3.0. argon2-cffi-bindings 21.2.0. asn1crypto 1.4.0. async-timeout 4.0.2. asynctest 0.13.0. attrs 20.3.0. backcall 0.2.0. beautifulsoup4 4.11.1. bleach 5.0.0. boto3 1.17.66. botocore 1.20.66. brotlipy 0.7.0. cached-property 1.5.2. cachetools 5.2.0. certifi 2020.12.5. cffi 1.14.5. chardet 4.0.0. charset-normalizer 2.0.12. chex 0.1.3. click 8.1.3. colormath 3.0.0. commonmark 0.9.1. conda 4.6.14. conda-package-handling 1.7.3. cryptography 3.4.7. cycler 0.10.0. Cython 0.29.30. decorator 5.0.7. defusedxml 0.7.1. dill 0.3.3. dm-tree 0.1.7. docrep 0.3.2. entrypoints 0.4. et-xmlfile 1.1.0. fa2 0.3.5. fastjsonschema 2.15.3. flatbuffers 2.0. flax 0.5.0. frozenlist 1.3.0. fsspec 2022.5.0. future 0.18.2. get-version 2.2. google-auth 2.6.6. google-auth-oauthlib 0.4.6. google-pasta 0.2.0. grpcio 1.46.3. h5py 3.2.1. idna 2.10. imageio 2.19.3. importlib-metadata 4.11.4. importlib-resources 5.7.1. ipykernel 5.5.4. ipython 7.23.1. ipython-genutils 0.2.0. ipywidgets 7.7.0. jax 0.3.13. jaxlib 0.3.10. jedi 0.18.0. Jinja2 3.1.2. jmespath 0.10.0. joblib 1.0.1. jsonschema 4.6.0. jupyter-client 6.1.12. jupyter-core 4.7.1. jupyterlab-pygments 0.2.2. jupyterlab-widgets 1.1.0. kiwisolver 1.3.1. legacy-api-wrap 1.2. leidenalg 0.8.4. llvmlite 0.35.0. loompy 3.0.7. louvain 0.7.0. Markdown 3.3.7. MarkupSafe 2.1.1. matplotlib 3.4.1. matplotlib-inline 0.1.2. mistune 0.8.4. msgpack 1.0.4. multidict 6.0.2. multipledispatch 0.6.0. multiprocess 0.70.11.1. natsort 7.1.1. nbclient 0.6.4. nbconvert 6.5.0. nbformat 5.4.0. nest-asyncio 1.5.5. networkx 2.5. notebook 6.4.11. numba 0.52.0. numexpr 2.7.3. numpy 1.19.5. numpy-groupies 0.9.17. numpyro 0.9.2. oauthlib 3.2.0. openpyxl 3.0.10. opt-einsum 3.3.0. optax 0.1.2. packagin,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:3928,modifiability,pac,packaging,3928,ersion 2.2. google-auth 2.6.6. google-auth-oauthlib 0.4.6. google-pasta 0.2.0. grpcio 1.46.3. h5py 3.2.1. idna 2.10. imageio 2.19.3. importlib-metadata 4.11.4. importlib-resources 5.7.1. ipykernel 5.5.4. ipython 7.23.1. ipython-genutils 0.2.0. ipywidgets 7.7.0. jax 0.3.13. jaxlib 0.3.10. jedi 0.18.0. Jinja2 3.1.2. jmespath 0.10.0. joblib 1.0.1. jsonschema 4.6.0. jupyter-client 6.1.12. jupyter-core 4.7.1. jupyterlab-pygments 0.2.2. jupyterlab-widgets 1.1.0. kiwisolver 1.3.1. legacy-api-wrap 1.2. leidenalg 0.8.4. llvmlite 0.35.0. loompy 3.0.7. louvain 0.7.0. Markdown 3.3.7. MarkupSafe 2.1.1. matplotlib 3.4.1. matplotlib-inline 0.1.2. mistune 0.8.4. msgpack 1.0.4. multidict 6.0.2. multipledispatch 0.6.0. multiprocess 0.70.11.1. natsort 7.1.1. nbclient 0.6.4. nbconvert 6.5.0. nbformat 5.4.0. nest-asyncio 1.5.5. networkx 2.5. notebook 6.4.11. numba 0.52.0. numexpr 2.7.3. numpy 1.19.5. numpy-groupies 0.9.17. numpyro 0.9.2. oauthlib 3.2.0. openpyxl 3.0.10. opt-einsum 3.3.0. optax 0.1.2. packaging 20.9. pandas 1.2.0. pandocfilters 1.5.0. parso 0.8.2. pathos 0.2.7. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 9.1.1. pip 21.1.1. pox 0.2.9. ppft 1.6.6.3. prometheus-client 0.14.1. prompt-toolkit 3.0.18. protobuf 3.19.0. protobuf3-to-dict 0.1.5. ptyprocess 0.7.0. pyasn1 0.4.8. pyasn1-modules 0.2.8. pycosat 0.6.3. pycparser 2.20. pyDeprecate 0.3.1. Pygments 2.9.0. pyOpenSSL 20.0.1. pyparsing 2.4.7. pyro-api 0.1.2. pyro-ppl 1.8.1. pyrsistent 0.18.1. PySocks 1.7.1. python-dateutil 2.8.1. python-igraph 0.9.1. pytorch-lightning 1.5.10. pytz 2021.1. PyWavelets 1.3.0. PyYAML 6.0. pyzmq 22.0.3. requests 2.25.1. requests-oauthlib 1.3.1. rich 12.4.4. rpy2 3.4.2. rsa 4.8. ruamel-yaml-conda 0.15.80. ruamel.yaml 0.17.21. ruamel.yaml.clib 0.2.6. s3transfer 0.4.2. sagemaker 2.39.0.post0. scanpy 1.6.1. scikit-image 0.19.2. scikit-learn 0.24.2. scikit-misc 0.1.4. scipy 1.6.0. scrublet 0.2.3. scvi-tools 0.16.2. seaborn 0.11.1. Send2Trash 1.8.0. setuptools 59.5.0. setuptools-scm 6.0.1. si,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:4234,modifiability,modul,modules,4234,ja2 3.1.2. jmespath 0.10.0. joblib 1.0.1. jsonschema 4.6.0. jupyter-client 6.1.12. jupyter-core 4.7.1. jupyterlab-pygments 0.2.2. jupyterlab-widgets 1.1.0. kiwisolver 1.3.1. legacy-api-wrap 1.2. leidenalg 0.8.4. llvmlite 0.35.0. loompy 3.0.7. louvain 0.7.0. Markdown 3.3.7. MarkupSafe 2.1.1. matplotlib 3.4.1. matplotlib-inline 0.1.2. mistune 0.8.4. msgpack 1.0.4. multidict 6.0.2. multipledispatch 0.6.0. multiprocess 0.70.11.1. natsort 7.1.1. nbclient 0.6.4. nbconvert 6.5.0. nbformat 5.4.0. nest-asyncio 1.5.5. networkx 2.5. notebook 6.4.11. numba 0.52.0. numexpr 2.7.3. numpy 1.19.5. numpy-groupies 0.9.17. numpyro 0.9.2. oauthlib 3.2.0. openpyxl 3.0.10. opt-einsum 3.3.0. optax 0.1.2. packaging 20.9. pandas 1.2.0. pandocfilters 1.5.0. parso 0.8.2. pathos 0.2.7. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 9.1.1. pip 21.1.1. pox 0.2.9. ppft 1.6.6.3. prometheus-client 0.14.1. prompt-toolkit 3.0.18. protobuf 3.19.0. protobuf3-to-dict 0.1.5. ptyprocess 0.7.0. pyasn1 0.4.8. pyasn1-modules 0.2.8. pycosat 0.6.3. pycparser 2.20. pyDeprecate 0.3.1. Pygments 2.9.0. pyOpenSSL 20.0.1. pyparsing 2.4.7. pyro-api 0.1.2. pyro-ppl 1.8.1. pyrsistent 0.18.1. PySocks 1.7.1. python-dateutil 2.8.1. python-igraph 0.9.1. pytorch-lightning 1.5.10. pytz 2021.1. PyWavelets 1.3.0. PyYAML 6.0. pyzmq 22.0.3. requests 2.25.1. requests-oauthlib 1.3.1. rich 12.4.4. rpy2 3.4.2. rsa 4.8. ruamel-yaml-conda 0.15.80. ruamel.yaml 0.17.21. ruamel.yaml.clib 0.2.6. s3transfer 0.4.2. sagemaker 2.39.0.post0. scanpy 1.6.1. scikit-image 0.19.2. scikit-learn 0.24.2. scikit-misc 0.1.4. scipy 1.6.0. scrublet 0.2.3. scvi-tools 0.16.2. seaborn 0.11.1. Send2Trash 1.8.0. setuptools 59.5.0. setuptools-scm 6.0.1. sinfo 0.3.1. six 1.15.0. smdebug-rulesconfig 1.0.1. soupsieve 2.3.2.post1. spectra 0.0.11. statsmodels 0.12.2. stdlib-list 0.8.0. tables 3.6.1. tensorboard 2.9.0. tensorboard-data-server 0.6.1. tensorboard-plugin-wit 1.8.1. terminado 0.15.0. texttable 1.6.3. threadpoolctl 2.1.0. tifffile 2021.11.2. tinycss,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:5351,modifiability,extens,extensions,5351," natsort 7.1.1. nbclient 0.6.4. nbconvert 6.5.0. nbformat 5.4.0. nest-asyncio 1.5.5. networkx 2.5. notebook 6.4.11. numba 0.52.0. numexpr 2.7.3. numpy 1.19.5. numpy-groupies 0.9.17. numpyro 0.9.2. oauthlib 3.2.0. openpyxl 3.0.10. opt-einsum 3.3.0. optax 0.1.2. packaging 20.9. pandas 1.2.0. pandocfilters 1.5.0. parso 0.8.2. pathos 0.2.7. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 9.1.1. pip 21.1.1. pox 0.2.9. ppft 1.6.6.3. prometheus-client 0.14.1. prompt-toolkit 3.0.18. protobuf 3.19.0. protobuf3-to-dict 0.1.5. ptyprocess 0.7.0. pyasn1 0.4.8. pyasn1-modules 0.2.8. pycosat 0.6.3. pycparser 2.20. pyDeprecate 0.3.1. Pygments 2.9.0. pyOpenSSL 20.0.1. pyparsing 2.4.7. pyro-api 0.1.2. pyro-ppl 1.8.1. pyrsistent 0.18.1. PySocks 1.7.1. python-dateutil 2.8.1. python-igraph 0.9.1. pytorch-lightning 1.5.10. pytz 2021.1. PyWavelets 1.3.0. PyYAML 6.0. pyzmq 22.0.3. requests 2.25.1. requests-oauthlib 1.3.1. rich 12.4.4. rpy2 3.4.2. rsa 4.8. ruamel-yaml-conda 0.15.80. ruamel.yaml 0.17.21. ruamel.yaml.clib 0.2.6. s3transfer 0.4.2. sagemaker 2.39.0.post0. scanpy 1.6.1. scikit-image 0.19.2. scikit-learn 0.24.2. scikit-misc 0.1.4. scipy 1.6.0. scrublet 0.2.3. scvi-tools 0.16.2. seaborn 0.11.1. Send2Trash 1.8.0. setuptools 59.5.0. setuptools-scm 6.0.1. sinfo 0.3.1. six 1.15.0. smdebug-rulesconfig 1.0.1. soupsieve 2.3.2.post1. spectra 0.0.11. statsmodels 0.12.2. stdlib-list 0.8.0. tables 3.6.1. tensorboard 2.9.0. tensorboard-data-server 0.6.1. tensorboard-plugin-wit 1.8.1. terminado 0.15.0. texttable 1.6.3. threadpoolctl 2.1.0. tifffile 2021.11.2. tinycss2 1.1.1. toolz 0.11.2. torch 1.11.0. torchmetrics 0.9.0. tornado 6.1. tqdm 4.60.0. traitlets 5.2.2.post1. typing-extensions 4.2.0. tzlocal 2.1. umap-learn 0.4.6. urllib3 1.26.4. wcwidth 0.2.5. webencodings 0.5.1. Werkzeug 2.1.2. wheel 0.36.2. widgetsnbextension 3.6.0. yarl 1.7.2. zipp 3.4.1. Note: you may need to restart the kernel to use updated packages."". </details>. Has anyone found any solution to work around this issue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:5587,modifiability,pac,packages,5587," natsort 7.1.1. nbclient 0.6.4. nbconvert 6.5.0. nbformat 5.4.0. nest-asyncio 1.5.5. networkx 2.5. notebook 6.4.11. numba 0.52.0. numexpr 2.7.3. numpy 1.19.5. numpy-groupies 0.9.17. numpyro 0.9.2. oauthlib 3.2.0. openpyxl 3.0.10. opt-einsum 3.3.0. optax 0.1.2. packaging 20.9. pandas 1.2.0. pandocfilters 1.5.0. parso 0.8.2. pathos 0.2.7. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 9.1.1. pip 21.1.1. pox 0.2.9. ppft 1.6.6.3. prometheus-client 0.14.1. prompt-toolkit 3.0.18. protobuf 3.19.0. protobuf3-to-dict 0.1.5. ptyprocess 0.7.0. pyasn1 0.4.8. pyasn1-modules 0.2.8. pycosat 0.6.3. pycparser 2.20. pyDeprecate 0.3.1. Pygments 2.9.0. pyOpenSSL 20.0.1. pyparsing 2.4.7. pyro-api 0.1.2. pyro-ppl 1.8.1. pyrsistent 0.18.1. PySocks 1.7.1. python-dateutil 2.8.1. python-igraph 0.9.1. pytorch-lightning 1.5.10. pytz 2021.1. PyWavelets 1.3.0. PyYAML 6.0. pyzmq 22.0.3. requests 2.25.1. requests-oauthlib 1.3.1. rich 12.4.4. rpy2 3.4.2. rsa 4.8. ruamel-yaml-conda 0.15.80. ruamel.yaml 0.17.21. ruamel.yaml.clib 0.2.6. s3transfer 0.4.2. sagemaker 2.39.0.post0. scanpy 1.6.1. scikit-image 0.19.2. scikit-learn 0.24.2. scikit-misc 0.1.4. scipy 1.6.0. scrublet 0.2.3. scvi-tools 0.16.2. seaborn 0.11.1. Send2Trash 1.8.0. setuptools 59.5.0. setuptools-scm 6.0.1. sinfo 0.3.1. six 1.15.0. smdebug-rulesconfig 1.0.1. soupsieve 2.3.2.post1. spectra 0.0.11. statsmodels 0.12.2. stdlib-list 0.8.0. tables 3.6.1. tensorboard 2.9.0. tensorboard-data-server 0.6.1. tensorboard-plugin-wit 1.8.1. terminado 0.15.0. texttable 1.6.3. threadpoolctl 2.1.0. tifffile 2021.11.2. tinycss2 1.1.1. toolz 0.11.2. torch 1.11.0. torchmetrics 0.9.0. tornado 6.1. tqdm 4.60.0. traitlets 5.2.2.post1. typing-extensions 4.2.0. tzlocal 2.1. umap-learn 0.4.6. urllib3 1.26.4. wcwidth 0.2.5. webencodings 0.5.1. Werkzeug 2.1.2. wheel 0.36.2. widgetsnbextension 3.6.0. yarl 1.7.2. zipp 3.4.1. Note: you may need to restart the kernel to use updated packages."". </details>. Has anyone found any solution to work around this issue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:15,performance,error,error,15,"Found the same error in our internal workflows. Saved the data to h5py files, but could not open them anymore for some reason. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_group(group). 531 if encoding_type:. --> 532 EncodingVersions[encoding_type].check(. 533 group.name, group.attrs[""encoding-version""]. /opt/conda/lib/python3.7/enum.py in __getitem__(cls, name). 356 def __getitem__(cls, name):. --> 357 return cls._member_map_[name]. 358 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-20-38a594ec7d06> in <module>. ----> 1 adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 424 d[k] = read_dataframe(f[k]). 425 else: # Base case. --> 426 d[k] = read_attribute(f[k]). 427 . 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:127,performance,Error,Error,127,"Found the same error in our internal workflows. Saved the data to h5py files, but could not open them anymore for some reason. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_group(group). 531 if encoding_type:. --> 532 EncodingVersions[encoding_type].check(. 533 group.name, group.attrs[""encoding-version""]. /opt/conda/lib/python3.7/enum.py in __getitem__(cls, name). 356 def __getitem__(cls, name):. --> 357 return cls._member_map_[name]. 358 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-20-38a594ec7d06> in <module>. ----> 1 adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 424 d[k] = read_dataframe(f[k]). 425 else: # Base case. --> 426 d[k] = read_attribute(f[k]). 427 . 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:1734,performance,error,error,1734,"):. --> 357 return cls._member_map_[name]. 358 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-20-38a594ec7d06> in <module>. ----> 1 adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 424 d[k] = read_dataframe(f[k]). 425 else: # Base case. --> 426 d[k] = read_attribute(f[k]). 427 . 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). ```. <details>. <summary>Versions</summary>. Package Version. ----------------------- ------------. absl-py 1.1.0. aiohttp 3.8.1. aiosignal 1.2.0. anndata 0.7.5. anndata2ri 1.0.6. annoy 1.17.0. argon2-cffi 21.3.0. argon2-cffi-bindings 21.2.0. asn1crypto 1.4.0. async-timeout 4.0.2. asynctest 0.13.0. attrs 20.3.0. backcall 0.2.0. beautifulsoup4 4.11.1. bleach 5.0.0. boto3 1.17.66. botocore 1.20.66. brotlipy 0.7.0. cached-property 1.5.2. cachetools 5.2.0. certifi 2020.12.5. cffi 1.14.5. chardet 4.0.0. charset-normalizer 2.0.12. chex 0.1.3. click 8.1.3. colormath 3.0.0. commonmark 0.9.1. conda 4.6.14. conda-package-handling 1.7.3. cryptography 3.4.7. cycler 0.10.0. Cython 0.29.30. decorator 5.0.7. defusedxml 0.7.1",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:1857,performance,error,error,1857,"n occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-20-38a594ec7d06> in <module>. ----> 1 adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 424 d[k] = read_dataframe(f[k]). 425 else: # Base case. --> 426 d[k] = read_attribute(f[k]). 427 . 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). ```. <details>. <summary>Versions</summary>. Package Version. ----------------------- ------------. absl-py 1.1.0. aiohttp 3.8.1. aiosignal 1.2.0. anndata 0.7.5. anndata2ri 1.0.6. annoy 1.17.0. argon2-cffi 21.3.0. argon2-cffi-bindings 21.2.0. asn1crypto 1.4.0. async-timeout 4.0.2. asynctest 0.13.0. attrs 20.3.0. backcall 0.2.0. beautifulsoup4 4.11.1. bleach 5.0.0. boto3 1.17.66. botocore 1.20.66. brotlipy 0.7.0. cached-property 1.5.2. cachetools 5.2.0. certifi 2020.12.5. cffi 1.14.5. chardet 4.0.0. charset-normalizer 2.0.12. chex 0.1.3. click 8.1.3. colormath 3.0.0. commonmark 0.9.1. conda 4.6.14. conda-package-handling 1.7.3. cryptography 3.4.7. cycler 0.10.0. Cython 0.29.30. decorator 5.0.7. defusedxml 0.7.1. dill 0.3.3. dm-tree 0.1.7. docrep 0.3.2. entrypoints 0.4. et-xmlfile 1.1.0. fa2 0.3.5. fastjsonschema 2.15.3. flatbuffers",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:2285,performance,time,timeout,2285,"""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). ```. <details>. <summary>Versions</summary>. Package Version. ----------------------- ------------. absl-py 1.1.0. aiohttp 3.8.1. aiosignal 1.2.0. anndata 0.7.5. anndata2ri 1.0.6. annoy 1.17.0. argon2-cffi 21.3.0. argon2-cffi-bindings 21.2.0. asn1crypto 1.4.0. async-timeout 4.0.2. asynctest 0.13.0. attrs 20.3.0. backcall 0.2.0. beautifulsoup4 4.11.1. bleach 5.0.0. boto3 1.17.66. botocore 1.20.66. brotlipy 0.7.0. cached-property 1.5.2. cachetools 5.2.0. certifi 2020.12.5. cffi 1.14.5. chardet 4.0.0. charset-normalizer 2.0.12. chex 0.1.3. click 8.1.3. colormath 3.0.0. commonmark 0.9.1. conda 4.6.14. conda-package-handling 1.7.3. cryptography 3.4.7. cycler 0.10.0. Cython 0.29.30. decorator 5.0.7. defusedxml 0.7.1. dill 0.3.3. dm-tree 0.1.7. docrep 0.3.2. entrypoints 0.4. et-xmlfile 1.1.0. fa2 0.3.5. fastjsonschema 2.15.3. flatbuffers 2.0. flax 0.5.0. frozenlist 1.3.0. fsspec 2022.5.0. future 0.18.2. get-version 2.2. google-auth 2.6.6. google-auth-oauthlib 0.4.6. google-pasta 0.2.0. grpcio 1.46.3. h5py 3.2.1. idna 2.10. imageio 2.19.3. importlib-metadata 4.11.4. importlib-resources 5.7.1. ipykernel 5.5.4. ipython 7.23.1. ipython-genutils 0.2.0. ipywidgets 7.7.0. jax 0.3.13. jaxlib 0.3.10. jedi 0.18.0. Jinja2 3.1.2. jmespath 0.10.0. joblib 1.0.1. jsonschem",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:2434,performance,cach,cached-property,2434,"spatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). ```. <details>. <summary>Versions</summary>. Package Version. ----------------------- ------------. absl-py 1.1.0. aiohttp 3.8.1. aiosignal 1.2.0. anndata 0.7.5. anndata2ri 1.0.6. annoy 1.17.0. argon2-cffi 21.3.0. argon2-cffi-bindings 21.2.0. asn1crypto 1.4.0. async-timeout 4.0.2. asynctest 0.13.0. attrs 20.3.0. backcall 0.2.0. beautifulsoup4 4.11.1. bleach 5.0.0. boto3 1.17.66. botocore 1.20.66. brotlipy 0.7.0. cached-property 1.5.2. cachetools 5.2.0. certifi 2020.12.5. cffi 1.14.5. chardet 4.0.0. charset-normalizer 2.0.12. chex 0.1.3. click 8.1.3. colormath 3.0.0. commonmark 0.9.1. conda 4.6.14. conda-package-handling 1.7.3. cryptography 3.4.7. cycler 0.10.0. Cython 0.29.30. decorator 5.0.7. defusedxml 0.7.1. dill 0.3.3. dm-tree 0.1.7. docrep 0.3.2. entrypoints 0.4. et-xmlfile 1.1.0. fa2 0.3.5. fastjsonschema 2.15.3. flatbuffers 2.0. flax 0.5.0. frozenlist 1.3.0. fsspec 2022.5.0. future 0.18.2. get-version 2.2. google-auth 2.6.6. google-auth-oauthlib 0.4.6. google-pasta 0.2.0. grpcio 1.46.3. h5py 3.2.1. idna 2.10. imageio 2.19.3. importlib-metadata 4.11.4. importlib-resources 5.7.1. ipykernel 5.5.4. ipython 7.23.1. ipython-genutils 0.2.0. ipywidgets 7.7.0. jax 0.3.13. jaxlib 0.3.10. jedi 0.18.0. Jinja2 3.1.2. jmespath 0.10.0. joblib 1.0.1. jsonschema 4.6.0. jupyter-client 6.1.12. jupyter-core 4.7.1. jupyterlab-pygments 0.2.2. jupyterlab-widgets 1.1.0. kiwisolver 1.3.1. legacy-api-wrap 1.2. leidenalg",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:2457,performance,cach,cachetools,2457,"ss__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). ```. <details>. <summary>Versions</summary>. Package Version. ----------------------- ------------. absl-py 1.1.0. aiohttp 3.8.1. aiosignal 1.2.0. anndata 0.7.5. anndata2ri 1.0.6. annoy 1.17.0. argon2-cffi 21.3.0. argon2-cffi-bindings 21.2.0. asn1crypto 1.4.0. async-timeout 4.0.2. asynctest 0.13.0. attrs 20.3.0. backcall 0.2.0. beautifulsoup4 4.11.1. bleach 5.0.0. boto3 1.17.66. botocore 1.20.66. brotlipy 0.7.0. cached-property 1.5.2. cachetools 5.2.0. certifi 2020.12.5. cffi 1.14.5. chardet 4.0.0. charset-normalizer 2.0.12. chex 0.1.3. click 8.1.3. colormath 3.0.0. commonmark 0.9.1. conda 4.6.14. conda-package-handling 1.7.3. cryptography 3.4.7. cycler 0.10.0. Cython 0.29.30. decorator 5.0.7. defusedxml 0.7.1. dill 0.3.3. dm-tree 0.1.7. docrep 0.3.2. entrypoints 0.4. et-xmlfile 1.1.0. fa2 0.3.5. fastjsonschema 2.15.3. flatbuffers 2.0. flax 0.5.0. frozenlist 1.3.0. fsspec 2022.5.0. future 0.18.2. get-version 2.2. google-auth 2.6.6. google-auth-oauthlib 0.4.6. google-pasta 0.2.0. grpcio 1.46.3. h5py 3.2.1. idna 2.10. imageio 2.19.3. importlib-metadata 4.11.4. importlib-resources 5.7.1. ipykernel 5.5.4. ipython 7.23.1. ipython-genutils 0.2.0. ipywidgets 7.7.0. jax 0.3.13. jaxlib 0.3.10. jedi 0.18.0. Jinja2 3.1.2. jmespath 0.10.0. joblib 1.0.1. jsonschema 4.6.0. jupyter-client 6.1.12. jupyter-core 4.7.1. jupyterlab-pygments 0.2.2. jupyterlab-widgets 1.1.0. kiwisolver 1.3.1. legacy-api-wrap 1.2. leidenalg 0.8.4. llvmlite 0.3",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:3103,performance,resourc,resources,3103,--------. absl-py 1.1.0. aiohttp 3.8.1. aiosignal 1.2.0. anndata 0.7.5. anndata2ri 1.0.6. annoy 1.17.0. argon2-cffi 21.3.0. argon2-cffi-bindings 21.2.0. asn1crypto 1.4.0. async-timeout 4.0.2. asynctest 0.13.0. attrs 20.3.0. backcall 0.2.0. beautifulsoup4 4.11.1. bleach 5.0.0. boto3 1.17.66. botocore 1.20.66. brotlipy 0.7.0. cached-property 1.5.2. cachetools 5.2.0. certifi 2020.12.5. cffi 1.14.5. chardet 4.0.0. charset-normalizer 2.0.12. chex 0.1.3. click 8.1.3. colormath 3.0.0. commonmark 0.9.1. conda 4.6.14. conda-package-handling 1.7.3. cryptography 3.4.7. cycler 0.10.0. Cython 0.29.30. decorator 5.0.7. defusedxml 0.7.1. dill 0.3.3. dm-tree 0.1.7. docrep 0.3.2. entrypoints 0.4. et-xmlfile 1.1.0. fa2 0.3.5. fastjsonschema 2.15.3. flatbuffers 2.0. flax 0.5.0. frozenlist 1.3.0. fsspec 2022.5.0. future 0.18.2. get-version 2.2. google-auth 2.6.6. google-auth-oauthlib 0.4.6. google-pasta 0.2.0. grpcio 1.46.3. h5py 3.2.1. idna 2.10. imageio 2.19.3. importlib-metadata 4.11.4. importlib-resources 5.7.1. ipykernel 5.5.4. ipython 7.23.1. ipython-genutils 0.2.0. ipywidgets 7.7.0. jax 0.3.13. jaxlib 0.3.10. jedi 0.18.0. Jinja2 3.1.2. jmespath 0.10.0. joblib 1.0.1. jsonschema 4.6.0. jupyter-client 6.1.12. jupyter-core 4.7.1. jupyterlab-pygments 0.2.2. jupyterlab-widgets 1.1.0. kiwisolver 1.3.1. legacy-api-wrap 1.2. leidenalg 0.8.4. llvmlite 0.35.0. loompy 3.0.7. louvain 0.7.0. Markdown 3.3.7. MarkupSafe 2.1.1. matplotlib 3.4.1. matplotlib-inline 0.1.2. mistune 0.8.4. msgpack 1.0.4. multidict 6.0.2. multipledispatch 0.6.0. multiprocess 0.70.11.1. natsort 7.1.1. nbclient 0.6.4. nbconvert 6.5.0. nbformat 5.4.0. nest-asyncio 1.5.5. networkx 2.5. notebook 6.4.11. numba 0.52.0. numexpr 2.7.3. numpy 1.19.5. numpy-groupies 0.9.17. numpyro 0.9.2. oauthlib 3.2.0. openpyxl 3.0.10. opt-einsum 3.3.0. optax 0.1.2. packaging 20.9. pandas 1.2.0. pandocfilters 1.5.0. parso 0.8.2. pathos 0.2.7. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 9.1.1. pip 21.1.1. pox 0.2.9. ppft 1.6.6.3. prom,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:3752,performance,network,networkx,3752,ee 0.1.7. docrep 0.3.2. entrypoints 0.4. et-xmlfile 1.1.0. fa2 0.3.5. fastjsonschema 2.15.3. flatbuffers 2.0. flax 0.5.0. frozenlist 1.3.0. fsspec 2022.5.0. future 0.18.2. get-version 2.2. google-auth 2.6.6. google-auth-oauthlib 0.4.6. google-pasta 0.2.0. grpcio 1.46.3. h5py 3.2.1. idna 2.10. imageio 2.19.3. importlib-metadata 4.11.4. importlib-resources 5.7.1. ipykernel 5.5.4. ipython 7.23.1. ipython-genutils 0.2.0. ipywidgets 7.7.0. jax 0.3.13. jaxlib 0.3.10. jedi 0.18.0. Jinja2 3.1.2. jmespath 0.10.0. joblib 1.0.1. jsonschema 4.6.0. jupyter-client 6.1.12. jupyter-core 4.7.1. jupyterlab-pygments 0.2.2. jupyterlab-widgets 1.1.0. kiwisolver 1.3.1. legacy-api-wrap 1.2. leidenalg 0.8.4. llvmlite 0.35.0. loompy 3.0.7. louvain 0.7.0. Markdown 3.3.7. MarkupSafe 2.1.1. matplotlib 3.4.1. matplotlib-inline 0.1.2. mistune 0.8.4. msgpack 1.0.4. multidict 6.0.2. multipledispatch 0.6.0. multiprocess 0.70.11.1. natsort 7.1.1. nbclient 0.6.4. nbconvert 6.5.0. nbformat 5.4.0. nest-asyncio 1.5.5. networkx 2.5. notebook 6.4.11. numba 0.52.0. numexpr 2.7.3. numpy 1.19.5. numpy-groupies 0.9.17. numpyro 0.9.2. oauthlib 3.2.0. openpyxl 3.0.10. opt-einsum 3.3.0. optax 0.1.2. packaging 20.9. pandas 1.2.0. pandocfilters 1.5.0. parso 0.8.2. pathos 0.2.7. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 9.1.1. pip 21.1.1. pox 0.2.9. ppft 1.6.6.3. prometheus-client 0.14.1. prompt-toolkit 3.0.18. protobuf 3.19.0. protobuf3-to-dict 0.1.5. ptyprocess 0.7.0. pyasn1 0.4.8. pyasn1-modules 0.2.8. pycosat 0.6.3. pycparser 2.20. pyDeprecate 0.3.1. Pygments 2.9.0. pyOpenSSL 20.0.1. pyparsing 2.4.7. pyro-api 0.1.2. pyro-ppl 1.8.1. pyrsistent 0.18.1. PySocks 1.7.1. python-dateutil 2.8.1. python-igraph 0.9.1. pytorch-lightning 1.5.10. pytz 2021.1. PyWavelets 1.3.0. PyYAML 6.0. pyzmq 22.0.3. requests 2.25.1. requests-oauthlib 1.3.1. rich 12.4.4. rpy2 3.4.2. rsa 4.8. ruamel-yaml-conda 0.15.80. ruamel.yaml 0.17.21. ruamel.yaml.clib 0.2.6. s3transfer 0.4.2. sagemaker 2.39.0.post0. scanpy 1.6.1. scikit-im,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:15,safety,error,error,15,"Found the same error in our internal workflows. Saved the data to h5py files, but could not open them anymore for some reason. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_group(group). 531 if encoding_type:. --> 532 EncodingVersions[encoding_type].check(. 533 group.name, group.attrs[""encoding-version""]. /opt/conda/lib/python3.7/enum.py in __getitem__(cls, name). 356 def __getitem__(cls, name):. --> 357 return cls._member_map_[name]. 358 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-20-38a594ec7d06> in <module>. ----> 1 adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 424 d[k] = read_dataframe(f[k]). 425 else: # Base case. --> 426 d[k] = read_attribute(f[k]). 427 . 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:127,safety,Error,Error,127,"Found the same error in our internal workflows. Saved the data to h5py files, but could not open them anymore for some reason. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_group(group). 531 if encoding_type:. --> 532 EncodingVersions[encoding_type].check(. 533 group.name, group.attrs[""encoding-version""]. /opt/conda/lib/python3.7/enum.py in __getitem__(cls, name). 356 def __getitem__(cls, name):. --> 357 return cls._member_map_[name]. 358 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-20-38a594ec7d06> in <module>. ----> 1 adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 424 d[k] = read_dataframe(f[k]). 425 else: # Base case. --> 426 d[k] = read_attribute(f[k]). 427 . 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:423,safety,except,except,423,"Found the same error in our internal workflows. Saved the data to h5py files, but could not open them anymore for some reason. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_group(group). 531 if encoding_type:. --> 532 EncodingVersions[encoding_type].check(. 533 group.name, group.attrs[""encoding-version""]. /opt/conda/lib/python3.7/enum.py in __getitem__(cls, name). 356 def __getitem__(cls, name):. --> 357 return cls._member_map_[name]. 358 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-20-38a594ec7d06> in <module>. ----> 1 adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 424 d[k] = read_dataframe(f[k]). 425 else: # Base case. --> 426 d[k] = read_attribute(f[k]). 427 . 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:430,safety,Except,Exception,430,"Found the same error in our internal workflows. Saved the data to h5py files, but could not open them anymore for some reason. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_group(group). 531 if encoding_type:. --> 532 EncodingVersions[encoding_type].check(. 533 group.name, group.attrs[""encoding-version""]. /opt/conda/lib/python3.7/enum.py in __getitem__(cls, name). 356 def __getitem__(cls, name):. --> 357 return cls._member_map_[name]. 358 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-20-38a594ec7d06> in <module>. ----> 1 adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 424 d[k] = read_dataframe(f[k]). 425 else: # Base case. --> 426 d[k] = read_attribute(f[k]). 427 . 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:833,safety,except,exception,833,"Found the same error in our internal workflows. Saved the data to h5py files, but could not open them anymore for some reason. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_group(group). 531 if encoding_type:. --> 532 EncodingVersions[encoding_type].check(. 533 group.name, group.attrs[""encoding-version""]. /opt/conda/lib/python3.7/enum.py in __getitem__(cls, name). 356 def __getitem__(cls, name):. --> 357 return cls._member_map_[name]. 358 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-20-38a594ec7d06> in <module>. ----> 1 adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 424 d[k] = read_dataframe(f[k]). 425 else: # Base case. --> 426 d[k] = read_attribute(f[k]). 427 . 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:852,safety,except,exception,852,"Found the same error in our internal workflows. Saved the data to h5py files, but could not open them anymore for some reason. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_group(group). 531 if encoding_type:. --> 532 EncodingVersions[encoding_type].check(. 533 group.name, group.attrs[""encoding-version""]. /opt/conda/lib/python3.7/enum.py in __getitem__(cls, name). 356 def __getitem__(cls, name):. --> 357 return cls._member_map_[name]. 358 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-20-38a594ec7d06> in <module>. ----> 1 adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 424 d[k] = read_dataframe(f[k]). 425 else: # Base case. --> 426 d[k] = read_attribute(f[k]). 427 . 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:934,safety,input,input-,934,"Found the same error in our internal workflows. Saved the data to h5py files, but could not open them anymore for some reason. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_group(group). 531 if encoding_type:. --> 532 EncodingVersions[encoding_type].check(. 533 group.name, group.attrs[""encoding-version""]. /opt/conda/lib/python3.7/enum.py in __getitem__(cls, name). 356 def __getitem__(cls, name):. --> 357 return cls._member_map_[name]. 358 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-20-38a594ec7d06> in <module>. ----> 1 adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 424 d[k] = read_dataframe(f[k]). 425 else: # Base case. --> 426 d[k] = read_attribute(f[k]). 427 . 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:961,safety,modul,module,961,"Found the same error in our internal workflows. Saved the data to h5py files, but could not open them anymore for some reason. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_group(group). 531 if encoding_type:. --> 532 EncodingVersions[encoding_type].check(. 533 group.name, group.attrs[""encoding-version""]. /opt/conda/lib/python3.7/enum.py in __getitem__(cls, name). 356 def __getitem__(cls, name):. --> 357 return cls._member_map_[name]. 358 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-20-38a594ec7d06> in <module>. ----> 1 adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 424 d[k] = read_dataframe(f[k]). 425 else: # Base case. --> 426 d[k] = read_attribute(f[k]). 427 . 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:1734,safety,error,error,1734,"):. --> 357 return cls._member_map_[name]. 358 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-20-38a594ec7d06> in <module>. ----> 1 adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 424 d[k] = read_dataframe(f[k]). 425 else: # Base case. --> 426 d[k] = read_attribute(f[k]). 427 . 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). ```. <details>. <summary>Versions</summary>. Package Version. ----------------------- ------------. absl-py 1.1.0. aiohttp 3.8.1. aiosignal 1.2.0. anndata 0.7.5. anndata2ri 1.0.6. annoy 1.17.0. argon2-cffi 21.3.0. argon2-cffi-bindings 21.2.0. asn1crypto 1.4.0. async-timeout 4.0.2. asynctest 0.13.0. attrs 20.3.0. backcall 0.2.0. beautifulsoup4 4.11.1. bleach 5.0.0. boto3 1.17.66. botocore 1.20.66. brotlipy 0.7.0. cached-property 1.5.2. cachetools 5.2.0. certifi 2020.12.5. cffi 1.14.5. chardet 4.0.0. charset-normalizer 2.0.12. chex 0.1.3. click 8.1.3. colormath 3.0.0. commonmark 0.9.1. conda 4.6.14. conda-package-handling 1.7.3. cryptography 3.4.7. cycler 0.10.0. Cython 0.29.30. decorator 5.0.7. defusedxml 0.7.1",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:1857,safety,error,error,1857,"n occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-20-38a594ec7d06> in <module>. ----> 1 adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 424 d[k] = read_dataframe(f[k]). 425 else: # Base case. --> 426 d[k] = read_attribute(f[k]). 427 . 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). ```. <details>. <summary>Versions</summary>. Package Version. ----------------------- ------------. absl-py 1.1.0. aiohttp 3.8.1. aiosignal 1.2.0. anndata 0.7.5. anndata2ri 1.0.6. annoy 1.17.0. argon2-cffi 21.3.0. argon2-cffi-bindings 21.2.0. asn1crypto 1.4.0. async-timeout 4.0.2. asynctest 0.13.0. attrs 20.3.0. backcall 0.2.0. beautifulsoup4 4.11.1. bleach 5.0.0. boto3 1.17.66. botocore 1.20.66. brotlipy 0.7.0. cached-property 1.5.2. cachetools 5.2.0. certifi 2020.12.5. cffi 1.14.5. chardet 4.0.0. charset-normalizer 2.0.12. chex 0.1.3. click 8.1.3. colormath 3.0.0. commonmark 0.9.1. conda 4.6.14. conda-package-handling 1.7.3. cryptography 3.4.7. cycler 0.10.0. Cython 0.29.30. decorator 5.0.7. defusedxml 0.7.1. dill 0.3.3. dm-tree 0.1.7. docrep 0.3.2. entrypoints 0.4. et-xmlfile 1.1.0. fa2 0.3.5. fastjsonschema 2.15.3. flatbuffers",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:2285,safety,timeout,timeout,2285,"""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). ```. <details>. <summary>Versions</summary>. Package Version. ----------------------- ------------. absl-py 1.1.0. aiohttp 3.8.1. aiosignal 1.2.0. anndata 0.7.5. anndata2ri 1.0.6. annoy 1.17.0. argon2-cffi 21.3.0. argon2-cffi-bindings 21.2.0. asn1crypto 1.4.0. async-timeout 4.0.2. asynctest 0.13.0. attrs 20.3.0. backcall 0.2.0. beautifulsoup4 4.11.1. bleach 5.0.0. boto3 1.17.66. botocore 1.20.66. brotlipy 0.7.0. cached-property 1.5.2. cachetools 5.2.0. certifi 2020.12.5. cffi 1.14.5. chardet 4.0.0. charset-normalizer 2.0.12. chex 0.1.3. click 8.1.3. colormath 3.0.0. commonmark 0.9.1. conda 4.6.14. conda-package-handling 1.7.3. cryptography 3.4.7. cycler 0.10.0. Cython 0.29.30. decorator 5.0.7. defusedxml 0.7.1. dill 0.3.3. dm-tree 0.1.7. docrep 0.3.2. entrypoints 0.4. et-xmlfile 1.1.0. fa2 0.3.5. fastjsonschema 2.15.3. flatbuffers 2.0. flax 0.5.0. frozenlist 1.3.0. fsspec 2022.5.0. future 0.18.2. get-version 2.2. google-auth 2.6.6. google-auth-oauthlib 0.4.6. google-pasta 0.2.0. grpcio 1.46.3. h5py 3.2.1. idna 2.10. imageio 2.19.3. importlib-metadata 4.11.4. importlib-resources 5.7.1. ipykernel 5.5.4. ipython 7.23.1. ipython-genutils 0.2.0. ipywidgets 7.7.0. jax 0.3.13. jaxlib 0.3.10. jedi 0.18.0. Jinja2 3.1.2. jmespath 0.10.0. joblib 1.0.1. jsonschem",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:3103,safety,resourc,resources,3103,--------. absl-py 1.1.0. aiohttp 3.8.1. aiosignal 1.2.0. anndata 0.7.5. anndata2ri 1.0.6. annoy 1.17.0. argon2-cffi 21.3.0. argon2-cffi-bindings 21.2.0. asn1crypto 1.4.0. async-timeout 4.0.2. asynctest 0.13.0. attrs 20.3.0. backcall 0.2.0. beautifulsoup4 4.11.1. bleach 5.0.0. boto3 1.17.66. botocore 1.20.66. brotlipy 0.7.0. cached-property 1.5.2. cachetools 5.2.0. certifi 2020.12.5. cffi 1.14.5. chardet 4.0.0. charset-normalizer 2.0.12. chex 0.1.3. click 8.1.3. colormath 3.0.0. commonmark 0.9.1. conda 4.6.14. conda-package-handling 1.7.3. cryptography 3.4.7. cycler 0.10.0. Cython 0.29.30. decorator 5.0.7. defusedxml 0.7.1. dill 0.3.3. dm-tree 0.1.7. docrep 0.3.2. entrypoints 0.4. et-xmlfile 1.1.0. fa2 0.3.5. fastjsonschema 2.15.3. flatbuffers 2.0. flax 0.5.0. frozenlist 1.3.0. fsspec 2022.5.0. future 0.18.2. get-version 2.2. google-auth 2.6.6. google-auth-oauthlib 0.4.6. google-pasta 0.2.0. grpcio 1.46.3. h5py 3.2.1. idna 2.10. imageio 2.19.3. importlib-metadata 4.11.4. importlib-resources 5.7.1. ipykernel 5.5.4. ipython 7.23.1. ipython-genutils 0.2.0. ipywidgets 7.7.0. jax 0.3.13. jaxlib 0.3.10. jedi 0.18.0. Jinja2 3.1.2. jmespath 0.10.0. joblib 1.0.1. jsonschema 4.6.0. jupyter-client 6.1.12. jupyter-core 4.7.1. jupyterlab-pygments 0.2.2. jupyterlab-widgets 1.1.0. kiwisolver 1.3.1. legacy-api-wrap 1.2. leidenalg 0.8.4. llvmlite 0.35.0. loompy 3.0.7. louvain 0.7.0. Markdown 3.3.7. MarkupSafe 2.1.1. matplotlib 3.4.1. matplotlib-inline 0.1.2. mistune 0.8.4. msgpack 1.0.4. multidict 6.0.2. multipledispatch 0.6.0. multiprocess 0.70.11.1. natsort 7.1.1. nbclient 0.6.4. nbconvert 6.5.0. nbformat 5.4.0. nest-asyncio 1.5.5. networkx 2.5. notebook 6.4.11. numba 0.52.0. numexpr 2.7.3. numpy 1.19.5. numpy-groupies 0.9.17. numpyro 0.9.2. oauthlib 3.2.0. openpyxl 3.0.10. opt-einsum 3.3.0. optax 0.1.2. packaging 20.9. pandas 1.2.0. pandocfilters 1.5.0. parso 0.8.2. pathos 0.2.7. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 9.1.1. pip 21.1.1. pox 0.2.9. ppft 1.6.6.3. prom,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:4234,safety,modul,modules,4234,ja2 3.1.2. jmespath 0.10.0. joblib 1.0.1. jsonschema 4.6.0. jupyter-client 6.1.12. jupyter-core 4.7.1. jupyterlab-pygments 0.2.2. jupyterlab-widgets 1.1.0. kiwisolver 1.3.1. legacy-api-wrap 1.2. leidenalg 0.8.4. llvmlite 0.35.0. loompy 3.0.7. louvain 0.7.0. Markdown 3.3.7. MarkupSafe 2.1.1. matplotlib 3.4.1. matplotlib-inline 0.1.2. mistune 0.8.4. msgpack 1.0.4. multidict 6.0.2. multipledispatch 0.6.0. multiprocess 0.70.11.1. natsort 7.1.1. nbclient 0.6.4. nbconvert 6.5.0. nbformat 5.4.0. nest-asyncio 1.5.5. networkx 2.5. notebook 6.4.11. numba 0.52.0. numexpr 2.7.3. numpy 1.19.5. numpy-groupies 0.9.17. numpyro 0.9.2. oauthlib 3.2.0. openpyxl 3.0.10. opt-einsum 3.3.0. optax 0.1.2. packaging 20.9. pandas 1.2.0. pandocfilters 1.5.0. parso 0.8.2. pathos 0.2.7. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 9.1.1. pip 21.1.1. pox 0.2.9. ppft 1.6.6.3. prometheus-client 0.14.1. prompt-toolkit 3.0.18. protobuf 3.19.0. protobuf3-to-dict 0.1.5. ptyprocess 0.7.0. pyasn1 0.4.8. pyasn1-modules 0.2.8. pycosat 0.6.3. pycparser 2.20. pyDeprecate 0.3.1. Pygments 2.9.0. pyOpenSSL 20.0.1. pyparsing 2.4.7. pyro-api 0.1.2. pyro-ppl 1.8.1. pyrsistent 0.18.1. PySocks 1.7.1. python-dateutil 2.8.1. python-igraph 0.9.1. pytorch-lightning 1.5.10. pytz 2021.1. PyWavelets 1.3.0. PyYAML 6.0. pyzmq 22.0.3. requests 2.25.1. requests-oauthlib 1.3.1. rich 12.4.4. rpy2 3.4.2. rsa 4.8. ruamel-yaml-conda 0.15.80. ruamel.yaml 0.17.21. ruamel.yaml.clib 0.2.6. s3transfer 0.4.2. sagemaker 2.39.0.post0. scanpy 1.6.1. scikit-image 0.19.2. scikit-learn 0.24.2. scikit-misc 0.1.4. scipy 1.6.0. scrublet 0.2.3. scvi-tools 0.16.2. seaborn 0.11.1. Send2Trash 1.8.0. setuptools 59.5.0. setuptools-scm 6.0.1. sinfo 0.3.1. six 1.15.0. smdebug-rulesconfig 1.0.1. soupsieve 2.3.2.post1. spectra 0.0.11. statsmodels 0.12.2. stdlib-list 0.8.0. tables 3.6.1. tensorboard 2.9.0. tensorboard-data-server 0.6.1. tensorboard-plugin-wit 1.8.1. terminado 0.15.0. texttable 1.6.3. threadpoolctl 2.1.0. tifffile 2021.11.2. tinycss,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:5579,safety,updat,updated,5579," natsort 7.1.1. nbclient 0.6.4. nbconvert 6.5.0. nbformat 5.4.0. nest-asyncio 1.5.5. networkx 2.5. notebook 6.4.11. numba 0.52.0. numexpr 2.7.3. numpy 1.19.5. numpy-groupies 0.9.17. numpyro 0.9.2. oauthlib 3.2.0. openpyxl 3.0.10. opt-einsum 3.3.0. optax 0.1.2. packaging 20.9. pandas 1.2.0. pandocfilters 1.5.0. parso 0.8.2. pathos 0.2.7. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 9.1.1. pip 21.1.1. pox 0.2.9. ppft 1.6.6.3. prometheus-client 0.14.1. prompt-toolkit 3.0.18. protobuf 3.19.0. protobuf3-to-dict 0.1.5. ptyprocess 0.7.0. pyasn1 0.4.8. pyasn1-modules 0.2.8. pycosat 0.6.3. pycparser 2.20. pyDeprecate 0.3.1. Pygments 2.9.0. pyOpenSSL 20.0.1. pyparsing 2.4.7. pyro-api 0.1.2. pyro-ppl 1.8.1. pyrsistent 0.18.1. PySocks 1.7.1. python-dateutil 2.8.1. python-igraph 0.9.1. pytorch-lightning 1.5.10. pytz 2021.1. PyWavelets 1.3.0. PyYAML 6.0. pyzmq 22.0.3. requests 2.25.1. requests-oauthlib 1.3.1. rich 12.4.4. rpy2 3.4.2. rsa 4.8. ruamel-yaml-conda 0.15.80. ruamel.yaml 0.17.21. ruamel.yaml.clib 0.2.6. s3transfer 0.4.2. sagemaker 2.39.0.post0. scanpy 1.6.1. scikit-image 0.19.2. scikit-learn 0.24.2. scikit-misc 0.1.4. scipy 1.6.0. scrublet 0.2.3. scvi-tools 0.16.2. seaborn 0.11.1. Send2Trash 1.8.0. setuptools 59.5.0. setuptools-scm 6.0.1. sinfo 0.3.1. six 1.15.0. smdebug-rulesconfig 1.0.1. soupsieve 2.3.2.post1. spectra 0.0.11. statsmodels 0.12.2. stdlib-list 0.8.0. tables 3.6.1. tensorboard 2.9.0. tensorboard-data-server 0.6.1. tensorboard-plugin-wit 1.8.1. terminado 0.15.0. texttable 1.6.3. threadpoolctl 2.1.0. tifffile 2021.11.2. tinycss2 1.1.1. toolz 0.11.2. torch 1.11.0. torchmetrics 0.9.0. tornado 6.1. tqdm 4.60.0. traitlets 5.2.2.post1. typing-extensions 4.2.0. tzlocal 2.1. umap-learn 0.4.6. urllib3 1.26.4. wcwidth 0.2.5. webencodings 0.5.1. Werkzeug 2.1.2. wheel 0.36.2. widgetsnbextension 3.6.0. yarl 1.7.2. zipp 3.4.1. Note: you may need to restart the kernel to use updated packages."". </details>. Has anyone found any solution to work around this issue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:2475,security,certif,certifi,2475,"). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). ```. <details>. <summary>Versions</summary>. Package Version. ----------------------- ------------. absl-py 1.1.0. aiohttp 3.8.1. aiosignal 1.2.0. anndata 0.7.5. anndata2ri 1.0.6. annoy 1.17.0. argon2-cffi 21.3.0. argon2-cffi-bindings 21.2.0. asn1crypto 1.4.0. async-timeout 4.0.2. asynctest 0.13.0. attrs 20.3.0. backcall 0.2.0. beautifulsoup4 4.11.1. bleach 5.0.0. boto3 1.17.66. botocore 1.20.66. brotlipy 0.7.0. cached-property 1.5.2. cachetools 5.2.0. certifi 2020.12.5. cffi 1.14.5. chardet 4.0.0. charset-normalizer 2.0.12. chex 0.1.3. click 8.1.3. colormath 3.0.0. commonmark 0.9.1. conda 4.6.14. conda-package-handling 1.7.3. cryptography 3.4.7. cycler 0.10.0. Cython 0.29.30. decorator 5.0.7. defusedxml 0.7.1. dill 0.3.3. dm-tree 0.1.7. docrep 0.3.2. entrypoints 0.4. et-xmlfile 1.1.0. fa2 0.3.5. fastjsonschema 2.15.3. flatbuffers 2.0. flax 0.5.0. frozenlist 1.3.0. fsspec 2022.5.0. future 0.18.2. get-version 2.2. google-auth 2.6.6. google-auth-oauthlib 0.4.6. google-pasta 0.2.0. grpcio 1.46.3. h5py 3.2.1. idna 2.10. imageio 2.19.3. importlib-metadata 4.11.4. importlib-resources 5.7.1. ipykernel 5.5.4. ipython 7.23.1. ipython-genutils 0.2.0. ipywidgets 7.7.0. jax 0.3.13. jaxlib 0.3.10. jedi 0.18.0. Jinja2 3.1.2. jmespath 0.10.0. joblib 1.0.1. jsonschema 4.6.0. jupyter-client 6.1.12. jupyter-core 4.7.1. jupyterlab-pygments 0.2.2. jupyterlab-widgets 1.1.0. kiwisolver 1.3.1. legacy-api-wrap 1.2. leidenalg 0.8.4. llvmlite 0.35.0. loompy 3.0.7",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:2653,security,cryptograph,cryptography,2653,"1 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). ```. <details>. <summary>Versions</summary>. Package Version. ----------------------- ------------. absl-py 1.1.0. aiohttp 3.8.1. aiosignal 1.2.0. anndata 0.7.5. anndata2ri 1.0.6. annoy 1.17.0. argon2-cffi 21.3.0. argon2-cffi-bindings 21.2.0. asn1crypto 1.4.0. async-timeout 4.0.2. asynctest 0.13.0. attrs 20.3.0. backcall 0.2.0. beautifulsoup4 4.11.1. bleach 5.0.0. boto3 1.17.66. botocore 1.20.66. brotlipy 0.7.0. cached-property 1.5.2. cachetools 5.2.0. certifi 2020.12.5. cffi 1.14.5. chardet 4.0.0. charset-normalizer 2.0.12. chex 0.1.3. click 8.1.3. colormath 3.0.0. commonmark 0.9.1. conda 4.6.14. conda-package-handling 1.7.3. cryptography 3.4.7. cycler 0.10.0. Cython 0.29.30. decorator 5.0.7. defusedxml 0.7.1. dill 0.3.3. dm-tree 0.1.7. docrep 0.3.2. entrypoints 0.4. et-xmlfile 1.1.0. fa2 0.3.5. fastjsonschema 2.15.3. flatbuffers 2.0. flax 0.5.0. frozenlist 1.3.0. fsspec 2022.5.0. future 0.18.2. get-version 2.2. google-auth 2.6.6. google-auth-oauthlib 0.4.6. google-pasta 0.2.0. grpcio 1.46.3. h5py 3.2.1. idna 2.10. imageio 2.19.3. importlib-metadata 4.11.4. importlib-resources 5.7.1. ipykernel 5.5.4. ipython 7.23.1. ipython-genutils 0.2.0. ipywidgets 7.7.0. jax 0.3.13. jaxlib 0.3.10. jedi 0.18.0. Jinja2 3.1.2. jmespath 0.10.0. joblib 1.0.1. jsonschema 4.6.0. jupyter-client 6.1.12. jupyter-core 4.7.1. jupyterlab-pygments 0.2.2. jupyterlab-widgets 1.1.0. kiwisolver 1.3.1. legacy-api-wrap 1.2. leidenalg 0.8.4. llvmlite 0.35.0. loompy 3.0.7. louvain 0.7.0. Markdown 3.3.7. MarkupSafe 2.1.1. matplotlib 3.4.1. matplotlib-inline 0.1.2. mistune 0.8.4. msgpack 1.0.4. multidict 6.0.2. multipledispatch 0.6.0. multiprocess 0.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:2952,security,auth,auth,2952,=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). ```. <details>. <summary>Versions</summary>. Package Version. ----------------------- ------------. absl-py 1.1.0. aiohttp 3.8.1. aiosignal 1.2.0. anndata 0.7.5. anndata2ri 1.0.6. annoy 1.17.0. argon2-cffi 21.3.0. argon2-cffi-bindings 21.2.0. asn1crypto 1.4.0. async-timeout 4.0.2. asynctest 0.13.0. attrs 20.3.0. backcall 0.2.0. beautifulsoup4 4.11.1. bleach 5.0.0. boto3 1.17.66. botocore 1.20.66. brotlipy 0.7.0. cached-property 1.5.2. cachetools 5.2.0. certifi 2020.12.5. cffi 1.14.5. chardet 4.0.0. charset-normalizer 2.0.12. chex 0.1.3. click 8.1.3. colormath 3.0.0. commonmark 0.9.1. conda 4.6.14. conda-package-handling 1.7.3. cryptography 3.4.7. cycler 0.10.0. Cython 0.29.30. decorator 5.0.7. defusedxml 0.7.1. dill 0.3.3. dm-tree 0.1.7. docrep 0.3.2. entrypoints 0.4. et-xmlfile 1.1.0. fa2 0.3.5. fastjsonschema 2.15.3. flatbuffers 2.0. flax 0.5.0. frozenlist 1.3.0. fsspec 2022.5.0. future 0.18.2. get-version 2.2. google-auth 2.6.6. google-auth-oauthlib 0.4.6. google-pasta 0.2.0. grpcio 1.46.3. h5py 3.2.1. idna 2.10. imageio 2.19.3. importlib-metadata 4.11.4. importlib-resources 5.7.1. ipykernel 5.5.4. ipython 7.23.1. ipython-genutils 0.2.0. ipywidgets 7.7.0. jax 0.3.13. jaxlib 0.3.10. jedi 0.18.0. Jinja2 3.1.2. jmespath 0.10.0. joblib 1.0.1. jsonschema 4.6.0. jupyter-client 6.1.12. jupyter-core 4.7.1. jupyterlab-pygments 0.2.2. jupyterlab-widgets 1.1.0. kiwisolver 1.3.1. legacy-api-wrap 1.2. leidenalg 0.8.4. llvmlite 0.35.0. loompy 3.0.7. louvain 0.7.0. Markdown 3.3.7. MarkupSafe 2.1.1. matplotlib 3.4.1. matplotlib-inline 0.1.2. mistune 0.8.4. msgpack 1.0.4. multidict 6.0.2. multipledispatch 0.6.0. multiprocess 0.70.11.1. natsort 7.1.1. nbclient 0.6.4. nbconvert 6.5.0. nbformat 5.4.0. nest-asyncio 1.5.5. networkx 2.5. notebook 6.4.11. numba 0.52.0. numexpr 2.7.3. numpy 1.19.5. numpy-groupies 0.9.17. numpyro 0.9.2. oauthlib 3.2.0. openpyxl 3.0.10. opt-einsum 3.3.0. optax 0.1.2. packaging 20.9. pandas 1.2,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:2971,security,auth,auth-oauthlib,2971,a_processed/Leng_2020/adata_ast.h5ad'). ```. <details>. <summary>Versions</summary>. Package Version. ----------------------- ------------. absl-py 1.1.0. aiohttp 3.8.1. aiosignal 1.2.0. anndata 0.7.5. anndata2ri 1.0.6. annoy 1.17.0. argon2-cffi 21.3.0. argon2-cffi-bindings 21.2.0. asn1crypto 1.4.0. async-timeout 4.0.2. asynctest 0.13.0. attrs 20.3.0. backcall 0.2.0. beautifulsoup4 4.11.1. bleach 5.0.0. boto3 1.17.66. botocore 1.20.66. brotlipy 0.7.0. cached-property 1.5.2. cachetools 5.2.0. certifi 2020.12.5. cffi 1.14.5. chardet 4.0.0. charset-normalizer 2.0.12. chex 0.1.3. click 8.1.3. colormath 3.0.0. commonmark 0.9.1. conda 4.6.14. conda-package-handling 1.7.3. cryptography 3.4.7. cycler 0.10.0. Cython 0.29.30. decorator 5.0.7. defusedxml 0.7.1. dill 0.3.3. dm-tree 0.1.7. docrep 0.3.2. entrypoints 0.4. et-xmlfile 1.1.0. fa2 0.3.5. fastjsonschema 2.15.3. flatbuffers 2.0. flax 0.5.0. frozenlist 1.3.0. fsspec 2022.5.0. future 0.18.2. get-version 2.2. google-auth 2.6.6. google-auth-oauthlib 0.4.6. google-pasta 0.2.0. grpcio 1.46.3. h5py 3.2.1. idna 2.10. imageio 2.19.3. importlib-metadata 4.11.4. importlib-resources 5.7.1. ipykernel 5.5.4. ipython 7.23.1. ipython-genutils 0.2.0. ipywidgets 7.7.0. jax 0.3.13. jaxlib 0.3.10. jedi 0.18.0. Jinja2 3.1.2. jmespath 0.10.0. joblib 1.0.1. jsonschema 4.6.0. jupyter-client 6.1.12. jupyter-core 4.7.1. jupyterlab-pygments 0.2.2. jupyterlab-widgets 1.1.0. kiwisolver 1.3.1. legacy-api-wrap 1.2. leidenalg 0.8.4. llvmlite 0.35.0. loompy 3.0.7. louvain 0.7.0. Markdown 3.3.7. MarkupSafe 2.1.1. matplotlib 3.4.1. matplotlib-inline 0.1.2. mistune 0.8.4. msgpack 1.0.4. multidict 6.0.2. multipledispatch 0.6.0. multiprocess 0.70.11.1. natsort 7.1.1. nbclient 0.6.4. nbconvert 6.5.0. nbformat 5.4.0. nest-asyncio 1.5.5. networkx 2.5. notebook 6.4.11. numba 0.52.0. numexpr 2.7.3. numpy 1.19.5. numpy-groupies 0.9.17. numpyro 0.9.2. oauthlib 3.2.0. openpyxl 3.0.10. opt-einsum 3.3.0. optax 0.1.2. packaging 20.9. pandas 1.2.0. pandocfilters 1.5.0.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:3752,security,network,networkx,3752,ee 0.1.7. docrep 0.3.2. entrypoints 0.4. et-xmlfile 1.1.0. fa2 0.3.5. fastjsonschema 2.15.3. flatbuffers 2.0. flax 0.5.0. frozenlist 1.3.0. fsspec 2022.5.0. future 0.18.2. get-version 2.2. google-auth 2.6.6. google-auth-oauthlib 0.4.6. google-pasta 0.2.0. grpcio 1.46.3. h5py 3.2.1. idna 2.10. imageio 2.19.3. importlib-metadata 4.11.4. importlib-resources 5.7.1. ipykernel 5.5.4. ipython 7.23.1. ipython-genutils 0.2.0. ipywidgets 7.7.0. jax 0.3.13. jaxlib 0.3.10. jedi 0.18.0. Jinja2 3.1.2. jmespath 0.10.0. joblib 1.0.1. jsonschema 4.6.0. jupyter-client 6.1.12. jupyter-core 4.7.1. jupyterlab-pygments 0.2.2. jupyterlab-widgets 1.1.0. kiwisolver 1.3.1. legacy-api-wrap 1.2. leidenalg 0.8.4. llvmlite 0.35.0. loompy 3.0.7. louvain 0.7.0. Markdown 3.3.7. MarkupSafe 2.1.1. matplotlib 3.4.1. matplotlib-inline 0.1.2. mistune 0.8.4. msgpack 1.0.4. multidict 6.0.2. multipledispatch 0.6.0. multiprocess 0.70.11.1. natsort 7.1.1. nbclient 0.6.4. nbconvert 6.5.0. nbformat 5.4.0. nest-asyncio 1.5.5. networkx 2.5. notebook 6.4.11. numba 0.52.0. numexpr 2.7.3. numpy 1.19.5. numpy-groupies 0.9.17. numpyro 0.9.2. oauthlib 3.2.0. openpyxl 3.0.10. opt-einsum 3.3.0. optax 0.1.2. packaging 20.9. pandas 1.2.0. pandocfilters 1.5.0. parso 0.8.2. pathos 0.2.7. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 9.1.1. pip 21.1.1. pox 0.2.9. ppft 1.6.6.3. prometheus-client 0.14.1. prompt-toolkit 3.0.18. protobuf 3.19.0. protobuf3-to-dict 0.1.5. ptyprocess 0.7.0. pyasn1 0.4.8. pyasn1-modules 0.2.8. pycosat 0.6.3. pycparser 2.20. pyDeprecate 0.3.1. Pygments 2.9.0. pyOpenSSL 20.0.1. pyparsing 2.4.7. pyro-api 0.1.2. pyro-ppl 1.8.1. pyrsistent 0.18.1. PySocks 1.7.1. python-dateutil 2.8.1. python-igraph 0.9.1. pytorch-lightning 1.5.10. pytz 2021.1. PyWavelets 1.3.0. PyYAML 6.0. pyzmq 22.0.3. requests 2.25.1. requests-oauthlib 1.3.1. rich 12.4.4. rpy2 3.4.2. rsa 4.8. ruamel-yaml-conda 0.15.80. ruamel.yaml 0.17.21. ruamel.yaml.clib 0.2.6. s3transfer 0.4.2. sagemaker 2.39.0.post0. scanpy 1.6.1. scikit-im,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:4610,security,rsa,rsa,4610," 6.0.2. multipledispatch 0.6.0. multiprocess 0.70.11.1. natsort 7.1.1. nbclient 0.6.4. nbconvert 6.5.0. nbformat 5.4.0. nest-asyncio 1.5.5. networkx 2.5. notebook 6.4.11. numba 0.52.0. numexpr 2.7.3. numpy 1.19.5. numpy-groupies 0.9.17. numpyro 0.9.2. oauthlib 3.2.0. openpyxl 3.0.10. opt-einsum 3.3.0. optax 0.1.2. packaging 20.9. pandas 1.2.0. pandocfilters 1.5.0. parso 0.8.2. pathos 0.2.7. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 9.1.1. pip 21.1.1. pox 0.2.9. ppft 1.6.6.3. prometheus-client 0.14.1. prompt-toolkit 3.0.18. protobuf 3.19.0. protobuf3-to-dict 0.1.5. ptyprocess 0.7.0. pyasn1 0.4.8. pyasn1-modules 0.2.8. pycosat 0.6.3. pycparser 2.20. pyDeprecate 0.3.1. Pygments 2.9.0. pyOpenSSL 20.0.1. pyparsing 2.4.7. pyro-api 0.1.2. pyro-ppl 1.8.1. pyrsistent 0.18.1. PySocks 1.7.1. python-dateutil 2.8.1. python-igraph 0.9.1. pytorch-lightning 1.5.10. pytz 2021.1. PyWavelets 1.3.0. PyYAML 6.0. pyzmq 22.0.3. requests 2.25.1. requests-oauthlib 1.3.1. rich 12.4.4. rpy2 3.4.2. rsa 4.8. ruamel-yaml-conda 0.15.80. ruamel.yaml 0.17.21. ruamel.yaml.clib 0.2.6. s3transfer 0.4.2. sagemaker 2.39.0.post0. scanpy 1.6.1. scikit-image 0.19.2. scikit-learn 0.24.2. scikit-misc 0.1.4. scipy 1.6.0. scrublet 0.2.3. scvi-tools 0.16.2. seaborn 0.11.1. Send2Trash 1.8.0. setuptools 59.5.0. setuptools-scm 6.0.1. sinfo 0.3.1. six 1.15.0. smdebug-rulesconfig 1.0.1. soupsieve 2.3.2.post1. spectra 0.0.11. statsmodels 0.12.2. stdlib-list 0.8.0. tables 3.6.1. tensorboard 2.9.0. tensorboard-data-server 0.6.1. tensorboard-plugin-wit 1.8.1. terminado 0.15.0. texttable 1.6.3. threadpoolctl 2.1.0. tifffile 2021.11.2. tinycss2 1.1.1. toolz 0.11.2. torch 1.11.0. torchmetrics 0.9.0. tornado 6.1. tqdm 4.60.0. traitlets 5.2.2.post1. typing-extensions 4.2.0. tzlocal 2.1. umap-learn 0.4.6. urllib3 1.26.4. wcwidth 0.2.5. webencodings 0.5.1. Werkzeug 2.1.2. wheel 0.36.2. widgetsnbextension 3.6.0. yarl 1.7.2. zipp 3.4.1. Note: you may need to restart the kernel to use updated packages."". </details>. H",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:5579,security,updat,updated,5579," natsort 7.1.1. nbclient 0.6.4. nbconvert 6.5.0. nbformat 5.4.0. nest-asyncio 1.5.5. networkx 2.5. notebook 6.4.11. numba 0.52.0. numexpr 2.7.3. numpy 1.19.5. numpy-groupies 0.9.17. numpyro 0.9.2. oauthlib 3.2.0. openpyxl 3.0.10. opt-einsum 3.3.0. optax 0.1.2. packaging 20.9. pandas 1.2.0. pandocfilters 1.5.0. parso 0.8.2. pathos 0.2.7. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 9.1.1. pip 21.1.1. pox 0.2.9. ppft 1.6.6.3. prometheus-client 0.14.1. prompt-toolkit 3.0.18. protobuf 3.19.0. protobuf3-to-dict 0.1.5. ptyprocess 0.7.0. pyasn1 0.4.8. pyasn1-modules 0.2.8. pycosat 0.6.3. pycparser 2.20. pyDeprecate 0.3.1. Pygments 2.9.0. pyOpenSSL 20.0.1. pyparsing 2.4.7. pyro-api 0.1.2. pyro-ppl 1.8.1. pyrsistent 0.18.1. PySocks 1.7.1. python-dateutil 2.8.1. python-igraph 0.9.1. pytorch-lightning 1.5.10. pytz 2021.1. PyWavelets 1.3.0. PyYAML 6.0. pyzmq 22.0.3. requests 2.25.1. requests-oauthlib 1.3.1. rich 12.4.4. rpy2 3.4.2. rsa 4.8. ruamel-yaml-conda 0.15.80. ruamel.yaml 0.17.21. ruamel.yaml.clib 0.2.6. s3transfer 0.4.2. sagemaker 2.39.0.post0. scanpy 1.6.1. scikit-image 0.19.2. scikit-learn 0.24.2. scikit-misc 0.1.4. scipy 1.6.0. scrublet 0.2.3. scvi-tools 0.16.2. seaborn 0.11.1. Send2Trash 1.8.0. setuptools 59.5.0. setuptools-scm 6.0.1. sinfo 0.3.1. six 1.15.0. smdebug-rulesconfig 1.0.1. soupsieve 2.3.2.post1. spectra 0.0.11. statsmodels 0.12.2. stdlib-list 0.8.0. tables 3.6.1. tensorboard 2.9.0. tensorboard-data-server 0.6.1. tensorboard-plugin-wit 1.8.1. terminado 0.15.0. texttable 1.6.3. threadpoolctl 2.1.0. tifffile 2021.11.2. tinycss2 1.1.1. toolz 0.11.2. torch 1.11.0. torchmetrics 0.9.0. tornado 6.1. tqdm 4.60.0. traitlets 5.2.2.post1. typing-extensions 4.2.0. tzlocal 2.1. umap-learn 0.4.6. urllib3 1.26.4. wcwidth 0.2.5. webencodings 0.5.1. Werkzeug 2.1.2. wheel 0.36.2. widgetsnbextension 3.6.0. yarl 1.7.2. zipp 3.4.1. Note: you may need to restart the kernel to use updated packages."". </details>. Has anyone found any solution to work around this issue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:230,testability,Trace,Traceback,230,"Found the same error in our internal workflows. Saved the data to h5py files, but could not open them anymore for some reason. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_group(group). 531 if encoding_type:. --> 532 EncodingVersions[encoding_type].check(. 533 group.name, group.attrs[""encoding-version""]. /opt/conda/lib/python3.7/enum.py in __getitem__(cls, name). 356 def __getitem__(cls, name):. --> 357 return cls._member_map_[name]. 358 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-20-38a594ec7d06> in <module>. ----> 1 adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 424 d[k] = read_dataframe(f[k]). 425 else: # Base case. --> 426 d[k] = read_attribute(f[k]). 427 . 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:890,testability,Trace,Traceback,890,"Found the same error in our internal workflows. Saved the data to h5py files, but could not open them anymore for some reason. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_group(group). 531 if encoding_type:. --> 532 EncodingVersions[encoding_type].check(. 533 group.name, group.attrs[""encoding-version""]. /opt/conda/lib/python3.7/enum.py in __getitem__(cls, name). 356 def __getitem__(cls, name):. --> 357 return cls._member_map_[name]. 358 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-20-38a594ec7d06> in <module>. ----> 1 adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 424 d[k] = read_dataframe(f[k]). 425 else: # Base case. --> 426 d[k] = read_attribute(f[k]). 427 . 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:3103,testability,resourc,resources,3103,--------. absl-py 1.1.0. aiohttp 3.8.1. aiosignal 1.2.0. anndata 0.7.5. anndata2ri 1.0.6. annoy 1.17.0. argon2-cffi 21.3.0. argon2-cffi-bindings 21.2.0. asn1crypto 1.4.0. async-timeout 4.0.2. asynctest 0.13.0. attrs 20.3.0. backcall 0.2.0. beautifulsoup4 4.11.1. bleach 5.0.0. boto3 1.17.66. botocore 1.20.66. brotlipy 0.7.0. cached-property 1.5.2. cachetools 5.2.0. certifi 2020.12.5. cffi 1.14.5. chardet 4.0.0. charset-normalizer 2.0.12. chex 0.1.3. click 8.1.3. colormath 3.0.0. commonmark 0.9.1. conda 4.6.14. conda-package-handling 1.7.3. cryptography 3.4.7. cycler 0.10.0. Cython 0.29.30. decorator 5.0.7. defusedxml 0.7.1. dill 0.3.3. dm-tree 0.1.7. docrep 0.3.2. entrypoints 0.4. et-xmlfile 1.1.0. fa2 0.3.5. fastjsonschema 2.15.3. flatbuffers 2.0. flax 0.5.0. frozenlist 1.3.0. fsspec 2022.5.0. future 0.18.2. get-version 2.2. google-auth 2.6.6. google-auth-oauthlib 0.4.6. google-pasta 0.2.0. grpcio 1.46.3. h5py 3.2.1. idna 2.10. imageio 2.19.3. importlib-metadata 4.11.4. importlib-resources 5.7.1. ipykernel 5.5.4. ipython 7.23.1. ipython-genutils 0.2.0. ipywidgets 7.7.0. jax 0.3.13. jaxlib 0.3.10. jedi 0.18.0. Jinja2 3.1.2. jmespath 0.10.0. joblib 1.0.1. jsonschema 4.6.0. jupyter-client 6.1.12. jupyter-core 4.7.1. jupyterlab-pygments 0.2.2. jupyterlab-widgets 1.1.0. kiwisolver 1.3.1. legacy-api-wrap 1.2. leidenalg 0.8.4. llvmlite 0.35.0. loompy 3.0.7. louvain 0.7.0. Markdown 3.3.7. MarkupSafe 2.1.1. matplotlib 3.4.1. matplotlib-inline 0.1.2. mistune 0.8.4. msgpack 1.0.4. multidict 6.0.2. multipledispatch 0.6.0. multiprocess 0.70.11.1. natsort 7.1.1. nbclient 0.6.4. nbconvert 6.5.0. nbformat 5.4.0. nest-asyncio 1.5.5. networkx 2.5. notebook 6.4.11. numba 0.52.0. numexpr 2.7.3. numpy 1.19.5. numpy-groupies 0.9.17. numpyro 0.9.2. oauthlib 3.2.0. openpyxl 3.0.10. opt-einsum 3.3.0. optax 0.1.2. packaging 20.9. pandas 1.2.0. pandocfilters 1.5.0. parso 0.8.2. pathos 0.2.7. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 9.1.1. pip 21.1.1. pox 0.2.9. ppft 1.6.6.3. prom,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:15,usability,error,error,15,"Found the same error in our internal workflows. Saved the data to h5py files, but could not open them anymore for some reason. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_group(group). 531 if encoding_type:. --> 532 EncodingVersions[encoding_type].check(. 533 group.name, group.attrs[""encoding-version""]. /opt/conda/lib/python3.7/enum.py in __getitem__(cls, name). 356 def __getitem__(cls, name):. --> 357 return cls._member_map_[name]. 358 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-20-38a594ec7d06> in <module>. ----> 1 adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 424 d[k] = read_dataframe(f[k]). 425 else: # Base case. --> 426 d[k] = read_attribute(f[k]). 427 . 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:37,usability,workflow,workflows,37,"Found the same error in our internal workflows. Saved the data to h5py files, but could not open them anymore for some reason. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_group(group). 531 if encoding_type:. --> 532 EncodingVersions[encoding_type].check(. 533 group.name, group.attrs[""encoding-version""]. /opt/conda/lib/python3.7/enum.py in __getitem__(cls, name). 356 def __getitem__(cls, name):. --> 357 return cls._member_map_[name]. 358 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-20-38a594ec7d06> in <module>. ----> 1 adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 424 d[k] = read_dataframe(f[k]). 425 else: # Base case. --> 426 d[k] = read_attribute(f[k]). 427 . 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:127,usability,Error,Error,127,"Found the same error in our internal workflows. Saved the data to h5py files, but could not open them anymore for some reason. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_group(group). 531 if encoding_type:. --> 532 EncodingVersions[encoding_type].check(. 533 group.name, group.attrs[""encoding-version""]. /opt/conda/lib/python3.7/enum.py in __getitem__(cls, name). 356 def __getitem__(cls, name):. --> 357 return cls._member_map_[name]. 358 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-20-38a594ec7d06> in <module>. ----> 1 adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 424 d[k] = read_dataframe(f[k]). 425 else: # Base case. --> 426 d[k] = read_attribute(f[k]). 427 . 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:934,usability,input,input-,934,"Found the same error in our internal workflows. Saved the data to h5py files, but could not open them anymore for some reason. Error:. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_group(group). 531 if encoding_type:. --> 532 EncodingVersions[encoding_type].check(. 533 group.name, group.attrs[""encoding-version""]. /opt/conda/lib/python3.7/enum.py in __getitem__(cls, name). 356 def __getitem__(cls, name):. --> 357 return cls._member_map_[name]. 358 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-20-38a594ec7d06> in <module>. ----> 1 adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 424 d[k] = read_dataframe(f[k]). 425 else: # Base case. --> 426 d[k] = read_attribute(f[k]). 427 . 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:1734,usability,error,error,1734,"):. --> 357 return cls._member_map_[name]. 358 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-20-38a594ec7d06> in <module>. ----> 1 adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 424 d[k] = read_dataframe(f[k]). 425 else: # Base case. --> 426 d[k] = read_attribute(f[k]). 427 . 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). ```. <details>. <summary>Versions</summary>. Package Version. ----------------------- ------------. absl-py 1.1.0. aiohttp 3.8.1. aiosignal 1.2.0. anndata 0.7.5. anndata2ri 1.0.6. annoy 1.17.0. argon2-cffi 21.3.0. argon2-cffi-bindings 21.2.0. asn1crypto 1.4.0. async-timeout 4.0.2. asynctest 0.13.0. attrs 20.3.0. backcall 0.2.0. beautifulsoup4 4.11.1. bleach 5.0.0. boto3 1.17.66. botocore 1.20.66. brotlipy 0.7.0. cached-property 1.5.2. cachetools 5.2.0. certifi 2020.12.5. cffi 1.14.5. chardet 4.0.0. charset-normalizer 2.0.12. chex 0.1.3. click 8.1.3. colormath 3.0.0. commonmark 0.9.1. conda 4.6.14. conda-package-handling 1.7.3. cryptography 3.4.7. cycler 0.10.0. Cython 0.29.30. decorator 5.0.7. defusedxml 0.7.1",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:1857,usability,error,error,1857,"n occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-20-38a594ec7d06> in <module>. ----> 1 adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 424 d[k] = read_dataframe(f[k]). 425 else: # Base case. --> 426 d[k] = read_attribute(f[k]). 427 . 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 161 parent = _get_parent(elem). 162 raise AnnDataReadError(. --> 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). ```. <details>. <summary>Versions</summary>. Package Version. ----------------------- ------------. absl-py 1.1.0. aiohttp 3.8.1. aiosignal 1.2.0. anndata 0.7.5. anndata2ri 1.0.6. annoy 1.17.0. argon2-cffi 21.3.0. argon2-cffi-bindings 21.2.0. asn1crypto 1.4.0. async-timeout 4.0.2. asynctest 0.13.0. attrs 20.3.0. backcall 0.2.0. beautifulsoup4 4.11.1. bleach 5.0.0. boto3 1.17.66. botocore 1.20.66. brotlipy 0.7.0. cached-property 1.5.2. cachetools 5.2.0. certifi 2020.12.5. cffi 1.14.5. chardet 4.0.0. charset-normalizer 2.0.12. chex 0.1.3. click 8.1.3. colormath 3.0.0. commonmark 0.9.1. conda 4.6.14. conda-package-handling 1.7.3. cryptography 3.4.7. cycler 0.10.0. Cython 0.29.30. decorator 5.0.7. defusedxml 0.7.1. dill 0.3.3. dm-tree 0.1.7. docrep 0.3.2. entrypoints 0.4. et-xmlfile 1.1.0. fa2 0.3.5. fastjsonschema 2.15.3. flatbuffers",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:3379,usability,widget,widgets,3379,. boto3 1.17.66. botocore 1.20.66. brotlipy 0.7.0. cached-property 1.5.2. cachetools 5.2.0. certifi 2020.12.5. cffi 1.14.5. chardet 4.0.0. charset-normalizer 2.0.12. chex 0.1.3. click 8.1.3. colormath 3.0.0. commonmark 0.9.1. conda 4.6.14. conda-package-handling 1.7.3. cryptography 3.4.7. cycler 0.10.0. Cython 0.29.30. decorator 5.0.7. defusedxml 0.7.1. dill 0.3.3. dm-tree 0.1.7. docrep 0.3.2. entrypoints 0.4. et-xmlfile 1.1.0. fa2 0.3.5. fastjsonschema 2.15.3. flatbuffers 2.0. flax 0.5.0. frozenlist 1.3.0. fsspec 2022.5.0. future 0.18.2. get-version 2.2. google-auth 2.6.6. google-auth-oauthlib 0.4.6. google-pasta 0.2.0. grpcio 1.46.3. h5py 3.2.1. idna 2.10. imageio 2.19.3. importlib-metadata 4.11.4. importlib-resources 5.7.1. ipykernel 5.5.4. ipython 7.23.1. ipython-genutils 0.2.0. ipywidgets 7.7.0. jax 0.3.13. jaxlib 0.3.10. jedi 0.18.0. Jinja2 3.1.2. jmespath 0.10.0. joblib 1.0.1. jsonschema 4.6.0. jupyter-client 6.1.12. jupyter-core 4.7.1. jupyterlab-pygments 0.2.2. jupyterlab-widgets 1.1.0. kiwisolver 1.3.1. legacy-api-wrap 1.2. leidenalg 0.8.4. llvmlite 0.35.0. loompy 3.0.7. louvain 0.7.0. Markdown 3.3.7. MarkupSafe 2.1.1. matplotlib 3.4.1. matplotlib-inline 0.1.2. mistune 0.8.4. msgpack 1.0.4. multidict 6.0.2. multipledispatch 0.6.0. multiprocess 0.70.11.1. natsort 7.1.1. nbclient 0.6.4. nbconvert 6.5.0. nbformat 5.4.0. nest-asyncio 1.5.5. networkx 2.5. notebook 6.4.11. numba 0.52.0. numexpr 2.7.3. numpy 1.19.5. numpy-groupies 0.9.17. numpyro 0.9.2. oauthlib 3.2.0. openpyxl 3.0.10. opt-einsum 3.3.0. optax 0.1.2. packaging 20.9. pandas 1.2.0. pandocfilters 1.5.0. parso 0.8.2. pathos 0.2.7. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 9.1.1. pip 21.1.1. pox 0.2.9. ppft 1.6.6.3. prometheus-client 0.14.1. prompt-toolkit 3.0.18. protobuf 3.19.0. protobuf3-to-dict 0.1.5. ptyprocess 0.7.0. pyasn1 0.4.8. pyasn1-modules 0.2.8. pycosat 0.6.3. pycparser 2.20. pyDeprecate 0.3.1. Pygments 2.9.0. pyOpenSSL 20.0.1. pyparsing 2.4.7. pyro-api 0.1.2. pyro-ppl 1.8.1. p,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:4137,usability,tool,toolkit,4137,hon 7.23.1. ipython-genutils 0.2.0. ipywidgets 7.7.0. jax 0.3.13. jaxlib 0.3.10. jedi 0.18.0. Jinja2 3.1.2. jmespath 0.10.0. joblib 1.0.1. jsonschema 4.6.0. jupyter-client 6.1.12. jupyter-core 4.7.1. jupyterlab-pygments 0.2.2. jupyterlab-widgets 1.1.0. kiwisolver 1.3.1. legacy-api-wrap 1.2. leidenalg 0.8.4. llvmlite 0.35.0. loompy 3.0.7. louvain 0.7.0. Markdown 3.3.7. MarkupSafe 2.1.1. matplotlib 3.4.1. matplotlib-inline 0.1.2. mistune 0.8.4. msgpack 1.0.4. multidict 6.0.2. multipledispatch 0.6.0. multiprocess 0.70.11.1. natsort 7.1.1. nbclient 0.6.4. nbconvert 6.5.0. nbformat 5.4.0. nest-asyncio 1.5.5. networkx 2.5. notebook 6.4.11. numba 0.52.0. numexpr 2.7.3. numpy 1.19.5. numpy-groupies 0.9.17. numpyro 0.9.2. oauthlib 3.2.0. openpyxl 3.0.10. opt-einsum 3.3.0. optax 0.1.2. packaging 20.9. pandas 1.2.0. pandocfilters 1.5.0. parso 0.8.2. pathos 0.2.7. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 9.1.1. pip 21.1.1. pox 0.2.9. ppft 1.6.6.3. prometheus-client 0.14.1. prompt-toolkit 3.0.18. protobuf 3.19.0. protobuf3-to-dict 0.1.5. ptyprocess 0.7.0. pyasn1 0.4.8. pyasn1-modules 0.2.8. pycosat 0.6.3. pycparser 2.20. pyDeprecate 0.3.1. Pygments 2.9.0. pyOpenSSL 20.0.1. pyparsing 2.4.7. pyro-api 0.1.2. pyro-ppl 1.8.1. pyrsistent 0.18.1. PySocks 1.7.1. python-dateutil 2.8.1. python-igraph 0.9.1. pytorch-lightning 1.5.10. pytz 2021.1. PyWavelets 1.3.0. PyYAML 6.0. pyzmq 22.0.3. requests 2.25.1. requests-oauthlib 1.3.1. rich 12.4.4. rpy2 3.4.2. rsa 4.8. ruamel-yaml-conda 0.15.80. ruamel.yaml 0.17.21. ruamel.yaml.clib 0.2.6. s3transfer 0.4.2. sagemaker 2.39.0.post0. scanpy 1.6.1. scikit-image 0.19.2. scikit-learn 0.24.2. scikit-misc 0.1.4. scipy 1.6.0. scrublet 0.2.3. scvi-tools 0.16.2. seaborn 0.11.1. Send2Trash 1.8.0. setuptools 59.5.0. setuptools-scm 6.0.1. sinfo 0.3.1. six 1.15.0. smdebug-rulesconfig 1.0.1. soupsieve 2.3.2.post1. spectra 0.0.11. statsmodels 0.12.2. stdlib-list 0.8.0. tables 3.6.1. tensorboard 2.9.0. tensorboard-data-server 0.6.1. tensorboard-plug,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:4775,usability,learn,learn,4775," natsort 7.1.1. nbclient 0.6.4. nbconvert 6.5.0. nbformat 5.4.0. nest-asyncio 1.5.5. networkx 2.5. notebook 6.4.11. numba 0.52.0. numexpr 2.7.3. numpy 1.19.5. numpy-groupies 0.9.17. numpyro 0.9.2. oauthlib 3.2.0. openpyxl 3.0.10. opt-einsum 3.3.0. optax 0.1.2. packaging 20.9. pandas 1.2.0. pandocfilters 1.5.0. parso 0.8.2. pathos 0.2.7. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 9.1.1. pip 21.1.1. pox 0.2.9. ppft 1.6.6.3. prometheus-client 0.14.1. prompt-toolkit 3.0.18. protobuf 3.19.0. protobuf3-to-dict 0.1.5. ptyprocess 0.7.0. pyasn1 0.4.8. pyasn1-modules 0.2.8. pycosat 0.6.3. pycparser 2.20. pyDeprecate 0.3.1. Pygments 2.9.0. pyOpenSSL 20.0.1. pyparsing 2.4.7. pyro-api 0.1.2. pyro-ppl 1.8.1. pyrsistent 0.18.1. PySocks 1.7.1. python-dateutil 2.8.1. python-igraph 0.9.1. pytorch-lightning 1.5.10. pytz 2021.1. PyWavelets 1.3.0. PyYAML 6.0. pyzmq 22.0.3. requests 2.25.1. requests-oauthlib 1.3.1. rich 12.4.4. rpy2 3.4.2. rsa 4.8. ruamel-yaml-conda 0.15.80. ruamel.yaml 0.17.21. ruamel.yaml.clib 0.2.6. s3transfer 0.4.2. sagemaker 2.39.0.post0. scanpy 1.6.1. scikit-image 0.19.2. scikit-learn 0.24.2. scikit-misc 0.1.4. scipy 1.6.0. scrublet 0.2.3. scvi-tools 0.16.2. seaborn 0.11.1. Send2Trash 1.8.0. setuptools 59.5.0. setuptools-scm 6.0.1. sinfo 0.3.1. six 1.15.0. smdebug-rulesconfig 1.0.1. soupsieve 2.3.2.post1. spectra 0.0.11. statsmodels 0.12.2. stdlib-list 0.8.0. tables 3.6.1. tensorboard 2.9.0. tensorboard-data-server 0.6.1. tensorboard-plugin-wit 1.8.1. terminado 0.15.0. texttable 1.6.3. threadpoolctl 2.1.0. tifffile 2021.11.2. tinycss2 1.1.1. toolz 0.11.2. torch 1.11.0. torchmetrics 0.9.0. tornado 6.1. tqdm 4.60.0. traitlets 5.2.2.post1. typing-extensions 4.2.0. tzlocal 2.1. umap-learn 0.4.6. urllib3 1.26.4. wcwidth 0.2.5. webencodings 0.5.1. Werkzeug 2.1.2. wheel 0.36.2. widgetsnbextension 3.6.0. yarl 1.7.2. zipp 3.4.1. Note: you may need to restart the kernel to use updated packages."". </details>. Has anyone found any solution to work around this issue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:4842,usability,tool,tools,4842," natsort 7.1.1. nbclient 0.6.4. nbconvert 6.5.0. nbformat 5.4.0. nest-asyncio 1.5.5. networkx 2.5. notebook 6.4.11. numba 0.52.0. numexpr 2.7.3. numpy 1.19.5. numpy-groupies 0.9.17. numpyro 0.9.2. oauthlib 3.2.0. openpyxl 3.0.10. opt-einsum 3.3.0. optax 0.1.2. packaging 20.9. pandas 1.2.0. pandocfilters 1.5.0. parso 0.8.2. pathos 0.2.7. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 9.1.1. pip 21.1.1. pox 0.2.9. ppft 1.6.6.3. prometheus-client 0.14.1. prompt-toolkit 3.0.18. protobuf 3.19.0. protobuf3-to-dict 0.1.5. ptyprocess 0.7.0. pyasn1 0.4.8. pyasn1-modules 0.2.8. pycosat 0.6.3. pycparser 2.20. pyDeprecate 0.3.1. Pygments 2.9.0. pyOpenSSL 20.0.1. pyparsing 2.4.7. pyro-api 0.1.2. pyro-ppl 1.8.1. pyrsistent 0.18.1. PySocks 1.7.1. python-dateutil 2.8.1. python-igraph 0.9.1. pytorch-lightning 1.5.10. pytz 2021.1. PyWavelets 1.3.0. PyYAML 6.0. pyzmq 22.0.3. requests 2.25.1. requests-oauthlib 1.3.1. rich 12.4.4. rpy2 3.4.2. rsa 4.8. ruamel-yaml-conda 0.15.80. ruamel.yaml 0.17.21. ruamel.yaml.clib 0.2.6. s3transfer 0.4.2. sagemaker 2.39.0.post0. scanpy 1.6.1. scikit-image 0.19.2. scikit-learn 0.24.2. scikit-misc 0.1.4. scipy 1.6.0. scrublet 0.2.3. scvi-tools 0.16.2. seaborn 0.11.1. Send2Trash 1.8.0. setuptools 59.5.0. setuptools-scm 6.0.1. sinfo 0.3.1. six 1.15.0. smdebug-rulesconfig 1.0.1. soupsieve 2.3.2.post1. spectra 0.0.11. statsmodels 0.12.2. stdlib-list 0.8.0. tables 3.6.1. tensorboard 2.9.0. tensorboard-data-server 0.6.1. tensorboard-plugin-wit 1.8.1. terminado 0.15.0. texttable 1.6.3. threadpoolctl 2.1.0. tifffile 2021.11.2. tinycss2 1.1.1. toolz 0.11.2. torch 1.11.0. torchmetrics 0.9.0. tornado 6.1. tqdm 4.60.0. traitlets 5.2.2.post1. typing-extensions 4.2.0. tzlocal 2.1. umap-learn 0.4.6. urllib3 1.26.4. wcwidth 0.2.5. webencodings 0.5.1. Werkzeug 2.1.2. wheel 0.36.2. widgetsnbextension 3.6.0. yarl 1.7.2. zipp 3.4.1. Note: you may need to restart the kernel to use updated packages."". </details>. Has anyone found any solution to work around this issue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:5247,usability,tool,toolz,5247," natsort 7.1.1. nbclient 0.6.4. nbconvert 6.5.0. nbformat 5.4.0. nest-asyncio 1.5.5. networkx 2.5. notebook 6.4.11. numba 0.52.0. numexpr 2.7.3. numpy 1.19.5. numpy-groupies 0.9.17. numpyro 0.9.2. oauthlib 3.2.0. openpyxl 3.0.10. opt-einsum 3.3.0. optax 0.1.2. packaging 20.9. pandas 1.2.0. pandocfilters 1.5.0. parso 0.8.2. pathos 0.2.7. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 9.1.1. pip 21.1.1. pox 0.2.9. ppft 1.6.6.3. prometheus-client 0.14.1. prompt-toolkit 3.0.18. protobuf 3.19.0. protobuf3-to-dict 0.1.5. ptyprocess 0.7.0. pyasn1 0.4.8. pyasn1-modules 0.2.8. pycosat 0.6.3. pycparser 2.20. pyDeprecate 0.3.1. Pygments 2.9.0. pyOpenSSL 20.0.1. pyparsing 2.4.7. pyro-api 0.1.2. pyro-ppl 1.8.1. pyrsistent 0.18.1. PySocks 1.7.1. python-dateutil 2.8.1. python-igraph 0.9.1. pytorch-lightning 1.5.10. pytz 2021.1. PyWavelets 1.3.0. PyYAML 6.0. pyzmq 22.0.3. requests 2.25.1. requests-oauthlib 1.3.1. rich 12.4.4. rpy2 3.4.2. rsa 4.8. ruamel-yaml-conda 0.15.80. ruamel.yaml 0.17.21. ruamel.yaml.clib 0.2.6. s3transfer 0.4.2. sagemaker 2.39.0.post0. scanpy 1.6.1. scikit-image 0.19.2. scikit-learn 0.24.2. scikit-misc 0.1.4. scipy 1.6.0. scrublet 0.2.3. scvi-tools 0.16.2. seaborn 0.11.1. Send2Trash 1.8.0. setuptools 59.5.0. setuptools-scm 6.0.1. sinfo 0.3.1. six 1.15.0. smdebug-rulesconfig 1.0.1. soupsieve 2.3.2.post1. spectra 0.0.11. statsmodels 0.12.2. stdlib-list 0.8.0. tables 3.6.1. tensorboard 2.9.0. tensorboard-data-server 0.6.1. tensorboard-plugin-wit 1.8.1. terminado 0.15.0. texttable 1.6.3. threadpoolctl 2.1.0. tifffile 2021.11.2. tinycss2 1.1.1. toolz 0.11.2. torch 1.11.0. torchmetrics 0.9.0. tornado 6.1. tqdm 4.60.0. traitlets 5.2.2.post1. typing-extensions 4.2.0. tzlocal 2.1. umap-learn 0.4.6. urllib3 1.26.4. wcwidth 0.2.5. webencodings 0.5.1. Werkzeug 2.1.2. wheel 0.36.2. widgetsnbextension 3.6.0. yarl 1.7.2. zipp 3.4.1. Note: you may need to restart the kernel to use updated packages."". </details>. Has anyone found any solution to work around this issue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:5387,usability,learn,learn,5387," natsort 7.1.1. nbclient 0.6.4. nbconvert 6.5.0. nbformat 5.4.0. nest-asyncio 1.5.5. networkx 2.5. notebook 6.4.11. numba 0.52.0. numexpr 2.7.3. numpy 1.19.5. numpy-groupies 0.9.17. numpyro 0.9.2. oauthlib 3.2.0. openpyxl 3.0.10. opt-einsum 3.3.0. optax 0.1.2. packaging 20.9. pandas 1.2.0. pandocfilters 1.5.0. parso 0.8.2. pathos 0.2.7. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 9.1.1. pip 21.1.1. pox 0.2.9. ppft 1.6.6.3. prometheus-client 0.14.1. prompt-toolkit 3.0.18. protobuf 3.19.0. protobuf3-to-dict 0.1.5. ptyprocess 0.7.0. pyasn1 0.4.8. pyasn1-modules 0.2.8. pycosat 0.6.3. pycparser 2.20. pyDeprecate 0.3.1. Pygments 2.9.0. pyOpenSSL 20.0.1. pyparsing 2.4.7. pyro-api 0.1.2. pyro-ppl 1.8.1. pyrsistent 0.18.1. PySocks 1.7.1. python-dateutil 2.8.1. python-igraph 0.9.1. pytorch-lightning 1.5.10. pytz 2021.1. PyWavelets 1.3.0. PyYAML 6.0. pyzmq 22.0.3. requests 2.25.1. requests-oauthlib 1.3.1. rich 12.4.4. rpy2 3.4.2. rsa 4.8. ruamel-yaml-conda 0.15.80. ruamel.yaml 0.17.21. ruamel.yaml.clib 0.2.6. s3transfer 0.4.2. sagemaker 2.39.0.post0. scanpy 1.6.1. scikit-image 0.19.2. scikit-learn 0.24.2. scikit-misc 0.1.4. scipy 1.6.0. scrublet 0.2.3. scvi-tools 0.16.2. seaborn 0.11.1. Send2Trash 1.8.0. setuptools 59.5.0. setuptools-scm 6.0.1. sinfo 0.3.1. six 1.15.0. smdebug-rulesconfig 1.0.1. soupsieve 2.3.2.post1. spectra 0.0.11. statsmodels 0.12.2. stdlib-list 0.8.0. tables 3.6.1. tensorboard 2.9.0. tensorboard-data-server 0.6.1. tensorboard-plugin-wit 1.8.1. terminado 0.15.0. texttable 1.6.3. threadpoolctl 2.1.0. tifffile 2021.11.2. tinycss2 1.1.1. toolz 0.11.2. torch 1.11.0. torchmetrics 0.9.0. tornado 6.1. tqdm 4.60.0. traitlets 5.2.2.post1. typing-extensions 4.2.0. tzlocal 2.1. umap-learn 0.4.6. urllib3 1.26.4. wcwidth 0.2.5. webencodings 0.5.1. Werkzeug 2.1.2. wheel 0.36.2. widgetsnbextension 3.6.0. yarl 1.7.2. zipp 3.4.1. Note: you may need to restart the kernel to use updated packages."". </details>. Has anyone found any solution to work around this issue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:5481,usability,widget,widgetsnbextension,5481," natsort 7.1.1. nbclient 0.6.4. nbconvert 6.5.0. nbformat 5.4.0. nest-asyncio 1.5.5. networkx 2.5. notebook 6.4.11. numba 0.52.0. numexpr 2.7.3. numpy 1.19.5. numpy-groupies 0.9.17. numpyro 0.9.2. oauthlib 3.2.0. openpyxl 3.0.10. opt-einsum 3.3.0. optax 0.1.2. packaging 20.9. pandas 1.2.0. pandocfilters 1.5.0. parso 0.8.2. pathos 0.2.7. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 9.1.1. pip 21.1.1. pox 0.2.9. ppft 1.6.6.3. prometheus-client 0.14.1. prompt-toolkit 3.0.18. protobuf 3.19.0. protobuf3-to-dict 0.1.5. ptyprocess 0.7.0. pyasn1 0.4.8. pyasn1-modules 0.2.8. pycosat 0.6.3. pycparser 2.20. pyDeprecate 0.3.1. Pygments 2.9.0. pyOpenSSL 20.0.1. pyparsing 2.4.7. pyro-api 0.1.2. pyro-ppl 1.8.1. pyrsistent 0.18.1. PySocks 1.7.1. python-dateutil 2.8.1. python-igraph 0.9.1. pytorch-lightning 1.5.10. pytz 2021.1. PyWavelets 1.3.0. PyYAML 6.0. pyzmq 22.0.3. requests 2.25.1. requests-oauthlib 1.3.1. rich 12.4.4. rpy2 3.4.2. rsa 4.8. ruamel-yaml-conda 0.15.80. ruamel.yaml 0.17.21. ruamel.yaml.clib 0.2.6. s3transfer 0.4.2. sagemaker 2.39.0.post0. scanpy 1.6.1. scikit-image 0.19.2. scikit-learn 0.24.2. scikit-misc 0.1.4. scipy 1.6.0. scrublet 0.2.3. scvi-tools 0.16.2. seaborn 0.11.1. Send2Trash 1.8.0. setuptools 59.5.0. setuptools-scm 6.0.1. sinfo 0.3.1. six 1.15.0. smdebug-rulesconfig 1.0.1. soupsieve 2.3.2.post1. spectra 0.0.11. statsmodels 0.12.2. stdlib-list 0.8.0. tables 3.6.1. tensorboard 2.9.0. tensorboard-data-server 0.6.1. tensorboard-plugin-wit 1.8.1. terminado 0.15.0. texttable 1.6.3. threadpoolctl 2.1.0. tifffile 2021.11.2. tinycss2 1.1.1. toolz 0.11.2. torch 1.11.0. torchmetrics 0.9.0. tornado 6.1. tqdm 4.60.0. traitlets 5.2.2.post1. typing-extensions 4.2.0. tzlocal 2.1. umap-learn 0.4.6. urllib3 1.26.4. wcwidth 0.2.5. webencodings 0.5.1. Werkzeug 2.1.2. wheel 0.36.2. widgetsnbextension 3.6.0. yarl 1.7.2. zipp 3.4.1. Note: you may need to restart the kernel to use updated packages."". </details>. Has anyone found any solution to work around this issue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:109,availability,error,error,109,I'm pretty sure none of you are having the same issue as the original one reported here. Compare @abuchin 's error message of `KeyError: 'dict'` to the original poster's error of `OSError: Can't read data`. The thing you're seeing is a new one stemming from an update to anndata. You're trying to read in a `h5ad` file created with a newer version of the package with your older one. I think the cutoff point is 0.8.0 but I could be mistaken. Upgrade your anndata and you should be ok.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:170,availability,error,error,170,I'm pretty sure none of you are having the same issue as the original one reported here. Compare @abuchin 's error message of `KeyError: 'dict'` to the original poster's error of `OSError: Can't read data`. The thing you're seeing is a new one stemming from an update to anndata. You're trying to read in a `h5ad` file created with a newer version of the package with your older one. I think the cutoff point is 0.8.0 but I could be mistaken. Upgrade your anndata and you should be ok.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:261,deployability,updat,update,261,I'm pretty sure none of you are having the same issue as the original one reported here. Compare @abuchin 's error message of `KeyError: 'dict'` to the original poster's error of `OSError: Can't read data`. The thing you're seeing is a new one stemming from an update to anndata. You're trying to read in a `h5ad` file created with a newer version of the package with your older one. I think the cutoff point is 0.8.0 but I could be mistaken. Upgrade your anndata and you should be ok.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:340,deployability,version,version,340,I'm pretty sure none of you are having the same issue as the original one reported here. Compare @abuchin 's error message of `KeyError: 'dict'` to the original poster's error of `OSError: Can't read data`. The thing you're seeing is a new one stemming from an update to anndata. You're trying to read in a `h5ad` file created with a newer version of the package with your older one. I think the cutoff point is 0.8.0 but I could be mistaken. Upgrade your anndata and you should be ok.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:443,deployability,Upgrad,Upgrade,443,I'm pretty sure none of you are having the same issue as the original one reported here. Compare @abuchin 's error message of `KeyError: 'dict'` to the original poster's error of `OSError: Can't read data`. The thing you're seeing is a new one stemming from an update to anndata. You're trying to read in a `h5ad` file created with a newer version of the package with your older one. I think the cutoff point is 0.8.0 but I could be mistaken. Upgrade your anndata and you should be ok.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:115,integrability,messag,message,115,I'm pretty sure none of you are having the same issue as the original one reported here. Compare @abuchin 's error message of `KeyError: 'dict'` to the original poster's error of `OSError: Can't read data`. The thing you're seeing is a new one stemming from an update to anndata. You're trying to read in a `h5ad` file created with a newer version of the package with your older one. I think the cutoff point is 0.8.0 but I could be mistaken. Upgrade your anndata and you should be ok.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:340,integrability,version,version,340,I'm pretty sure none of you are having the same issue as the original one reported here. Compare @abuchin 's error message of `KeyError: 'dict'` to the original poster's error of `OSError: Can't read data`. The thing you're seeing is a new one stemming from an update to anndata. You're trying to read in a `h5ad` file created with a newer version of the package with your older one. I think the cutoff point is 0.8.0 but I could be mistaken. Upgrade your anndata and you should be ok.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:115,interoperability,messag,message,115,I'm pretty sure none of you are having the same issue as the original one reported here. Compare @abuchin 's error message of `KeyError: 'dict'` to the original poster's error of `OSError: Can't read data`. The thing you're seeing is a new one stemming from an update to anndata. You're trying to read in a `h5ad` file created with a newer version of the package with your older one. I think the cutoff point is 0.8.0 but I could be mistaken. Upgrade your anndata and you should be ok.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:340,modifiability,version,version,340,I'm pretty sure none of you are having the same issue as the original one reported here. Compare @abuchin 's error message of `KeyError: 'dict'` to the original poster's error of `OSError: Can't read data`. The thing you're seeing is a new one stemming from an update to anndata. You're trying to read in a `h5ad` file created with a newer version of the package with your older one. I think the cutoff point is 0.8.0 but I could be mistaken. Upgrade your anndata and you should be ok.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:355,modifiability,pac,package,355,I'm pretty sure none of you are having the same issue as the original one reported here. Compare @abuchin 's error message of `KeyError: 'dict'` to the original poster's error of `OSError: Can't read data`. The thing you're seeing is a new one stemming from an update to anndata. You're trying to read in a `h5ad` file created with a newer version of the package with your older one. I think the cutoff point is 0.8.0 but I could be mistaken. Upgrade your anndata and you should be ok.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:443,modifiability,Upgrad,Upgrade,443,I'm pretty sure none of you are having the same issue as the original one reported here. Compare @abuchin 's error message of `KeyError: 'dict'` to the original poster's error of `OSError: Can't read data`. The thing you're seeing is a new one stemming from an update to anndata. You're trying to read in a `h5ad` file created with a newer version of the package with your older one. I think the cutoff point is 0.8.0 but I could be mistaken. Upgrade your anndata and you should be ok.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:109,performance,error,error,109,I'm pretty sure none of you are having the same issue as the original one reported here. Compare @abuchin 's error message of `KeyError: 'dict'` to the original poster's error of `OSError: Can't read data`. The thing you're seeing is a new one stemming from an update to anndata. You're trying to read in a `h5ad` file created with a newer version of the package with your older one. I think the cutoff point is 0.8.0 but I could be mistaken. Upgrade your anndata and you should be ok.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:170,performance,error,error,170,I'm pretty sure none of you are having the same issue as the original one reported here. Compare @abuchin 's error message of `KeyError: 'dict'` to the original poster's error of `OSError: Can't read data`. The thing you're seeing is a new one stemming from an update to anndata. You're trying to read in a `h5ad` file created with a newer version of the package with your older one. I think the cutoff point is 0.8.0 but I could be mistaken. Upgrade your anndata and you should be ok.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:109,safety,error,error,109,I'm pretty sure none of you are having the same issue as the original one reported here. Compare @abuchin 's error message of `KeyError: 'dict'` to the original poster's error of `OSError: Can't read data`. The thing you're seeing is a new one stemming from an update to anndata. You're trying to read in a `h5ad` file created with a newer version of the package with your older one. I think the cutoff point is 0.8.0 but I could be mistaken. Upgrade your anndata and you should be ok.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:170,safety,error,error,170,I'm pretty sure none of you are having the same issue as the original one reported here. Compare @abuchin 's error message of `KeyError: 'dict'` to the original poster's error of `OSError: Can't read data`. The thing you're seeing is a new one stemming from an update to anndata. You're trying to read in a `h5ad` file created with a newer version of the package with your older one. I think the cutoff point is 0.8.0 but I could be mistaken. Upgrade your anndata and you should be ok.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:261,safety,updat,update,261,I'm pretty sure none of you are having the same issue as the original one reported here. Compare @abuchin 's error message of `KeyError: 'dict'` to the original poster's error of `OSError: Can't read data`. The thing you're seeing is a new one stemming from an update to anndata. You're trying to read in a `h5ad` file created with a newer version of the package with your older one. I think the cutoff point is 0.8.0 but I could be mistaken. Upgrade your anndata and you should be ok.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:261,security,updat,update,261,I'm pretty sure none of you are having the same issue as the original one reported here. Compare @abuchin 's error message of `KeyError: 'dict'` to the original poster's error of `OSError: Can't read data`. The thing you're seeing is a new one stemming from an update to anndata. You're trying to read in a `h5ad` file created with a newer version of the package with your older one. I think the cutoff point is 0.8.0 but I could be mistaken. Upgrade your anndata and you should be ok.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:109,usability,error,error,109,I'm pretty sure none of you are having the same issue as the original one reported here. Compare @abuchin 's error message of `KeyError: 'dict'` to the original poster's error of `OSError: Can't read data`. The thing you're seeing is a new one stemming from an update to anndata. You're trying to read in a `h5ad` file created with a newer version of the package with your older one. I think the cutoff point is 0.8.0 but I could be mistaken. Upgrade your anndata and you should be ok.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:170,usability,error,error,170,I'm pretty sure none of you are having the same issue as the original one reported here. Compare @abuchin 's error message of `KeyError: 'dict'` to the original poster's error of `OSError: Can't read data`. The thing you're seeing is a new one stemming from an update to anndata. You're trying to read in a `h5ad` file created with a newer version of the package with your older one. I think the cutoff point is 0.8.0 but I could be mistaken. Upgrade your anndata and you should be ok.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:34,deployability,Upgrad,Upgrading,34,I was facing this issue in 0.7.8. Upgrading to 0.8.0 solved the problem,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:34,modifiability,Upgrad,Upgrading,34,I was facing this issue in 0.7.8. Upgrading to 0.8.0 solved the problem,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:36,deployability,Upgrad,Upgrading,36,> I was facing this issue in 0.7.8. Upgrading to 0.8.0 solved the problem. how did you update? pip says that 0.7.8 is the latest version,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:87,deployability,updat,update,87,> I was facing this issue in 0.7.8. Upgrading to 0.8.0 solved the problem. how did you update? pip says that 0.7.8 is the latest version,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:129,deployability,version,version,129,> I was facing this issue in 0.7.8. Upgrading to 0.8.0 solved the problem. how did you update? pip says that 0.7.8 is the latest version,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:129,integrability,version,version,129,> I was facing this issue in 0.7.8. Upgrading to 0.8.0 solved the problem. how did you update? pip says that 0.7.8 is the latest version,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:36,modifiability,Upgrad,Upgrading,36,> I was facing this issue in 0.7.8. Upgrading to 0.8.0 solved the problem. how did you update? pip says that 0.7.8 is the latest version,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:129,modifiability,version,version,129,> I was facing this issue in 0.7.8. Upgrading to 0.8.0 solved the problem. how did you update? pip says that 0.7.8 is the latest version,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:87,safety,updat,update,87,> I was facing this issue in 0.7.8. Upgrading to 0.8.0 solved the problem. how did you update? pip says that 0.7.8 is the latest version,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:87,security,updat,update,87,> I was facing this issue in 0.7.8. Upgrading to 0.8.0 solved the problem. how did you update? pip says that 0.7.8 is the latest version,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:12,deployability,instal,install,12,For me `pip install anndata --upgrade` did the trick. You could also do `pip install anndata==0.8.0` if that's the specific version you want to have.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:30,deployability,upgrad,upgrade,30,For me `pip install anndata --upgrade` did the trick. You could also do `pip install anndata==0.8.0` if that's the specific version you want to have.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:77,deployability,instal,install,77,For me `pip install anndata --upgrade` did the trick. You could also do `pip install anndata==0.8.0` if that's the specific version you want to have.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:124,deployability,version,version,124,For me `pip install anndata --upgrade` did the trick. You could also do `pip install anndata==0.8.0` if that's the specific version you want to have.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:124,integrability,version,version,124,For me `pip install anndata --upgrade` did the trick. You could also do `pip install anndata==0.8.0` if that's the specific version you want to have.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:115,interoperability,specif,specific,115,For me `pip install anndata --upgrade` did the trick. You could also do `pip install anndata==0.8.0` if that's the specific version you want to have.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:30,modifiability,upgrad,upgrade,30,For me `pip install anndata --upgrade` did the trick. You could also do `pip install anndata==0.8.0` if that's the specific version you want to have.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:124,modifiability,version,version,124,For me `pip install anndata --upgrade` did the trick. You could also do `pip install anndata==0.8.0` if that's the specific version you want to have.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:120,deployability,version,version,120,Then it's probably a case of having an old python3. I loaded up an environment where I have python 3.6.9 and the newest version it saw was 0.7.8.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:54,energy efficiency,load,loaded,54,Then it's probably a case of having an old python3. I loaded up an environment where I have python 3.6.9 and the newest version it saw was 0.7.8.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:120,integrability,version,version,120,Then it's probably a case of having an old python3. I loaded up an environment where I have python 3.6.9 and the newest version it saw was 0.7.8.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:120,modifiability,version,version,120,Then it's probably a case of having an old python3. I loaded up an environment where I have python 3.6.9 and the newest version it saw was 0.7.8.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:54,performance,load,loaded,54,Then it's probably a case of having an old python3. I loaded up an environment where I have python 3.6.9 and the newest version it saw was 0.7.8.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:4,deployability,instal,install,4,pip install anndata --upgrade works. The issue occurs when you saved anndata from a new version and when you try to load with old version.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:22,deployability,upgrad,upgrade,22,pip install anndata --upgrade works. The issue occurs when you saved anndata from a new version and when you try to load with old version.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:88,deployability,version,version,88,pip install anndata --upgrade works. The issue occurs when you saved anndata from a new version and when you try to load with old version.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:130,deployability,version,version,130,pip install anndata --upgrade works. The issue occurs when you saved anndata from a new version and when you try to load with old version.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:116,energy efficiency,load,load,116,pip install anndata --upgrade works. The issue occurs when you saved anndata from a new version and when you try to load with old version.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:88,integrability,version,version,88,pip install anndata --upgrade works. The issue occurs when you saved anndata from a new version and when you try to load with old version.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:130,integrability,version,version,130,pip install anndata --upgrade works. The issue occurs when you saved anndata from a new version and when you try to load with old version.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:22,modifiability,upgrad,upgrade,22,pip install anndata --upgrade works. The issue occurs when you saved anndata from a new version and when you try to load with old version.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:88,modifiability,version,version,88,pip install anndata --upgrade works. The issue occurs when you saved anndata from a new version and when you try to load with old version.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:130,modifiability,version,version,130,pip install anndata --upgrade works. The issue occurs when you saved anndata from a new version and when you try to load with old version.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:116,performance,load,load,116,pip install anndata --upgrade works. The issue occurs when you saved anndata from a new version and when you try to load with old version.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:41,deployability,instal,install,41,"I am having the same problem,however pip install anndata --upgrade didn't work for me. pip said it is already the latest version: Requirement already satisfied: anndata in d:\python3.10.9\lib\site-packages (0.9.1), then I really don't know what to do. Could you guys help me with that? [crying]",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:59,deployability,upgrad,upgrade,59,"I am having the same problem,however pip install anndata --upgrade didn't work for me. pip said it is already the latest version: Requirement already satisfied: anndata in d:\python3.10.9\lib\site-packages (0.9.1), then I really don't know what to do. Could you guys help me with that? [crying]",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:121,deployability,version,version,121,"I am having the same problem,however pip install anndata --upgrade didn't work for me. pip said it is already the latest version: Requirement already satisfied: anndata in d:\python3.10.9\lib\site-packages (0.9.1), then I really don't know what to do. Could you guys help me with that? [crying]",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:121,integrability,version,version,121,"I am having the same problem,however pip install anndata --upgrade didn't work for me. pip said it is already the latest version: Requirement already satisfied: anndata in d:\python3.10.9\lib\site-packages (0.9.1), then I really don't know what to do. Could you guys help me with that? [crying]",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:59,modifiability,upgrad,upgrade,59,"I am having the same problem,however pip install anndata --upgrade didn't work for me. pip said it is already the latest version: Requirement already satisfied: anndata in d:\python3.10.9\lib\site-packages (0.9.1), then I really don't know what to do. Could you guys help me with that? [crying]",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:121,modifiability,version,version,121,"I am having the same problem,however pip install anndata --upgrade didn't work for me. pip said it is already the latest version: Requirement already satisfied: anndata in d:\python3.10.9\lib\site-packages (0.9.1), then I really don't know what to do. Could you guys help me with that? [crying]",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:197,modifiability,pac,packages,197,"I am having the same problem,however pip install anndata --upgrade didn't work for me. pip said it is already the latest version: Requirement already satisfied: anndata in d:\python3.10.9\lib\site-packages (0.9.1), then I really don't know what to do. Could you guys help me with that? [crying]",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:267,usability,help,help,267,"I am having the same problem,however pip install anndata --upgrade didn't work for me. pip said it is already the latest version: Requirement already satisfied: anndata in d:\python3.10.9\lib\site-packages (0.9.1), then I really don't know what to do. Could you guys help me with that? [crying]",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:102,deployability,version,versions,102,"@Sunyiqing2003 we certainly dont want you crying! people here had problem reading with older anndata versions, but you seem to have the newest one, so its not the same issue. could you file a new issue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:102,integrability,version,versions,102,"@Sunyiqing2003 we certainly dont want you crying! people here had problem reading with older anndata versions, but you seem to have the newest one, so its not the same issue. could you file a new issue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:102,modifiability,version,versions,102,"@Sunyiqing2003 we certainly dont want you crying! people here had problem reading with older anndata versions, but you seem to have the newest one, so its not the same issue. could you file a new issue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:472,availability,error,error,472,"> @Sunyiqing2003 we certainly dont want you crying! > . > people here had problem reading with older anndata versions, but you seem to have the newest one, so its not the same issue. could you file a new issue? Thank you for your time and attention , I really appreciate it. I have filed a new issue : [https://github.com/scverse/scanpy/issues/2551](url). I might know the reason why updating anndata didn't work. the main reason for me seems to be big array and memory error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:110,deployability,version,versions,110,"> @Sunyiqing2003 we certainly dont want you crying! > . > people here had problem reading with older anndata versions, but you seem to have the newest one, so its not the same issue. could you file a new issue? Thank you for your time and attention , I really appreciate it. I have filed a new issue : [https://github.com/scverse/scanpy/issues/2551](url). I might know the reason why updating anndata didn't work. the main reason for me seems to be big array and memory error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:386,deployability,updat,updating,386,"> @Sunyiqing2003 we certainly dont want you crying! > . > people here had problem reading with older anndata versions, but you seem to have the newest one, so its not the same issue. could you file a new issue? Thank you for your time and attention , I really appreciate it. I have filed a new issue : [https://github.com/scverse/scanpy/issues/2551](url). I might know the reason why updating anndata didn't work. the main reason for me seems to be big array and memory error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:110,integrability,version,versions,110,"> @Sunyiqing2003 we certainly dont want you crying! > . > people here had problem reading with older anndata versions, but you seem to have the newest one, so its not the same issue. could you file a new issue? Thank you for your time and attention , I really appreciate it. I have filed a new issue : [https://github.com/scverse/scanpy/issues/2551](url). I might know the reason why updating anndata didn't work. the main reason for me seems to be big array and memory error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:110,modifiability,version,versions,110,"> @Sunyiqing2003 we certainly dont want you crying! > . > people here had problem reading with older anndata versions, but you seem to have the newest one, so its not the same issue. could you file a new issue? Thank you for your time and attention , I really appreciate it. I have filed a new issue : [https://github.com/scverse/scanpy/issues/2551](url). I might know the reason why updating anndata didn't work. the main reason for me seems to be big array and memory error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:232,performance,time,time,232,"> @Sunyiqing2003 we certainly dont want you crying! > . > people here had problem reading with older anndata versions, but you seem to have the newest one, so its not the same issue. could you file a new issue? Thank you for your time and attention , I really appreciate it. I have filed a new issue : [https://github.com/scverse/scanpy/issues/2551](url). I might know the reason why updating anndata didn't work. the main reason for me seems to be big array and memory error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:465,performance,memor,memory,465,"> @Sunyiqing2003 we certainly dont want you crying! > . > people here had problem reading with older anndata versions, but you seem to have the newest one, so its not the same issue. could you file a new issue? Thank you for your time and attention , I really appreciate it. I have filed a new issue : [https://github.com/scverse/scanpy/issues/2551](url). I might know the reason why updating anndata didn't work. the main reason for me seems to be big array and memory error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:472,performance,error,error,472,"> @Sunyiqing2003 we certainly dont want you crying! > . > people here had problem reading with older anndata versions, but you seem to have the newest one, so its not the same issue. could you file a new issue? Thank you for your time and attention , I really appreciate it. I have filed a new issue : [https://github.com/scverse/scanpy/issues/2551](url). I might know the reason why updating anndata didn't work. the main reason for me seems to be big array and memory error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:386,safety,updat,updating,386,"> @Sunyiqing2003 we certainly dont want you crying! > . > people here had problem reading with older anndata versions, but you seem to have the newest one, so its not the same issue. could you file a new issue? Thank you for your time and attention , I really appreciate it. I have filed a new issue : [https://github.com/scverse/scanpy/issues/2551](url). I might know the reason why updating anndata didn't work. the main reason for me seems to be big array and memory error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:472,safety,error,error,472,"> @Sunyiqing2003 we certainly dont want you crying! > . > people here had problem reading with older anndata versions, but you seem to have the newest one, so its not the same issue. could you file a new issue? Thank you for your time and attention , I really appreciate it. I have filed a new issue : [https://github.com/scverse/scanpy/issues/2551](url). I might know the reason why updating anndata didn't work. the main reason for me seems to be big array and memory error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:386,security,updat,updating,386,"> @Sunyiqing2003 we certainly dont want you crying! > . > people here had problem reading with older anndata versions, but you seem to have the newest one, so its not the same issue. could you file a new issue? Thank you for your time and attention , I really appreciate it. I have filed a new issue : [https://github.com/scverse/scanpy/issues/2551](url). I might know the reason why updating anndata didn't work. the main reason for me seems to be big array and memory error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:465,usability,memor,memory,465,"> @Sunyiqing2003 we certainly dont want you crying! > . > people here had problem reading with older anndata versions, but you seem to have the newest one, so its not the same issue. could you file a new issue? Thank you for your time and attention , I really appreciate it. I have filed a new issue : [https://github.com/scverse/scanpy/issues/2551](url). I might know the reason why updating anndata didn't work. the main reason for me seems to be big array and memory error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:472,usability,error,error,472,"> @Sunyiqing2003 we certainly dont want you crying! > . > people here had problem reading with older anndata versions, but you seem to have the newest one, so its not the same issue. could you file a new issue? Thank you for your time and attention , I really appreciate it. I have filed a new issue : [https://github.com/scverse/scanpy/issues/2551](url). I might know the reason why updating anndata didn't work. the main reason for me seems to be big array and memory error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1352:48,modifiability,paramet,parameters,48,"Hi @CadenZhao,. Check out the `vmax` and `vmin` parameters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1352
https://github.com/scverse/scanpy/issues/1353:505,deployability,api,api,505,"You can set fonts directly through Matplotlib. For example, using serif fonts:. ```python. import scanpy as sc. from matplotlib import pyplot as plt. pbmc = sc.datasets.pbmc3k_processed(). with plt.rc_context({""font.family"": ""serif""}):. sc.pl.umap(pbmc, color=""louvain""). ```. ![serif](https://user-images.githubusercontent.com/8238804/89146953-a8aee180-d598-11ea-8b01-9e9f867517fe.png). There's more details about this scattered throughout the matplotlib docs, [like here](https://matplotlib.org/gallery/api/font_family_rc_sgskip.html)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1353
https://github.com/scverse/scanpy/issues/1353:505,integrability,api,api,505,"You can set fonts directly through Matplotlib. For example, using serif fonts:. ```python. import scanpy as sc. from matplotlib import pyplot as plt. pbmc = sc.datasets.pbmc3k_processed(). with plt.rc_context({""font.family"": ""serif""}):. sc.pl.umap(pbmc, color=""louvain""). ```. ![serif](https://user-images.githubusercontent.com/8238804/89146953-a8aee180-d598-11ea-8b01-9e9f867517fe.png). There's more details about this scattered throughout the matplotlib docs, [like here](https://matplotlib.org/gallery/api/font_family_rc_sgskip.html)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1353
https://github.com/scverse/scanpy/issues/1353:505,interoperability,api,api,505,"You can set fonts directly through Matplotlib. For example, using serif fonts:. ```python. import scanpy as sc. from matplotlib import pyplot as plt. pbmc = sc.datasets.pbmc3k_processed(). with plt.rc_context({""font.family"": ""serif""}):. sc.pl.umap(pbmc, color=""louvain""). ```. ![serif](https://user-images.githubusercontent.com/8238804/89146953-a8aee180-d598-11ea-8b01-9e9f867517fe.png). There's more details about this scattered throughout the matplotlib docs, [like here](https://matplotlib.org/gallery/api/font_family_rc_sgskip.html)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1353
https://github.com/scverse/scanpy/issues/1353:294,usability,user,user-images,294,"You can set fonts directly through Matplotlib. For example, using serif fonts:. ```python. import scanpy as sc. from matplotlib import pyplot as plt. pbmc = sc.datasets.pbmc3k_processed(). with plt.rc_context({""font.family"": ""serif""}):. sc.pl.umap(pbmc, color=""louvain""). ```. ![serif](https://user-images.githubusercontent.com/8238804/89146953-a8aee180-d598-11ea-8b01-9e9f867517fe.png). There's more details about this scattered throughout the matplotlib docs, [like here](https://matplotlib.org/gallery/api/font_family_rc_sgskip.html)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1353
https://github.com/scverse/scanpy/issues/1355:390,reliability,doe,does,390,"Thanks for all the great bug reports! This is really useful! The way that we assign colors to each obs is basically:. ```. values = adata.obs[categorical_column]. color_vector = np.asarray(adata.uns[color_key])[values.codes]. ```. When there is a missing value in a categorical array, the code for that value is `-1` (which is why the color of the last category is being assigned). [Pandas does not allow you to make `NA` a category](https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html#missing-data), so `NA` will always have a code of `-1`. I think handling of this could take some consideration. I'm not sure we can safely set a default color for missing categorical values since that color (or one that looks very similar) could already be used. That said, it could be much more complex to allow passing a color for missing values. It might be worth looking into how other plotting libraries deal with missing categorical values and color. . Right now we have a related concept with the `groups` argument. Any samples not in the passed groups will just be colored light gray. This could probably also handle missing values if we want to go with that. I've started an implementation of this in #1356.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1355
https://github.com/scverse/scanpy/issues/1355:639,safety,safe,safely,639,"Thanks for all the great bug reports! This is really useful! The way that we assign colors to each obs is basically:. ```. values = adata.obs[categorical_column]. color_vector = np.asarray(adata.uns[color_key])[values.codes]. ```. When there is a missing value in a categorical array, the code for that value is `-1` (which is why the color of the last category is being assigned). [Pandas does not allow you to make `NA` a category](https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html#missing-data), so `NA` will always have a code of `-1`. I think handling of this could take some consideration. I'm not sure we can safely set a default color for missing categorical values since that color (or one that looks very similar) could already be used. That said, it could be much more complex to allow passing a color for missing values. It might be worth looking into how other plotting libraries deal with missing categorical values and color. . Right now we have a related concept with the `groups` argument. Any samples not in the passed groups will just be colored light gray. This could probably also handle missing values if we want to go with that. I've started an implementation of this in #1356.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1355
https://github.com/scverse/scanpy/issues/1355:803,safety,compl,complex,803,"Thanks for all the great bug reports! This is really useful! The way that we assign colors to each obs is basically:. ```. values = adata.obs[categorical_column]. color_vector = np.asarray(adata.uns[color_key])[values.codes]. ```. When there is a missing value in a categorical array, the code for that value is `-1` (which is why the color of the last category is being assigned). [Pandas does not allow you to make `NA` a category](https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html#missing-data), so `NA` will always have a code of `-1`. I think handling of this could take some consideration. I'm not sure we can safely set a default color for missing categorical values since that color (or one that looks very similar) could already be used. That said, it could be much more complex to allow passing a color for missing values. It might be worth looking into how other plotting libraries deal with missing categorical values and color. . Right now we have a related concept with the `groups` argument. Any samples not in the passed groups will just be colored light gray. This could probably also handle missing values if we want to go with that. I've started an implementation of this in #1356.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1355
https://github.com/scverse/scanpy/issues/1355:803,security,compl,complex,803,"Thanks for all the great bug reports! This is really useful! The way that we assign colors to each obs is basically:. ```. values = adata.obs[categorical_column]. color_vector = np.asarray(adata.uns[color_key])[values.codes]. ```. When there is a missing value in a categorical array, the code for that value is `-1` (which is why the color of the last category is being assigned). [Pandas does not allow you to make `NA` a category](https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html#missing-data), so `NA` will always have a code of `-1`. I think handling of this could take some consideration. I'm not sure we can safely set a default color for missing categorical values since that color (or one that looks very similar) could already be used. That said, it could be much more complex to allow passing a color for missing values. It might be worth looking into how other plotting libraries deal with missing categorical values and color. . Right now we have a related concept with the `groups` argument. Any samples not in the passed groups will just be colored light gray. This could probably also handle missing values if we want to go with that. I've started an implementation of this in #1356.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1355
https://github.com/scverse/scanpy/issues/1355:101,safety,safe,safer,101,"I think Seaborn would typically use `.dropna()` to just omit values that are `NA`, no? That would be safer than assigning a colour.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1355
https://github.com/scverse/scanpy/issues/1355:78,availability,cluster,cluster,78,I think it is important to see nan values (in my case above the whole pink NA cluster would not be seen if I had not changed np.nan to string 'NA'). Some plotting libraries (e.g. ComplexHeatmap in R) have a special parameter for missing values with some default.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1355
https://github.com/scverse/scanpy/issues/1355:78,deployability,cluster,cluster,78,I think it is important to see nan values (in my case above the whole pink NA cluster would not be seen if I had not changed np.nan to string 'NA'). Some plotting libraries (e.g. ComplexHeatmap in R) have a special parameter for missing values with some default.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1355
https://github.com/scverse/scanpy/issues/1355:215,modifiability,paramet,parameter,215,I think it is important to see nan values (in my case above the whole pink NA cluster would not be seen if I had not changed np.nan to string 'NA'). Some plotting libraries (e.g. ComplexHeatmap in R) have a special parameter for missing values with some default.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1355
https://github.com/scverse/scanpy/issues/1355:179,safety,Compl,ComplexHeatmap,179,I think it is important to see nan values (in my case above the whole pink NA cluster would not be seen if I had not changed np.nan to string 'NA'). Some plotting libraries (e.g. ComplexHeatmap in R) have a special parameter for missing values with some default.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1355
https://github.com/scverse/scanpy/issues/1355:179,security,Compl,ComplexHeatmap,179,I think it is important to see nan values (in my case above the whole pink NA cluster would not be seen if I had not changed np.nan to string 'NA'). Some plotting libraries (e.g. ComplexHeatmap in R) have a special parameter for missing values with some default.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1355
https://github.com/scverse/scanpy/issues/1355:47,modifiability,paramet,parameter,47,"I believe datashader uses a `clipping_colors ` parameter for this. Altair seems to add a category for null values, but this might not always be the case. Pandas [mostly drops nulls](https://pandas.pydata.org/docs/user_guide/visualization.html#plotting-with-missing-data).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1355
https://github.com/scverse/scanpy/issues/1355:224,usability,visual,visualization,224,"I believe datashader uses a `clipping_colors ` parameter for this. Altair seems to add a category for null values, but this might not always be the case. Pandas [mostly drops nulls](https://pandas.pydata.org/docs/user_guide/visualization.html#plotting-with-missing-data).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1355
https://github.com/scverse/scanpy/issues/1355:19,availability,down,down,19,"I guess this comes down to what you interpret an `NA` value as. If I want to show another category, I give it a name and it's shown. Doing this is very easy. If I don't assign a category to a group of observations, I would interpret this as this group of observations not being relevant in the context.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1355
https://github.com/scverse/scanpy/issues/1355:201,deployability,observ,observations,201,"I guess this comes down to what you interpret an `NA` value as. If I want to show another category, I give it a name and it's shown. Doing this is very easy. If I don't assign a category to a group of observations, I would interpret this as this group of observations not being relevant in the context.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1355
https://github.com/scverse/scanpy/issues/1355:255,deployability,observ,observations,255,"I guess this comes down to what you interpret an `NA` value as. If I want to show another category, I give it a name and it's shown. Doing this is very easy. If I don't assign a category to a group of observations, I would interpret this as this group of observations not being relevant in the context.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1355
https://github.com/scverse/scanpy/issues/1355:201,testability,observ,observations,201,"I guess this comes down to what you interpret an `NA` value as. If I want to show another category, I give it a name and it's shown. Doing this is very easy. If I don't assign a category to a group of observations, I would interpret this as this group of observations not being relevant in the context.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1355
https://github.com/scverse/scanpy/issues/1355:255,testability,observ,observations,255,"I guess this comes down to what you interpret an `NA` value as. If I want to show another category, I give it a name and it's shown. Doing this is very easy. If I don't assign a category to a group of observations, I would interpret this as this group of observations not being relevant in the context.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1355
https://github.com/scverse/scanpy/issues/1355:294,testability,context,context,294,"I guess this comes down to what you interpret an `NA` value as. If I want to show another category, I give it a name and it's shown. Doing this is very easy. If I don't assign a category to a group of observations, I would interpret this as this group of observations not being relevant in the context.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1355
https://github.com/scverse/scanpy/issues/1355:210,performance,time,time,210,"I think the result of a missing value should be very visible, whether through a warning or something in the plot. This comes from me thinking that I'd probably not intentionally have missing values most of the time, and really wouldn't want to miss that. I generally go for having the points be light gray in the background when they aren't relevant.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1355
https://github.com/scverse/scanpy/issues/1355:136,deployability,continu,continuous,136,Then I guess light grays would need to be removed from the default colour maps? And the question remains for how to deal with this in a continuous covariate.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1355
https://github.com/scverse/scanpy/issues/1355:109,deployability,api,api,109,"Matplotlibs color maps should be able to handle things, through [`ColorMap.set_bad`](https://matplotlib.org/api/_as_gen/matplotlib.colors.Colormap.html?highlight=set_bad#matplotlib.colors.Colormap.set_bad). We can do. ```py. from copy import copy. def ...(...):. 	... 	color_map = copy(color_map). color_map.set_bad('lightgray'). 	... ax.scatter(..., cmap=color_map, plotnonfinite=True). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1355
https://github.com/scverse/scanpy/issues/1355:109,integrability,api,api,109,"Matplotlibs color maps should be able to handle things, through [`ColorMap.set_bad`](https://matplotlib.org/api/_as_gen/matplotlib.colors.Colormap.html?highlight=set_bad#matplotlib.colors.Colormap.set_bad). We can do. ```py. from copy import copy. def ...(...):. 	... 	color_map = copy(color_map). color_map.set_bad('lightgray'). 	... ax.scatter(..., cmap=color_map, plotnonfinite=True). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1355
https://github.com/scverse/scanpy/issues/1355:109,interoperability,api,api,109,"Matplotlibs color maps should be able to handle things, through [`ColorMap.set_bad`](https://matplotlib.org/api/_as_gen/matplotlib.colors.Colormap.html?highlight=set_bad#matplotlib.colors.Colormap.set_bad). We can do. ```py. from copy import copy. def ...(...):. 	... 	color_map = copy(color_map). color_map.set_bad('lightgray'). 	... ax.scatter(..., cmap=color_map, plotnonfinite=True). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1355
https://github.com/scverse/scanpy/issues/1355:192,deployability,continu,continuous,192,"Currently matplotlibs colors maps are dealing with things, it's just their default ""bad color"" is often transparent. We currently don't do any handling of color maps, which makes dealing with continuous values a little more complicated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1355
https://github.com/scverse/scanpy/issues/1355:0,energy efficiency,Current,Currently,0,"Currently matplotlibs colors maps are dealing with things, it's just their default ""bad color"" is often transparent. We currently don't do any handling of color maps, which makes dealing with continuous values a little more complicated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1355
https://github.com/scverse/scanpy/issues/1355:120,energy efficiency,current,currently,120,"Currently matplotlibs colors maps are dealing with things, it's just their default ""bad color"" is often transparent. We currently don't do any handling of color maps, which makes dealing with continuous values a little more complicated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1355
https://github.com/scverse/scanpy/issues/1355:224,safety,compl,complicated,224,"Currently matplotlibs colors maps are dealing with things, it's just their default ""bad color"" is often transparent. We currently don't do any handling of color maps, which makes dealing with continuous values a little more complicated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1355
https://github.com/scverse/scanpy/issues/1355:224,security,compl,complicated,224,"Currently matplotlibs colors maps are dealing with things, it's just their default ""bad color"" is often transparent. We currently don't do any handling of color maps, which makes dealing with continuous values a little more complicated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1355
https://github.com/scverse/scanpy/pull/1356:47,availability,mask,masked,47,"I've managed to fix this up a bit. Missing (or masked - for `groups`) values in categorical arrays are now always plotted on bottom and use a default color. For spatial plots this default color is transparent. This has led to some code simplification. Surprisingly, this didn't break any tests locally, so a bunch of new tests are probably needed. Continuous values are still a little weird. Right now the points don't show up on embedding plots, and mess up all the colors for spatial plots.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:5,deployability,manag,managed,5,"I've managed to fix this up a bit. Missing (or masked - for `groups`) values in categorical arrays are now always plotted on bottom and use a default color. For spatial plots this default color is transparent. This has led to some code simplification. Surprisingly, this didn't break any tests locally, so a bunch of new tests are probably needed. Continuous values are still a little weird. Right now the points don't show up on embedding plots, and mess up all the colors for spatial plots.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:348,deployability,Continu,Continuous,348,"I've managed to fix this up a bit. Missing (or masked - for `groups`) values in categorical arrays are now always plotted on bottom and use a default color. For spatial plots this default color is transparent. This has led to some code simplification. Surprisingly, this didn't break any tests locally, so a bunch of new tests are probably needed. Continuous values are still a little weird. Right now the points don't show up on embedding plots, and mess up all the colors for spatial plots.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:5,energy efficiency,manag,managed,5,"I've managed to fix this up a bit. Missing (or masked - for `groups`) values in categorical arrays are now always plotted on bottom and use a default color. For spatial plots this default color is transparent. This has led to some code simplification. Surprisingly, this didn't break any tests locally, so a bunch of new tests are probably needed. Continuous values are still a little weird. Right now the points don't show up on embedding plots, and mess up all the colors for spatial plots.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:5,safety,manag,managed,5,"I've managed to fix this up a bit. Missing (or masked - for `groups`) values in categorical arrays are now always plotted on bottom and use a default color. For spatial plots this default color is transparent. This has led to some code simplification. Surprisingly, this didn't break any tests locally, so a bunch of new tests are probably needed. Continuous values are still a little weird. Right now the points don't show up on embedding plots, and mess up all the colors for spatial plots.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:288,safety,test,tests,288,"I've managed to fix this up a bit. Missing (or masked - for `groups`) values in categorical arrays are now always plotted on bottom and use a default color. For spatial plots this default color is transparent. This has led to some code simplification. Surprisingly, this didn't break any tests locally, so a bunch of new tests are probably needed. Continuous values are still a little weird. Right now the points don't show up on embedding plots, and mess up all the colors for spatial plots.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:321,safety,test,tests,321,"I've managed to fix this up a bit. Missing (or masked - for `groups`) values in categorical arrays are now always plotted on bottom and use a default color. For spatial plots this default color is transparent. This has led to some code simplification. Surprisingly, this didn't break any tests locally, so a bunch of new tests are probably needed. Continuous values are still a little weird. Right now the points don't show up on embedding plots, and mess up all the colors for spatial plots.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:236,testability,simpl,simplification,236,"I've managed to fix this up a bit. Missing (or masked - for `groups`) values in categorical arrays are now always plotted on bottom and use a default color. For spatial plots this default color is transparent. This has led to some code simplification. Surprisingly, this didn't break any tests locally, so a bunch of new tests are probably needed. Continuous values are still a little weird. Right now the points don't show up on embedding plots, and mess up all the colors for spatial plots.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:288,testability,test,tests,288,"I've managed to fix this up a bit. Missing (or masked - for `groups`) values in categorical arrays are now always plotted on bottom and use a default color. For spatial plots this default color is transparent. This has led to some code simplification. Surprisingly, this didn't break any tests locally, so a bunch of new tests are probably needed. Continuous values are still a little weird. Right now the points don't show up on embedding plots, and mess up all the colors for spatial plots.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:321,testability,test,tests,321,"I've managed to fix this up a bit. Missing (or masked - for `groups`) values in categorical arrays are now always plotted on bottom and use a default color. For spatial plots this default color is transparent. This has led to some code simplification. Surprisingly, this didn't break any tests locally, so a bunch of new tests are probably needed. Continuous values are still a little weird. Right now the points don't show up on embedding plots, and mess up all the colors for spatial plots.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:236,usability,simpl,simplification,236,"I've managed to fix this up a bit. Missing (or masked - for `groups`) values in categorical arrays are now always plotted on bottom and use a default color. For spatial plots this default color is transparent. This has led to some code simplification. Surprisingly, this didn't break any tests locally, so a bunch of new tests are probably needed. Continuous values are still a little weird. Right now the points don't show up on embedding plots, and mess up all the colors for spatial plots.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:2798,deployability,Continu,Continuous,2798,"0-e169-11ea-86f9-597bb1d5da01.png). ### Master. ![output_6_0](https://user-images.githubusercontent.com/8238804/90475475-da17d780-e16a-11ea-9ae9-6fb61fd6357b.png). </details>. <details>. <summary> Embedding </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""leiden"", ""leiden_missing""]). ```. ### Current. ![output_8_0](https://user-images.githubusercontent.com/8238804/90474984-ec454600-e169-11ea-935c-cb094f520a1a.png). ### Master. ![output_8_0](https://user-images.githubusercontent.com/8238804/90475481-de43f500-e16a-11ea-80da-2636b1b6dddf.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""leiden"", ""leiden_missing""], groups=[""0"", ""1""]). ```. ### Current. ![output_9_0](https://user-images.githubusercontent.com/8238804/90475011-fb2bf880-e169-11ea-90a6-17e13388672e.png). ### Master. ![output_9_0](https://user-images.githubusercontent.com/8238804/90475498-e69c3000-e16a-11ea-876c-747ec02fae6d.png). </details>. ## Continuous values. <details>. <summary> Spatial </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""Bc1"", ""Bc1_missing""]). ```. ### Current. ![output_12_0](https://user-images.githubusercontent.com/8238804/90475149-4219ee00-e16a-11ea-9b42-aea86a8883a4.png). ### Master. ![output_12_0](https://user-images.githubusercontent.com/8238804/90475522-eef46b00-e16a-11ea-8d88-4ede97e16252.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""Bc1"", ""Bc1_missing""], vmin=""p10"", vmax=""p90""). ```. ### Current. ![output_13_0](https://user-images.githubusercontent.com/8238804/90475174-5100a080-e16a-11ea-91ae-d3c883829b9a.png). ### Master. ![output_13_0](https://user-images.githubusercontent.com/8238804/90475536-f3b91f00-e16a-11ea-8ceb-fc954a9601e6.png). </details>. <details>. <summary> Embedding </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""Bc1"", ""Bc1_missing""]). ```. ### Current. ![out",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:473,energy efficiency,current,currently,473,"I think I've got this mostly working. Here are some comparisons between plots on master and this branch. This will show the major cases I've caught and was thinking about. In each of the cases where there has been a significant change, I'd say the previous behavior seemed like a bug. A few open questions:. * Are these reasonable defaults for null values? * Are there cases I've missed? * How should users be able to interact with this/ choose the color for null values? (currently, this is a private parameter which would override the ""bad value"" for a passed colormap). @Hrovatin @LuckyMD @fidelram @giovp @flying-sheep . # Setup. ```python. import scanpy as sc, matplotlib.pyplot as plt, numpy as np, pandas as pd. ```. ```python. # Setup. brain = sc.read(""./tmp_brain.h5ad"") # just an example visium dataset with some preprocessing. sc.tl.umap(brain). # Add some points with misssing values. brain.obs[""leiden_missing""] = brain.obs[""leiden""].copy(). brain.obs[""leiden_missing""].iloc[::2] = np.nan. brain.obs[""Bc1_missing""] = brain.obs_vector(""Bc1"").copy(). brain.obs[""Bc1_missing""].iloc[::3] = np.nan. ```. ## Null values in categoricals. <details>. <summary> Spatial </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden"", ""leiden_missing""]). ```. ### Current (this branch):. ![output_5_0](https://user-images.githubusercontent.com/8238804/90474913-c029c500-e169-11ea-8b06-2a3eaa8f994c.png). ### Master. ![output_5_0](https://user-images.githubusercontent.com/8238804/90475410-be143600-e16a-11ea-86f2-7e631e73cd8f.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden"", ""leiden_missing""], groups=[""0"", ""1""]). ```. ### Current. ![output_6_0](https://user-images.githubusercontent.com/8238804/90474940-d0da3b00-e169-11ea-86f9-597bb1d5da01.png). ### Master. ![output_6_0](https://user-images.githubusercontent.com/8238804/90475475-da17d780-e16a-11ea-9ae9-6fb61fd6357b.png). </details>. <details>. <summary> ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:1306,energy efficiency,Current,Current,1306,"Are these reasonable defaults for null values? * Are there cases I've missed? * How should users be able to interact with this/ choose the color for null values? (currently, this is a private parameter which would override the ""bad value"" for a passed colormap). @Hrovatin @LuckyMD @fidelram @giovp @flying-sheep . # Setup. ```python. import scanpy as sc, matplotlib.pyplot as plt, numpy as np, pandas as pd. ```. ```python. # Setup. brain = sc.read(""./tmp_brain.h5ad"") # just an example visium dataset with some preprocessing. sc.tl.umap(brain). # Add some points with misssing values. brain.obs[""leiden_missing""] = brain.obs[""leiden""].copy(). brain.obs[""leiden_missing""].iloc[::2] = np.nan. brain.obs[""Bc1_missing""] = brain.obs_vector(""Bc1"").copy(). brain.obs[""Bc1_missing""].iloc[::3] = np.nan. ```. ## Null values in categoricals. <details>. <summary> Spatial </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden"", ""leiden_missing""]). ```. ### Current (this branch):. ![output_5_0](https://user-images.githubusercontent.com/8238804/90474913-c029c500-e169-11ea-8b06-2a3eaa8f994c.png). ### Master. ![output_5_0](https://user-images.githubusercontent.com/8238804/90475410-be143600-e16a-11ea-86f2-7e631e73cd8f.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden"", ""leiden_missing""], groups=[""0"", ""1""]). ```. ### Current. ![output_6_0](https://user-images.githubusercontent.com/8238804/90474940-d0da3b00-e169-11ea-86f9-597bb1d5da01.png). ### Master. ![output_6_0](https://user-images.githubusercontent.com/8238804/90475475-da17d780-e16a-11ea-9ae9-6fb61fd6357b.png). </details>. <details>. <summary> Embedding </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""leiden"", ""leiden_missing""]). ```. ### Current. ![output_8_0](https://user-images.githubusercontent.com/8238804/90474984-ec454600-e169-11ea-935c-cb094f520a1a.png). ### Master. ![output_8_0](https://user-images",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:1714,energy efficiency,Current,Current,1714," ```. ```python. # Setup. brain = sc.read(""./tmp_brain.h5ad"") # just an example visium dataset with some preprocessing. sc.tl.umap(brain). # Add some points with misssing values. brain.obs[""leiden_missing""] = brain.obs[""leiden""].copy(). brain.obs[""leiden_missing""].iloc[::2] = np.nan. brain.obs[""Bc1_missing""] = brain.obs_vector(""Bc1"").copy(). brain.obs[""Bc1_missing""].iloc[::3] = np.nan. ```. ## Null values in categoricals. <details>. <summary> Spatial </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden"", ""leiden_missing""]). ```. ### Current (this branch):. ![output_5_0](https://user-images.githubusercontent.com/8238804/90474913-c029c500-e169-11ea-8b06-2a3eaa8f994c.png). ### Master. ![output_5_0](https://user-images.githubusercontent.com/8238804/90475410-be143600-e16a-11ea-86f2-7e631e73cd8f.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden"", ""leiden_missing""], groups=[""0"", ""1""]). ```. ### Current. ![output_6_0](https://user-images.githubusercontent.com/8238804/90474940-d0da3b00-e169-11ea-86f9-597bb1d5da01.png). ### Master. ![output_6_0](https://user-images.githubusercontent.com/8238804/90475475-da17d780-e16a-11ea-9ae9-6fb61fd6357b.png). </details>. <details>. <summary> Embedding </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""leiden"", ""leiden_missing""]). ```. ### Current. ![output_8_0](https://user-images.githubusercontent.com/8238804/90474984-ec454600-e169-11ea-935c-cb094f520a1a.png). ### Master. ![output_8_0](https://user-images.githubusercontent.com/8238804/90475481-de43f500-e16a-11ea-80da-2636b1b6dddf.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""leiden"", ""leiden_missing""], groups=[""0"", ""1""]). ```. ### Current. ![output_9_0](https://user-images.githubusercontent.com/8238804/90475011-fb2bf880-e169-11ea-90a6-17e13388672e.png). ### Master. ![output_9_0](https://user-images.githubusercontent",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:2140,energy efficiency,Current,Current,2140,"<details>. <summary> Spatial </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden"", ""leiden_missing""]). ```. ### Current (this branch):. ![output_5_0](https://user-images.githubusercontent.com/8238804/90474913-c029c500-e169-11ea-8b06-2a3eaa8f994c.png). ### Master. ![output_5_0](https://user-images.githubusercontent.com/8238804/90475410-be143600-e16a-11ea-86f2-7e631e73cd8f.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden"", ""leiden_missing""], groups=[""0"", ""1""]). ```. ### Current. ![output_6_0](https://user-images.githubusercontent.com/8238804/90474940-d0da3b00-e169-11ea-86f9-597bb1d5da01.png). ### Master. ![output_6_0](https://user-images.githubusercontent.com/8238804/90475475-da17d780-e16a-11ea-9ae9-6fb61fd6357b.png). </details>. <details>. <summary> Embedding </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""leiden"", ""leiden_missing""]). ```. ### Current. ![output_8_0](https://user-images.githubusercontent.com/8238804/90474984-ec454600-e169-11ea-935c-cb094f520a1a.png). ### Master. ![output_8_0](https://user-images.githubusercontent.com/8238804/90475481-de43f500-e16a-11ea-80da-2636b1b6dddf.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""leiden"", ""leiden_missing""], groups=[""0"", ""1""]). ```. ### Current. ![output_9_0](https://user-images.githubusercontent.com/8238804/90475011-fb2bf880-e169-11ea-90a6-17e13388672e.png). ### Master. ![output_9_0](https://user-images.githubusercontent.com/8238804/90475498-e69c3000-e16a-11ea-876c-747ec02fae6d.png). </details>. ## Continuous values. <details>. <summary> Spatial </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""Bc1"", ""Bc1_missing""]). ```. ### Current. ![output_12_0](https://user-images.githubusercontent.com/8238804/90475149-4219ee00-e16a-11ea-9b42-aea86a8883a4.png). ### Master. ![output_12_0](https://user-image",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:2530,energy efficiency,Current,Current,2530,"43600-e16a-11ea-86f2-7e631e73cd8f.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden"", ""leiden_missing""], groups=[""0"", ""1""]). ```. ### Current. ![output_6_0](https://user-images.githubusercontent.com/8238804/90474940-d0da3b00-e169-11ea-86f9-597bb1d5da01.png). ### Master. ![output_6_0](https://user-images.githubusercontent.com/8238804/90475475-da17d780-e16a-11ea-9ae9-6fb61fd6357b.png). </details>. <details>. <summary> Embedding </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""leiden"", ""leiden_missing""]). ```. ### Current. ![output_8_0](https://user-images.githubusercontent.com/8238804/90474984-ec454600-e169-11ea-935c-cb094f520a1a.png). ### Master. ![output_8_0](https://user-images.githubusercontent.com/8238804/90475481-de43f500-e16a-11ea-80da-2636b1b6dddf.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""leiden"", ""leiden_missing""], groups=[""0"", ""1""]). ```. ### Current. ![output_9_0](https://user-images.githubusercontent.com/8238804/90475011-fb2bf880-e169-11ea-90a6-17e13388672e.png). ### Master. ![output_9_0](https://user-images.githubusercontent.com/8238804/90475498-e69c3000-e16a-11ea-876c-747ec02fae6d.png). </details>. ## Continuous values. <details>. <summary> Spatial </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""Bc1"", ""Bc1_missing""]). ```. ### Current. ![output_12_0](https://user-images.githubusercontent.com/8238804/90475149-4219ee00-e16a-11ea-9b42-aea86a8883a4.png). ### Master. ![output_12_0](https://user-images.githubusercontent.com/8238804/90475522-eef46b00-e16a-11ea-8d88-4ede97e16252.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""Bc1"", ""Bc1_missing""], vmin=""p10"", vmax=""p90""). ```. ### Current. ![output_13_0](https://user-images.githubusercontent.com/8238804/90475174-5100a080-e16a-11ea-91ae-d3c883829b9a.png). ### Master. ![output_13_0](https://user-i",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:2973,energy efficiency,Current,Current,2973,". <details>. <summary> Embedding </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""leiden"", ""leiden_missing""]). ```. ### Current. ![output_8_0](https://user-images.githubusercontent.com/8238804/90474984-ec454600-e169-11ea-935c-cb094f520a1a.png). ### Master. ![output_8_0](https://user-images.githubusercontent.com/8238804/90475481-de43f500-e16a-11ea-80da-2636b1b6dddf.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""leiden"", ""leiden_missing""], groups=[""0"", ""1""]). ```. ### Current. ![output_9_0](https://user-images.githubusercontent.com/8238804/90475011-fb2bf880-e169-11ea-90a6-17e13388672e.png). ### Master. ![output_9_0](https://user-images.githubusercontent.com/8238804/90475498-e69c3000-e16a-11ea-876c-747ec02fae6d.png). </details>. ## Continuous values. <details>. <summary> Spatial </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""Bc1"", ""Bc1_missing""]). ```. ### Current. ![output_12_0](https://user-images.githubusercontent.com/8238804/90475149-4219ee00-e16a-11ea-9b42-aea86a8883a4.png). ### Master. ![output_12_0](https://user-images.githubusercontent.com/8238804/90475522-eef46b00-e16a-11ea-8d88-4ede97e16252.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""Bc1"", ""Bc1_missing""], vmin=""p10"", vmax=""p90""). ```. ### Current. ![output_13_0](https://user-images.githubusercontent.com/8238804/90475174-5100a080-e16a-11ea-91ae-d3c883829b9a.png). ### Master. ![output_13_0](https://user-images.githubusercontent.com/8238804/90475536-f3b91f00-e16a-11ea-8ceb-fc954a9601e6.png). </details>. <details>. <summary> Embedding </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""Bc1"", ""Bc1_missing""]). ```. ### Current. ![output_15_0](https://user-images.githubusercontent.com/8238804/90475221-6aa1e800-e16a-11ea-844a-e4e46dbdc717.png). ### Master. ![output_15_0](https://user-images.githubuserconte",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:3367,energy efficiency,Current,Current,3367,"da-2636b1b6dddf.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""leiden"", ""leiden_missing""], groups=[""0"", ""1""]). ```. ### Current. ![output_9_0](https://user-images.githubusercontent.com/8238804/90475011-fb2bf880-e169-11ea-90a6-17e13388672e.png). ### Master. ![output_9_0](https://user-images.githubusercontent.com/8238804/90475498-e69c3000-e16a-11ea-876c-747ec02fae6d.png). </details>. ## Continuous values. <details>. <summary> Spatial </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""Bc1"", ""Bc1_missing""]). ```. ### Current. ![output_12_0](https://user-images.githubusercontent.com/8238804/90475149-4219ee00-e16a-11ea-9b42-aea86a8883a4.png). ### Master. ![output_12_0](https://user-images.githubusercontent.com/8238804/90475522-eef46b00-e16a-11ea-8d88-4ede97e16252.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""Bc1"", ""Bc1_missing""], vmin=""p10"", vmax=""p90""). ```. ### Current. ![output_13_0](https://user-images.githubusercontent.com/8238804/90475174-5100a080-e16a-11ea-91ae-d3c883829b9a.png). ### Master. ![output_13_0](https://user-images.githubusercontent.com/8238804/90475536-f3b91f00-e16a-11ea-8ceb-fc954a9601e6.png). </details>. <details>. <summary> Embedding </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""Bc1"", ""Bc1_missing""]). ```. ### Current. ![output_15_0](https://user-images.githubusercontent.com/8238804/90475221-6aa1e800-e16a-11ea-844a-e4e46dbdc717.png). ### Master. ![output_15_0](https://user-images.githubusercontent.com/8238804/90475543-fa479680-e16a-11ea-8da1-93dbc1526192.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""Bc1"", ""Bc1_missing""], vmin=""p10"", vmax=""p90""). ```. ### Current. ![output_16_0](https://user-images.githubusercontent.com/8238804/90475232-6f669c00-e16a-11ea-9889-0c0986346cc0.png). ### Master. ![output_16_0](https://user-images.githubusercontent.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:3789,energy efficiency,Current,Current,3789,"sc.pl.umap(brain, color=[""leiden"", ""leiden_missing""], groups=[""0"", ""1""]). ```. ### Current. ![output_9_0](https://user-images.githubusercontent.com/8238804/90475011-fb2bf880-e169-11ea-90a6-17e13388672e.png). ### Master. ![output_9_0](https://user-images.githubusercontent.com/8238804/90475498-e69c3000-e16a-11ea-876c-747ec02fae6d.png). </details>. ## Continuous values. <details>. <summary> Spatial </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""Bc1"", ""Bc1_missing""]). ```. ### Current. ![output_12_0](https://user-images.githubusercontent.com/8238804/90475149-4219ee00-e16a-11ea-9b42-aea86a8883a4.png). ### Master. ![output_12_0](https://user-images.githubusercontent.com/8238804/90475522-eef46b00-e16a-11ea-8d88-4ede97e16252.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""Bc1"", ""Bc1_missing""], vmin=""p10"", vmax=""p90""). ```. ### Current. ![output_13_0](https://user-images.githubusercontent.com/8238804/90475174-5100a080-e16a-11ea-91ae-d3c883829b9a.png). ### Master. ![output_13_0](https://user-images.githubusercontent.com/8238804/90475536-f3b91f00-e16a-11ea-8ceb-fc954a9601e6.png). </details>. <details>. <summary> Embedding </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""Bc1"", ""Bc1_missing""]). ```. ### Current. ![output_15_0](https://user-images.githubusercontent.com/8238804/90475221-6aa1e800-e16a-11ea-844a-e4e46dbdc717.png). ### Master. ![output_15_0](https://user-images.githubusercontent.com/8238804/90475543-fa479680-e16a-11ea-8da1-93dbc1526192.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""Bc1"", ""Bc1_missing""], vmin=""p10"", vmax=""p90""). ```. ### Current. ![output_16_0](https://user-images.githubusercontent.com/8238804/90475232-6f669c00-e16a-11ea-9889-0c0986346cc0.png). ### Master. ![output_16_0](https://user-images.githubusercontent.com/8238804/90475556-003d7780-e16b-11ea-9ee6-4b59cbee8915.png). </details> .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:4180,energy efficiency,Current,Current,4180,"sc.pl.umap(brain, color=[""leiden"", ""leiden_missing""], groups=[""0"", ""1""]). ```. ### Current. ![output_9_0](https://user-images.githubusercontent.com/8238804/90475011-fb2bf880-e169-11ea-90a6-17e13388672e.png). ### Master. ![output_9_0](https://user-images.githubusercontent.com/8238804/90475498-e69c3000-e16a-11ea-876c-747ec02fae6d.png). </details>. ## Continuous values. <details>. <summary> Spatial </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""Bc1"", ""Bc1_missing""]). ```. ### Current. ![output_12_0](https://user-images.githubusercontent.com/8238804/90475149-4219ee00-e16a-11ea-9b42-aea86a8883a4.png). ### Master. ![output_12_0](https://user-images.githubusercontent.com/8238804/90475522-eef46b00-e16a-11ea-8d88-4ede97e16252.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""Bc1"", ""Bc1_missing""], vmin=""p10"", vmax=""p90""). ```. ### Current. ![output_13_0](https://user-images.githubusercontent.com/8238804/90475174-5100a080-e16a-11ea-91ae-d3c883829b9a.png). ### Master. ![output_13_0](https://user-images.githubusercontent.com/8238804/90475536-f3b91f00-e16a-11ea-8ceb-fc954a9601e6.png). </details>. <details>. <summary> Embedding </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""Bc1"", ""Bc1_missing""]). ```. ### Current. ![output_15_0](https://user-images.githubusercontent.com/8238804/90475221-6aa1e800-e16a-11ea-844a-e4e46dbdc717.png). ### Master. ![output_15_0](https://user-images.githubusercontent.com/8238804/90475543-fa479680-e16a-11ea-8da1-93dbc1526192.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""Bc1"", ""Bc1_missing""], vmin=""p10"", vmax=""p90""). ```. ### Current. ![output_16_0](https://user-images.githubusercontent.com/8238804/90475232-6f669c00-e16a-11ea-9889-0c0986346cc0.png). ### Master. ![output_16_0](https://user-images.githubusercontent.com/8238804/90475556-003d7780-e16b-11ea-9ee6-4b59cbee8915.png). </details> .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:502,modifiability,paramet,parameter,502,"I think I've got this mostly working. Here are some comparisons between plots on master and this branch. This will show the major cases I've caught and was thinking about. In each of the cases where there has been a significant change, I'd say the previous behavior seemed like a bug. A few open questions:. * Are these reasonable defaults for null values? * Are there cases I've missed? * How should users be able to interact with this/ choose the color for null values? (currently, this is a private parameter which would override the ""bad value"" for a passed colormap). @Hrovatin @LuckyMD @fidelram @giovp @flying-sheep . # Setup. ```python. import scanpy as sc, matplotlib.pyplot as plt, numpy as np, pandas as pd. ```. ```python. # Setup. brain = sc.read(""./tmp_brain.h5ad"") # just an example visium dataset with some preprocessing. sc.tl.umap(brain). # Add some points with misssing values. brain.obs[""leiden_missing""] = brain.obs[""leiden""].copy(). brain.obs[""leiden_missing""].iloc[::2] = np.nan. brain.obs[""Bc1_missing""] = brain.obs_vector(""Bc1"").copy(). brain.obs[""Bc1_missing""].iloc[::3] = np.nan. ```. ## Null values in categoricals. <details>. <summary> Spatial </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden"", ""leiden_missing""]). ```. ### Current (this branch):. ![output_5_0](https://user-images.githubusercontent.com/8238804/90474913-c029c500-e169-11ea-8b06-2a3eaa8f994c.png). ### Master. ![output_5_0](https://user-images.githubusercontent.com/8238804/90475410-be143600-e16a-11ea-86f2-7e631e73cd8f.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden"", ""leiden_missing""], groups=[""0"", ""1""]). ```. ### Current. ![output_6_0](https://user-images.githubusercontent.com/8238804/90474940-d0da3b00-e169-11ea-86f9-597bb1d5da01.png). ### Master. ![output_6_0](https://user-images.githubusercontent.com/8238804/90475475-da17d780-e16a-11ea-9ae9-6fb61fd6357b.png). </details>. <details>. <summary> ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:216,security,sign,significant,216,"I think I've got this mostly working. Here are some comparisons between plots on master and this branch. This will show the major cases I've caught and was thinking about. In each of the cases where there has been a significant change, I'd say the previous behavior seemed like a bug. A few open questions:. * Are these reasonable defaults for null values? * Are there cases I've missed? * How should users be able to interact with this/ choose the color for null values? (currently, this is a private parameter which would override the ""bad value"" for a passed colormap). @Hrovatin @LuckyMD @fidelram @giovp @flying-sheep . # Setup. ```python. import scanpy as sc, matplotlib.pyplot as plt, numpy as np, pandas as pd. ```. ```python. # Setup. brain = sc.read(""./tmp_brain.h5ad"") # just an example visium dataset with some preprocessing. sc.tl.umap(brain). # Add some points with misssing values. brain.obs[""leiden_missing""] = brain.obs[""leiden""].copy(). brain.obs[""leiden_missing""].iloc[::2] = np.nan. brain.obs[""Bc1_missing""] = brain.obs_vector(""Bc1"").copy(). brain.obs[""Bc1_missing""].iloc[::3] = np.nan. ```. ## Null values in categoricals. <details>. <summary> Spatial </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden"", ""leiden_missing""]). ```. ### Current (this branch):. ![output_5_0](https://user-images.githubusercontent.com/8238804/90474913-c029c500-e169-11ea-8b06-2a3eaa8f994c.png). ### Master. ![output_5_0](https://user-images.githubusercontent.com/8238804/90475410-be143600-e16a-11ea-86f2-7e631e73cd8f.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden"", ""leiden_missing""], groups=[""0"", ""1""]). ```. ### Current. ![output_6_0](https://user-images.githubusercontent.com/8238804/90474940-d0da3b00-e169-11ea-86f9-597bb1d5da01.png). ### Master. ![output_6_0](https://user-images.githubusercontent.com/8238804/90475475-da17d780-e16a-11ea-9ae9-6fb61fd6357b.png). </details>. <details>. <summary> ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:257,usability,behavi,behavior,257,"I think I've got this mostly working. Here are some comparisons between plots on master and this branch. This will show the major cases I've caught and was thinking about. In each of the cases where there has been a significant change, I'd say the previous behavior seemed like a bug. A few open questions:. * Are these reasonable defaults for null values? * Are there cases I've missed? * How should users be able to interact with this/ choose the color for null values? (currently, this is a private parameter which would override the ""bad value"" for a passed colormap). @Hrovatin @LuckyMD @fidelram @giovp @flying-sheep . # Setup. ```python. import scanpy as sc, matplotlib.pyplot as plt, numpy as np, pandas as pd. ```. ```python. # Setup. brain = sc.read(""./tmp_brain.h5ad"") # just an example visium dataset with some preprocessing. sc.tl.umap(brain). # Add some points with misssing values. brain.obs[""leiden_missing""] = brain.obs[""leiden""].copy(). brain.obs[""leiden_missing""].iloc[::2] = np.nan. brain.obs[""Bc1_missing""] = brain.obs_vector(""Bc1"").copy(). brain.obs[""Bc1_missing""].iloc[::3] = np.nan. ```. ## Null values in categoricals. <details>. <summary> Spatial </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden"", ""leiden_missing""]). ```. ### Current (this branch):. ![output_5_0](https://user-images.githubusercontent.com/8238804/90474913-c029c500-e169-11ea-8b06-2a3eaa8f994c.png). ### Master. ![output_5_0](https://user-images.githubusercontent.com/8238804/90475410-be143600-e16a-11ea-86f2-7e631e73cd8f.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden"", ""leiden_missing""], groups=[""0"", ""1""]). ```. ### Current. ![output_6_0](https://user-images.githubusercontent.com/8238804/90474940-d0da3b00-e169-11ea-86f9-597bb1d5da01.png). ### Master. ![output_6_0](https://user-images.githubusercontent.com/8238804/90475475-da17d780-e16a-11ea-9ae9-6fb61fd6357b.png). </details>. <details>. <summary> ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:401,usability,user,users,401,"I think I've got this mostly working. Here are some comparisons between plots on master and this branch. This will show the major cases I've caught and was thinking about. In each of the cases where there has been a significant change, I'd say the previous behavior seemed like a bug. A few open questions:. * Are these reasonable defaults for null values? * Are there cases I've missed? * How should users be able to interact with this/ choose the color for null values? (currently, this is a private parameter which would override the ""bad value"" for a passed colormap). @Hrovatin @LuckyMD @fidelram @giovp @flying-sheep . # Setup. ```python. import scanpy as sc, matplotlib.pyplot as plt, numpy as np, pandas as pd. ```. ```python. # Setup. brain = sc.read(""./tmp_brain.h5ad"") # just an example visium dataset with some preprocessing. sc.tl.umap(brain). # Add some points with misssing values. brain.obs[""leiden_missing""] = brain.obs[""leiden""].copy(). brain.obs[""leiden_missing""].iloc[::2] = np.nan. brain.obs[""Bc1_missing""] = brain.obs_vector(""Bc1"").copy(). brain.obs[""Bc1_missing""].iloc[::3] = np.nan. ```. ## Null values in categoricals. <details>. <summary> Spatial </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden"", ""leiden_missing""]). ```. ### Current (this branch):. ![output_5_0](https://user-images.githubusercontent.com/8238804/90474913-c029c500-e169-11ea-8b06-2a3eaa8f994c.png). ### Master. ![output_5_0](https://user-images.githubusercontent.com/8238804/90475410-be143600-e16a-11ea-86f2-7e631e73cd8f.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden"", ""leiden_missing""], groups=[""0"", ""1""]). ```. ### Current. ![output_6_0](https://user-images.githubusercontent.com/8238804/90474940-d0da3b00-e169-11ea-86f9-597bb1d5da01.png). ### Master. ![output_6_0](https://user-images.githubusercontent.com/8238804/90475475-da17d780-e16a-11ea-9ae9-6fb61fd6357b.png). </details>. <details>. <summary> ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:418,usability,interact,interact,418,"I think I've got this mostly working. Here are some comparisons between plots on master and this branch. This will show the major cases I've caught and was thinking about. In each of the cases where there has been a significant change, I'd say the previous behavior seemed like a bug. A few open questions:. * Are these reasonable defaults for null values? * Are there cases I've missed? * How should users be able to interact with this/ choose the color for null values? (currently, this is a private parameter which would override the ""bad value"" for a passed colormap). @Hrovatin @LuckyMD @fidelram @giovp @flying-sheep . # Setup. ```python. import scanpy as sc, matplotlib.pyplot as plt, numpy as np, pandas as pd. ```. ```python. # Setup. brain = sc.read(""./tmp_brain.h5ad"") # just an example visium dataset with some preprocessing. sc.tl.umap(brain). # Add some points with misssing values. brain.obs[""leiden_missing""] = brain.obs[""leiden""].copy(). brain.obs[""leiden_missing""].iloc[::2] = np.nan. brain.obs[""Bc1_missing""] = brain.obs_vector(""Bc1"").copy(). brain.obs[""Bc1_missing""].iloc[::3] = np.nan. ```. ## Null values in categoricals. <details>. <summary> Spatial </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden"", ""leiden_missing""]). ```. ### Current (this branch):. ![output_5_0](https://user-images.githubusercontent.com/8238804/90474913-c029c500-e169-11ea-8b06-2a3eaa8f994c.png). ### Master. ![output_5_0](https://user-images.githubusercontent.com/8238804/90475410-be143600-e16a-11ea-86f2-7e631e73cd8f.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden"", ""leiden_missing""], groups=[""0"", ""1""]). ```. ### Current. ![output_6_0](https://user-images.githubusercontent.com/8238804/90474940-d0da3b00-e169-11ea-86f9-597bb1d5da01.png). ### Master. ![output_6_0](https://user-images.githubusercontent.com/8238804/90475475-da17d780-e16a-11ea-9ae9-6fb61fd6357b.png). </details>. <details>. <summary> ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:1352,usability,user,user-images,1352," Are there cases I've missed? * How should users be able to interact with this/ choose the color for null values? (currently, this is a private parameter which would override the ""bad value"" for a passed colormap). @Hrovatin @LuckyMD @fidelram @giovp @flying-sheep . # Setup. ```python. import scanpy as sc, matplotlib.pyplot as plt, numpy as np, pandas as pd. ```. ```python. # Setup. brain = sc.read(""./tmp_brain.h5ad"") # just an example visium dataset with some preprocessing. sc.tl.umap(brain). # Add some points with misssing values. brain.obs[""leiden_missing""] = brain.obs[""leiden""].copy(). brain.obs[""leiden_missing""].iloc[::2] = np.nan. brain.obs[""Bc1_missing""] = brain.obs_vector(""Bc1"").copy(). brain.obs[""Bc1_missing""].iloc[::3] = np.nan. ```. ## Null values in categoricals. <details>. <summary> Spatial </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden"", ""leiden_missing""]). ```. ### Current (this branch):. ![output_5_0](https://user-images.githubusercontent.com/8238804/90474913-c029c500-e169-11ea-8b06-2a3eaa8f994c.png). ### Master. ![output_5_0](https://user-images.githubusercontent.com/8238804/90475410-be143600-e16a-11ea-86f2-7e631e73cd8f.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden"", ""leiden_missing""], groups=[""0"", ""1""]). ```. ### Current. ![output_6_0](https://user-images.githubusercontent.com/8238804/90474940-d0da3b00-e169-11ea-86f9-597bb1d5da01.png). ### Master. ![output_6_0](https://user-images.githubusercontent.com/8238804/90475475-da17d780-e16a-11ea-9ae9-6fb61fd6357b.png). </details>. <details>. <summary> Embedding </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""leiden"", ""leiden_missing""]). ```. ### Current. ![output_8_0](https://user-images.githubusercontent.com/8238804/90474984-ec454600-e169-11ea-935c-cb094f520a1a.png). ### Master. ![output_8_0](https://user-images.githubusercontent.com/8238804/90475481-de43f500",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:1480,usability,user,user-images,1480,"is is a private parameter which would override the ""bad value"" for a passed colormap). @Hrovatin @LuckyMD @fidelram @giovp @flying-sheep . # Setup. ```python. import scanpy as sc, matplotlib.pyplot as plt, numpy as np, pandas as pd. ```. ```python. # Setup. brain = sc.read(""./tmp_brain.h5ad"") # just an example visium dataset with some preprocessing. sc.tl.umap(brain). # Add some points with misssing values. brain.obs[""leiden_missing""] = brain.obs[""leiden""].copy(). brain.obs[""leiden_missing""].iloc[::2] = np.nan. brain.obs[""Bc1_missing""] = brain.obs_vector(""Bc1"").copy(). brain.obs[""Bc1_missing""].iloc[::3] = np.nan. ```. ## Null values in categoricals. <details>. <summary> Spatial </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden"", ""leiden_missing""]). ```. ### Current (this branch):. ![output_5_0](https://user-images.githubusercontent.com/8238804/90474913-c029c500-e169-11ea-8b06-2a3eaa8f994c.png). ### Master. ![output_5_0](https://user-images.githubusercontent.com/8238804/90475410-be143600-e16a-11ea-86f2-7e631e73cd8f.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden"", ""leiden_missing""], groups=[""0"", ""1""]). ```. ### Current. ![output_6_0](https://user-images.githubusercontent.com/8238804/90474940-d0da3b00-e169-11ea-86f9-597bb1d5da01.png). ### Master. ![output_6_0](https://user-images.githubusercontent.com/8238804/90475475-da17d780-e16a-11ea-9ae9-6fb61fd6357b.png). </details>. <details>. <summary> Embedding </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""leiden"", ""leiden_missing""]). ```. ### Current. ![output_8_0](https://user-images.githubusercontent.com/8238804/90474984-ec454600-e169-11ea-935c-cb094f520a1a.png). ### Master. ![output_8_0](https://user-images.githubusercontent.com/8238804/90475481-de43f500-e16a-11ea-80da-2636b1b6dddf.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""leiden"", ""lei",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:1745,usability,user,user-images,1745," sc.read(""./tmp_brain.h5ad"") # just an example visium dataset with some preprocessing. sc.tl.umap(brain). # Add some points with misssing values. brain.obs[""leiden_missing""] = brain.obs[""leiden""].copy(). brain.obs[""leiden_missing""].iloc[::2] = np.nan. brain.obs[""Bc1_missing""] = brain.obs_vector(""Bc1"").copy(). brain.obs[""Bc1_missing""].iloc[::3] = np.nan. ```. ## Null values in categoricals. <details>. <summary> Spatial </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden"", ""leiden_missing""]). ```. ### Current (this branch):. ![output_5_0](https://user-images.githubusercontent.com/8238804/90474913-c029c500-e169-11ea-8b06-2a3eaa8f994c.png). ### Master. ![output_5_0](https://user-images.githubusercontent.com/8238804/90475410-be143600-e16a-11ea-86f2-7e631e73cd8f.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden"", ""leiden_missing""], groups=[""0"", ""1""]). ```. ### Current. ![output_6_0](https://user-images.githubusercontent.com/8238804/90474940-d0da3b00-e169-11ea-86f9-597bb1d5da01.png). ### Master. ![output_6_0](https://user-images.githubusercontent.com/8238804/90475475-da17d780-e16a-11ea-9ae9-6fb61fd6357b.png). </details>. <details>. <summary> Embedding </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""leiden"", ""leiden_missing""]). ```. ### Current. ![output_8_0](https://user-images.githubusercontent.com/8238804/90474984-ec454600-e169-11ea-935c-cb094f520a1a.png). ### Master. ![output_8_0](https://user-images.githubusercontent.com/8238804/90475481-de43f500-e16a-11ea-80da-2636b1b6dddf.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""leiden"", ""leiden_missing""], groups=[""0"", ""1""]). ```. ### Current. ![output_9_0](https://user-images.githubusercontent.com/8238804/90475011-fb2bf880-e169-11ea-90a6-17e13388672e.png). ### Master. ![output_9_0](https://user-images.githubusercontent.com/8238804/90475498-e69c3000-e1",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:1873,usability,user,user-images,1873," misssing values. brain.obs[""leiden_missing""] = brain.obs[""leiden""].copy(). brain.obs[""leiden_missing""].iloc[::2] = np.nan. brain.obs[""Bc1_missing""] = brain.obs_vector(""Bc1"").copy(). brain.obs[""Bc1_missing""].iloc[::3] = np.nan. ```. ## Null values in categoricals. <details>. <summary> Spatial </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden"", ""leiden_missing""]). ```. ### Current (this branch):. ![output_5_0](https://user-images.githubusercontent.com/8238804/90474913-c029c500-e169-11ea-8b06-2a3eaa8f994c.png). ### Master. ![output_5_0](https://user-images.githubusercontent.com/8238804/90475410-be143600-e16a-11ea-86f2-7e631e73cd8f.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden"", ""leiden_missing""], groups=[""0"", ""1""]). ```. ### Current. ![output_6_0](https://user-images.githubusercontent.com/8238804/90474940-d0da3b00-e169-11ea-86f9-597bb1d5da01.png). ### Master. ![output_6_0](https://user-images.githubusercontent.com/8238804/90475475-da17d780-e16a-11ea-9ae9-6fb61fd6357b.png). </details>. <details>. <summary> Embedding </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""leiden"", ""leiden_missing""]). ```. ### Current. ![output_8_0](https://user-images.githubusercontent.com/8238804/90474984-ec454600-e169-11ea-935c-cb094f520a1a.png). ### Master. ![output_8_0](https://user-images.githubusercontent.com/8238804/90475481-de43f500-e16a-11ea-80da-2636b1b6dddf.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""leiden"", ""leiden_missing""], groups=[""0"", ""1""]). ```. ### Current. ![output_9_0](https://user-images.githubusercontent.com/8238804/90475011-fb2bf880-e169-11ea-90a6-17e13388672e.png). ### Master. ![output_9_0](https://user-images.githubusercontent.com/8238804/90475498-e69c3000-e16a-11ea-876c-747ec02fae6d.png). </details>. ## Continuous values. <details>. <summary> Spatial </summary>. ```python. with plt.r",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:2171,usability,user,user-images,2171,"mmary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden"", ""leiden_missing""]). ```. ### Current (this branch):. ![output_5_0](https://user-images.githubusercontent.com/8238804/90474913-c029c500-e169-11ea-8b06-2a3eaa8f994c.png). ### Master. ![output_5_0](https://user-images.githubusercontent.com/8238804/90475410-be143600-e16a-11ea-86f2-7e631e73cd8f.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden"", ""leiden_missing""], groups=[""0"", ""1""]). ```. ### Current. ![output_6_0](https://user-images.githubusercontent.com/8238804/90474940-d0da3b00-e169-11ea-86f9-597bb1d5da01.png). ### Master. ![output_6_0](https://user-images.githubusercontent.com/8238804/90475475-da17d780-e16a-11ea-9ae9-6fb61fd6357b.png). </details>. <details>. <summary> Embedding </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""leiden"", ""leiden_missing""]). ```. ### Current. ![output_8_0](https://user-images.githubusercontent.com/8238804/90474984-ec454600-e169-11ea-935c-cb094f520a1a.png). ### Master. ![output_8_0](https://user-images.githubusercontent.com/8238804/90475481-de43f500-e16a-11ea-80da-2636b1b6dddf.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""leiden"", ""leiden_missing""], groups=[""0"", ""1""]). ```. ### Current. ![output_9_0](https://user-images.githubusercontent.com/8238804/90475011-fb2bf880-e169-11ea-90a6-17e13388672e.png). ### Master. ![output_9_0](https://user-images.githubusercontent.com/8238804/90475498-e69c3000-e16a-11ea-876c-747ec02fae6d.png). </details>. ## Continuous values. <details>. <summary> Spatial </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""Bc1"", ""Bc1_missing""]). ```. ### Current. ![output_12_0](https://user-images.githubusercontent.com/8238804/90475149-4219ee00-e16a-11ea-9b42-aea86a8883a4.png). ### Master. ![output_12_0](https://user-images.githubusercontent.com/8238804/9",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:2299,usability,user,user-images,2299," Current (this branch):. ![output_5_0](https://user-images.githubusercontent.com/8238804/90474913-c029c500-e169-11ea-8b06-2a3eaa8f994c.png). ### Master. ![output_5_0](https://user-images.githubusercontent.com/8238804/90475410-be143600-e16a-11ea-86f2-7e631e73cd8f.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden"", ""leiden_missing""], groups=[""0"", ""1""]). ```. ### Current. ![output_6_0](https://user-images.githubusercontent.com/8238804/90474940-d0da3b00-e169-11ea-86f9-597bb1d5da01.png). ### Master. ![output_6_0](https://user-images.githubusercontent.com/8238804/90475475-da17d780-e16a-11ea-9ae9-6fb61fd6357b.png). </details>. <details>. <summary> Embedding </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""leiden"", ""leiden_missing""]). ```. ### Current. ![output_8_0](https://user-images.githubusercontent.com/8238804/90474984-ec454600-e169-11ea-935c-cb094f520a1a.png). ### Master. ![output_8_0](https://user-images.githubusercontent.com/8238804/90475481-de43f500-e16a-11ea-80da-2636b1b6dddf.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""leiden"", ""leiden_missing""], groups=[""0"", ""1""]). ```. ### Current. ![output_9_0](https://user-images.githubusercontent.com/8238804/90475011-fb2bf880-e169-11ea-90a6-17e13388672e.png). ### Master. ![output_9_0](https://user-images.githubusercontent.com/8238804/90475498-e69c3000-e16a-11ea-876c-747ec02fae6d.png). </details>. ## Continuous values. <details>. <summary> Spatial </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""Bc1"", ""Bc1_missing""]). ```. ### Current. ![output_12_0](https://user-images.githubusercontent.com/8238804/90475149-4219ee00-e16a-11ea-9b42-aea86a8883a4.png). ### Master. ![output_12_0](https://user-images.githubusercontent.com/8238804/90475522-eef46b00-e16a-11ea-8d88-4ede97e16252.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, co",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:2561,usability,user,user-images,2561,".png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden"", ""leiden_missing""], groups=[""0"", ""1""]). ```. ### Current. ![output_6_0](https://user-images.githubusercontent.com/8238804/90474940-d0da3b00-e169-11ea-86f9-597bb1d5da01.png). ### Master. ![output_6_0](https://user-images.githubusercontent.com/8238804/90475475-da17d780-e16a-11ea-9ae9-6fb61fd6357b.png). </details>. <details>. <summary> Embedding </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""leiden"", ""leiden_missing""]). ```. ### Current. ![output_8_0](https://user-images.githubusercontent.com/8238804/90474984-ec454600-e169-11ea-935c-cb094f520a1a.png). ### Master. ![output_8_0](https://user-images.githubusercontent.com/8238804/90475481-de43f500-e16a-11ea-80da-2636b1b6dddf.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""leiden"", ""leiden_missing""], groups=[""0"", ""1""]). ```. ### Current. ![output_9_0](https://user-images.githubusercontent.com/8238804/90475011-fb2bf880-e169-11ea-90a6-17e13388672e.png). ### Master. ![output_9_0](https://user-images.githubusercontent.com/8238804/90475498-e69c3000-e16a-11ea-876c-747ec02fae6d.png). </details>. ## Continuous values. <details>. <summary> Spatial </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""Bc1"", ""Bc1_missing""]). ```. ### Current. ![output_12_0](https://user-images.githubusercontent.com/8238804/90475149-4219ee00-e16a-11ea-9b42-aea86a8883a4.png). ### Master. ![output_12_0](https://user-images.githubusercontent.com/8238804/90475522-eef46b00-e16a-11ea-8d88-4ede97e16252.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""Bc1"", ""Bc1_missing""], vmin=""p10"", vmax=""p90""). ```. ### Current. ![output_13_0](https://user-images.githubusercontent.com/8238804/90475174-5100a080-e16a-11ea-91ae-d3c883829b9a.png). ### Master. ![output_13_0](https://user-images.githubusercontent.com/82388",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:2689,usability,user,user-images,2689,""", ""1""]). ```. ### Current. ![output_6_0](https://user-images.githubusercontent.com/8238804/90474940-d0da3b00-e169-11ea-86f9-597bb1d5da01.png). ### Master. ![output_6_0](https://user-images.githubusercontent.com/8238804/90475475-da17d780-e16a-11ea-9ae9-6fb61fd6357b.png). </details>. <details>. <summary> Embedding </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""leiden"", ""leiden_missing""]). ```. ### Current. ![output_8_0](https://user-images.githubusercontent.com/8238804/90474984-ec454600-e169-11ea-935c-cb094f520a1a.png). ### Master. ![output_8_0](https://user-images.githubusercontent.com/8238804/90475481-de43f500-e16a-11ea-80da-2636b1b6dddf.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""leiden"", ""leiden_missing""], groups=[""0"", ""1""]). ```. ### Current. ![output_9_0](https://user-images.githubusercontent.com/8238804/90475011-fb2bf880-e169-11ea-90a6-17e13388672e.png). ### Master. ![output_9_0](https://user-images.githubusercontent.com/8238804/90475498-e69c3000-e16a-11ea-876c-747ec02fae6d.png). </details>. ## Continuous values. <details>. <summary> Spatial </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""Bc1"", ""Bc1_missing""]). ```. ### Current. ![output_12_0](https://user-images.githubusercontent.com/8238804/90475149-4219ee00-e16a-11ea-9b42-aea86a8883a4.png). ### Master. ![output_12_0](https://user-images.githubusercontent.com/8238804/90475522-eef46b00-e16a-11ea-8d88-4ede97e16252.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""Bc1"", ""Bc1_missing""], vmin=""p10"", vmax=""p90""). ```. ### Current. ![output_13_0](https://user-images.githubusercontent.com/8238804/90475174-5100a080-e16a-11ea-91ae-d3c883829b9a.png). ### Master. ![output_13_0](https://user-images.githubusercontent.com/8238804/90475536-f3b91f00-e16a-11ea-8ceb-fc954a9601e6.png). </details>. <details>. <summary> Embedding </summary>. ```python. with pl",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:3005,usability,user,user-images,3005,"/summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""leiden"", ""leiden_missing""]). ```. ### Current. ![output_8_0](https://user-images.githubusercontent.com/8238804/90474984-ec454600-e169-11ea-935c-cb094f520a1a.png). ### Master. ![output_8_0](https://user-images.githubusercontent.com/8238804/90475481-de43f500-e16a-11ea-80da-2636b1b6dddf.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""leiden"", ""leiden_missing""], groups=[""0"", ""1""]). ```. ### Current. ![output_9_0](https://user-images.githubusercontent.com/8238804/90475011-fb2bf880-e169-11ea-90a6-17e13388672e.png). ### Master. ![output_9_0](https://user-images.githubusercontent.com/8238804/90475498-e69c3000-e16a-11ea-876c-747ec02fae6d.png). </details>. ## Continuous values. <details>. <summary> Spatial </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""Bc1"", ""Bc1_missing""]). ```. ### Current. ![output_12_0](https://user-images.githubusercontent.com/8238804/90475149-4219ee00-e16a-11ea-9b42-aea86a8883a4.png). ### Master. ![output_12_0](https://user-images.githubusercontent.com/8238804/90475522-eef46b00-e16a-11ea-8d88-4ede97e16252.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""Bc1"", ""Bc1_missing""], vmin=""p10"", vmax=""p90""). ```. ### Current. ![output_13_0](https://user-images.githubusercontent.com/8238804/90475174-5100a080-e16a-11ea-91ae-d3c883829b9a.png). ### Master. ![output_13_0](https://user-images.githubusercontent.com/8238804/90475536-f3b91f00-e16a-11ea-8ceb-fc954a9601e6.png). </details>. <details>. <summary> Embedding </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""Bc1"", ""Bc1_missing""]). ```. ### Current. ![output_15_0](https://user-images.githubusercontent.com/8238804/90475221-6aa1e800-e16a-11ea-844a-e4e46dbdc717.png). ### Master. ![output_15_0](https://user-images.githubusercontent.com/8238804/90475543-fa479680-e",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:3134,usability,user,user-images,3134,"Current. ![output_8_0](https://user-images.githubusercontent.com/8238804/90474984-ec454600-e169-11ea-935c-cb094f520a1a.png). ### Master. ![output_8_0](https://user-images.githubusercontent.com/8238804/90475481-de43f500-e16a-11ea-80da-2636b1b6dddf.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""leiden"", ""leiden_missing""], groups=[""0"", ""1""]). ```. ### Current. ![output_9_0](https://user-images.githubusercontent.com/8238804/90475011-fb2bf880-e169-11ea-90a6-17e13388672e.png). ### Master. ![output_9_0](https://user-images.githubusercontent.com/8238804/90475498-e69c3000-e16a-11ea-876c-747ec02fae6d.png). </details>. ## Continuous values. <details>. <summary> Spatial </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""Bc1"", ""Bc1_missing""]). ```. ### Current. ![output_12_0](https://user-images.githubusercontent.com/8238804/90475149-4219ee00-e16a-11ea-9b42-aea86a8883a4.png). ### Master. ![output_12_0](https://user-images.githubusercontent.com/8238804/90475522-eef46b00-e16a-11ea-8d88-4ede97e16252.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""Bc1"", ""Bc1_missing""], vmin=""p10"", vmax=""p90""). ```. ### Current. ![output_13_0](https://user-images.githubusercontent.com/8238804/90475174-5100a080-e16a-11ea-91ae-d3c883829b9a.png). ### Master. ![output_13_0](https://user-images.githubusercontent.com/8238804/90475536-f3b91f00-e16a-11ea-8ceb-fc954a9601e6.png). </details>. <details>. <summary> Embedding </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""Bc1"", ""Bc1_missing""]). ```. ### Current. ![output_15_0](https://user-images.githubusercontent.com/8238804/90475221-6aa1e800-e16a-11ea-844a-e4e46dbdc717.png). ### Master. ![output_15_0](https://user-images.githubusercontent.com/8238804/90475543-fa479680-e16a-11ea-8da1-93dbc1526192.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""Bc1"", ""Bc1_missi",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:3399,usability,user,user-images,3399,"ith plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""leiden"", ""leiden_missing""], groups=[""0"", ""1""]). ```. ### Current. ![output_9_0](https://user-images.githubusercontent.com/8238804/90475011-fb2bf880-e169-11ea-90a6-17e13388672e.png). ### Master. ![output_9_0](https://user-images.githubusercontent.com/8238804/90475498-e69c3000-e16a-11ea-876c-747ec02fae6d.png). </details>. ## Continuous values. <details>. <summary> Spatial </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""Bc1"", ""Bc1_missing""]). ```. ### Current. ![output_12_0](https://user-images.githubusercontent.com/8238804/90475149-4219ee00-e16a-11ea-9b42-aea86a8883a4.png). ### Master. ![output_12_0](https://user-images.githubusercontent.com/8238804/90475522-eef46b00-e16a-11ea-8d88-4ede97e16252.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""Bc1"", ""Bc1_missing""], vmin=""p10"", vmax=""p90""). ```. ### Current. ![output_13_0](https://user-images.githubusercontent.com/8238804/90475174-5100a080-e16a-11ea-91ae-d3c883829b9a.png). ### Master. ![output_13_0](https://user-images.githubusercontent.com/8238804/90475536-f3b91f00-e16a-11ea-8ceb-fc954a9601e6.png). </details>. <details>. <summary> Embedding </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""Bc1"", ""Bc1_missing""]). ```. ### Current. ![output_15_0](https://user-images.githubusercontent.com/8238804/90475221-6aa1e800-e16a-11ea-844a-e4e46dbdc717.png). ### Master. ![output_15_0](https://user-images.githubusercontent.com/8238804/90475543-fa479680-e16a-11ea-8da1-93dbc1526192.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""Bc1"", ""Bc1_missing""], vmin=""p10"", vmax=""p90""). ```. ### Current. ![output_16_0](https://user-images.githubusercontent.com/8238804/90475232-6f669c00-e16a-11ea-9889-0c0986346cc0.png). ### Master. ![output_16_0](https://user-images.githubusercontent.com/8238804/90475556-003d7780-e16b",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:3528,usability,user,user-images,3528,"sc.pl.umap(brain, color=[""leiden"", ""leiden_missing""], groups=[""0"", ""1""]). ```. ### Current. ![output_9_0](https://user-images.githubusercontent.com/8238804/90475011-fb2bf880-e169-11ea-90a6-17e13388672e.png). ### Master. ![output_9_0](https://user-images.githubusercontent.com/8238804/90475498-e69c3000-e16a-11ea-876c-747ec02fae6d.png). </details>. ## Continuous values. <details>. <summary> Spatial </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""Bc1"", ""Bc1_missing""]). ```. ### Current. ![output_12_0](https://user-images.githubusercontent.com/8238804/90475149-4219ee00-e16a-11ea-9b42-aea86a8883a4.png). ### Master. ![output_12_0](https://user-images.githubusercontent.com/8238804/90475522-eef46b00-e16a-11ea-8d88-4ede97e16252.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""Bc1"", ""Bc1_missing""], vmin=""p10"", vmax=""p90""). ```. ### Current. ![output_13_0](https://user-images.githubusercontent.com/8238804/90475174-5100a080-e16a-11ea-91ae-d3c883829b9a.png). ### Master. ![output_13_0](https://user-images.githubusercontent.com/8238804/90475536-f3b91f00-e16a-11ea-8ceb-fc954a9601e6.png). </details>. <details>. <summary> Embedding </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""Bc1"", ""Bc1_missing""]). ```. ### Current. ![output_15_0](https://user-images.githubusercontent.com/8238804/90475221-6aa1e800-e16a-11ea-844a-e4e46dbdc717.png). ### Master. ![output_15_0](https://user-images.githubusercontent.com/8238804/90475543-fa479680-e16a-11ea-8da1-93dbc1526192.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""Bc1"", ""Bc1_missing""], vmin=""p10"", vmax=""p90""). ```. ### Current. ![output_16_0](https://user-images.githubusercontent.com/8238804/90475232-6f669c00-e16a-11ea-9889-0c0986346cc0.png). ### Master. ![output_16_0](https://user-images.githubusercontent.com/8238804/90475556-003d7780-e16b-11ea-9ee6-4b59cbee8915.png). </details> .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:3821,usability,user,user-images,3821,"sc.pl.umap(brain, color=[""leiden"", ""leiden_missing""], groups=[""0"", ""1""]). ```. ### Current. ![output_9_0](https://user-images.githubusercontent.com/8238804/90475011-fb2bf880-e169-11ea-90a6-17e13388672e.png). ### Master. ![output_9_0](https://user-images.githubusercontent.com/8238804/90475498-e69c3000-e16a-11ea-876c-747ec02fae6d.png). </details>. ## Continuous values. <details>. <summary> Spatial </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""Bc1"", ""Bc1_missing""]). ```. ### Current. ![output_12_0](https://user-images.githubusercontent.com/8238804/90475149-4219ee00-e16a-11ea-9b42-aea86a8883a4.png). ### Master. ![output_12_0](https://user-images.githubusercontent.com/8238804/90475522-eef46b00-e16a-11ea-8d88-4ede97e16252.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""Bc1"", ""Bc1_missing""], vmin=""p10"", vmax=""p90""). ```. ### Current. ![output_13_0](https://user-images.githubusercontent.com/8238804/90475174-5100a080-e16a-11ea-91ae-d3c883829b9a.png). ### Master. ![output_13_0](https://user-images.githubusercontent.com/8238804/90475536-f3b91f00-e16a-11ea-8ceb-fc954a9601e6.png). </details>. <details>. <summary> Embedding </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""Bc1"", ""Bc1_missing""]). ```. ### Current. ![output_15_0](https://user-images.githubusercontent.com/8238804/90475221-6aa1e800-e16a-11ea-844a-e4e46dbdc717.png). ### Master. ![output_15_0](https://user-images.githubusercontent.com/8238804/90475543-fa479680-e16a-11ea-8da1-93dbc1526192.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""Bc1"", ""Bc1_missing""], vmin=""p10"", vmax=""p90""). ```. ### Current. ![output_16_0](https://user-images.githubusercontent.com/8238804/90475232-6f669c00-e16a-11ea-9889-0c0986346cc0.png). ### Master. ![output_16_0](https://user-images.githubusercontent.com/8238804/90475556-003d7780-e16b-11ea-9ee6-4b59cbee8915.png). </details> .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:3950,usability,user,user-images,3950,"sc.pl.umap(brain, color=[""leiden"", ""leiden_missing""], groups=[""0"", ""1""]). ```. ### Current. ![output_9_0](https://user-images.githubusercontent.com/8238804/90475011-fb2bf880-e169-11ea-90a6-17e13388672e.png). ### Master. ![output_9_0](https://user-images.githubusercontent.com/8238804/90475498-e69c3000-e16a-11ea-876c-747ec02fae6d.png). </details>. ## Continuous values. <details>. <summary> Spatial </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""Bc1"", ""Bc1_missing""]). ```. ### Current. ![output_12_0](https://user-images.githubusercontent.com/8238804/90475149-4219ee00-e16a-11ea-9b42-aea86a8883a4.png). ### Master. ![output_12_0](https://user-images.githubusercontent.com/8238804/90475522-eef46b00-e16a-11ea-8d88-4ede97e16252.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""Bc1"", ""Bc1_missing""], vmin=""p10"", vmax=""p90""). ```. ### Current. ![output_13_0](https://user-images.githubusercontent.com/8238804/90475174-5100a080-e16a-11ea-91ae-d3c883829b9a.png). ### Master. ![output_13_0](https://user-images.githubusercontent.com/8238804/90475536-f3b91f00-e16a-11ea-8ceb-fc954a9601e6.png). </details>. <details>. <summary> Embedding </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""Bc1"", ""Bc1_missing""]). ```. ### Current. ![output_15_0](https://user-images.githubusercontent.com/8238804/90475221-6aa1e800-e16a-11ea-844a-e4e46dbdc717.png). ### Master. ![output_15_0](https://user-images.githubusercontent.com/8238804/90475543-fa479680-e16a-11ea-8da1-93dbc1526192.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""Bc1"", ""Bc1_missing""], vmin=""p10"", vmax=""p90""). ```. ### Current. ![output_16_0](https://user-images.githubusercontent.com/8238804/90475232-6f669c00-e16a-11ea-9889-0c0986346cc0.png). ### Master. ![output_16_0](https://user-images.githubusercontent.com/8238804/90475556-003d7780-e16b-11ea-9ee6-4b59cbee8915.png). </details> .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:4212,usability,user,user-images,4212,"sc.pl.umap(brain, color=[""leiden"", ""leiden_missing""], groups=[""0"", ""1""]). ```. ### Current. ![output_9_0](https://user-images.githubusercontent.com/8238804/90475011-fb2bf880-e169-11ea-90a6-17e13388672e.png). ### Master. ![output_9_0](https://user-images.githubusercontent.com/8238804/90475498-e69c3000-e16a-11ea-876c-747ec02fae6d.png). </details>. ## Continuous values. <details>. <summary> Spatial </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""Bc1"", ""Bc1_missing""]). ```. ### Current. ![output_12_0](https://user-images.githubusercontent.com/8238804/90475149-4219ee00-e16a-11ea-9b42-aea86a8883a4.png). ### Master. ![output_12_0](https://user-images.githubusercontent.com/8238804/90475522-eef46b00-e16a-11ea-8d88-4ede97e16252.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""Bc1"", ""Bc1_missing""], vmin=""p10"", vmax=""p90""). ```. ### Current. ![output_13_0](https://user-images.githubusercontent.com/8238804/90475174-5100a080-e16a-11ea-91ae-d3c883829b9a.png). ### Master. ![output_13_0](https://user-images.githubusercontent.com/8238804/90475536-f3b91f00-e16a-11ea-8ceb-fc954a9601e6.png). </details>. <details>. <summary> Embedding </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""Bc1"", ""Bc1_missing""]). ```. ### Current. ![output_15_0](https://user-images.githubusercontent.com/8238804/90475221-6aa1e800-e16a-11ea-844a-e4e46dbdc717.png). ### Master. ![output_15_0](https://user-images.githubusercontent.com/8238804/90475543-fa479680-e16a-11ea-8da1-93dbc1526192.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""Bc1"", ""Bc1_missing""], vmin=""p10"", vmax=""p90""). ```. ### Current. ![output_16_0](https://user-images.githubusercontent.com/8238804/90475232-6f669c00-e16a-11ea-9889-0c0986346cc0.png). ### Master. ![output_16_0](https://user-images.githubusercontent.com/8238804/90475556-003d7780-e16b-11ea-9ee6-4b59cbee8915.png). </details> .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:4341,usability,user,user-images,4341,"sc.pl.umap(brain, color=[""leiden"", ""leiden_missing""], groups=[""0"", ""1""]). ```. ### Current. ![output_9_0](https://user-images.githubusercontent.com/8238804/90475011-fb2bf880-e169-11ea-90a6-17e13388672e.png). ### Master. ![output_9_0](https://user-images.githubusercontent.com/8238804/90475498-e69c3000-e16a-11ea-876c-747ec02fae6d.png). </details>. ## Continuous values. <details>. <summary> Spatial </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""Bc1"", ""Bc1_missing""]). ```. ### Current. ![output_12_0](https://user-images.githubusercontent.com/8238804/90475149-4219ee00-e16a-11ea-9b42-aea86a8883a4.png). ### Master. ![output_12_0](https://user-images.githubusercontent.com/8238804/90475522-eef46b00-e16a-11ea-8d88-4ede97e16252.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""Bc1"", ""Bc1_missing""], vmin=""p10"", vmax=""p90""). ```. ### Current. ![output_13_0](https://user-images.githubusercontent.com/8238804/90475174-5100a080-e16a-11ea-91ae-d3c883829b9a.png). ### Master. ![output_13_0](https://user-images.githubusercontent.com/8238804/90475536-f3b91f00-e16a-11ea-8ceb-fc954a9601e6.png). </details>. <details>. <summary> Embedding </summary>. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""Bc1"", ""Bc1_missing""]). ```. ### Current. ![output_15_0](https://user-images.githubusercontent.com/8238804/90475221-6aa1e800-e16a-11ea-844a-e4e46dbdc717.png). ### Master. ![output_15_0](https://user-images.githubusercontent.com/8238804/90475543-fa479680-e16a-11ea-8da1-93dbc1526192.png). ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.umap(brain, color=[""Bc1"", ""Bc1_missing""], vmin=""p10"", vmax=""p90""). ```. ### Current. ![output_16_0](https://user-images.githubusercontent.com/8238804/90475232-6f669c00-e16a-11ea-9889-0c0986346cc0.png). ### Master. ![output_16_0](https://user-images.githubusercontent.com/8238804/90475556-003d7780-e16b-11ea-9ee6-4b59cbee8915.png). </details> .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:212,deployability,continu,continuous,212,"I like the new behaviour. Maybe a parameter like na_colors could be used to specify a different na color if needed. . Also, should the NaN and its colour be added to the legend (if categorical) or besides it (if continuous)?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:76,interoperability,specif,specify,76,"I like the new behaviour. Maybe a parameter like na_colors could be used to specify a different na color if needed. . Also, should the NaN and its colour be added to the legend (if categorical) or besides it (if continuous)?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:34,modifiability,paramet,parameter,34,"I like the new behaviour. Maybe a parameter like na_colors could be used to specify a different na color if needed. . Also, should the NaN and its colour be added to the legend (if categorical) or besides it (if continuous)?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:15,usability,behavi,behaviour,15,"I like the new behaviour. Maybe a parameter like na_colors could be used to specify a different na color if needed. . Also, should the NaN and its colour be added to the legend (if categorical) or besides it (if continuous)?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:309,energy efficiency,current,current,309,"Looks pretty great! Improvements everywhere! Im especially surprised that in this pic, the missing values share a color with an existing category! Thats pretty wrong:. ![](https://user-images.githubusercontent.com/8238804/90475410-be143600-e16a-11ea-86f2-7e631e73cd8f.png). At first I was confused because current and master often mean before and after in the opposite order than here, and also you put the after plots above the before ones.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:107,interoperability,share,share,107,"Looks pretty great! Improvements everywhere! Im especially surprised that in this pic, the missing values share a color with an existing category! Thats pretty wrong:. ![](https://user-images.githubusercontent.com/8238804/90475410-be143600-e16a-11ea-86f2-7e631e73cd8f.png). At first I was confused because current and master often mean before and after in the opposite order than here, and also you put the after plots above the before ones.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:182,usability,user,user-images,182,"Looks pretty great! Improvements everywhere! Im especially surprised that in this pic, the missing values share a color with an existing category! Thats pretty wrong:. ![](https://user-images.githubusercontent.com/8238804/90475410-be143600-e16a-11ea-86f2-7e631e73cd8f.png). At first I was confused because current and master often mean before and after in the opposite order than here, and also you put the after plots above the before ones.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:403,energy efficiency,current,current,403,"Thanks for the changes and for the clean up of the code. From the output that you show the changes seem to be working well. Maybe the only relevant issue would be to change the default color if this clashes with a color already assigned to a category. . Now that you are looking into this, any chance that the missing_color can also be used as the default color when the `color` parameter is empty? The current default is light gray .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:379,modifiability,paramet,parameter,379,"Thanks for the changes and for the clean up of the code. From the output that you show the changes seem to be working well. Maybe the only relevant issue would be to change the default color if this clashes with a color already assigned to a category. . Now that you are looking into this, any chance that the missing_color can also be used as the default color when the `color` parameter is empty? The current default is light gray .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:352,deployability,continu,continuous,352,"> Maybe the only relevant issue would be to change the default color if this clashes with a color already assigned to a category. I'm not sure how to check if colors are similar. But I think @Hrovatin's suggestion could make this obvious enough to users:. > Also, should the NaN and its colour be added to the legend (if categorical) or besides it (if continuous)? Any suggestions for how to handle this @fidelram? > Now that you are looking into this, any chance that the missing_color can also be used as the default color when the color parameter is empty? The current default is light gray . Yes, but it took a little bit more work than I expected (https://github.com/matplotlib/matplotlib/issues/18294). Basically we can't just pass an array of nulls for the color values here, since matplotlib throws user visible warnings about this at plot time.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:564,energy efficiency,current,current,564,"> Maybe the only relevant issue would be to change the default color if this clashes with a color already assigned to a category. I'm not sure how to check if colors are similar. But I think @Hrovatin's suggestion could make this obvious enough to users:. > Also, should the NaN and its colour be added to the legend (if categorical) or besides it (if continuous)? Any suggestions for how to handle this @fidelram? > Now that you are looking into this, any chance that the missing_color can also be used as the default color when the color parameter is empty? The current default is light gray . Yes, but it took a little bit more work than I expected (https://github.com/matplotlib/matplotlib/issues/18294). Basically we can't just pass an array of nulls for the color values here, since matplotlib throws user visible warnings about this at plot time.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:540,modifiability,paramet,parameter,540,"> Maybe the only relevant issue would be to change the default color if this clashes with a color already assigned to a category. I'm not sure how to check if colors are similar. But I think @Hrovatin's suggestion could make this obvious enough to users:. > Also, should the NaN and its colour be added to the legend (if categorical) or besides it (if continuous)? Any suggestions for how to handle this @fidelram? > Now that you are looking into this, any chance that the missing_color can also be used as the default color when the color parameter is empty? The current default is light gray . Yes, but it took a little bit more work than I expected (https://github.com/matplotlib/matplotlib/issues/18294). Basically we can't just pass an array of nulls for the color values here, since matplotlib throws user visible warnings about this at plot time.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:848,performance,time,time,848,"> Maybe the only relevant issue would be to change the default color if this clashes with a color already assigned to a category. I'm not sure how to check if colors are similar. But I think @Hrovatin's suggestion could make this obvious enough to users:. > Also, should the NaN and its colour be added to the legend (if categorical) or besides it (if continuous)? Any suggestions for how to handle this @fidelram? > Now that you are looking into this, any chance that the missing_color can also be used as the default color when the color parameter is empty? The current default is light gray . Yes, but it took a little bit more work than I expected (https://github.com/matplotlib/matplotlib/issues/18294). Basically we can't just pass an array of nulls for the color values here, since matplotlib throws user visible warnings about this at plot time.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:248,usability,user,users,248,"> Maybe the only relevant issue would be to change the default color if this clashes with a color already assigned to a category. I'm not sure how to check if colors are similar. But I think @Hrovatin's suggestion could make this obvious enough to users:. > Also, should the NaN and its colour be added to the legend (if categorical) or besides it (if continuous)? Any suggestions for how to handle this @fidelram? > Now that you are looking into this, any chance that the missing_color can also be used as the default color when the color parameter is empty? The current default is light gray . Yes, but it took a little bit more work than I expected (https://github.com/matplotlib/matplotlib/issues/18294). Basically we can't just pass an array of nulls for the color values here, since matplotlib throws user visible warnings about this at plot time.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:807,usability,user,user,807,"> Maybe the only relevant issue would be to change the default color if this clashes with a color already assigned to a category. I'm not sure how to check if colors are similar. But I think @Hrovatin's suggestion could make this obvious enough to users:. > Also, should the NaN and its colour be added to the legend (if categorical) or besides it (if continuous)? Any suggestions for how to handle this @fidelram? > Now that you are looking into this, any chance that the missing_color can also be used as the default color when the color parameter is empty? The current default is light gray . Yes, but it took a little bit more work than I expected (https://github.com/matplotlib/matplotlib/issues/18294). Basically we can't just pass an array of nulls for the color values here, since matplotlib throws user visible warnings about this at plot time.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:635,modifiability,paramet,parameter,635,"For me the most informative solution when I do get NaN values (usually after anndata concatenate), is to visualize them as a new category labelled 'NaN'. (What I do is convert the categorical data to string and then back to categorical (e.g. `adata.obs['label'] = adata.obs['label'].astype(str).astype('category')`). This solution has the advantage of creating a 'nan' category that solves many of the mentioned problems like the 'on data' labels and the potential color clash of nan color with category color. What it does not do and that I like from the new code is to put those NaN values in the back. . What we can do is to have a parameter like `na_as_category` that will do what I just mentioned. Otherwise, the NaNs are plotted in gray but do not get a label.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:519,reliability,doe,does,519,"For me the most informative solution when I do get NaN values (usually after anndata concatenate), is to visualize them as a new category labelled 'NaN'. (What I do is convert the categorical data to string and then back to categorical (e.g. `adata.obs['label'] = adata.obs['label'].astype(str).astype('category')`). This solution has the advantage of creating a 'nan' category that solves many of the mentioned problems like the 'on data' labels and the potential color clash of nan color with category color. What it does not do and that I like from the new code is to put those NaN values in the back. . What we can do is to have a parameter like `na_as_category` that will do what I just mentioned. Otherwise, the NaNs are plotted in gray but do not get a label.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:105,usability,visual,visualize,105,"For me the most informative solution when I do get NaN values (usually after anndata concatenate), is to visualize them as a new category labelled 'NaN'. (What I do is convert the categorical data to string and then back to categorical (e.g. `adata.obs['label'] = adata.obs['label'].astype(str).astype('category')`). This solution has the advantage of creating a 'nan' category that solves many of the mentioned problems like the 'on data' labels and the potential color clash of nan color with category color. What it does not do and that I like from the new code is to put those NaN values in the back. . What we can do is to have a parameter like `na_as_category` that will do what I just mentioned. Otherwise, the NaNs are plotted in gray but do not get a label.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:114,deployability,continu,continuous,114,"When would you want `na_as_category` off? Is it important enough to add a new parameter for? Also, how should the continuous color bar show that there is a null value? (Suggestions with code very welcome)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:78,modifiability,paramet,parameter,78,"When would you want `na_as_category` off? Is it important enough to add a new parameter for? Also, how should the continuous color bar show that there is a null value? (Suggestions with code very welcome)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:13,deployability,continu,continuous,13,When data is continuous and legend is a continuous color bar a second legend could be added below it showing the categorical NaN (like the usual categorical legend).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:40,deployability,continu,continuous,40,When data is continuous and legend is a continuous color bar a second legend could be added below it showing the categorical NaN (like the usual categorical legend).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:127,usability,user,user-images,127,"I guess I'm wondering when I would want results like this with `""on data""`:. <details>. <summary> </summary>. ![image](https://user-images.githubusercontent.com/8238804/90611402-06565580-e24a-11ea-9698-797f75823a2c.png). ![image](https://user-images.githubusercontent.com/8238804/90611411-08201900-e24a-11ea-919b-bc6362f3efd7.png). </details>. And when I wouldn't want results like this with `""right margin""`:. <details>. <summary> </summary>. ![image](https://user-images.githubusercontent.com/8238804/90611433-10785400-e24a-11ea-92ac-f4f7c8dc148c.png). ![image](https://user-images.githubusercontent.com/8238804/90611439-12421780-e24a-11ea-91fe-6a5111673948.png). </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:238,usability,user,user-images,238,"I guess I'm wondering when I would want results like this with `""on data""`:. <details>. <summary> </summary>. ![image](https://user-images.githubusercontent.com/8238804/90611402-06565580-e24a-11ea-9698-797f75823a2c.png). ![image](https://user-images.githubusercontent.com/8238804/90611411-08201900-e24a-11ea-919b-bc6362f3efd7.png). </details>. And when I wouldn't want results like this with `""right margin""`:. <details>. <summary> </summary>. ![image](https://user-images.githubusercontent.com/8238804/90611433-10785400-e24a-11ea-92ac-f4f7c8dc148c.png). ![image](https://user-images.githubusercontent.com/8238804/90611439-12421780-e24a-11ea-91fe-6a5111673948.png). </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:461,usability,user,user-images,461,"I guess I'm wondering when I would want results like this with `""on data""`:. <details>. <summary> </summary>. ![image](https://user-images.githubusercontent.com/8238804/90611402-06565580-e24a-11ea-9698-797f75823a2c.png). ![image](https://user-images.githubusercontent.com/8238804/90611411-08201900-e24a-11ea-919b-bc6362f3efd7.png). </details>. And when I wouldn't want results like this with `""right margin""`:. <details>. <summary> </summary>. ![image](https://user-images.githubusercontent.com/8238804/90611433-10785400-e24a-11ea-92ac-f4f7c8dc148c.png). ![image](https://user-images.githubusercontent.com/8238804/90611439-12421780-e24a-11ea-91fe-6a5111673948.png). </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:572,usability,user,user-images,572,"I guess I'm wondering when I would want results like this with `""on data""`:. <details>. <summary> </summary>. ![image](https://user-images.githubusercontent.com/8238804/90611402-06565580-e24a-11ea-9698-797f75823a2c.png). ![image](https://user-images.githubusercontent.com/8238804/90611411-08201900-e24a-11ea-919b-bc6362f3efd7.png). </details>. And when I wouldn't want results like this with `""right margin""`:. <details>. <summary> </summary>. ![image](https://user-images.githubusercontent.com/8238804/90611433-10785400-e24a-11ea-92ac-f4f7c8dc148c.png). ![image](https://user-images.githubusercontent.com/8238804/90611439-12421780-e24a-11ea-91fe-6a5111673948.png). </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:89,usability,prototyp,prototype,89,"@Hrovatin, that sounds good, but I'm not totally sure how I should do that. If you had a prototype of that it would be very useful. Maybe @fidelram has a suggestion based on the DotPlot legends?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:4,deployability,continu,continuous,4,"For continuous values I don't think we need to add anything to the color bar. If a dot color is not part of the colorbar then is assumed that is a NaN. I searched in matplotlib for a similar case in which a colorbar includes NaN values but could not find any example. If this feature is wanted, what we can do is to use the option for colorbar extension and use it for NaNs but we need to find a way to set the label for NaN. ```PYTHON. import numpy as np. import matplotlib.pyplot as plt. adata = sc.datasets.pbmc68k_reduced(). adata.obs['n_genes'].iloc[::4] = np.nan. cmap = plt.get_cmap('viridis'). cmap.set_under('lightgray'). cmap.set_bad('lightgray'). fig, ax = plt.subplots(). cax = ax.scatter(adata.obsm['X_umap'][:,0], adata.obsm['X_umap'][:,1], . c=adata.obs['n_genes'], s=20, . cmap=cmap, . vmin=1000, . vmax=2000, plotnonfinite=True). fig.colorbar(cax, extend='min', extendrect=True, extendfrac=0.1). plt.show(). ```. ![image](https://user-images.githubusercontent.com/4964309/90750699-7b22a180-e2d5-11ea-9a67-1ad7feb8a6a4.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:672,integrability,sub,subplots,672,"For continuous values I don't think we need to add anything to the color bar. If a dot color is not part of the colorbar then is assumed that is a NaN. I searched in matplotlib for a similar case in which a colorbar includes NaN values but could not find any example. If this feature is wanted, what we can do is to use the option for colorbar extension and use it for NaNs but we need to find a way to set the label for NaN. ```PYTHON. import numpy as np. import matplotlib.pyplot as plt. adata = sc.datasets.pbmc68k_reduced(). adata.obs['n_genes'].iloc[::4] = np.nan. cmap = plt.get_cmap('viridis'). cmap.set_under('lightgray'). cmap.set_bad('lightgray'). fig, ax = plt.subplots(). cax = ax.scatter(adata.obsm['X_umap'][:,0], adata.obsm['X_umap'][:,1], . c=adata.obs['n_genes'], s=20, . cmap=cmap, . vmin=1000, . vmax=2000, plotnonfinite=True). fig.colorbar(cax, extend='min', extendrect=True, extendfrac=0.1). plt.show(). ```. ![image](https://user-images.githubusercontent.com/4964309/90750699-7b22a180-e2d5-11ea-9a67-1ad7feb8a6a4.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:344,modifiability,extens,extension,344,"For continuous values I don't think we need to add anything to the color bar. If a dot color is not part of the colorbar then is assumed that is a NaN. I searched in matplotlib for a similar case in which a colorbar includes NaN values but could not find any example. If this feature is wanted, what we can do is to use the option for colorbar extension and use it for NaNs but we need to find a way to set the label for NaN. ```PYTHON. import numpy as np. import matplotlib.pyplot as plt. adata = sc.datasets.pbmc68k_reduced(). adata.obs['n_genes'].iloc[::4] = np.nan. cmap = plt.get_cmap('viridis'). cmap.set_under('lightgray'). cmap.set_bad('lightgray'). fig, ax = plt.subplots(). cax = ax.scatter(adata.obsm['X_umap'][:,0], adata.obsm['X_umap'][:,1], . c=adata.obs['n_genes'], s=20, . cmap=cmap, . vmin=1000, . vmax=2000, plotnonfinite=True). fig.colorbar(cax, extend='min', extendrect=True, extendfrac=0.1). plt.show(). ```. ![image](https://user-images.githubusercontent.com/4964309/90750699-7b22a180-e2d5-11ea-9a67-1ad7feb8a6a4.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:865,modifiability,exten,extend,865,"For continuous values I don't think we need to add anything to the color bar. If a dot color is not part of the colorbar then is assumed that is a NaN. I searched in matplotlib for a similar case in which a colorbar includes NaN values but could not find any example. If this feature is wanted, what we can do is to use the option for colorbar extension and use it for NaNs but we need to find a way to set the label for NaN. ```PYTHON. import numpy as np. import matplotlib.pyplot as plt. adata = sc.datasets.pbmc68k_reduced(). adata.obs['n_genes'].iloc[::4] = np.nan. cmap = plt.get_cmap('viridis'). cmap.set_under('lightgray'). cmap.set_bad('lightgray'). fig, ax = plt.subplots(). cax = ax.scatter(adata.obsm['X_umap'][:,0], adata.obsm['X_umap'][:,1], . c=adata.obs['n_genes'], s=20, . cmap=cmap, . vmin=1000, . vmax=2000, plotnonfinite=True). fig.colorbar(cax, extend='min', extendrect=True, extendfrac=0.1). plt.show(). ```. ![image](https://user-images.githubusercontent.com/4964309/90750699-7b22a180-e2d5-11ea-9a67-1ad7feb8a6a4.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:879,modifiability,exten,extendrect,879,"For continuous values I don't think we need to add anything to the color bar. If a dot color is not part of the colorbar then is assumed that is a NaN. I searched in matplotlib for a similar case in which a colorbar includes NaN values but could not find any example. If this feature is wanted, what we can do is to use the option for colorbar extension and use it for NaNs but we need to find a way to set the label for NaN. ```PYTHON. import numpy as np. import matplotlib.pyplot as plt. adata = sc.datasets.pbmc68k_reduced(). adata.obs['n_genes'].iloc[::4] = np.nan. cmap = plt.get_cmap('viridis'). cmap.set_under('lightgray'). cmap.set_bad('lightgray'). fig, ax = plt.subplots(). cax = ax.scatter(adata.obsm['X_umap'][:,0], adata.obsm['X_umap'][:,1], . c=adata.obs['n_genes'], s=20, . cmap=cmap, . vmin=1000, . vmax=2000, plotnonfinite=True). fig.colorbar(cax, extend='min', extendrect=True, extendfrac=0.1). plt.show(). ```. ![image](https://user-images.githubusercontent.com/4964309/90750699-7b22a180-e2d5-11ea-9a67-1ad7feb8a6a4.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:896,modifiability,exten,extendfrac,896,"For continuous values I don't think we need to add anything to the color bar. If a dot color is not part of the colorbar then is assumed that is a NaN. I searched in matplotlib for a similar case in which a colorbar includes NaN values but could not find any example. If this feature is wanted, what we can do is to use the option for colorbar extension and use it for NaNs but we need to find a way to set the label for NaN. ```PYTHON. import numpy as np. import matplotlib.pyplot as plt. adata = sc.datasets.pbmc68k_reduced(). adata.obs['n_genes'].iloc[::4] = np.nan. cmap = plt.get_cmap('viridis'). cmap.set_under('lightgray'). cmap.set_bad('lightgray'). fig, ax = plt.subplots(). cax = ax.scatter(adata.obsm['X_umap'][:,0], adata.obsm['X_umap'][:,1], . c=adata.obs['n_genes'], s=20, . cmap=cmap, . vmin=1000, . vmax=2000, plotnonfinite=True). fig.colorbar(cax, extend='min', extendrect=True, extendfrac=0.1). plt.show(). ```. ![image](https://user-images.githubusercontent.com/4964309/90750699-7b22a180-e2d5-11ea-9a67-1ad7feb8a6a4.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:947,usability,user,user-images,947,"For continuous values I don't think we need to add anything to the color bar. If a dot color is not part of the colorbar then is assumed that is a NaN. I searched in matplotlib for a similar case in which a colorbar includes NaN values but could not find any example. If this feature is wanted, what we can do is to use the option for colorbar extension and use it for NaNs but we need to find a way to set the label for NaN. ```PYTHON. import numpy as np. import matplotlib.pyplot as plt. adata = sc.datasets.pbmc68k_reduced(). adata.obs['n_genes'].iloc[::4] = np.nan. cmap = plt.get_cmap('viridis'). cmap.set_under('lightgray'). cmap.set_bad('lightgray'). fig, ax = plt.subplots(). cax = ax.scatter(adata.obsm['X_umap'][:,0], adata.obsm['X_umap'][:,1], . c=adata.obs['n_genes'], s=20, . cmap=cmap, . vmin=1000, . vmax=2000, plotnonfinite=True). fig.colorbar(cax, extend='min', extendrect=True, extendfrac=0.1). plt.show(). ```. ![image](https://user-images.githubusercontent.com/4964309/90750699-7b22a180-e2d5-11ea-9a67-1ad7feb8a6a4.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:100,deployability,continu,continuous,100,"I think this is now ready for review. . ## Legends. I've decided to leave showing the null value in continuous legends for another PR, since I don't have an obvious solution now. I have added an argument for specifying whether the na value should show up in the legend, `na_in_legend`. It defaults to `True`. Here's an example:. ```python. sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""]). sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], na_in_legend=False). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855448-fd3cc400-e3c2-11ea-9e01-6e8266ab6d10.png). ![image](https://user-images.githubusercontent.com/8238804/90855459-0332a500-e3c3-11ea-8b7b-0ba997664f93.png). </details>. The current default of true is a bit weird for ""on data"":. ```python. sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data""). sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data"", na_in_legend=False). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855740-a8e61400-e3c3-11ea-99fa-d9cdcd3320ed.png). ![image](https://user-images.githubusercontent.com/8238804/90855745-abe10480-e3c3-11ea-88fd-9c794c95773d.png). </details>. ## Missing color. The missing color can now be specified with `na_color`. This defaults to transparent for spatial plots, and light gray for all other embedding based plots. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""]). sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""], na_color=(.8, .8, .8, .2)). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855677-894eeb80-e3c3-11ea-91a5-51049080af45.png). ![image](https://user-images.githubusercontent.com/8238804/90855880-05493380-e3c4-11ea-878b-492872198b7f.png). </details>. ## Tests. I've added a parameterized regression test around a perhaps-to",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:751,energy efficiency,current,current,751,"I think this is now ready for review. . ## Legends. I've decided to leave showing the null value in continuous legends for another PR, since I don't have an obvious solution now. I have added an argument for specifying whether the na value should show up in the legend, `na_in_legend`. It defaults to `True`. Here's an example:. ```python. sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""]). sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], na_in_legend=False). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855448-fd3cc400-e3c2-11ea-9e01-6e8266ab6d10.png). ![image](https://user-images.githubusercontent.com/8238804/90855459-0332a500-e3c3-11ea-8b7b-0ba997664f93.png). </details>. The current default of true is a bit weird for ""on data"":. ```python. sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data""). sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data"", na_in_legend=False). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855740-a8e61400-e3c3-11ea-99fa-d9cdcd3320ed.png). ![image](https://user-images.githubusercontent.com/8238804/90855745-abe10480-e3c3-11ea-88fd-9c794c95773d.png). </details>. ## Missing color. The missing color can now be specified with `na_color`. This defaults to transparent for spatial plots, and light gray for all other embedding based plots. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""]). sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""], na_color=(.8, .8, .8, .2)). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855677-894eeb80-e3c3-11ea-91a5-51049080af45.png). ![image](https://user-images.githubusercontent.com/8238804/90855880-05493380-e3c4-11ea-878b-492872198b7f.png). </details>. ## Tests. I've added a parameterized regression test around a perhaps-to",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:2611,energy efficiency,current,current,2611,"age](https://user-images.githubusercontent.com/8238804/90855459-0332a500-e3c3-11ea-8b7b-0ba997664f93.png). </details>. The current default of true is a bit weird for ""on data"":. ```python. sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data""). sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data"", na_in_legend=False). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855740-a8e61400-e3c3-11ea-99fa-d9cdcd3320ed.png). ![image](https://user-images.githubusercontent.com/8238804/90855745-abe10480-e3c3-11ea-88fd-9c794c95773d.png). </details>. ## Missing color. The missing color can now be specified with `na_color`. This defaults to transparent for spatial plots, and light gray for all other embedding based plots. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""]). sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""], na_color=(.8, .8, .8, .2)). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855677-894eeb80-e3c3-11ea-91a5-51049080af45.png). ![image](https://user-images.githubusercontent.com/8238804/90855880-05493380-e3c4-11ea-878b-492872198b7f.png). </details>. ## Tests. I've added a parameterized regression test around a perhaps-too-cute test case. <details>. <summary> Test case </summary>. ```python. sc.pl.spatial(adata, color=""label""). ```. ![image](https://user-images.githubusercontent.com/8238804/90856156-ab953900-e3c4-11ea-83da-9caf5fb5d82e.png). </details>. This test makes a lot of files, so I'll rebase the revisions away before merge. ## Possible problems. * I'm hoping I haven't missed any edge cases, but would appreciate some testing from @giovp and @fidelram. * What do you think about the interaction between `groups` and `legend_loc=""on data""`? I'd like to keep `na_in_legend` as a simple boolean, but this does change the current behavior.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:208,interoperability,specif,specifying,208,"I think this is now ready for review. . ## Legends. I've decided to leave showing the null value in continuous legends for another PR, since I don't have an obvious solution now. I have added an argument for specifying whether the na value should show up in the legend, `na_in_legend`. It defaults to `True`. Here's an example:. ```python. sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""]). sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], na_in_legend=False). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855448-fd3cc400-e3c2-11ea-9e01-6e8266ab6d10.png). ![image](https://user-images.githubusercontent.com/8238804/90855459-0332a500-e3c3-11ea-8b7b-0ba997664f93.png). </details>. The current default of true is a bit weird for ""on data"":. ```python. sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data""). sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data"", na_in_legend=False). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855740-a8e61400-e3c3-11ea-99fa-d9cdcd3320ed.png). ![image](https://user-images.githubusercontent.com/8238804/90855745-abe10480-e3c3-11ea-88fd-9c794c95773d.png). </details>. ## Missing color. The missing color can now be specified with `na_color`. This defaults to transparent for spatial plots, and light gray for all other embedding based plots. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""]). sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""], na_color=(.8, .8, .8, .2)). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855677-894eeb80-e3c3-11ea-91a5-51049080af45.png). ![image](https://user-images.githubusercontent.com/8238804/90855880-05493380-e3c4-11ea-878b-492872198b7f.png). </details>. ## Tests. I've added a parameterized regression test around a perhaps-to",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:1315,interoperability,specif,specified,1315,"xample:. ```python. sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""]). sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], na_in_legend=False). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855448-fd3cc400-e3c2-11ea-9e01-6e8266ab6d10.png). ![image](https://user-images.githubusercontent.com/8238804/90855459-0332a500-e3c3-11ea-8b7b-0ba997664f93.png). </details>. The current default of true is a bit weird for ""on data"":. ```python. sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data""). sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data"", na_in_legend=False). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855740-a8e61400-e3c3-11ea-99fa-d9cdcd3320ed.png). ![image](https://user-images.githubusercontent.com/8238804/90855745-abe10480-e3c3-11ea-88fd-9c794c95773d.png). </details>. ## Missing color. The missing color can now be specified with `na_color`. This defaults to transparent for spatial plots, and light gray for all other embedding based plots. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""]). sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""], na_color=(.8, .8, .8, .2)). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855677-894eeb80-e3c3-11ea-91a5-51049080af45.png). ![image](https://user-images.githubusercontent.com/8238804/90855880-05493380-e3c4-11ea-878b-492872198b7f.png). </details>. ## Tests. I've added a parameterized regression test around a perhaps-too-cute test case. <details>. <summary> Test case </summary>. ```python. sc.pl.spatial(adata, color=""label""). ```. ![image](https://user-images.githubusercontent.com/8238804/90856156-ab953900-e3c4-11ea-83da-9caf5fb5d82e.png). </details>. This test makes a lot of files, so I'll rebase the revisions away before merge. ## ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:1951,modifiability,paramet,parameterized,1951,"age](https://user-images.githubusercontent.com/8238804/90855459-0332a500-e3c3-11ea-8b7b-0ba997664f93.png). </details>. The current default of true is a bit weird for ""on data"":. ```python. sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data""). sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data"", na_in_legend=False). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855740-a8e61400-e3c3-11ea-99fa-d9cdcd3320ed.png). ![image](https://user-images.githubusercontent.com/8238804/90855745-abe10480-e3c3-11ea-88fd-9c794c95773d.png). </details>. ## Missing color. The missing color can now be specified with `na_color`. This defaults to transparent for spatial plots, and light gray for all other embedding based plots. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""]). sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""], na_color=(.8, .8, .8, .2)). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855677-894eeb80-e3c3-11ea-91a5-51049080af45.png). ![image](https://user-images.githubusercontent.com/8238804/90855880-05493380-e3c4-11ea-878b-492872198b7f.png). </details>. ## Tests. I've added a parameterized regression test around a perhaps-too-cute test case. <details>. <summary> Test case </summary>. ```python. sc.pl.spatial(adata, color=""label""). ```. ![image](https://user-images.githubusercontent.com/8238804/90856156-ab953900-e3c4-11ea-83da-9caf5fb5d82e.png). </details>. This test makes a lot of files, so I'll rebase the revisions away before merge. ## Possible problems. * I'm hoping I haven't missed any edge cases, but would appreciate some testing from @giovp and @fidelram. * What do you think about the interaction between `groups` and `legend_loc=""on data""`? I'd like to keep `na_in_legend` as a simple boolean, but this does change the current behavior.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:2595,reliability,doe,does,2595,"age](https://user-images.githubusercontent.com/8238804/90855459-0332a500-e3c3-11ea-8b7b-0ba997664f93.png). </details>. The current default of true is a bit weird for ""on data"":. ```python. sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data""). sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data"", na_in_legend=False). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855740-a8e61400-e3c3-11ea-99fa-d9cdcd3320ed.png). ![image](https://user-images.githubusercontent.com/8238804/90855745-abe10480-e3c3-11ea-88fd-9c794c95773d.png). </details>. ## Missing color. The missing color can now be specified with `na_color`. This defaults to transparent for spatial plots, and light gray for all other embedding based plots. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""]). sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""], na_color=(.8, .8, .8, .2)). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855677-894eeb80-e3c3-11ea-91a5-51049080af45.png). ![image](https://user-images.githubusercontent.com/8238804/90855880-05493380-e3c4-11ea-878b-492872198b7f.png). </details>. ## Tests. I've added a parameterized regression test around a perhaps-too-cute test case. <details>. <summary> Test case </summary>. ```python. sc.pl.spatial(adata, color=""label""). ```. ![image](https://user-images.githubusercontent.com/8238804/90856156-ab953900-e3c4-11ea-83da-9caf5fb5d82e.png). </details>. This test makes a lot of files, so I'll rebase the revisions away before merge. ## Possible problems. * I'm hoping I haven't missed any edge cases, but would appreciate some testing from @giovp and @fidelram. * What do you think about the interaction between `groups` and `legend_loc=""on data""`? I'd like to keep `na_in_legend` as a simple boolean, but this does change the current behavior.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:30,safety,review,review,30,"I think this is now ready for review. . ## Legends. I've decided to leave showing the null value in continuous legends for another PR, since I don't have an obvious solution now. I have added an argument for specifying whether the na value should show up in the legend, `na_in_legend`. It defaults to `True`. Here's an example:. ```python. sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""]). sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], na_in_legend=False). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855448-fd3cc400-e3c2-11ea-9e01-6e8266ab6d10.png). ![image](https://user-images.githubusercontent.com/8238804/90855459-0332a500-e3c3-11ea-8b7b-0ba997664f93.png). </details>. The current default of true is a bit weird for ""on data"":. ```python. sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data""). sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data"", na_in_legend=False). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855740-a8e61400-e3c3-11ea-99fa-d9cdcd3320ed.png). ![image](https://user-images.githubusercontent.com/8238804/90855745-abe10480-e3c3-11ea-88fd-9c794c95773d.png). </details>. ## Missing color. The missing color can now be specified with `na_color`. This defaults to transparent for spatial plots, and light gray for all other embedding based plots. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""]). sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""], na_color=(.8, .8, .8, .2)). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855677-894eeb80-e3c3-11ea-91a5-51049080af45.png). ![image](https://user-images.githubusercontent.com/8238804/90855880-05493380-e3c4-11ea-878b-492872198b7f.png). </details>. ## Tests. I've added a parameterized regression test around a perhaps-to",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:1931,safety,Test,Tests,1931,"age](https://user-images.githubusercontent.com/8238804/90855459-0332a500-e3c3-11ea-8b7b-0ba997664f93.png). </details>. The current default of true is a bit weird for ""on data"":. ```python. sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data""). sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data"", na_in_legend=False). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855740-a8e61400-e3c3-11ea-99fa-d9cdcd3320ed.png). ![image](https://user-images.githubusercontent.com/8238804/90855745-abe10480-e3c3-11ea-88fd-9c794c95773d.png). </details>. ## Missing color. The missing color can now be specified with `na_color`. This defaults to transparent for spatial plots, and light gray for all other embedding based plots. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""]). sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""], na_color=(.8, .8, .8, .2)). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855677-894eeb80-e3c3-11ea-91a5-51049080af45.png). ![image](https://user-images.githubusercontent.com/8238804/90855880-05493380-e3c4-11ea-878b-492872198b7f.png). </details>. ## Tests. I've added a parameterized regression test around a perhaps-too-cute test case. <details>. <summary> Test case </summary>. ```python. sc.pl.spatial(adata, color=""label""). ```. ![image](https://user-images.githubusercontent.com/8238804/90856156-ab953900-e3c4-11ea-83da-9caf5fb5d82e.png). </details>. This test makes a lot of files, so I'll rebase the revisions away before merge. ## Possible problems. * I'm hoping I haven't missed any edge cases, but would appreciate some testing from @giovp and @fidelram. * What do you think about the interaction between `groups` and `legend_loc=""on data""`? I'd like to keep `na_in_legend` as a simple boolean, but this does change the current behavior.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:1976,safety,test,test,1976,"age](https://user-images.githubusercontent.com/8238804/90855459-0332a500-e3c3-11ea-8b7b-0ba997664f93.png). </details>. The current default of true is a bit weird for ""on data"":. ```python. sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data""). sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data"", na_in_legend=False). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855740-a8e61400-e3c3-11ea-99fa-d9cdcd3320ed.png). ![image](https://user-images.githubusercontent.com/8238804/90855745-abe10480-e3c3-11ea-88fd-9c794c95773d.png). </details>. ## Missing color. The missing color can now be specified with `na_color`. This defaults to transparent for spatial plots, and light gray for all other embedding based plots. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""]). sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""], na_color=(.8, .8, .8, .2)). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855677-894eeb80-e3c3-11ea-91a5-51049080af45.png). ![image](https://user-images.githubusercontent.com/8238804/90855880-05493380-e3c4-11ea-878b-492872198b7f.png). </details>. ## Tests. I've added a parameterized regression test around a perhaps-too-cute test case. <details>. <summary> Test case </summary>. ```python. sc.pl.spatial(adata, color=""label""). ```. ![image](https://user-images.githubusercontent.com/8238804/90856156-ab953900-e3c4-11ea-83da-9caf5fb5d82e.png). </details>. This test makes a lot of files, so I'll rebase the revisions away before merge. ## Possible problems. * I'm hoping I haven't missed any edge cases, but would appreciate some testing from @giovp and @fidelram. * What do you think about the interaction between `groups` and `legend_loc=""on data""`? I'd like to keep `na_in_legend` as a simple boolean, but this does change the current behavior.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:2007,safety,test,test,2007,"age](https://user-images.githubusercontent.com/8238804/90855459-0332a500-e3c3-11ea-8b7b-0ba997664f93.png). </details>. The current default of true is a bit weird for ""on data"":. ```python. sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data""). sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data"", na_in_legend=False). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855740-a8e61400-e3c3-11ea-99fa-d9cdcd3320ed.png). ![image](https://user-images.githubusercontent.com/8238804/90855745-abe10480-e3c3-11ea-88fd-9c794c95773d.png). </details>. ## Missing color. The missing color can now be specified with `na_color`. This defaults to transparent for spatial plots, and light gray for all other embedding based plots. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""]). sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""], na_color=(.8, .8, .8, .2)). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855677-894eeb80-e3c3-11ea-91a5-51049080af45.png). ![image](https://user-images.githubusercontent.com/8238804/90855880-05493380-e3c4-11ea-878b-492872198b7f.png). </details>. ## Tests. I've added a parameterized regression test around a perhaps-too-cute test case. <details>. <summary> Test case </summary>. ```python. sc.pl.spatial(adata, color=""label""). ```. ![image](https://user-images.githubusercontent.com/8238804/90856156-ab953900-e3c4-11ea-83da-9caf5fb5d82e.png). </details>. This test makes a lot of files, so I'll rebase the revisions away before merge. ## Possible problems. * I'm hoping I haven't missed any edge cases, but would appreciate some testing from @giovp and @fidelram. * What do you think about the interaction between `groups` and `legend_loc=""on data""`? I'd like to keep `na_in_legend` as a simple boolean, but this does change the current behavior.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:2039,safety,Test,Test,2039,"age](https://user-images.githubusercontent.com/8238804/90855459-0332a500-e3c3-11ea-8b7b-0ba997664f93.png). </details>. The current default of true is a bit weird for ""on data"":. ```python. sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data""). sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data"", na_in_legend=False). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855740-a8e61400-e3c3-11ea-99fa-d9cdcd3320ed.png). ![image](https://user-images.githubusercontent.com/8238804/90855745-abe10480-e3c3-11ea-88fd-9c794c95773d.png). </details>. ## Missing color. The missing color can now be specified with `na_color`. This defaults to transparent for spatial plots, and light gray for all other embedding based plots. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""]). sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""], na_color=(.8, .8, .8, .2)). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855677-894eeb80-e3c3-11ea-91a5-51049080af45.png). ![image](https://user-images.githubusercontent.com/8238804/90855880-05493380-e3c4-11ea-878b-492872198b7f.png). </details>. ## Tests. I've added a parameterized regression test around a perhaps-too-cute test case. <details>. <summary> Test case </summary>. ```python. sc.pl.spatial(adata, color=""label""). ```. ![image](https://user-images.githubusercontent.com/8238804/90856156-ab953900-e3c4-11ea-83da-9caf5fb5d82e.png). </details>. This test makes a lot of files, so I'll rebase the revisions away before merge. ## Possible problems. * I'm hoping I haven't missed any edge cases, but would appreciate some testing from @giovp and @fidelram. * What do you think about the interaction between `groups` and `legend_loc=""on data""`? I'd like to keep `na_in_legend` as a simple boolean, but this does change the current behavior.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:2242,safety,test,test,2242,"age](https://user-images.githubusercontent.com/8238804/90855459-0332a500-e3c3-11ea-8b7b-0ba997664f93.png). </details>. The current default of true is a bit weird for ""on data"":. ```python. sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data""). sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data"", na_in_legend=False). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855740-a8e61400-e3c3-11ea-99fa-d9cdcd3320ed.png). ![image](https://user-images.githubusercontent.com/8238804/90855745-abe10480-e3c3-11ea-88fd-9c794c95773d.png). </details>. ## Missing color. The missing color can now be specified with `na_color`. This defaults to transparent for spatial plots, and light gray for all other embedding based plots. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""]). sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""], na_color=(.8, .8, .8, .2)). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855677-894eeb80-e3c3-11ea-91a5-51049080af45.png). ![image](https://user-images.githubusercontent.com/8238804/90855880-05493380-e3c4-11ea-878b-492872198b7f.png). </details>. ## Tests. I've added a parameterized regression test around a perhaps-too-cute test case. <details>. <summary> Test case </summary>. ```python. sc.pl.spatial(adata, color=""label""). ```. ![image](https://user-images.githubusercontent.com/8238804/90856156-ab953900-e3c4-11ea-83da-9caf5fb5d82e.png). </details>. This test makes a lot of files, so I'll rebase the revisions away before merge. ## Possible problems. * I'm hoping I haven't missed any edge cases, but would appreciate some testing from @giovp and @fidelram. * What do you think about the interaction between `groups` and `legend_loc=""on data""`? I'd like to keep `na_in_legend` as a simple boolean, but this does change the current behavior.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:2411,safety,test,testing,2411,"age](https://user-images.githubusercontent.com/8238804/90855459-0332a500-e3c3-11ea-8b7b-0ba997664f93.png). </details>. The current default of true is a bit weird for ""on data"":. ```python. sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data""). sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data"", na_in_legend=False). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855740-a8e61400-e3c3-11ea-99fa-d9cdcd3320ed.png). ![image](https://user-images.githubusercontent.com/8238804/90855745-abe10480-e3c3-11ea-88fd-9c794c95773d.png). </details>. ## Missing color. The missing color can now be specified with `na_color`. This defaults to transparent for spatial plots, and light gray for all other embedding based plots. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""]). sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""], na_color=(.8, .8, .8, .2)). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855677-894eeb80-e3c3-11ea-91a5-51049080af45.png). ![image](https://user-images.githubusercontent.com/8238804/90855880-05493380-e3c4-11ea-878b-492872198b7f.png). </details>. ## Tests. I've added a parameterized regression test around a perhaps-too-cute test case. <details>. <summary> Test case </summary>. ```python. sc.pl.spatial(adata, color=""label""). ```. ![image](https://user-images.githubusercontent.com/8238804/90856156-ab953900-e3c4-11ea-83da-9caf5fb5d82e.png). </details>. This test makes a lot of files, so I'll rebase the revisions away before merge. ## Possible problems. * I'm hoping I haven't missed any edge cases, but would appreciate some testing from @giovp and @fidelram. * What do you think about the interaction between `groups` and `legend_loc=""on data""`? I'd like to keep `na_in_legend` as a simple boolean, but this does change the current behavior.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:30,testability,review,review,30,"I think this is now ready for review. . ## Legends. I've decided to leave showing the null value in continuous legends for another PR, since I don't have an obvious solution now. I have added an argument for specifying whether the na value should show up in the legend, `na_in_legend`. It defaults to `True`. Here's an example:. ```python. sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""]). sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], na_in_legend=False). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855448-fd3cc400-e3c2-11ea-9e01-6e8266ab6d10.png). ![image](https://user-images.githubusercontent.com/8238804/90855459-0332a500-e3c3-11ea-8b7b-0ba997664f93.png). </details>. The current default of true is a bit weird for ""on data"":. ```python. sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data""). sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data"", na_in_legend=False). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855740-a8e61400-e3c3-11ea-99fa-d9cdcd3320ed.png). ![image](https://user-images.githubusercontent.com/8238804/90855745-abe10480-e3c3-11ea-88fd-9c794c95773d.png). </details>. ## Missing color. The missing color can now be specified with `na_color`. This defaults to transparent for spatial plots, and light gray for all other embedding based plots. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""]). sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""], na_color=(.8, .8, .8, .2)). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855677-894eeb80-e3c3-11ea-91a5-51049080af45.png). ![image](https://user-images.githubusercontent.com/8238804/90855880-05493380-e3c4-11ea-878b-492872198b7f.png). </details>. ## Tests. I've added a parameterized regression test around a perhaps-to",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:1931,testability,Test,Tests,1931,"age](https://user-images.githubusercontent.com/8238804/90855459-0332a500-e3c3-11ea-8b7b-0ba997664f93.png). </details>. The current default of true is a bit weird for ""on data"":. ```python. sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data""). sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data"", na_in_legend=False). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855740-a8e61400-e3c3-11ea-99fa-d9cdcd3320ed.png). ![image](https://user-images.githubusercontent.com/8238804/90855745-abe10480-e3c3-11ea-88fd-9c794c95773d.png). </details>. ## Missing color. The missing color can now be specified with `na_color`. This defaults to transparent for spatial plots, and light gray for all other embedding based plots. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""]). sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""], na_color=(.8, .8, .8, .2)). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855677-894eeb80-e3c3-11ea-91a5-51049080af45.png). ![image](https://user-images.githubusercontent.com/8238804/90855880-05493380-e3c4-11ea-878b-492872198b7f.png). </details>. ## Tests. I've added a parameterized regression test around a perhaps-too-cute test case. <details>. <summary> Test case </summary>. ```python. sc.pl.spatial(adata, color=""label""). ```. ![image](https://user-images.githubusercontent.com/8238804/90856156-ab953900-e3c4-11ea-83da-9caf5fb5d82e.png). </details>. This test makes a lot of files, so I'll rebase the revisions away before merge. ## Possible problems. * I'm hoping I haven't missed any edge cases, but would appreciate some testing from @giovp and @fidelram. * What do you think about the interaction between `groups` and `legend_loc=""on data""`? I'd like to keep `na_in_legend` as a simple boolean, but this does change the current behavior.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:1965,testability,regress,regression,1965,"age](https://user-images.githubusercontent.com/8238804/90855459-0332a500-e3c3-11ea-8b7b-0ba997664f93.png). </details>. The current default of true is a bit weird for ""on data"":. ```python. sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data""). sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data"", na_in_legend=False). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855740-a8e61400-e3c3-11ea-99fa-d9cdcd3320ed.png). ![image](https://user-images.githubusercontent.com/8238804/90855745-abe10480-e3c3-11ea-88fd-9c794c95773d.png). </details>. ## Missing color. The missing color can now be specified with `na_color`. This defaults to transparent for spatial plots, and light gray for all other embedding based plots. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""]). sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""], na_color=(.8, .8, .8, .2)). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855677-894eeb80-e3c3-11ea-91a5-51049080af45.png). ![image](https://user-images.githubusercontent.com/8238804/90855880-05493380-e3c4-11ea-878b-492872198b7f.png). </details>. ## Tests. I've added a parameterized regression test around a perhaps-too-cute test case. <details>. <summary> Test case </summary>. ```python. sc.pl.spatial(adata, color=""label""). ```. ![image](https://user-images.githubusercontent.com/8238804/90856156-ab953900-e3c4-11ea-83da-9caf5fb5d82e.png). </details>. This test makes a lot of files, so I'll rebase the revisions away before merge. ## Possible problems. * I'm hoping I haven't missed any edge cases, but would appreciate some testing from @giovp and @fidelram. * What do you think about the interaction between `groups` and `legend_loc=""on data""`? I'd like to keep `na_in_legend` as a simple boolean, but this does change the current behavior.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:1976,testability,test,test,1976,"age](https://user-images.githubusercontent.com/8238804/90855459-0332a500-e3c3-11ea-8b7b-0ba997664f93.png). </details>. The current default of true is a bit weird for ""on data"":. ```python. sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data""). sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data"", na_in_legend=False). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855740-a8e61400-e3c3-11ea-99fa-d9cdcd3320ed.png). ![image](https://user-images.githubusercontent.com/8238804/90855745-abe10480-e3c3-11ea-88fd-9c794c95773d.png). </details>. ## Missing color. The missing color can now be specified with `na_color`. This defaults to transparent for spatial plots, and light gray for all other embedding based plots. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""]). sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""], na_color=(.8, .8, .8, .2)). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855677-894eeb80-e3c3-11ea-91a5-51049080af45.png). ![image](https://user-images.githubusercontent.com/8238804/90855880-05493380-e3c4-11ea-878b-492872198b7f.png). </details>. ## Tests. I've added a parameterized regression test around a perhaps-too-cute test case. <details>. <summary> Test case </summary>. ```python. sc.pl.spatial(adata, color=""label""). ```. ![image](https://user-images.githubusercontent.com/8238804/90856156-ab953900-e3c4-11ea-83da-9caf5fb5d82e.png). </details>. This test makes a lot of files, so I'll rebase the revisions away before merge. ## Possible problems. * I'm hoping I haven't missed any edge cases, but would appreciate some testing from @giovp and @fidelram. * What do you think about the interaction between `groups` and `legend_loc=""on data""`? I'd like to keep `na_in_legend` as a simple boolean, but this does change the current behavior.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:2007,testability,test,test,2007,"age](https://user-images.githubusercontent.com/8238804/90855459-0332a500-e3c3-11ea-8b7b-0ba997664f93.png). </details>. The current default of true is a bit weird for ""on data"":. ```python. sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data""). sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data"", na_in_legend=False). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855740-a8e61400-e3c3-11ea-99fa-d9cdcd3320ed.png). ![image](https://user-images.githubusercontent.com/8238804/90855745-abe10480-e3c3-11ea-88fd-9c794c95773d.png). </details>. ## Missing color. The missing color can now be specified with `na_color`. This defaults to transparent for spatial plots, and light gray for all other embedding based plots. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""]). sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""], na_color=(.8, .8, .8, .2)). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855677-894eeb80-e3c3-11ea-91a5-51049080af45.png). ![image](https://user-images.githubusercontent.com/8238804/90855880-05493380-e3c4-11ea-878b-492872198b7f.png). </details>. ## Tests. I've added a parameterized regression test around a perhaps-too-cute test case. <details>. <summary> Test case </summary>. ```python. sc.pl.spatial(adata, color=""label""). ```. ![image](https://user-images.githubusercontent.com/8238804/90856156-ab953900-e3c4-11ea-83da-9caf5fb5d82e.png). </details>. This test makes a lot of files, so I'll rebase the revisions away before merge. ## Possible problems. * I'm hoping I haven't missed any edge cases, but would appreciate some testing from @giovp and @fidelram. * What do you think about the interaction between `groups` and `legend_loc=""on data""`? I'd like to keep `na_in_legend` as a simple boolean, but this does change the current behavior.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:2039,testability,Test,Test,2039,"age](https://user-images.githubusercontent.com/8238804/90855459-0332a500-e3c3-11ea-8b7b-0ba997664f93.png). </details>. The current default of true is a bit weird for ""on data"":. ```python. sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data""). sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data"", na_in_legend=False). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855740-a8e61400-e3c3-11ea-99fa-d9cdcd3320ed.png). ![image](https://user-images.githubusercontent.com/8238804/90855745-abe10480-e3c3-11ea-88fd-9c794c95773d.png). </details>. ## Missing color. The missing color can now be specified with `na_color`. This defaults to transparent for spatial plots, and light gray for all other embedding based plots. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""]). sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""], na_color=(.8, .8, .8, .2)). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855677-894eeb80-e3c3-11ea-91a5-51049080af45.png). ![image](https://user-images.githubusercontent.com/8238804/90855880-05493380-e3c4-11ea-878b-492872198b7f.png). </details>. ## Tests. I've added a parameterized regression test around a perhaps-too-cute test case. <details>. <summary> Test case </summary>. ```python. sc.pl.spatial(adata, color=""label""). ```. ![image](https://user-images.githubusercontent.com/8238804/90856156-ab953900-e3c4-11ea-83da-9caf5fb5d82e.png). </details>. This test makes a lot of files, so I'll rebase the revisions away before merge. ## Possible problems. * I'm hoping I haven't missed any edge cases, but would appreciate some testing from @giovp and @fidelram. * What do you think about the interaction between `groups` and `legend_loc=""on data""`? I'd like to keep `na_in_legend` as a simple boolean, but this does change the current behavior.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:2242,testability,test,test,2242,"age](https://user-images.githubusercontent.com/8238804/90855459-0332a500-e3c3-11ea-8b7b-0ba997664f93.png). </details>. The current default of true is a bit weird for ""on data"":. ```python. sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data""). sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data"", na_in_legend=False). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855740-a8e61400-e3c3-11ea-99fa-d9cdcd3320ed.png). ![image](https://user-images.githubusercontent.com/8238804/90855745-abe10480-e3c3-11ea-88fd-9c794c95773d.png). </details>. ## Missing color. The missing color can now be specified with `na_color`. This defaults to transparent for spatial plots, and light gray for all other embedding based plots. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""]). sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""], na_color=(.8, .8, .8, .2)). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855677-894eeb80-e3c3-11ea-91a5-51049080af45.png). ![image](https://user-images.githubusercontent.com/8238804/90855880-05493380-e3c4-11ea-878b-492872198b7f.png). </details>. ## Tests. I've added a parameterized regression test around a perhaps-too-cute test case. <details>. <summary> Test case </summary>. ```python. sc.pl.spatial(adata, color=""label""). ```. ![image](https://user-images.githubusercontent.com/8238804/90856156-ab953900-e3c4-11ea-83da-9caf5fb5d82e.png). </details>. This test makes a lot of files, so I'll rebase the revisions away before merge. ## Possible problems. * I'm hoping I haven't missed any edge cases, but would appreciate some testing from @giovp and @fidelram. * What do you think about the interaction between `groups` and `legend_loc=""on data""`? I'd like to keep `na_in_legend` as a simple boolean, but this does change the current behavior.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:2411,testability,test,testing,2411,"age](https://user-images.githubusercontent.com/8238804/90855459-0332a500-e3c3-11ea-8b7b-0ba997664f93.png). </details>. The current default of true is a bit weird for ""on data"":. ```python. sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data""). sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data"", na_in_legend=False). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855740-a8e61400-e3c3-11ea-99fa-d9cdcd3320ed.png). ![image](https://user-images.githubusercontent.com/8238804/90855745-abe10480-e3c3-11ea-88fd-9c794c95773d.png). </details>. ## Missing color. The missing color can now be specified with `na_color`. This defaults to transparent for spatial plots, and light gray for all other embedding based plots. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""]). sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""], na_color=(.8, .8, .8, .2)). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855677-894eeb80-e3c3-11ea-91a5-51049080af45.png). ![image](https://user-images.githubusercontent.com/8238804/90855880-05493380-e3c4-11ea-878b-492872198b7f.png). </details>. ## Tests. I've added a parameterized regression test around a perhaps-too-cute test case. <details>. <summary> Test case </summary>. ```python. sc.pl.spatial(adata, color=""label""). ```. ![image](https://user-images.githubusercontent.com/8238804/90856156-ab953900-e3c4-11ea-83da-9caf5fb5d82e.png). </details>. This test makes a lot of files, so I'll rebase the revisions away before merge. ## Possible problems. * I'm hoping I haven't missed any edge cases, but would appreciate some testing from @giovp and @fidelram. * What do you think about the interaction between `groups` and `legend_loc=""on data""`? I'd like to keep `na_in_legend` as a simple boolean, but this does change the current behavior.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:2570,testability,simpl,simple,2570,"age](https://user-images.githubusercontent.com/8238804/90855459-0332a500-e3c3-11ea-8b7b-0ba997664f93.png). </details>. The current default of true is a bit weird for ""on data"":. ```python. sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data""). sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data"", na_in_legend=False). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855740-a8e61400-e3c3-11ea-99fa-d9cdcd3320ed.png). ![image](https://user-images.githubusercontent.com/8238804/90855745-abe10480-e3c3-11ea-88fd-9c794c95773d.png). </details>. ## Missing color. The missing color can now be specified with `na_color`. This defaults to transparent for spatial plots, and light gray for all other embedding based plots. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""]). sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""], na_color=(.8, .8, .8, .2)). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855677-894eeb80-e3c3-11ea-91a5-51049080af45.png). ![image](https://user-images.githubusercontent.com/8238804/90855880-05493380-e3c4-11ea-878b-492872198b7f.png). </details>. ## Tests. I've added a parameterized regression test around a perhaps-too-cute test case. <details>. <summary> Test case </summary>. ```python. sc.pl.spatial(adata, color=""label""). ```. ![image](https://user-images.githubusercontent.com/8238804/90856156-ab953900-e3c4-11ea-83da-9caf5fb5d82e.png). </details>. This test makes a lot of files, so I'll rebase the revisions away before merge. ## Possible problems. * I'm hoping I haven't missed any edge cases, but would appreciate some testing from @giovp and @fidelram. * What do you think about the interaction between `groups` and `legend_loc=""on data""`? I'd like to keep `na_in_legend` as a simple boolean, but this does change the current behavior.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:530,usability,user,user-images,530,"I think this is now ready for review. . ## Legends. I've decided to leave showing the null value in continuous legends for another PR, since I don't have an obvious solution now. I have added an argument for specifying whether the na value should show up in the legend, `na_in_legend`. It defaults to `True`. Here's an example:. ```python. sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""]). sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], na_in_legend=False). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855448-fd3cc400-e3c2-11ea-9e01-6e8266ab6d10.png). ![image](https://user-images.githubusercontent.com/8238804/90855459-0332a500-e3c3-11ea-8b7b-0ba997664f93.png). </details>. The current default of true is a bit weird for ""on data"":. ```python. sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data""). sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data"", na_in_legend=False). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855740-a8e61400-e3c3-11ea-99fa-d9cdcd3320ed.png). ![image](https://user-images.githubusercontent.com/8238804/90855745-abe10480-e3c3-11ea-88fd-9c794c95773d.png). </details>. ## Missing color. The missing color can now be specified with `na_color`. This defaults to transparent for spatial plots, and light gray for all other embedding based plots. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""]). sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""], na_color=(.8, .8, .8, .2)). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855677-894eeb80-e3c3-11ea-91a5-51049080af45.png). ![image](https://user-images.githubusercontent.com/8238804/90855880-05493380-e3c4-11ea-878b-492872198b7f.png). </details>. ## Tests. I've added a parameterized regression test around a perhaps-to",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:641,usability,user,user-images,641,"I think this is now ready for review. . ## Legends. I've decided to leave showing the null value in continuous legends for another PR, since I don't have an obvious solution now. I have added an argument for specifying whether the na value should show up in the legend, `na_in_legend`. It defaults to `True`. Here's an example:. ```python. sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""]). sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], na_in_legend=False). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855448-fd3cc400-e3c2-11ea-9e01-6e8266ab6d10.png). ![image](https://user-images.githubusercontent.com/8238804/90855459-0332a500-e3c3-11ea-8b7b-0ba997664f93.png). </details>. The current default of true is a bit weird for ""on data"":. ```python. sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data""). sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data"", na_in_legend=False). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855740-a8e61400-e3c3-11ea-99fa-d9cdcd3320ed.png). ![image](https://user-images.githubusercontent.com/8238804/90855745-abe10480-e3c3-11ea-88fd-9c794c95773d.png). </details>. ## Missing color. The missing color can now be specified with `na_color`. This defaults to transparent for spatial plots, and light gray for all other embedding based plots. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""]). sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""], na_color=(.8, .8, .8, .2)). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855677-894eeb80-e3c3-11ea-91a5-51049080af45.png). ![image](https://user-images.githubusercontent.com/8238804/90855880-05493380-e3c4-11ea-878b-492872198b7f.png). </details>. ## Tests. I've added a parameterized regression test around a perhaps-to",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:1051,usability,user,user-images,1051,"decided to leave showing the null value in continuous legends for another PR, since I don't have an obvious solution now. I have added an argument for specifying whether the na value should show up in the legend, `na_in_legend`. It defaults to `True`. Here's an example:. ```python. sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""]). sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], na_in_legend=False). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855448-fd3cc400-e3c2-11ea-9e01-6e8266ab6d10.png). ![image](https://user-images.githubusercontent.com/8238804/90855459-0332a500-e3c3-11ea-8b7b-0ba997664f93.png). </details>. The current default of true is a bit weird for ""on data"":. ```python. sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data""). sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data"", na_in_legend=False). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855740-a8e61400-e3c3-11ea-99fa-d9cdcd3320ed.png). ![image](https://user-images.githubusercontent.com/8238804/90855745-abe10480-e3c3-11ea-88fd-9c794c95773d.png). </details>. ## Missing color. The missing color can now be specified with `na_color`. This defaults to transparent for spatial plots, and light gray for all other embedding based plots. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""]). sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""], na_color=(.8, .8, .8, .2)). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855677-894eeb80-e3c3-11ea-91a5-51049080af45.png). ![image](https://user-images.githubusercontent.com/8238804/90855880-05493380-e3c4-11ea-878b-492872198b7f.png). </details>. ## Tests. I've added a parameterized regression test around a perhaps-too-cute test case. <details>. <summary> Test case </summar",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:1162,usability,user,user-images,1162,"ution now. I have added an argument for specifying whether the na value should show up in the legend, `na_in_legend`. It defaults to `True`. Here's an example:. ```python. sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""]). sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], na_in_legend=False). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855448-fd3cc400-e3c2-11ea-9e01-6e8266ab6d10.png). ![image](https://user-images.githubusercontent.com/8238804/90855459-0332a500-e3c3-11ea-8b7b-0ba997664f93.png). </details>. The current default of true is a bit weird for ""on data"":. ```python. sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data""). sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data"", na_in_legend=False). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855740-a8e61400-e3c3-11ea-99fa-d9cdcd3320ed.png). ![image](https://user-images.githubusercontent.com/8238804/90855745-abe10480-e3c3-11ea-88fd-9c794c95773d.png). </details>. ## Missing color. The missing color can now be specified with `na_color`. This defaults to transparent for spatial plots, and light gray for all other embedding based plots. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""]). sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""], na_color=(.8, .8, .8, .2)). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855677-894eeb80-e3c3-11ea-91a5-51049080af45.png). ![image](https://user-images.githubusercontent.com/8238804/90855880-05493380-e3c4-11ea-878b-492872198b7f.png). </details>. ## Tests. I've added a parameterized regression test around a perhaps-too-cute test case. <details>. <summary> Test case </summary>. ```python. sc.pl.spatial(adata, color=""label""). ```. ![image](https://user-images.githubusercontent.com/823",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:1711,usability,user,user-images,1711,"age](https://user-images.githubusercontent.com/8238804/90855459-0332a500-e3c3-11ea-8b7b-0ba997664f93.png). </details>. The current default of true is a bit weird for ""on data"":. ```python. sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data""). sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data"", na_in_legend=False). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855740-a8e61400-e3c3-11ea-99fa-d9cdcd3320ed.png). ![image](https://user-images.githubusercontent.com/8238804/90855745-abe10480-e3c3-11ea-88fd-9c794c95773d.png). </details>. ## Missing color. The missing color can now be specified with `na_color`. This defaults to transparent for spatial plots, and light gray for all other embedding based plots. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""]). sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""], na_color=(.8, .8, .8, .2)). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855677-894eeb80-e3c3-11ea-91a5-51049080af45.png). ![image](https://user-images.githubusercontent.com/8238804/90855880-05493380-e3c4-11ea-878b-492872198b7f.png). </details>. ## Tests. I've added a parameterized regression test around a perhaps-too-cute test case. <details>. <summary> Test case </summary>. ```python. sc.pl.spatial(adata, color=""label""). ```. ![image](https://user-images.githubusercontent.com/8238804/90856156-ab953900-e3c4-11ea-83da-9caf5fb5d82e.png). </details>. This test makes a lot of files, so I'll rebase the revisions away before merge. ## Possible problems. * I'm hoping I haven't missed any edge cases, but would appreciate some testing from @giovp and @fidelram. * What do you think about the interaction between `groups` and `legend_loc=""on data""`? I'd like to keep `na_in_legend` as a simple boolean, but this does change the current behavior.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:1822,usability,user,user-images,1822,"age](https://user-images.githubusercontent.com/8238804/90855459-0332a500-e3c3-11ea-8b7b-0ba997664f93.png). </details>. The current default of true is a bit weird for ""on data"":. ```python. sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data""). sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data"", na_in_legend=False). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855740-a8e61400-e3c3-11ea-99fa-d9cdcd3320ed.png). ![image](https://user-images.githubusercontent.com/8238804/90855745-abe10480-e3c3-11ea-88fd-9c794c95773d.png). </details>. ## Missing color. The missing color can now be specified with `na_color`. This defaults to transparent for spatial plots, and light gray for all other embedding based plots. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""]). sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""], na_color=(.8, .8, .8, .2)). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855677-894eeb80-e3c3-11ea-91a5-51049080af45.png). ![image](https://user-images.githubusercontent.com/8238804/90855880-05493380-e3c4-11ea-878b-492872198b7f.png). </details>. ## Tests. I've added a parameterized regression test around a perhaps-too-cute test case. <details>. <summary> Test case </summary>. ```python. sc.pl.spatial(adata, color=""label""). ```. ![image](https://user-images.githubusercontent.com/8238804/90856156-ab953900-e3c4-11ea-83da-9caf5fb5d82e.png). </details>. This test makes a lot of files, so I'll rebase the revisions away before merge. ## Possible problems. * I'm hoping I haven't missed any edge cases, but would appreciate some testing from @giovp and @fidelram. * What do you think about the interaction between `groups` and `legend_loc=""on data""`? I'd like to keep `na_in_legend` as a simple boolean, but this does change the current behavior.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:2131,usability,user,user-images,2131,"age](https://user-images.githubusercontent.com/8238804/90855459-0332a500-e3c3-11ea-8b7b-0ba997664f93.png). </details>. The current default of true is a bit weird for ""on data"":. ```python. sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data""). sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data"", na_in_legend=False). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855740-a8e61400-e3c3-11ea-99fa-d9cdcd3320ed.png). ![image](https://user-images.githubusercontent.com/8238804/90855745-abe10480-e3c3-11ea-88fd-9c794c95773d.png). </details>. ## Missing color. The missing color can now be specified with `na_color`. This defaults to transparent for spatial plots, and light gray for all other embedding based plots. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""]). sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""], na_color=(.8, .8, .8, .2)). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855677-894eeb80-e3c3-11ea-91a5-51049080af45.png). ![image](https://user-images.githubusercontent.com/8238804/90855880-05493380-e3c4-11ea-878b-492872198b7f.png). </details>. ## Tests. I've added a parameterized regression test around a perhaps-too-cute test case. <details>. <summary> Test case </summary>. ```python. sc.pl.spatial(adata, color=""label""). ```. ![image](https://user-images.githubusercontent.com/8238804/90856156-ab953900-e3c4-11ea-83da-9caf5fb5d82e.png). </details>. This test makes a lot of files, so I'll rebase the revisions away before merge. ## Possible problems. * I'm hoping I haven't missed any edge cases, but would appreciate some testing from @giovp and @fidelram. * What do you think about the interaction between `groups` and `legend_loc=""on data""`? I'd like to keep `na_in_legend` as a simple boolean, but this does change the current behavior.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:2476,usability,interact,interaction,2476,"age](https://user-images.githubusercontent.com/8238804/90855459-0332a500-e3c3-11ea-8b7b-0ba997664f93.png). </details>. The current default of true is a bit weird for ""on data"":. ```python. sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data""). sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data"", na_in_legend=False). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855740-a8e61400-e3c3-11ea-99fa-d9cdcd3320ed.png). ![image](https://user-images.githubusercontent.com/8238804/90855745-abe10480-e3c3-11ea-88fd-9c794c95773d.png). </details>. ## Missing color. The missing color can now be specified with `na_color`. This defaults to transparent for spatial plots, and light gray for all other embedding based plots. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""]). sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""], na_color=(.8, .8, .8, .2)). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855677-894eeb80-e3c3-11ea-91a5-51049080af45.png). ![image](https://user-images.githubusercontent.com/8238804/90855880-05493380-e3c4-11ea-878b-492872198b7f.png). </details>. ## Tests. I've added a parameterized regression test around a perhaps-too-cute test case. <details>. <summary> Test case </summary>. ```python. sc.pl.spatial(adata, color=""label""). ```. ![image](https://user-images.githubusercontent.com/8238804/90856156-ab953900-e3c4-11ea-83da-9caf5fb5d82e.png). </details>. This test makes a lot of files, so I'll rebase the revisions away before merge. ## Possible problems. * I'm hoping I haven't missed any edge cases, but would appreciate some testing from @giovp and @fidelram. * What do you think about the interaction between `groups` and `legend_loc=""on data""`? I'd like to keep `na_in_legend` as a simple boolean, but this does change the current behavior.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:2570,usability,simpl,simple,2570,"age](https://user-images.githubusercontent.com/8238804/90855459-0332a500-e3c3-11ea-8b7b-0ba997664f93.png). </details>. The current default of true is a bit weird for ""on data"":. ```python. sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data""). sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data"", na_in_legend=False). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855740-a8e61400-e3c3-11ea-99fa-d9cdcd3320ed.png). ![image](https://user-images.githubusercontent.com/8238804/90855745-abe10480-e3c3-11ea-88fd-9c794c95773d.png). </details>. ## Missing color. The missing color can now be specified with `na_color`. This defaults to transparent for spatial plots, and light gray for all other embedding based plots. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""]). sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""], na_color=(.8, .8, .8, .2)). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855677-894eeb80-e3c3-11ea-91a5-51049080af45.png). ![image](https://user-images.githubusercontent.com/8238804/90855880-05493380-e3c4-11ea-878b-492872198b7f.png). </details>. ## Tests. I've added a parameterized regression test around a perhaps-too-cute test case. <details>. <summary> Test case </summary>. ```python. sc.pl.spatial(adata, color=""label""). ```. ![image](https://user-images.githubusercontent.com/8238804/90856156-ab953900-e3c4-11ea-83da-9caf5fb5d82e.png). </details>. This test makes a lot of files, so I'll rebase the revisions away before merge. ## Possible problems. * I'm hoping I haven't missed any edge cases, but would appreciate some testing from @giovp and @fidelram. * What do you think about the interaction between `groups` and `legend_loc=""on data""`? I'd like to keep `na_in_legend` as a simple boolean, but this does change the current behavior.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:2619,usability,behavi,behavior,2619,"age](https://user-images.githubusercontent.com/8238804/90855459-0332a500-e3c3-11ea-8b7b-0ba997664f93.png). </details>. The current default of true is a bit weird for ""on data"":. ```python. sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data""). sc.pl.umap(brain, color=""leiden"", groups=[""0"", ""1""], legend_loc=""on data"", na_in_legend=False). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855740-a8e61400-e3c3-11ea-99fa-d9cdcd3320ed.png). ![image](https://user-images.githubusercontent.com/8238804/90855745-abe10480-e3c3-11ea-88fd-9c794c95773d.png). </details>. ## Missing color. The missing color can now be specified with `na_color`. This defaults to transparent for spatial plots, and light gray for all other embedding based plots. ```python. with plt.rc_context({""figure.dpi"": 150}):. sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""]). sc.pl.spatial(brain, color=[""leiden_missing"", ""Bc1_missing""], na_color=(.8, .8, .8, .2)). ```. <details>. <summary> Images </summary>. ![image](https://user-images.githubusercontent.com/8238804/90855677-894eeb80-e3c3-11ea-91a5-51049080af45.png). ![image](https://user-images.githubusercontent.com/8238804/90855880-05493380-e3c4-11ea-878b-492872198b7f.png). </details>. ## Tests. I've added a parameterized regression test around a perhaps-too-cute test case. <details>. <summary> Test case </summary>. ```python. sc.pl.spatial(adata, color=""label""). ```. ![image](https://user-images.githubusercontent.com/8238804/90856156-ab953900-e3c4-11ea-83da-9caf5fb5d82e.png). </details>. This test makes a lot of files, so I'll rebase the revisions away before merge. ## Possible problems. * I'm hoping I haven't missed any edge cases, but would appreciate some testing from @giovp and @fidelram. * What do you think about the interaction between `groups` and `legend_loc=""on data""`? I'd like to keep `na_in_legend` as a simple boolean, but this does change the current behavior.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:746,deployability,version,version,746,"@ivirshup Looks great! I like the new spatial test image ;) well done! I just give it a try and didn't find any problem. One little change: can you add to the legend of `na_color` that this is also the color used when the parameter for `color` is not given. . I noticed two parameters in the embedding that I think belong only to the spatial.. Those are `bw` and `alpha_img`. In embeddings they do nothing. . Other issue, that I don't expect to address at the moment, is the increase in parameters because is becoming difficult to go through the list of parameters when browsing through the documentation. To help on this we can start using alphabetical order for all optional parameters. Other suggestion is to add to the documentation in which version a parameter was added. Thus, power users can easily track changes and try new options.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:783,energy efficiency,power,power,783,"@ivirshup Looks great! I like the new spatial test image ;) well done! I just give it a try and didn't find any problem. One little change: can you add to the legend of `na_color` that this is also the color used when the parameter for `color` is not given. . I noticed two parameters in the embedding that I think belong only to the spatial.. Those are `bw` and `alpha_img`. In embeddings they do nothing. . Other issue, that I don't expect to address at the moment, is the increase in parameters because is becoming difficult to go through the list of parameters when browsing through the documentation. To help on this we can start using alphabetical order for all optional parameters. Other suggestion is to add to the documentation in which version a parameter was added. Thus, power users can easily track changes and try new options.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:746,integrability,version,version,746,"@ivirshup Looks great! I like the new spatial test image ;) well done! I just give it a try and didn't find any problem. One little change: can you add to the legend of `na_color` that this is also the color used when the parameter for `color` is not given. . I noticed two parameters in the embedding that I think belong only to the spatial.. Those are `bw` and `alpha_img`. In embeddings they do nothing. . Other issue, that I don't expect to address at the moment, is the increase in parameters because is becoming difficult to go through the list of parameters when browsing through the documentation. To help on this we can start using alphabetical order for all optional parameters. Other suggestion is to add to the documentation in which version a parameter was added. Thus, power users can easily track changes and try new options.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:222,modifiability,paramet,parameter,222,"@ivirshup Looks great! I like the new spatial test image ;) well done! I just give it a try and didn't find any problem. One little change: can you add to the legend of `na_color` that this is also the color used when the parameter for `color` is not given. . I noticed two parameters in the embedding that I think belong only to the spatial.. Those are `bw` and `alpha_img`. In embeddings they do nothing. . Other issue, that I don't expect to address at the moment, is the increase in parameters because is becoming difficult to go through the list of parameters when browsing through the documentation. To help on this we can start using alphabetical order for all optional parameters. Other suggestion is to add to the documentation in which version a parameter was added. Thus, power users can easily track changes and try new options.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:274,modifiability,paramet,parameters,274,"@ivirshup Looks great! I like the new spatial test image ;) well done! I just give it a try and didn't find any problem. One little change: can you add to the legend of `na_color` that this is also the color used when the parameter for `color` is not given. . I noticed two parameters in the embedding that I think belong only to the spatial.. Those are `bw` and `alpha_img`. In embeddings they do nothing. . Other issue, that I don't expect to address at the moment, is the increase in parameters because is becoming difficult to go through the list of parameters when browsing through the documentation. To help on this we can start using alphabetical order for all optional parameters. Other suggestion is to add to the documentation in which version a parameter was added. Thus, power users can easily track changes and try new options.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:487,modifiability,paramet,parameters,487,"@ivirshup Looks great! I like the new spatial test image ;) well done! I just give it a try and didn't find any problem. One little change: can you add to the legend of `na_color` that this is also the color used when the parameter for `color` is not given. . I noticed two parameters in the embedding that I think belong only to the spatial.. Those are `bw` and `alpha_img`. In embeddings they do nothing. . Other issue, that I don't expect to address at the moment, is the increase in parameters because is becoming difficult to go through the list of parameters when browsing through the documentation. To help on this we can start using alphabetical order for all optional parameters. Other suggestion is to add to the documentation in which version a parameter was added. Thus, power users can easily track changes and try new options.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:554,modifiability,paramet,parameters,554,"@ivirshup Looks great! I like the new spatial test image ;) well done! I just give it a try and didn't find any problem. One little change: can you add to the legend of `na_color` that this is also the color used when the parameter for `color` is not given. . I noticed two parameters in the embedding that I think belong only to the spatial.. Those are `bw` and `alpha_img`. In embeddings they do nothing. . Other issue, that I don't expect to address at the moment, is the increase in parameters because is becoming difficult to go through the list of parameters when browsing through the documentation. To help on this we can start using alphabetical order for all optional parameters. Other suggestion is to add to the documentation in which version a parameter was added. Thus, power users can easily track changes and try new options.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:677,modifiability,paramet,parameters,677,"@ivirshup Looks great! I like the new spatial test image ;) well done! I just give it a try and didn't find any problem. One little change: can you add to the legend of `na_color` that this is also the color used when the parameter for `color` is not given. . I noticed two parameters in the embedding that I think belong only to the spatial.. Those are `bw` and `alpha_img`. In embeddings they do nothing. . Other issue, that I don't expect to address at the moment, is the increase in parameters because is becoming difficult to go through the list of parameters when browsing through the documentation. To help on this we can start using alphabetical order for all optional parameters. Other suggestion is to add to the documentation in which version a parameter was added. Thus, power users can easily track changes and try new options.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:746,modifiability,version,version,746,"@ivirshup Looks great! I like the new spatial test image ;) well done! I just give it a try and didn't find any problem. One little change: can you add to the legend of `na_color` that this is also the color used when the parameter for `color` is not given. . I noticed two parameters in the embedding that I think belong only to the spatial.. Those are `bw` and `alpha_img`. In embeddings they do nothing. . Other issue, that I don't expect to address at the moment, is the increase in parameters because is becoming difficult to go through the list of parameters when browsing through the documentation. To help on this we can start using alphabetical order for all optional parameters. Other suggestion is to add to the documentation in which version a parameter was added. Thus, power users can easily track changes and try new options.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:756,modifiability,paramet,parameter,756,"@ivirshup Looks great! I like the new spatial test image ;) well done! I just give it a try and didn't find any problem. One little change: can you add to the legend of `na_color` that this is also the color used when the parameter for `color` is not given. . I noticed two parameters in the embedding that I think belong only to the spatial.. Those are `bw` and `alpha_img`. In embeddings they do nothing. . Other issue, that I don't expect to address at the moment, is the increase in parameters because is becoming difficult to go through the list of parameters when browsing through the documentation. To help on this we can start using alphabetical order for all optional parameters. Other suggestion is to add to the documentation in which version a parameter was added. Thus, power users can easily track changes and try new options.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:46,safety,test,test,46,"@ivirshup Looks great! I like the new spatial test image ;) well done! I just give it a try and didn't find any problem. One little change: can you add to the legend of `na_color` that this is also the color used when the parameter for `color` is not given. . I noticed two parameters in the embedding that I think belong only to the spatial.. Those are `bw` and `alpha_img`. In embeddings they do nothing. . Other issue, that I don't expect to address at the moment, is the increase in parameters because is becoming difficult to go through the list of parameters when browsing through the documentation. To help on this we can start using alphabetical order for all optional parameters. Other suggestion is to add to the documentation in which version a parameter was added. Thus, power users can easily track changes and try new options.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:46,testability,test,test,46,"@ivirshup Looks great! I like the new spatial test image ;) well done! I just give it a try and didn't find any problem. One little change: can you add to the legend of `na_color` that this is also the color used when the parameter for `color` is not given. . I noticed two parameters in the embedding that I think belong only to the spatial.. Those are `bw` and `alpha_img`. In embeddings they do nothing. . Other issue, that I don't expect to address at the moment, is the increase in parameters because is becoming difficult to go through the list of parameters when browsing through the documentation. To help on this we can start using alphabetical order for all optional parameters. Other suggestion is to add to the documentation in which version a parameter was added. Thus, power users can easily track changes and try new options.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:591,usability,document,documentation,591,"@ivirshup Looks great! I like the new spatial test image ;) well done! I just give it a try and didn't find any problem. One little change: can you add to the legend of `na_color` that this is also the color used when the parameter for `color` is not given. . I noticed two parameters in the embedding that I think belong only to the spatial.. Those are `bw` and `alpha_img`. In embeddings they do nothing. . Other issue, that I don't expect to address at the moment, is the increase in parameters because is becoming difficult to go through the list of parameters when browsing through the documentation. To help on this we can start using alphabetical order for all optional parameters. Other suggestion is to add to the documentation in which version a parameter was added. Thus, power users can easily track changes and try new options.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:609,usability,help,help,609,"@ivirshup Looks great! I like the new spatial test image ;) well done! I just give it a try and didn't find any problem. One little change: can you add to the legend of `na_color` that this is also the color used when the parameter for `color` is not given. . I noticed two parameters in the embedding that I think belong only to the spatial.. Those are `bw` and `alpha_img`. In embeddings they do nothing. . Other issue, that I don't expect to address at the moment, is the increase in parameters because is becoming difficult to go through the list of parameters when browsing through the documentation. To help on this we can start using alphabetical order for all optional parameters. Other suggestion is to add to the documentation in which version a parameter was added. Thus, power users can easily track changes and try new options.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:723,usability,document,documentation,723,"@ivirshup Looks great! I like the new spatial test image ;) well done! I just give it a try and didn't find any problem. One little change: can you add to the legend of `na_color` that this is also the color used when the parameter for `color` is not given. . I noticed two parameters in the embedding that I think belong only to the spatial.. Those are `bw` and `alpha_img`. In embeddings they do nothing. . Other issue, that I don't expect to address at the moment, is the increase in parameters because is becoming difficult to go through the list of parameters when browsing through the documentation. To help on this we can start using alphabetical order for all optional parameters. Other suggestion is to add to the documentation in which version a parameter was added. Thus, power users can easily track changes and try new options.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:789,usability,user,users,789,"@ivirshup Looks great! I like the new spatial test image ;) well done! I just give it a try and didn't find any problem. One little change: can you add to the legend of `na_color` that this is also the color used when the parameter for `color` is not given. . I noticed two parameters in the embedding that I think belong only to the spatial.. Those are `bw` and `alpha_img`. In embeddings they do nothing. . Other issue, that I don't expect to address at the moment, is the increase in parameters because is becoming difficult to go through the list of parameters when browsing through the documentation. To help on this we can start using alphabetical order for all optional parameters. Other suggestion is to add to the documentation in which version a parameter was added. Thus, power users can easily track changes and try new options.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:688,deployability,version,versioning,688,"@fidelram Thanks! > I noticed two parameters in the embedding that I think belong only to the spatial.. Those are bw and alpha_img. In embeddings they do nothing. Yeah, those probably shouldn't get documented for functions like `sc.pl.umap`. > Other issue, that I don't expect to address at the moment, is the increase in parameters is becoming difficult to go through. I agree (related: #956). There are so many that I'm not sure alphabetical always makes sense? Perhaps they could be grouped into sections of related parameters? This would require some work on how the docs are generated. It would definitely be good to note when features were added. Related to this, I want to discuss versioning at the next meeting to figure out when this should go in a release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:758,deployability,releas,release,758,"@fidelram Thanks! > I noticed two parameters in the embedding that I think belong only to the spatial.. Those are bw and alpha_img. In embeddings they do nothing. Yeah, those probably shouldn't get documented for functions like `sc.pl.umap`. > Other issue, that I don't expect to address at the moment, is the increase in parameters is becoming difficult to go through. I agree (related: #956). There are so many that I'm not sure alphabetical always makes sense? Perhaps they could be grouped into sections of related parameters? This would require some work on how the docs are generated. It would definitely be good to note when features were added. Related to this, I want to discuss versioning at the next meeting to figure out when this should go in a release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:688,integrability,version,versioning,688,"@fidelram Thanks! > I noticed two parameters in the embedding that I think belong only to the spatial.. Those are bw and alpha_img. In embeddings they do nothing. Yeah, those probably shouldn't get documented for functions like `sc.pl.umap`. > Other issue, that I don't expect to address at the moment, is the increase in parameters is becoming difficult to go through. I agree (related: #956). There are so many that I'm not sure alphabetical always makes sense? Perhaps they could be grouped into sections of related parameters? This would require some work on how the docs are generated. It would definitely be good to note when features were added. Related to this, I want to discuss versioning at the next meeting to figure out when this should go in a release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:34,modifiability,paramet,parameters,34,"@fidelram Thanks! > I noticed two parameters in the embedding that I think belong only to the spatial.. Those are bw and alpha_img. In embeddings they do nothing. Yeah, those probably shouldn't get documented for functions like `sc.pl.umap`. > Other issue, that I don't expect to address at the moment, is the increase in parameters is becoming difficult to go through. I agree (related: #956). There are so many that I'm not sure alphabetical always makes sense? Perhaps they could be grouped into sections of related parameters? This would require some work on how the docs are generated. It would definitely be good to note when features were added. Related to this, I want to discuss versioning at the next meeting to figure out when this should go in a release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:322,modifiability,paramet,parameters,322,"@fidelram Thanks! > I noticed two parameters in the embedding that I think belong only to the spatial.. Those are bw and alpha_img. In embeddings they do nothing. Yeah, those probably shouldn't get documented for functions like `sc.pl.umap`. > Other issue, that I don't expect to address at the moment, is the increase in parameters is becoming difficult to go through. I agree (related: #956). There are so many that I'm not sure alphabetical always makes sense? Perhaps they could be grouped into sections of related parameters? This would require some work on how the docs are generated. It would definitely be good to note when features were added. Related to this, I want to discuss versioning at the next meeting to figure out when this should go in a release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:519,modifiability,paramet,parameters,519,"@fidelram Thanks! > I noticed two parameters in the embedding that I think belong only to the spatial.. Those are bw and alpha_img. In embeddings they do nothing. Yeah, those probably shouldn't get documented for functions like `sc.pl.umap`. > Other issue, that I don't expect to address at the moment, is the increase in parameters is becoming difficult to go through. I agree (related: #956). There are so many that I'm not sure alphabetical always makes sense? Perhaps they could be grouped into sections of related parameters? This would require some work on how the docs are generated. It would definitely be good to note when features were added. Related to this, I want to discuss versioning at the next meeting to figure out when this should go in a release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:688,modifiability,version,versioning,688,"@fidelram Thanks! > I noticed two parameters in the embedding that I think belong only to the spatial.. Those are bw and alpha_img. In embeddings they do nothing. Yeah, those probably shouldn't get documented for functions like `sc.pl.umap`. > Other issue, that I don't expect to address at the moment, is the increase in parameters is becoming difficult to go through. I agree (related: #956). There are so many that I'm not sure alphabetical always makes sense? Perhaps they could be grouped into sections of related parameters? This would require some work on how the docs are generated. It would definitely be good to note when features were added. Related to this, I want to discuss versioning at the next meeting to figure out when this should go in a release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:198,usability,document,documented,198,"@fidelram Thanks! > I noticed two parameters in the embedding that I think belong only to the spatial.. Those are bw and alpha_img. In embeddings they do nothing. Yeah, those probably shouldn't get documented for functions like `sc.pl.umap`. > Other issue, that I don't expect to address at the moment, is the increase in parameters is becoming difficult to go through. I agree (related: #956). There are so many that I'm not sure alphabetical always makes sense? Perhaps they could be grouped into sections of related parameters? This would require some work on how the docs are generated. It would definitely be good to note when features were added. Related to this, I want to discuss versioning at the next meeting to figure out when this should go in a release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:42,modifiability,paramet,parameters,42,"> @fidelram Thanks! > . > > I noticed two parameters in the embedding that I think belong only to the spatial.. Those are bw and alpha_img. In embeddings they do nothing. > . > Yeah, those probably shouldn't get documented for functions like `sc.pl.umap`. > . well, they are passed to functions that are called in `sc.pl.embedding`, for instance [here](https://github.com/theislab/scanpy/blob/c9fbe5c1e00f5a262262cb7dee2c28d9d536ee34/scanpy/plotting/_tools/scatterplots.py#L296) . For sure it doesn't look great though. Honestly when I first approached the spatial plot, I just hhijacked what was there from the scatterplot and added modifications needed. It worked, but indeed it contributed to make the code really long and difficult to read. . For the rest, sorry for late reply, it looks great for both the umaps and the spatials, especially the fact that they can be left transparent.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:493,reliability,doe,doesn,493,"> @fidelram Thanks! > . > > I noticed two parameters in the embedding that I think belong only to the spatial.. Those are bw and alpha_img. In embeddings they do nothing. > . > Yeah, those probably shouldn't get documented for functions like `sc.pl.umap`. > . well, they are passed to functions that are called in `sc.pl.embedding`, for instance [here](https://github.com/theislab/scanpy/blob/c9fbe5c1e00f5a262262cb7dee2c28d9d536ee34/scanpy/plotting/_tools/scatterplots.py#L296) . For sure it doesn't look great though. Honestly when I first approached the spatial plot, I just hhijacked what was there from the scatterplot and added modifications needed. It worked, but indeed it contributed to make the code really long and difficult to read. . For the rest, sorry for late reply, it looks great for both the umaps and the spatials, especially the fact that they can be left transparent.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:634,security,modif,modifications,634,"> @fidelram Thanks! > . > > I noticed two parameters in the embedding that I think belong only to the spatial.. Those are bw and alpha_img. In embeddings they do nothing. > . > Yeah, those probably shouldn't get documented for functions like `sc.pl.umap`. > . well, they are passed to functions that are called in `sc.pl.embedding`, for instance [here](https://github.com/theislab/scanpy/blob/c9fbe5c1e00f5a262262cb7dee2c28d9d536ee34/scanpy/plotting/_tools/scatterplots.py#L296) . For sure it doesn't look great though. Honestly when I first approached the spatial plot, I just hhijacked what was there from the scatterplot and added modifications needed. It worked, but indeed it contributed to make the code really long and difficult to read. . For the rest, sorry for late reply, it looks great for both the umaps and the spatials, especially the fact that they can be left transparent.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:212,usability,document,documented,212,"> @fidelram Thanks! > . > > I noticed two parameters in the embedding that I think belong only to the spatial.. Those are bw and alpha_img. In embeddings they do nothing. > . > Yeah, those probably shouldn't get documented for functions like `sc.pl.umap`. > . well, they are passed to functions that are called in `sc.pl.embedding`, for instance [here](https://github.com/theislab/scanpy/blob/c9fbe5c1e00f5a262262cb7dee2c28d9d536ee34/scanpy/plotting/_tools/scatterplots.py#L296) . For sure it doesn't look great though. Honestly when I first approached the spatial plot, I just hhijacked what was there from the scatterplot and added modifications needed. It worked, but indeed it contributed to make the code really long and difficult to read. . For the rest, sorry for late reply, it looks great for both the umaps and the spatials, especially the fact that they can be left transparent.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/issues/1357:74,deployability,updat,updated,74,"On the point of the notebooks... some of the tutorials should probably be updated. The analysis steps that are performed in those are quite old and would not be considered as good practice anymore. Might be worth combining this effort... (see e.g., #1338 )",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:111,performance,perform,performed,111,"On the point of the notebooks... some of the tutorials should probably be updated. The analysis steps that are performed in those are quite old and would not be considered as good practice anymore. Might be worth combining this effort... (see e.g., #1338 )",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:180,reliability,pra,practice,180,"On the point of the notebooks... some of the tutorials should probably be updated. The analysis steps that are performed in those are quite old and would not be considered as good practice anymore. Might be worth combining this effort... (see e.g., #1338 )",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:74,safety,updat,updated,74,"On the point of the notebooks... some of the tutorials should probably be updated. The analysis steps that are performed in those are quite old and would not be considered as good practice anymore. Might be worth combining this effort... (see e.g., #1338 )",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:74,security,updat,updated,74,"On the point of the notebooks... some of the tutorials should probably be updated. The analysis steps that are performed in those are quite old and would not be considered as good practice anymore. Might be worth combining this effort... (see e.g., #1338 )",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:111,usability,perform,performed,111,"On the point of the notebooks... some of the tutorials should probably be updated. The analysis steps that are performed in those are quite old and would not be considered as good practice anymore. Might be worth combining this effort... (see e.g., #1338 )",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:77,deployability,version,version,77,"@LuckyMD, I definitely agree. . I personally find it kinda hard to work with version management and updating of notebooks, as well as keeping them clean with useful prose. This makes updating tutorials a pain. A lot of this just has to do with the interface, as I find this much easier with `.Rmd`. . I'm thinking this could be alleviated a bit with better automation around tutorials. Namely:. * Running + rendering notebooks through CI. * Save tutorials in a more git friendly format, maybe through something like [jupytext](https://jupytext.readthedocs.io). It looks to me like @michalk8 has set up some more extensive CI for tutorials with notebooks. @michalk8 do you have any recommendations here? How are you finding running CI against notebooks?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:85,deployability,manag,management,85,"@LuckyMD, I definitely agree. . I personally find it kinda hard to work with version management and updating of notebooks, as well as keeping them clean with useful prose. This makes updating tutorials a pain. A lot of this just has to do with the interface, as I find this much easier with `.Rmd`. . I'm thinking this could be alleviated a bit with better automation around tutorials. Namely:. * Running + rendering notebooks through CI. * Save tutorials in a more git friendly format, maybe through something like [jupytext](https://jupytext.readthedocs.io). It looks to me like @michalk8 has set up some more extensive CI for tutorials with notebooks. @michalk8 do you have any recommendations here? How are you finding running CI against notebooks?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:100,deployability,updat,updating,100,"@LuckyMD, I definitely agree. . I personally find it kinda hard to work with version management and updating of notebooks, as well as keeping them clean with useful prose. This makes updating tutorials a pain. A lot of this just has to do with the interface, as I find this much easier with `.Rmd`. . I'm thinking this could be alleviated a bit with better automation around tutorials. Namely:. * Running + rendering notebooks through CI. * Save tutorials in a more git friendly format, maybe through something like [jupytext](https://jupytext.readthedocs.io). It looks to me like @michalk8 has set up some more extensive CI for tutorials with notebooks. @michalk8 do you have any recommendations here? How are you finding running CI against notebooks?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:183,deployability,updat,updating,183,"@LuckyMD, I definitely agree. . I personally find it kinda hard to work with version management and updating of notebooks, as well as keeping them clean with useful prose. This makes updating tutorials a pain. A lot of this just has to do with the interface, as I find this much easier with `.Rmd`. . I'm thinking this could be alleviated a bit with better automation around tutorials. Namely:. * Running + rendering notebooks through CI. * Save tutorials in a more git friendly format, maybe through something like [jupytext](https://jupytext.readthedocs.io). It looks to me like @michalk8 has set up some more extensive CI for tutorials with notebooks. @michalk8 do you have any recommendations here? How are you finding running CI against notebooks?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:357,deployability,automat,automation,357,"@LuckyMD, I definitely agree. . I personally find it kinda hard to work with version management and updating of notebooks, as well as keeping them clean with useful prose. This makes updating tutorials a pain. A lot of this just has to do with the interface, as I find this much easier with `.Rmd`. . I'm thinking this could be alleviated a bit with better automation around tutorials. Namely:. * Running + rendering notebooks through CI. * Save tutorials in a more git friendly format, maybe through something like [jupytext](https://jupytext.readthedocs.io). It looks to me like @michalk8 has set up some more extensive CI for tutorials with notebooks. @michalk8 do you have any recommendations here? How are you finding running CI against notebooks?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:85,energy efficiency,manag,management,85,"@LuckyMD, I definitely agree. . I personally find it kinda hard to work with version management and updating of notebooks, as well as keeping them clean with useful prose. This makes updating tutorials a pain. A lot of this just has to do with the interface, as I find this much easier with `.Rmd`. . I'm thinking this could be alleviated a bit with better automation around tutorials. Namely:. * Running + rendering notebooks through CI. * Save tutorials in a more git friendly format, maybe through something like [jupytext](https://jupytext.readthedocs.io). It looks to me like @michalk8 has set up some more extensive CI for tutorials with notebooks. @michalk8 do you have any recommendations here? How are you finding running CI against notebooks?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:77,integrability,version,version,77,"@LuckyMD, I definitely agree. . I personally find it kinda hard to work with version management and updating of notebooks, as well as keeping them clean with useful prose. This makes updating tutorials a pain. A lot of this just has to do with the interface, as I find this much easier with `.Rmd`. . I'm thinking this could be alleviated a bit with better automation around tutorials. Namely:. * Running + rendering notebooks through CI. * Save tutorials in a more git friendly format, maybe through something like [jupytext](https://jupytext.readthedocs.io). It looks to me like @michalk8 has set up some more extensive CI for tutorials with notebooks. @michalk8 do you have any recommendations here? How are you finding running CI against notebooks?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:248,integrability,interfac,interface,248,"@LuckyMD, I definitely agree. . I personally find it kinda hard to work with version management and updating of notebooks, as well as keeping them clean with useful prose. This makes updating tutorials a pain. A lot of this just has to do with the interface, as I find this much easier with `.Rmd`. . I'm thinking this could be alleviated a bit with better automation around tutorials. Namely:. * Running + rendering notebooks through CI. * Save tutorials in a more git friendly format, maybe through something like [jupytext](https://jupytext.readthedocs.io). It looks to me like @michalk8 has set up some more extensive CI for tutorials with notebooks. @michalk8 do you have any recommendations here? How are you finding running CI against notebooks?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:248,interoperability,interfac,interface,248,"@LuckyMD, I definitely agree. . I personally find it kinda hard to work with version management and updating of notebooks, as well as keeping them clean with useful prose. This makes updating tutorials a pain. A lot of this just has to do with the interface, as I find this much easier with `.Rmd`. . I'm thinking this could be alleviated a bit with better automation around tutorials. Namely:. * Running + rendering notebooks through CI. * Save tutorials in a more git friendly format, maybe through something like [jupytext](https://jupytext.readthedocs.io). It looks to me like @michalk8 has set up some more extensive CI for tutorials with notebooks. @michalk8 do you have any recommendations here? How are you finding running CI against notebooks?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:479,interoperability,format,format,479,"@LuckyMD, I definitely agree. . I personally find it kinda hard to work with version management and updating of notebooks, as well as keeping them clean with useful prose. This makes updating tutorials a pain. A lot of this just has to do with the interface, as I find this much easier with `.Rmd`. . I'm thinking this could be alleviated a bit with better automation around tutorials. Namely:. * Running + rendering notebooks through CI. * Save tutorials in a more git friendly format, maybe through something like [jupytext](https://jupytext.readthedocs.io). It looks to me like @michalk8 has set up some more extensive CI for tutorials with notebooks. @michalk8 do you have any recommendations here? How are you finding running CI against notebooks?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:77,modifiability,version,version,77,"@LuckyMD, I definitely agree. . I personally find it kinda hard to work with version management and updating of notebooks, as well as keeping them clean with useful prose. This makes updating tutorials a pain. A lot of this just has to do with the interface, as I find this much easier with `.Rmd`. . I'm thinking this could be alleviated a bit with better automation around tutorials. Namely:. * Running + rendering notebooks through CI. * Save tutorials in a more git friendly format, maybe through something like [jupytext](https://jupytext.readthedocs.io). It looks to me like @michalk8 has set up some more extensive CI for tutorials with notebooks. @michalk8 do you have any recommendations here? How are you finding running CI against notebooks?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:248,modifiability,interfac,interface,248,"@LuckyMD, I definitely agree. . I personally find it kinda hard to work with version management and updating of notebooks, as well as keeping them clean with useful prose. This makes updating tutorials a pain. A lot of this just has to do with the interface, as I find this much easier with `.Rmd`. . I'm thinking this could be alleviated a bit with better automation around tutorials. Namely:. * Running + rendering notebooks through CI. * Save tutorials in a more git friendly format, maybe through something like [jupytext](https://jupytext.readthedocs.io). It looks to me like @michalk8 has set up some more extensive CI for tutorials with notebooks. @michalk8 do you have any recommendations here? How are you finding running CI against notebooks?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:612,modifiability,extens,extensive,612,"@LuckyMD, I definitely agree. . I personally find it kinda hard to work with version management and updating of notebooks, as well as keeping them clean with useful prose. This makes updating tutorials a pain. A lot of this just has to do with the interface, as I find this much easier with `.Rmd`. . I'm thinking this could be alleviated a bit with better automation around tutorials. Namely:. * Running + rendering notebooks through CI. * Save tutorials in a more git friendly format, maybe through something like [jupytext](https://jupytext.readthedocs.io). It looks to me like @michalk8 has set up some more extensive CI for tutorials with notebooks. @michalk8 do you have any recommendations here? How are you finding running CI against notebooks?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:85,safety,manag,management,85,"@LuckyMD, I definitely agree. . I personally find it kinda hard to work with version management and updating of notebooks, as well as keeping them clean with useful prose. This makes updating tutorials a pain. A lot of this just has to do with the interface, as I find this much easier with `.Rmd`. . I'm thinking this could be alleviated a bit with better automation around tutorials. Namely:. * Running + rendering notebooks through CI. * Save tutorials in a more git friendly format, maybe through something like [jupytext](https://jupytext.readthedocs.io). It looks to me like @michalk8 has set up some more extensive CI for tutorials with notebooks. @michalk8 do you have any recommendations here? How are you finding running CI against notebooks?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:100,safety,updat,updating,100,"@LuckyMD, I definitely agree. . I personally find it kinda hard to work with version management and updating of notebooks, as well as keeping them clean with useful prose. This makes updating tutorials a pain. A lot of this just has to do with the interface, as I find this much easier with `.Rmd`. . I'm thinking this could be alleviated a bit with better automation around tutorials. Namely:. * Running + rendering notebooks through CI. * Save tutorials in a more git friendly format, maybe through something like [jupytext](https://jupytext.readthedocs.io). It looks to me like @michalk8 has set up some more extensive CI for tutorials with notebooks. @michalk8 do you have any recommendations here? How are you finding running CI against notebooks?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:183,safety,updat,updating,183,"@LuckyMD, I definitely agree. . I personally find it kinda hard to work with version management and updating of notebooks, as well as keeping them clean with useful prose. This makes updating tutorials a pain. A lot of this just has to do with the interface, as I find this much easier with `.Rmd`. . I'm thinking this could be alleviated a bit with better automation around tutorials. Namely:. * Running + rendering notebooks through CI. * Save tutorials in a more git friendly format, maybe through something like [jupytext](https://jupytext.readthedocs.io). It looks to me like @michalk8 has set up some more extensive CI for tutorials with notebooks. @michalk8 do you have any recommendations here? How are you finding running CI against notebooks?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:100,security,updat,updating,100,"@LuckyMD, I definitely agree. . I personally find it kinda hard to work with version management and updating of notebooks, as well as keeping them clean with useful prose. This makes updating tutorials a pain. A lot of this just has to do with the interface, as I find this much easier with `.Rmd`. . I'm thinking this could be alleviated a bit with better automation around tutorials. Namely:. * Running + rendering notebooks through CI. * Save tutorials in a more git friendly format, maybe through something like [jupytext](https://jupytext.readthedocs.io). It looks to me like @michalk8 has set up some more extensive CI for tutorials with notebooks. @michalk8 do you have any recommendations here? How are you finding running CI against notebooks?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:183,security,updat,updating,183,"@LuckyMD, I definitely agree. . I personally find it kinda hard to work with version management and updating of notebooks, as well as keeping them clean with useful prose. This makes updating tutorials a pain. A lot of this just has to do with the interface, as I find this much easier with `.Rmd`. . I'm thinking this could be alleviated a bit with better automation around tutorials. Namely:. * Running + rendering notebooks through CI. * Save tutorials in a more git friendly format, maybe through something like [jupytext](https://jupytext.readthedocs.io). It looks to me like @michalk8 has set up some more extensive CI for tutorials with notebooks. @michalk8 do you have any recommendations here? How are you finding running CI against notebooks?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:357,testability,automat,automation,357,"@LuckyMD, I definitely agree. . I personally find it kinda hard to work with version management and updating of notebooks, as well as keeping them clean with useful prose. This makes updating tutorials a pain. A lot of this just has to do with the interface, as I find this much easier with `.Rmd`. . I'm thinking this could be alleviated a bit with better automation around tutorials. Namely:. * Running + rendering notebooks through CI. * Save tutorials in a more git friendly format, maybe through something like [jupytext](https://jupytext.readthedocs.io). It looks to me like @michalk8 has set up some more extensive CI for tutorials with notebooks. @michalk8 do you have any recommendations here? How are you finding running CI against notebooks?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:34,usability,person,personally,34,"@LuckyMD, I definitely agree. . I personally find it kinda hard to work with version management and updating of notebooks, as well as keeping them clean with useful prose. This makes updating tutorials a pain. A lot of this just has to do with the interface, as I find this much easier with `.Rmd`. . I'm thinking this could be alleviated a bit with better automation around tutorials. Namely:. * Running + rendering notebooks through CI. * Save tutorials in a more git friendly format, maybe through something like [jupytext](https://jupytext.readthedocs.io). It looks to me like @michalk8 has set up some more extensive CI for tutorials with notebooks. @michalk8 do you have any recommendations here? How are you finding running CI against notebooks?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:76,deployability,API,API,76,"You could run notebooks from Travis by just executing them with the execute API (https://nbconvert.readthedocs.io/en/latest/execute_api.html). That might take a while though of course... and not really help with the speed up you were looking for above. On another note, updating the tutorials would be a great hackathon topic for Scanpy. We could also link my single-cell-tutorial repo on the scanpy page as it's mostly based on scanpy functionality and functionality that is being added atm.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:270,deployability,updat,updating,270,"You could run notebooks from Travis by just executing them with the execute API (https://nbconvert.readthedocs.io/en/latest/execute_api.html). That might take a while though of course... and not really help with the speed up you were looking for above. On another note, updating the tutorials would be a great hackathon topic for Scanpy. We could also link my single-cell-tutorial repo on the scanpy page as it's mostly based on scanpy functionality and functionality that is being added atm.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:76,integrability,API,API,76,"You could run notebooks from Travis by just executing them with the execute API (https://nbconvert.readthedocs.io/en/latest/execute_api.html). That might take a while though of course... and not really help with the speed up you were looking for above. On another note, updating the tutorials would be a great hackathon topic for Scanpy. We could also link my single-cell-tutorial repo on the scanpy page as it's mostly based on scanpy functionality and functionality that is being added atm.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:320,integrability,topic,topic,320,"You could run notebooks from Travis by just executing them with the execute API (https://nbconvert.readthedocs.io/en/latest/execute_api.html). That might take a while though of course... and not really help with the speed up you were looking for above. On another note, updating the tutorials would be a great hackathon topic for Scanpy. We could also link my single-cell-tutorial repo on the scanpy page as it's mostly based on scanpy functionality and functionality that is being added atm.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:76,interoperability,API,API,76,"You could run notebooks from Travis by just executing them with the execute API (https://nbconvert.readthedocs.io/en/latest/execute_api.html). That might take a while though of course... and not really help with the speed up you were looking for above. On another note, updating the tutorials would be a great hackathon topic for Scanpy. We could also link my single-cell-tutorial repo on the scanpy page as it's mostly based on scanpy functionality and functionality that is being added atm.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:270,safety,updat,updating,270,"You could run notebooks from Travis by just executing them with the execute API (https://nbconvert.readthedocs.io/en/latest/execute_api.html). That might take a while though of course... and not really help with the speed up you were looking for above. On another note, updating the tutorials would be a great hackathon topic for Scanpy. We could also link my single-cell-tutorial repo on the scanpy page as it's mostly based on scanpy functionality and functionality that is being added atm.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:270,security,updat,updating,270,"You could run notebooks from Travis by just executing them with the execute API (https://nbconvert.readthedocs.io/en/latest/execute_api.html). That might take a while though of course... and not really help with the speed up you were looking for above. On another note, updating the tutorials would be a great hackathon topic for Scanpy. We could also link my single-cell-tutorial repo on the scanpy page as it's mostly based on scanpy functionality and functionality that is being added atm.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:310,security,hack,hackathon,310,"You could run notebooks from Travis by just executing them with the execute API (https://nbconvert.readthedocs.io/en/latest/execute_api.html). That might take a while though of course... and not really help with the speed up you were looking for above. On another note, updating the tutorials would be a great hackathon topic for Scanpy. We could also link my single-cell-tutorial repo on the scanpy page as it's mostly based on scanpy functionality and functionality that is being added atm.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:202,usability,help,help,202,"You could run notebooks from Travis by just executing them with the execute API (https://nbconvert.readthedocs.io/en/latest/execute_api.html). That might take a while though of course... and not really help with the speed up you were looking for above. On another note, updating the tutorials would be a great hackathon topic for Scanpy. We could also link my single-cell-tutorial repo on the scanpy page as it's mostly based on scanpy functionality and functionality that is being added atm.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:59,deployability,API,API,59,"@ivirshup I find it useful, since we're still changing our API a lot, so I don't forget to update the tutorials. Our main issue is just runtime of some functions. I'm using https://github.com/chrisjsewell/pytest-notebook, which can compare expected output of certain cells (or completely) ignore them, but it's still a very small library. I haven't gotten around pushing the updates, since I figured if the notebooks run, it's fine if there are some small discrepencies in output (like images/printed stuff) - though maybe I will update this soon.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:91,deployability,updat,update,91,"@ivirshup I find it useful, since we're still changing our API a lot, so I don't forget to update the tutorials. Our main issue is just runtime of some functions. I'm using https://github.com/chrisjsewell/pytest-notebook, which can compare expected output of certain cells (or completely) ignore them, but it's still a very small library. I haven't gotten around pushing the updates, since I figured if the notebooks run, it's fine if there are some small discrepencies in output (like images/printed stuff) - though maybe I will update this soon.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:375,deployability,updat,updates,375,"@ivirshup I find it useful, since we're still changing our API a lot, so I don't forget to update the tutorials. Our main issue is just runtime of some functions. I'm using https://github.com/chrisjsewell/pytest-notebook, which can compare expected output of certain cells (or completely) ignore them, but it's still a very small library. I haven't gotten around pushing the updates, since I figured if the notebooks run, it's fine if there are some small discrepencies in output (like images/printed stuff) - though maybe I will update this soon.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:530,deployability,updat,update,530,"@ivirshup I find it useful, since we're still changing our API a lot, so I don't forget to update the tutorials. Our main issue is just runtime of some functions. I'm using https://github.com/chrisjsewell/pytest-notebook, which can compare expected output of certain cells (or completely) ignore them, but it's still a very small library. I haven't gotten around pushing the updates, since I figured if the notebooks run, it's fine if there are some small discrepencies in output (like images/printed stuff) - though maybe I will update this soon.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:59,integrability,API,API,59,"@ivirshup I find it useful, since we're still changing our API a lot, so I don't forget to update the tutorials. Our main issue is just runtime of some functions. I'm using https://github.com/chrisjsewell/pytest-notebook, which can compare expected output of certain cells (or completely) ignore them, but it's still a very small library. I haven't gotten around pushing the updates, since I figured if the notebooks run, it's fine if there are some small discrepencies in output (like images/printed stuff) - though maybe I will update this soon.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:59,interoperability,API,API,59,"@ivirshup I find it useful, since we're still changing our API a lot, so I don't forget to update the tutorials. Our main issue is just runtime of some functions. I'm using https://github.com/chrisjsewell/pytest-notebook, which can compare expected output of certain cells (or completely) ignore them, but it's still a very small library. I haven't gotten around pushing the updates, since I figured if the notebooks run, it's fine if there are some small discrepencies in output (like images/printed stuff) - though maybe I will update this soon.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:91,safety,updat,update,91,"@ivirshup I find it useful, since we're still changing our API a lot, so I don't forget to update the tutorials. Our main issue is just runtime of some functions. I'm using https://github.com/chrisjsewell/pytest-notebook, which can compare expected output of certain cells (or completely) ignore them, but it's still a very small library. I haven't gotten around pushing the updates, since I figured if the notebooks run, it's fine if there are some small discrepencies in output (like images/printed stuff) - though maybe I will update this soon.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:277,safety,compl,completely,277,"@ivirshup I find it useful, since we're still changing our API a lot, so I don't forget to update the tutorials. Our main issue is just runtime of some functions. I'm using https://github.com/chrisjsewell/pytest-notebook, which can compare expected output of certain cells (or completely) ignore them, but it's still a very small library. I haven't gotten around pushing the updates, since I figured if the notebooks run, it's fine if there are some small discrepencies in output (like images/printed stuff) - though maybe I will update this soon.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:375,safety,updat,updates,375,"@ivirshup I find it useful, since we're still changing our API a lot, so I don't forget to update the tutorials. Our main issue is just runtime of some functions. I'm using https://github.com/chrisjsewell/pytest-notebook, which can compare expected output of certain cells (or completely) ignore them, but it's still a very small library. I haven't gotten around pushing the updates, since I figured if the notebooks run, it's fine if there are some small discrepencies in output (like images/printed stuff) - though maybe I will update this soon.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:530,safety,updat,update,530,"@ivirshup I find it useful, since we're still changing our API a lot, so I don't forget to update the tutorials. Our main issue is just runtime of some functions. I'm using https://github.com/chrisjsewell/pytest-notebook, which can compare expected output of certain cells (or completely) ignore them, but it's still a very small library. I haven't gotten around pushing the updates, since I figured if the notebooks run, it's fine if there are some small discrepencies in output (like images/printed stuff) - though maybe I will update this soon.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:91,security,updat,update,91,"@ivirshup I find it useful, since we're still changing our API a lot, so I don't forget to update the tutorials. Our main issue is just runtime of some functions. I'm using https://github.com/chrisjsewell/pytest-notebook, which can compare expected output of certain cells (or completely) ignore them, but it's still a very small library. I haven't gotten around pushing the updates, since I figured if the notebooks run, it's fine if there are some small discrepencies in output (like images/printed stuff) - though maybe I will update this soon.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:277,security,compl,completely,277,"@ivirshup I find it useful, since we're still changing our API a lot, so I don't forget to update the tutorials. Our main issue is just runtime of some functions. I'm using https://github.com/chrisjsewell/pytest-notebook, which can compare expected output of certain cells (or completely) ignore them, but it's still a very small library. I haven't gotten around pushing the updates, since I figured if the notebooks run, it's fine if there are some small discrepencies in output (like images/printed stuff) - though maybe I will update this soon.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:375,security,updat,updates,375,"@ivirshup I find it useful, since we're still changing our API a lot, so I don't forget to update the tutorials. Our main issue is just runtime of some functions. I'm using https://github.com/chrisjsewell/pytest-notebook, which can compare expected output of certain cells (or completely) ignore them, but it's still a very small library. I haven't gotten around pushing the updates, since I figured if the notebooks run, it's fine if there are some small discrepencies in output (like images/printed stuff) - though maybe I will update this soon.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:530,security,updat,update,530,"@ivirshup I find it useful, since we're still changing our API a lot, so I don't forget to update the tutorials. Our main issue is just runtime of some functions. I'm using https://github.com/chrisjsewell/pytest-notebook, which can compare expected output of certain cells (or completely) ignore them, but it's still a very small library. I haven't gotten around pushing the updates, since I figured if the notebooks run, it's fine if there are some small discrepencies in output (like images/printed stuff) - though maybe I will update this soon.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1358:119,safety,compl,completeness,119,"As an alternative: GitHub actions. Its pretty manual, and I had good experiences with Azure, so I just mention it for completenesss sake.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:119,security,compl,completeness,119,"As an alternative: GitHub actions. Its pretty manual, and I had good experiences with Azure, so I just mention it for completenesss sake.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:70,usability,experien,experiences,70,"As an alternative: GitHub actions. Its pretty manual, and I had good experiences with Azure, so I just mention it for completenesss sake.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:160,deployability,integr,integration,160,"Just my 2cents: . I made really good experiences with Github actions. * I find them easy to set-up and they run many (20-40?) jobs in parallel. . * Really good integration with Github (e.g. upload to PyPI on release) . * windows testing works well, but it is a pain to setup pycairo, see [here](https://github.com/icbi-lab/scirpy/blob/725664a22e6265643633d89a7f38ea3383ccab48/.github/workflows/test.yml#L34) and [here](https://github.com/pygobject/pycairo/issues/19#issuecomment-638716293). . Here's the [github actions script for scirpy](https://github.com/icbi-lab/scirpy/blob/master/.github/workflows/test.yml).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:208,deployability,releas,release,208,"Just my 2cents: . I made really good experiences with Github actions. * I find them easy to set-up and they run many (20-40?) jobs in parallel. . * Really good integration with Github (e.g. upload to PyPI on release) . * windows testing works well, but it is a pain to setup pycairo, see [here](https://github.com/icbi-lab/scirpy/blob/725664a22e6265643633d89a7f38ea3383ccab48/.github/workflows/test.yml#L34) and [here](https://github.com/pygobject/pycairo/issues/19#issuecomment-638716293). . Here's the [github actions script for scirpy](https://github.com/icbi-lab/scirpy/blob/master/.github/workflows/test.yml).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:160,integrability,integr,integration,160,"Just my 2cents: . I made really good experiences with Github actions. * I find them easy to set-up and they run many (20-40?) jobs in parallel. . * Really good integration with Github (e.g. upload to PyPI on release) . * windows testing works well, but it is a pain to setup pycairo, see [here](https://github.com/icbi-lab/scirpy/blob/725664a22e6265643633d89a7f38ea3383ccab48/.github/workflows/test.yml#L34) and [here](https://github.com/pygobject/pycairo/issues/19#issuecomment-638716293). . Here's the [github actions script for scirpy](https://github.com/icbi-lab/scirpy/blob/master/.github/workflows/test.yml).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:160,interoperability,integr,integration,160,"Just my 2cents: . I made really good experiences with Github actions. * I find them easy to set-up and they run many (20-40?) jobs in parallel. . * Really good integration with Github (e.g. upload to PyPI on release) . * windows testing works well, but it is a pain to setup pycairo, see [here](https://github.com/icbi-lab/scirpy/blob/725664a22e6265643633d89a7f38ea3383ccab48/.github/workflows/test.yml#L34) and [here](https://github.com/pygobject/pycairo/issues/19#issuecomment-638716293). . Here's the [github actions script for scirpy](https://github.com/icbi-lab/scirpy/blob/master/.github/workflows/test.yml).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:160,modifiability,integr,integration,160,"Just my 2cents: . I made really good experiences with Github actions. * I find them easy to set-up and they run many (20-40?) jobs in parallel. . * Really good integration with Github (e.g. upload to PyPI on release) . * windows testing works well, but it is a pain to setup pycairo, see [here](https://github.com/icbi-lab/scirpy/blob/725664a22e6265643633d89a7f38ea3383ccab48/.github/workflows/test.yml#L34) and [here](https://github.com/pygobject/pycairo/issues/19#issuecomment-638716293). . Here's the [github actions script for scirpy](https://github.com/icbi-lab/scirpy/blob/master/.github/workflows/test.yml).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:134,performance,parallel,parallel,134,"Just my 2cents: . I made really good experiences with Github actions. * I find them easy to set-up and they run many (20-40?) jobs in parallel. . * Really good integration with Github (e.g. upload to PyPI on release) . * windows testing works well, but it is a pain to setup pycairo, see [here](https://github.com/icbi-lab/scirpy/blob/725664a22e6265643633d89a7f38ea3383ccab48/.github/workflows/test.yml#L34) and [here](https://github.com/pygobject/pycairo/issues/19#issuecomment-638716293). . Here's the [github actions script for scirpy](https://github.com/icbi-lab/scirpy/blob/master/.github/workflows/test.yml).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:160,reliability,integr,integration,160,"Just my 2cents: . I made really good experiences with Github actions. * I find them easy to set-up and they run many (20-40?) jobs in parallel. . * Really good integration with Github (e.g. upload to PyPI on release) . * windows testing works well, but it is a pain to setup pycairo, see [here](https://github.com/icbi-lab/scirpy/blob/725664a22e6265643633d89a7f38ea3383ccab48/.github/workflows/test.yml#L34) and [here](https://github.com/pygobject/pycairo/issues/19#issuecomment-638716293). . Here's the [github actions script for scirpy](https://github.com/icbi-lab/scirpy/blob/master/.github/workflows/test.yml).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:229,safety,test,testing,229,"Just my 2cents: . I made really good experiences with Github actions. * I find them easy to set-up and they run many (20-40?) jobs in parallel. . * Really good integration with Github (e.g. upload to PyPI on release) . * windows testing works well, but it is a pain to setup pycairo, see [here](https://github.com/icbi-lab/scirpy/blob/725664a22e6265643633d89a7f38ea3383ccab48/.github/workflows/test.yml#L34) and [here](https://github.com/pygobject/pycairo/issues/19#issuecomment-638716293). . Here's the [github actions script for scirpy](https://github.com/icbi-lab/scirpy/blob/master/.github/workflows/test.yml).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:394,safety,test,test,394,"Just my 2cents: . I made really good experiences with Github actions. * I find them easy to set-up and they run many (20-40?) jobs in parallel. . * Really good integration with Github (e.g. upload to PyPI on release) . * windows testing works well, but it is a pain to setup pycairo, see [here](https://github.com/icbi-lab/scirpy/blob/725664a22e6265643633d89a7f38ea3383ccab48/.github/workflows/test.yml#L34) and [here](https://github.com/pygobject/pycairo/issues/19#issuecomment-638716293). . Here's the [github actions script for scirpy](https://github.com/icbi-lab/scirpy/blob/master/.github/workflows/test.yml).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:604,safety,test,test,604,"Just my 2cents: . I made really good experiences with Github actions. * I find them easy to set-up and they run many (20-40?) jobs in parallel. . * Really good integration with Github (e.g. upload to PyPI on release) . * windows testing works well, but it is a pain to setup pycairo, see [here](https://github.com/icbi-lab/scirpy/blob/725664a22e6265643633d89a7f38ea3383ccab48/.github/workflows/test.yml#L34) and [here](https://github.com/pygobject/pycairo/issues/19#issuecomment-638716293). . Here's the [github actions script for scirpy](https://github.com/icbi-lab/scirpy/blob/master/.github/workflows/test.yml).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:160,security,integr,integration,160,"Just my 2cents: . I made really good experiences with Github actions. * I find them easy to set-up and they run many (20-40?) jobs in parallel. . * Really good integration with Github (e.g. upload to PyPI on release) . * windows testing works well, but it is a pain to setup pycairo, see [here](https://github.com/icbi-lab/scirpy/blob/725664a22e6265643633d89a7f38ea3383ccab48/.github/workflows/test.yml#L34) and [here](https://github.com/pygobject/pycairo/issues/19#issuecomment-638716293). . Here's the [github actions script for scirpy](https://github.com/icbi-lab/scirpy/blob/master/.github/workflows/test.yml).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:160,testability,integr,integration,160,"Just my 2cents: . I made really good experiences with Github actions. * I find them easy to set-up and they run many (20-40?) jobs in parallel. . * Really good integration with Github (e.g. upload to PyPI on release) . * windows testing works well, but it is a pain to setup pycairo, see [here](https://github.com/icbi-lab/scirpy/blob/725664a22e6265643633d89a7f38ea3383ccab48/.github/workflows/test.yml#L34) and [here](https://github.com/pygobject/pycairo/issues/19#issuecomment-638716293). . Here's the [github actions script for scirpy](https://github.com/icbi-lab/scirpy/blob/master/.github/workflows/test.yml).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:229,testability,test,testing,229,"Just my 2cents: . I made really good experiences with Github actions. * I find them easy to set-up and they run many (20-40?) jobs in parallel. . * Really good integration with Github (e.g. upload to PyPI on release) . * windows testing works well, but it is a pain to setup pycairo, see [here](https://github.com/icbi-lab/scirpy/blob/725664a22e6265643633d89a7f38ea3383ccab48/.github/workflows/test.yml#L34) and [here](https://github.com/pygobject/pycairo/issues/19#issuecomment-638716293). . Here's the [github actions script for scirpy](https://github.com/icbi-lab/scirpy/blob/master/.github/workflows/test.yml).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:394,testability,test,test,394,"Just my 2cents: . I made really good experiences with Github actions. * I find them easy to set-up and they run many (20-40?) jobs in parallel. . * Really good integration with Github (e.g. upload to PyPI on release) . * windows testing works well, but it is a pain to setup pycairo, see [here](https://github.com/icbi-lab/scirpy/blob/725664a22e6265643633d89a7f38ea3383ccab48/.github/workflows/test.yml#L34) and [here](https://github.com/pygobject/pycairo/issues/19#issuecomment-638716293). . Here's the [github actions script for scirpy](https://github.com/icbi-lab/scirpy/blob/master/.github/workflows/test.yml).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:604,testability,test,test,604,"Just my 2cents: . I made really good experiences with Github actions. * I find them easy to set-up and they run many (20-40?) jobs in parallel. . * Really good integration with Github (e.g. upload to PyPI on release) . * windows testing works well, but it is a pain to setup pycairo, see [here](https://github.com/icbi-lab/scirpy/blob/725664a22e6265643633d89a7f38ea3383ccab48/.github/workflows/test.yml#L34) and [here](https://github.com/pygobject/pycairo/issues/19#issuecomment-638716293). . Here's the [github actions script for scirpy](https://github.com/icbi-lab/scirpy/blob/master/.github/workflows/test.yml).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:37,usability,experien,experiences,37,"Just my 2cents: . I made really good experiences with Github actions. * I find them easy to set-up and they run many (20-40?) jobs in parallel. . * Really good integration with Github (e.g. upload to PyPI on release) . * windows testing works well, but it is a pain to setup pycairo, see [here](https://github.com/icbi-lab/scirpy/blob/725664a22e6265643633d89a7f38ea3383ccab48/.github/workflows/test.yml#L34) and [here](https://github.com/pygobject/pycairo/issues/19#issuecomment-638716293). . Here's the [github actions script for scirpy](https://github.com/icbi-lab/scirpy/blob/master/.github/workflows/test.yml).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:384,usability,workflow,workflows,384,"Just my 2cents: . I made really good experiences with Github actions. * I find them easy to set-up and they run many (20-40?) jobs in parallel. . * Really good integration with Github (e.g. upload to PyPI on release) . * windows testing works well, but it is a pain to setup pycairo, see [here](https://github.com/icbi-lab/scirpy/blob/725664a22e6265643633d89a7f38ea3383ccab48/.github/workflows/test.yml#L34) and [here](https://github.com/pygobject/pycairo/issues/19#issuecomment-638716293). . Here's the [github actions script for scirpy](https://github.com/icbi-lab/scirpy/blob/master/.github/workflows/test.yml).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:594,usability,workflow,workflows,594,"Just my 2cents: . I made really good experiences with Github actions. * I find them easy to set-up and they run many (20-40?) jobs in parallel. . * Really good integration with Github (e.g. upload to PyPI on release) . * windows testing works well, but it is a pain to setup pycairo, see [here](https://github.com/icbi-lab/scirpy/blob/725664a22e6265643633d89a7f38ea3383ccab48/.github/workflows/test.yml#L34) and [here](https://github.com/pygobject/pycairo/issues/19#issuecomment-638716293). . Here's the [github actions script for scirpy](https://github.com/icbi-lab/scirpy/blob/master/.github/workflows/test.yml).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/pull/1359:255,availability,consist,consistent,255,"CC @flying-sheep this is an untested as I don't have a windows machine handy to trigger the platform-int-size problem. I'm also somewhat guessing at the fix! From looking at the scanpy source, I don't think that changing the `dtype` of `ns` to a platform consistent and wider `int` will do anything catastrophic to performance or alter the logic in the alg in which it's used as it seems to be a simple index. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1359
https://github.com/scverse/scanpy/pull/1359:340,deployability,log,logic,340,"CC @flying-sheep this is an untested as I don't have a windows machine handy to trigger the platform-int-size problem. I'm also somewhat guessing at the fix! From looking at the scanpy source, I don't think that changing the `dtype` of `ns` to a platform consistent and wider `int` will do anything catastrophic to performance or alter the logic in the alg in which it's used as it seems to be a simple index. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1359
https://github.com/scverse/scanpy/pull/1359:92,interoperability,platform,platform-int-size,92,"CC @flying-sheep this is an untested as I don't have a windows machine handy to trigger the platform-int-size problem. I'm also somewhat guessing at the fix! From looking at the scanpy source, I don't think that changing the `dtype` of `ns` to a platform consistent and wider `int` will do anything catastrophic to performance or alter the logic in the alg in which it's used as it seems to be a simple index. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1359
https://github.com/scverse/scanpy/pull/1359:246,interoperability,platform,platform,246,"CC @flying-sheep this is an untested as I don't have a windows machine handy to trigger the platform-int-size problem. I'm also somewhat guessing at the fix! From looking at the scanpy source, I don't think that changing the `dtype` of `ns` to a platform consistent and wider `int` will do anything catastrophic to performance or alter the logic in the alg in which it's used as it seems to be a simple index. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1359
